number,title,body,labels,assignee,created_at,closed_at,assignee_login,time_to_close_days
62052,BUG: Pandas mean function fails on type pd.NA with axis=1 but not axis=0,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df = pd.DataFrame({'a': [1.0, pd.NA, 3.0], 'b': [4.0, 5.0, pd.NA]}, dtype='Float64')
df.mean(axis=0, skipna=False) # works
df.mean(axis=1, skipna=False) # fails
```

### Issue Description

the treatment of type pd.NA is inconsistent across rows versus down columns. 

### Expected Behavior

the mean across rows should resolve to type pd.NA when at least one of the values in any column is of type pd.NA

### Installed Versions

pandas           : 1.5.3
numpy            : 1.24.4","['Bug', 'Needs Triage']",,2025-08-05 23:13:56+00:00,2025-08-05 23:16:41+00:00,,0.0019097222222222222
62049,REF: simplify mask_missing,"In the past this had to handle list-like values_to_mask but that is no longer the case, so this can be simplified a bit.  The edit in dtypes.common makes `dtype.kind in ...` checks very slightly faster.",['Refactor'],,2025-08-05 16:28:39+00:00,2025-08-05 17:19:35+00:00,,0.03537037037037037
62048,API: Series[Float64] == False,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
ser = pd.Series([0], dtype=""Float64"")
>>> ser == False
0    True
dtype: boolean
```

### Issue Description

NA

### Expected Behavior

I would expect this to be stricter in type-safety.  The lack of strictness necessitates special-casing in mask_missing (called from Block.replace).

Note that these also compare as equal for numpy float64 and float64[pyarrow]

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Needs Triage']",,2025-08-05 15:35:11+00:00,2025-08-06 02:34:49+00:00,,0.4580787037037037
62047,BUG: failing when groupby on data containing bytes,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd                                                                                                                                                                          
pd.Series(np.array([b""""])).groupby(level=0).last()
```

### Issue Description

when calling `groupby` on a frame or series containing bytes, an exception is raised:
`AttributeError: 'numpy.dtypes.BytesDType' object has no attribute 'construct_array_type'`


### Expected Behavior

Normal groupby behaviour

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.13.5
python-bits           : 64
OS                    : Linux
OS-release            : 4.18.0-425.3.1.el8.x86_64
Version               : #1 SMP Fri Sep 30 11:45:06 EDT 2022
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.1
numpy                 : 2.3.2
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.2
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Duplicate Report', 'Error Reporting', 'Constructors']",,2025-08-05 15:23:14+00:00,2025-08-06 01:51:55+00:00,,0.43658564814814815
62044,DOC: BooleanDType docstring update,"- [61939 ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [check ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-08-04 22:11:05+00:00,2025-08-04 22:15:16+00:00,,0.002905092592592593
62043,API: rank with nullable dtypes preserve NA,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['NA - MaskedArrays'],,2025-08-04 18:09:09+00:00,2025-08-04 20:43:51+00:00,,0.10743055555555556
62042,REF: Avoid/defer `dtype=object` containers in plotting,Probably best to avoid operations on containers with these types unless needed/expected,['Visualization'],,2025-08-04 17:53:54+00:00,2025-08-05 14:52:08+00:00,,0.8737731481481481
62041,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.12.2 ‚Üí v0.12.7](https://github.com/astral-sh/ruff-pre-commit/compare/v0.12.2...v0.12.7)
- [github.com/pre-commit/mirrors-clang-format: v20.1.7 ‚Üí v20.1.8](https://github.com/pre-commit/mirrors-clang-format/compare/v20.1.7...v20.1.8)
- [github.com/trim21/pre-commit-mirror-meson: v1.8.2 ‚Üí v1.8.3](https://github.com/trim21/pre-commit-mirror-meson/compare/v1.8.2...v1.8.3)
<!--pre-commit.ci end-->",['Code Style'],,2025-08-04 16:30:39+00:00,2025-08-04 20:37:22+00:00,,0.1713310185185185
62039,Bump pypa/cibuildwheel from 3.1.1 to 3.1.3,"Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 3.1.1 to 3.1.3.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/releases"">pypa/cibuildwheel's releases</a>.</em></p>
<blockquote>
<h2>v3.1.3</h2>
<ul>
<li>üêõ Fix bug where &quot;latest&quot; dependencies couldn't update to pip 25.2 on Windows (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2537"">#2537</a>)</li>
<li>üõ† Use pytest-rerunfailures to improve some of our iOS/Android tests (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2527"">#2527</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2539"">#2539</a>)</li>
<li>üõ† Remove some GraalPy Windows workarounds in our tests (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2501"">#2501</a>)</li>
</ul>
<h2>v3.1.2</h2>
<ul>
<li>‚ö†Ô∏è  Add an error if <code>CIBW_FREE_THREADING_SUPPORT</code> is set; you are likely missing 3.13t wheels, please use the <code>enable</code>/<code>CIBW_ENABLE</code> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2520"">#2520</a>)</li>
<li>üõ† <code>riscv64</code> now enabled if you target that architecture, it's now supported on PyPI (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2509"">#2509</a>)</li>
<li>üõ† Add warning when using <code>cpython-experimental-riscv64</code> (no longer needed) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2526"">#2526</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2528"">#2528</a>)</li>
<li>üõ† iOS versions bumped, fixing issues with 3.14 (now RC 1) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2530"">#2530</a>)</li>
<li>üêõ Fix bug in Android running wheel from our GitHub Action (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2517"">#2517</a>)</li>
<li>üêõ Fix warning when using <code>test-skip</code> of <code>&quot;*-macosx_universal2:arm64&quot;</code> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2522"">#2522</a>)</li>
<li>üêõ Fix incorrect number of wheels reported in logs, again (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2517"">#2517</a>)</li>
<li>üìö We welcome our Android platform maintainer (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2516"">#2516</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/blob/main/docs/changelog.md"">pypa/cibuildwheel's changelog</a>.</em></p>
<blockquote>
<h3>v3.1.3</h3>
<p><em>1 August 2025</em></p>
<ul>
<li>üêõ Fix bug where &quot;latest&quot; dependencies couldn't update to pip 25.2 on Windows (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2537"">#2537</a>)</li>
<li>üõ† Use pytest-rerunfailures to improve some of our iOS/Android tests (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2527"">#2527</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2539"">#2539</a>)</li>
<li>üõ† Remove some GraalPy Windows workarounds in our tests (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2501"">#2501</a>)</li>
</ul>
<h3>v3.1.2</h3>
<p><em>29 July 2025</em></p>
<ul>
<li>‚ö†Ô∏è  Add an error if <code>CIBW_FREE_THREADING_SUPPORT</code> is set; you are likely missing 3.13t wheels, please use the <code>enable</code>/<code>CIBW_ENABLE</code> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2520"">#2520</a>)</li>
<li>üõ† <code>riscv64</code> now enabled if you target that architecture, it's now supported on PyPI (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2509"">#2509</a>)</li>
<li>üõ† Add warning when using <code>cpython-experimental-riscv64</code> (no longer needed) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2526"">#2526</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2528"">#2528</a>)</li>
<li>üõ† iOS versions bumped, fixing issues with 3.14 (now RC 1) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2530"">#2530</a>)</li>
<li>üêõ Fix bug in Android running wheel from our GitHub Action (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2517"">#2517</a>)</li>
<li>üêõ Fix warning when using <code>test-skip</code> of <code>&quot;*-macosx_universal2:arm64&quot;</code> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2522"">#2522</a>)</li>
<li>üêõ Fix incorrect number of wheels reported in logs, again (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2517"">#2517</a>)</li>
<li>üìö We welcome our Android platform maintainer (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2516"">#2516</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/352e01339f0a173aa2a3eb57f01492e341e83865""><code>352e013</code></a> Bump version: v3.1.3</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/c463e56ba22f7f7e6c8871b006a06384c08cff34""><code>c463e56</code></a> tests: another iOS flaky spot (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2539"">#2539</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/8c5c738023fee8aad6412105b42ea798066b1438""><code>8c5c738</code></a> docs(project): add Falcon to working examples (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2538"">#2538</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/feeb3992a7ea36ffbc9d4446debea40f9aa24861""><code>feeb399</code></a> tests: add flaky test handling (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2527"">#2527</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/60b9cc95db51f9f5e48562fcb1b3f7ac3f9cb4a1""><code>60b9cc9</code></a> fix: never call pip directly (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2537"">#2537</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/e2c7102ed7981cd79d28a5eb0a196f8242b1adab""><code>e2c7102</code></a> chore: remove some GraalPy Windows workarounds. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2501"">#2501</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/9e4e50bd76b3190f55304387e333f6234823ea9b""><code>9e4e50b</code></a> Bump version: v3.1.2</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/8ef9414f60b366420233447f0abd96586ed394c7""><code>8ef9414</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2532"">#2532</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/1953c0497215dcf2711e1fbfd3ae8952e8ad604c""><code>1953c04</code></a> Adding <a href=""https://github.com/mhsmith""><code>@‚Äãmhsmith</code></a> as platform maintainer for Android (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2516"">#2516</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/46a6d279953e2947496fa28a22ded264f4027a5f""><code>46a6d27</code></a> Bump iOS support package versions. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2530"">#2530</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/cibuildwheel/compare/v3.1.1...v3.1.3"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/cibuildwheel&package-manager=github_actions&previous-version=3.1.1&new-version=3.1.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","['CI', 'Dependencies']",,2025-08-04 11:15:30+00:00,2025-08-04 16:32:52+00:00,,0.22039351851851852
62038,API: improve dtype in df.where with EA other,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Improves the patch-job done by #38742.  Also makes the affected test robust to always-distinguish NAN-vs-NA behavior.","['Dtype Conversions', 'Error Reporting']",,2025-08-03 21:08:57+00:00,2025-08-05 01:40:28+00:00,,1.1885532407407406
62037," ""BUG: Fix repeated rolling mean assignment causing all-NaN values""","## Fix repeated rolling mean assignment causing all-NaN values

- Closes #<issue_number> (if there‚Äôs an issue, otherwise leave this out)
- This PR fixes a regression where assigning the result of `.rolling().mean()` to a DataFrame column more than once caused all values in the column to become NaN (see pandas-dev/pandas#61841).
- The bug was due to pandas reusing memory blocks when overwriting an existing column with a rolling result Series, leading to incorrect block alignment.
- The fix is to make a defensive `.copy()` of the Series when overwriting an existing column, ensuring correct assignment.

### Example

```python
df = pd.DataFrame({""A"": range(30)})
df[""SMA""] = df[""A""].rolling(20).mean()
df[""SMA""] = df[""A""].rolling(20).mean()
print(df[""SMA""].notna().sum())  # should be > 0, not all NaN
```

### Tests

- Added a regression test in `pandas/tests/window/test_rolling.py`.
- All tests pass locally.

---

Thanks for your consideration!",[],,2025-08-03 17:44:44+00:00,2025-08-03 18:32:09+00:00,,0.032928240740740744
62034,Ignore this,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-08-03 13:42:03+00:00,2025-08-03 14:39:35+00:00,,0.03995370370370371
62032,EHN: return early when the result is None,There's no need to continue the loop when the result is destined to be None.,['Index'],,2025-08-03 09:13:48+00:00,2025-08-04 16:48:22+00:00,,1.3156712962962962
62028,TST: Speed up hypothesis and slow tests,"* Hypothesis tests seems to be the slowest running tests in CI. Limiting the `max_examples` IMO is OK as we're looking to exercise some edge cases
* Avoiding some work being done in `test_*number_of_levels_larger_than_int32` as we're just looking to check a warning",['Testing'],,2025-08-02 20:49:14+00:00,2025-08-03 16:45:53+00:00,,0.8310069444444445
62027,BUG: Fix DataFrame reduction to preserve NaN vs <NA> in mixed dtypes (GH#62024),"(GH#62024)

This PR fixes a bug in  (DataFrame._reduce) where reductions on (DataFrames) with mixed dtypes (e.g., float64 and nullable integer Int64) would incorrectly upcast all results to use pd.NA and the Float64 dtype if any column was a pandas extension type.

Please let me know if my approach or fix needs any improvements . I‚Äôm open to feedback and happy to make changes based on suggestions.
Thankyou!

",[],,2025-08-02 17:49:23+00:00,2025-08-02 22:34:45+00:00,,0.1981712962962963
62026,BUG: groupby.idxmin/idxmax with all NA values should raise,"- [x] closes #57745
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Groupby', 'API - Consistency', 'Reduction Operations']",,2025-08-02 17:47:07+00:00,2025-08-05 18:55:42+00:00,,3.047627314814815
62025,BUG: Change default of observed in Series.groupby,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Fix for #57330. In all tests where `observed` makes a difference, we explicitly specify `observed` so this wasn't noticed. The deprecation itself was properly done (saying that we were changing the default to True), it was only the enforcement of the deprecation that had a mistake.","['Bug', 'Groupby', 'Categorical']",,2025-08-02 17:44:40+00:00,2025-08-02 20:52:25+00:00,,0.13038194444444445
62021,TST: nan->NA in non-construction tests,Significantly trim the diff for PR(s) implementing always-distinguish behavior.,"['Testing', 'Missing-data']",,2025-08-02 00:45:44+00:00,2025-08-04 16:52:42+00:00,,2.6715046296296294
62019,REF: make copy keyword in recode_for_categories keyword only,"Follows up to https://github.com/pandas-dev/pandas/pull/62000

`recode_for_categories` had a default `copy=True` to copy the passed codes if the codes didn't need re-coding. This PR makes this argument keyword only to make it explicit if the caller wants to copy - to avoid unnecessary copying when blindly using `recode_for_categories`",['Categorical'],,2025-08-01 17:36:37+00:00,2025-08-04 21:19:49+00:00,,3.155
62015,DOC: Add SSLCertVerificationError warning message for documentation b‚Ä¶,"‚Ä¶uild fail

- [ ] closes #61975
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

`pre-commit run --files doc/source/development/contributing_documentation.rst` PASSED locally
",['Docs'],,2025-07-31 22:04:18+00:00,2025-08-05 16:05:54+00:00,,4.751111111111111
62012,BUG: Raise TypeError for invalid calendar types in CustomBusinessDay (#60647),"- Closes #60647

### Bug Description
Previously, if an invalid `calendar` argument was passed to `CustomBusinessDay` (e.g., a `pandas_market_calendars` object), it was silently ignored. This resulted in potentially incorrect behavior without warning, which could lead to confusion and incorrect results.

### What This Fix Does
- Adds a strict type check in `offsets.pyx` to ensure the `calendar` parameter is either a `numpy.busdaycalendar` or `AbstractHolidayCalendar`.
- If the type is invalid, a `TypeError` is raised with a clear error message.
- This aligns with expected behavior and helps prevent incorrect usage.

### Tests Added
- ‚úÖ New unit test `test_invalid_calendar_raises_typeerror` added to `test_custom_business_day.py` to assert that an invalid calendar raises a `TypeError`.
- ‚úÖ Existing test `test_calendar` was updated to construct a valid `np.busdaycalendar` from `USFederalHolidayCalendar` dates.
- ‚úÖ All 8 tests in this module now pass successfully.

### Why This Matters
Silently ignoring invalid input is dangerous and can introduce subtle bugs. This fix ensures strict input validation and protects downstream consumers from incorrect assumptions.

### Checklist
- [x] Bug fix added and tested
- [x] New test added for reproducibility
- [x] All existing + new tests pass locally via `pytest`
- [x] Clear commit message: `""BUG: Raise TypeError for invalid calendar types in CustomBusinessDay (#60647)""`
- [x] pandas test structure followed
",[],,2025-07-31 13:11:29+00:00,2025-07-31 15:54:54+00:00,,0.11348379629629629
62010,"DOC: Series and DataFrame.reindex accepts Timedelta as tolerance, which is not documented","### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.reindex.html
- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html

### Documentation problem

The following code snippet works:
```py
import pandas as pd

sr = pd.Series([1, 2], pd.to_datetime([""2023-01-01"", ""2023-01-02""]))
sr.reindex(index=pd.to_datetime([""2023-01-02"", ""2023-01-03""]), method=""ffill"", tolerance=pd.Timedelta(""1D""))

df = sr.to_frame()
df.reindex(index=pd.to_datetime([""2023-01-02"", ""2023-01-03""]), method=""ffill"", tolerance=pd.Timedelta(""1D""))
```
but in the documentation, `tolerance` being `Timedelta` is undefined.

### Suggested fix for documentation

Append `Timedelta` in the documentation for `tolerance`.","['Docs', 'Needs Triage']",,2025-07-31 09:23:06+00:00,2025-08-05 07:47:38+00:00,,4.933703703703704
62006,BUG: Implement elementwise IntervalArray.overlaps (#62004),"This PR : Fixes #62004: IntervalArray.overlaps now supports IntervalArray and IntervalIndex inputs .

Please let me know if there are any improvements.  I can make to my approach or fix. I‚Äôm happy to incorporate any feedback or suggestions you may have.

Thankyou !",[],,2025-07-30 23:46:44+00:00,2025-07-31 11:16:57+00:00,,0.47931712962962963
62003,Fix for issue 62001; ENH: Context-aware error messages for optional dependencies,"#62001

Summary

  This PR enhances import_optional_dependency() to provide context-aware error messages that suggest relevant alternatives when       
  dependencies are missing, addressing issue #62001.

  Before:
  Missing optional dependency 'openpyxl'. Use pip or conda to install openpyxl.

  After:
  Missing optional dependency 'openpyxl'. For Excel file operations, try installing xlsxwriter, calamine, xlrd, pyxlsb, or odfpy.     
   Use pip or conda to install openpyxl.

  Implementation Details

  - Core Enhancement: Added operation_context parameter to import_optional_dependency() with 13 predefined contexts (excel,
  plotting, html, xml, sql, performance, compression, cloud, formats, computation, timezone, testing, development)
  - Smart Alternative Filtering: Excludes the failed dependency from suggestions to avoid confusion
  - Backward Compatibility: All existing calls work unchanged; new parameter is optional
  - Strategic Implementation: Updated high-impact locations where users commonly encounter missing dependencies:
    - Excel operations (5 readers: openpyxl, xlrd, calamine, pyxlsb, odf)
    - Plotting operations (matplotlib)
    - HTML parsing operations (html5lib)

  Files Modified

  1. pandas/compat/_optional.py: Core enhancement with context mapping and message building
  2. pandas/tests/test_optional_dependency.py: Updated test patterns and added comprehensive context tests
  3. pandas/io/excel/_*.py: Added context to 5 Excel readers
  4. pandas/plotting/_core.py: Added plotting context
  5. pandas/io/html.py: Added HTML parsing context
  6. doc/source/whatsnew/v3.0.0.rst: Added whatsnew entry

  Testing

  - All existing tests pass with updated patterns
  - New tests verify context functionality works correctly
  - Manual verification confirms all files compile successfully
  - Backward compatibility maintained for existing calls

- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Please make sure to double check I am still new to contributions and let me know if there are any mistakes.",[],,2025-07-30 19:18:29+00:00,2025-07-30 20:49:11+00:00,,0.06298611111111112
62002,DOC: Simplify footer text in pandas documentation,"This PR simplifies the documentation footer template for clarity.
(Note: This is unrelated to issue #60647, which is about CustomBusinessDay.)

",[],,2025-07-30 15:17:42+00:00,2025-07-30 15:50:08+00:00,,0.02252314814814815
62000,BUG: Avoid copying categorical codes if `copy=False`,"Categorical codes are always copied by `recode_for_categories` regardless of the copy argument. This fixes it by passing the copy argument down to `recode_for_categories`

- ~[ ] closes #xxxx (Replace xxxx with the GitHub issue number)~
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Categorical'],,2025-07-30 11:24:54+00:00,2025-08-01 16:58:40+00:00,,2.2317824074074073
61999,Maddie doc simplify footer theme,"Not using _template, all in conf.py",[],,2025-07-30 01:42:49+00:00,2025-07-30 01:43:15+00:00,,0.00030092592592592595
61997,DOC: add button to edit on GitHub,"- [x] closes #39859 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Changes made:
- Added an extension that allows to have a sidebar with extra ""Show on GitHub"" and ""Edit on GitHub"" links. Found [here](https://mg.pov.lt/blog/sphinx-edit-on-github.html).
- Modified conf.py to make sure the extension is added and links direct to editable pages.",[],,2025-07-29 21:57:48+00:00,2025-07-29 23:59:40+00:00,,0.08462962962962962
61996,TST: Raise on `pytest.PytestWarning`,Just to make the pytest warning summary a bit shorter,['Testing'],,2025-07-29 18:08:43+00:00,2025-07-30 16:08:44+00:00,,0.9166782407407408
61995,BUG/DEPR: logical operation with bool and string,"- [x] closes #60234 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Numeric Operations', 'Strings', 'Still Needs Manual Backport']",,2025-07-29 17:55:19+00:00,2025-07-29 20:52:04+00:00,,0.12274305555555555
61994,PERF: `pandas.DataFrame.stack` with `future_stack=True`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this issue exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this issue exists on the main branch of pandas.


### Reproducible Example

```
import numpy as np
df = pd.DataFrame(np.random.randn(100, 100))
%timeit df.stack(future_stack=False)
%timeit df.stack(future_stack=True)
```

```
242 Œºs ¬± 40.4 Œºs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
25.6 ms ¬± 4.75 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
```

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.11.13
python-bits           : 64
OS                    : Linux
OS-release            : 4.18.0-553.36.1.el8_10.x86_64
Version               : #1 SMP Wed Jan 22 03:07:54 EST 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.1
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : 9.4.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : 1.5.0
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.7.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.3
numba                 : 0.61.2
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : 8.4.1
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.7.0
scipy                 : 1.14.1
sqlalchemy            : 2.0.41
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>


### Prior Performance

_No response_","['Performance', 'Needs Triage']",,2025-07-29 15:20:05+00:00,2025-07-29 16:43:23+00:00,,0.057847222222222223
61993,BUG: Inconsistent `datetime` dtype based on how the dataframe gets initialized,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
(Pdb) pd.DataFrame({""0"": [datetime.fromtimestamp(1568888888, tz=pytz.utc)]}).dtypes
0    datetime64[ns, UTC]
dtype: object
(Pdb) pd.DataFrame({""0"": datetime.fromtimestamp(1568888888, tz=pytz.utc)}, index=[0]).dtypes
0    datetime64[us, UTC]
dtype: object
(Pdb)
```

### Issue Description

When creating a Pandas DataFrame with a timezone-aware datetime object (e.g., datetime.datetime with tzinfo=pytz.UTC), the inferred datetime64 precision differs depending on whether the datetime is passed as a scalar or inside a list. This leads to inconsistent and potentially unexpected behavior

### Expected Behavior

Both DataFrame initializations should infer the same datetime dtype (datetime64[ns, UTC]), ideally following Pandas‚Äô default precision of nanoseconds.

### Installed Versions

<details>

>>> pd.show_versions()

INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.13.5
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-47-generic
Version               : #47-Ubuntu SMP PREEMPT_DYNAMIC Fri Sep 27 22:03:50 UTC 2024
machine               : aarch64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.3.1
numpy                 : 2.3.2
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : 8.2.3
IPython               : 9.4.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : 21.0.0
pyreadstat            : None
pytest                : 8.4.1
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.16.0
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
>>> 

</details>
","['Bug', 'Datetime', 'Needs Info']",,2025-07-29 14:24:21+00:00,2025-07-31 15:04:51+00:00,,2.028125
61991,"BUG: Python Package fails to load for some users, but not others.","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
# Code
import pandas as pd

df = pd.DataFrame({""Name"":[""Braund""]})
```

### Issue Description

# Venv
The venv is owned by root:root with 755 permissions.
Pandas version 2.3.1 (but also happens with 2.2.3)

# Command
/opt/.venv/bin/python /home/user.name/python_scripts/sketches.py

# Traceback Message 
Traceback (most recent call last):
  File ""/home/user.name/python_scripts/sketches.py"", line 7, in <module>
    df = pandas.DataFrame(
AttributeError: module 'pandas' has no attribute 'DataFrame'

Note: In fact, regardless of the method used, it seems to always output the same error message. I have used <user.name> to work with other packages in the same environment without any problem. However, if I use root user, then all the scripts I've tried with pandas work as expected.

### Expected Behavior

No error message, and creation of a data frame.

### Installed Versions


 -> Replace this line with the output of pd.show_versions()

Using root privileges, 

INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.10.12
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.0-142-generic
Version               : #152-Ubuntu SMP Mon May 19 10:54:31 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8
 
pandas                : 2.3.1
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 22.0.2
Cython                : None
sphinx                : 8.1.3
IPython               : 8.35.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.2
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.2
matplotlib            : 3.10.1
numba                 : 0.61.2
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.13.1
sqlalchemy            : 2.0.40
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None","['Bug', 'Needs Info']",,2025-07-29 08:57:34+00:00,2025-07-30 08:19:21+00:00,,0.9734606481481481
61989,ENH: Add engine='polars' support in read_csv,"### üöÄ Enhancement: Add `engine='polars'` Support in `read_csv`

#### üîß Summary of Changes

This PR introduces support for using **[[Polars](https://pola-rs.github.io/polars/py-polars/html/reference/api/pl.read_csv.html)](https://pola-rs.github.io/polars/py-polars/html/reference/api/pl.read_csv.html)** as a backend CSV parsing engine in `pandas.read_csv`, providing faster parsing capabilities for large files.

The following changes are included:

* ‚úÖ **Added support for** `engine=""polars""` in `pandas.read_csv`
* ‚úÖ **Dynamically imported** Polars and handled `ImportError` gracefully
* ‚úÖ **Filtered** `read_csv()` kwargs to only allow those compatible with Polars
* ‚úÖ **Converted** `Path` input to string (Polars does not accept path-like objects in all versions)
* ‚úÖ **Added test case** `test_read_csv_with_polars` under `tests/io/parser`
* ‚úÖ **Updated version** to `2.3.3.dev0` in `__init__.py` and `pyproject.toml` (as part of the development build)
* ‚úÖ **Resolved all `ruff` linter errors and pre-commit hook failures** (e.g., B904, E501, F841, SC1017)
* ‚úÖ **Formatted shell scripts** using `dos2unix` to fix line-ending issues across:

  * `ci/code_checks.sh`
  * `ci/run_tests.sh`
  * `scripts/cibw_before_build.sh`
  * `scripts/download_wheels.sh`
  * `scripts/upload_wheels.sh`
  * `gitpod/workspace_config`

---

#### üìÜ Usage Example

```python
import pandas as pd

df = pd.read_csv(""sample.csv"", engine=""polars"")
print(df)
```

##### ‚úÖ Expected Output:

```
   a  b
0  1  2
1  3  4
```

---

#### üí° Why This Matters

Polars is a high-performance DataFrame library designed for speed and multi-threaded performance. Adding it as a supported backend:

* Provides **significant performance boosts** for CSV reading
* Enhances **flexibility** for end-users to choose engines (like `c`, `python`, or `polars`)
* Keeps Pandas future-ready with **optional modular parsing backends**

---

#### ‚úÖ Tests & Quality Checks

* üî™ Unit test added: `test_read_csv_with_polars`
* ‚úÖ Passed: All pytest tests
* ‚úÖ Passed: All pre-commit hooks
* ‚úÖ Passed: `ruff`, `shellcheck`, `cython-lint`, `codespell`, etc.
* ‚Ü∫ Converted scripts to LF line endings using `dos2unix` for consistent CI/CD compatibility

---

#### üß† Notes

* `polars` is treated as an **optional dependency**
* If not installed, Pandas will raise a clear error:
  *‚ÄúPolars is not installed. Please install it with 'pip install polars'.‚Äù*

---

#### üôå Acknowledgements

Thanks to the maintainers for reviewing this contribution!
Looking forward to feedback or further improvements.

",[],,2025-07-29 04:49:16+00:00,2025-07-29 05:10:40+00:00,,0.014861111111111111
61988,[ENH] Add `polars` Engine Support to `pd.read_csv()`,"### üöÄ Pull Request: [ENH] Add `polars` Engine Support to `pd.read_csv()`

---

### ‚ùì Problem Statement

Pandas' `read_csv()` function supports multiple engines like ""c"", ""python"", and ""pyarrow"" for reading CSV files. However, there is **no built-in support for the high-performance [Polars](https://pola-rs.github.io/polars-book/) engine**, which is known for its speed and efficiency in parsing large datasets.

‚úÖ **Community Request**: Feature proposed in [Issue #61813](https://github.com/pandas-dev/pandas/issues/61813)

---

### üõ†Ô∏è Solution & What‚Äôs Included

This PR implements optional support for `engine=""polars""` in `pandas.read_csv()` by:

1. **Modifying `readers.py`**:
   - Checks if engine is ""polars"".
   - Dynamically imports Polars and uses `pl.read_csv(...).to_pandas()` to return a pandas DataFrame.

   ```python
   if kwds.get(""engine"") == ""polars"":
       try:
           import polars as pl  # type: ignore[import-untyped]
       except ImportError:
           raise ImportError(""Polars is not installed. Please install it with 'pip install polars'."")
       df = pl.read_csv(filepath_or_buffer, **kwds).to_pandas()
       return df
   ```

2. **Ensuring compatibility in engine validation**:
   ```python
   if engine not in (""c"", ""python"", ""pyarrow"", ""polars""):
       raise ValueError(f""Unknown engine: {engine}"")
   ```

3. **Version Updates**:
   - Updated version to `2.3.3.dev0` in:
     - `__init__.py`
     - `pyproject.toml`

4. **Testing**:
   - Added a dedicated test: `pandas/tests/io/parser/test_read_csv_polars.py`

---

### üí° Example Usage

```python
import pandas as pd

df = pd.read_csv(""sample.csv"", engine=""polars"")
print(df)
```

**Input file: `sample.csv`**

```
a,b
1,2
3,4
```

---

### üéØ Expected Output

```
   a  b
0  1  2
1  3  4
```

- The file is parsed using Polars under the hood and returned as a `pandas.DataFrame`.
- Performance benefits without changing the Pandas API.
- Optional: only active if `polars` is installed.

---

### üìÇ Files Modified

- `pandas/io/parsers/readers.py` ‚Üí Add polars engine logic
- `pandas/__init__.py` ‚Üí Version bump to `2.3.3.dev0`
- `pyproject.toml` ‚Üí Version update
- `pandas/tests/io/parser/test_read_csv_polars.py` ‚Üí New test file added

---

### üß™ Tests

**Test name**: `test_read_csv_with_polars`

```python
def test_read_csv_with_polars(tmp_path):
    pl = pytest.importorskip(""polars"")
    pd = pytest.importorskip(""pandas"")

    file = tmp_path / ""sample.csv""
    file.write_text(""a,b\n1,2\n3,4"")

    df = pd.read_csv(file, engine=""polars"")

    assert df.equals(pd.DataFrame({""a"": [1, 3], ""b"": [2, 4]}))
```

‚úÖ Result: **Passed with warning** (unrelated deprecation from pyarrow)

---

### üß∑ Notes

- Falls back to error if Polars is not installed.
- This is a non-breaking enhancement and does not affect existing functionality.
- Future expansion possible to support write or more Polars features.

---

üîÅ Feedback welcome!
",[],,2025-07-29 03:14:05+00:00,2025-07-29 03:43:50+00:00,,0.02065972222222222
61986,DOC: Improve docstrings in utility functions in pandas/core/common.py (lines 176‚Äì210),"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

pandas/core/common.py (lines 176‚Äì210)


### Documentation problem

Several internal utility functionshave unclear or missing docstrings.

- `not_none` returns a generator, unlike others nearby which return booleans (not documented).
- Functions like `any_not_none`, `all_none`, and `any_none` lack parameter descriptions, return types
- `any_not_none` duplicates the logic of `any_none` but does not explain the inversion 


### Suggested fix for documentation

To imrpove the docstrings for the following utility functions in `pandas/core/common.py`:

- Add return type clarification to `not_none` to explain that it returns a generator, unlike others in the section.
- For `any_not_none`, `all_none`, and similar functions, add full docstring structure with:
  - Parameters section
  - Returns section  np
- Optional: refactor duplicated logic between `any_not_none` and `any_none`.
",['Docs'],,2025-07-29 00:36:13+00:00,2025-07-29 01:33:53+00:00,,0.040046296296296295
61984,MNT: simplify `cibuildwheel` configuration,"follow up to https://github.com/pandas-dev/pandas/pull/61981#discussion_r2237723118
This reduce the maintenance burden for `cibuildwheel` config parameters:
- cibw takes `project.requires-python` into account for target selection, so there is no need for explicitly excluding unsupported versions
- using `test-extras` instead of `test-requires` avoids a repetition and keeps `project.optional-dependencies` as the one source of truth in this area

- [N/A] closes #xxxx (Replace xxxx with the GitHub issue number)
- [N/A] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [N/A] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [N/A] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Build'],,2025-07-28 20:18:54+00:00,2025-07-28 22:06:12+00:00,,0.0745138888888889
61983,ENH: Add Polars engine to read_csv (#61813),"### What does this PR do?

This PR adds support for `engine=""polars""` in the `pandas.read_csv()` function. It enables users to leverage the performance of the [Polars](https://www.pola.rs/) DataFrame engine when reading CSV files in pandas.

---

### Why is this needed?

This enhancement addresses issue #61813. Since Polars is a high-performance DataFrame library with fast CSV parsing, adding it as an engine allows pandas users to benefit from its speed while staying within the pandas API.

---

### What changes were made?

#### ‚úÖ Added Polars Support in `_read()` Function
- Included a conditional block inside the `_read()` function in `pandas/io/parsers/readers.py` to handle `engine=""polars""`
- This helps pandas use `polars.read_csv()` under the hood and convert the result to a pandas DataFrame using `.to_pandas()`

#### ‚úÖ Updated Engine Validation
- Modified `_refine_defaults_read()` to accept `""polars""` as a valid engine
- This ensures pandas doesn‚Äôt raise a ValueError when `engine=""polars""` is passed

#### ‚úÖ Created a New Test File
- Created `test_read_csv_polars.py` inside `pandas/tests/io/parser/`
- The test verifies that using `engine=""polars""` in `read_csv()` loads a simple CSV correctly
- Ensures code coverage and prevents future regressions

---

### How to use it?

```python
import pandas as pd

# Requires Polars to be installed
# pip install polars

df = pd.read_csv(""example.csv"", engine=""polars"")
print(df.head())
```

This allows pandas users to benefit from Polars' speed and memory efficiency while still using the familiar pandas API.

---

### Dependencies

Requires the user to have Polars installed:
```bash
pip install polars
```

If `polars` is not installed, the engine will raise an `ImportError` with instructions.

---

### Related Issues

Closes #61813

---

Let me know if any additional tests or validations are needed.
",[],,2025-07-28 18:04:56+00:00,2025-07-28 18:30:06+00:00,,0.01747685185185185
61982,BUG: Fix boolean column indexing for DataFrame (#61980),"(#61980)

This Pr fixes:
Boolean column names in DataFrame indexing are now correctly treated as column labels, not boolean masks, unless the key is a valid mask for row selection.

Please let me know if my approach or fix needs any improvements . I‚Äôm open to feedback and happy to make changes based on suggestions.",[],,2025-07-28 14:29:12+00:00,2025-07-28 19:24:11+00:00,,0.20484953703703704
61981,Bump pypa/cibuildwheel from 2.23.3 to 3.1.1,"Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 2.23.3 to 3.1.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/releases"">pypa/cibuildwheel's releases</a>.</em></p>
<blockquote>
<h2>v3.1.1</h2>
<ul>
<li>üêõ Fix a bug showing an incorrect wheel count at the end of execution, and misrepresenting test-only runs in the GitHub Action summary (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2512"">#2512</a>)</li>
<li>üìö Docs fix (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2510"">#2510</a>)</li>
</ul>
<h2>v3.1.0</h2>
<ul>
<li>üåü CPython 3.14 wheels are now built by default - without the <code>&quot;cpython-prerelease&quot;</code> <code>enable</code> set. It's time to build and upload these wheels to PyPI! This release includes CPython 3.14.0rc1, which is guaranteed to be ABI compatible with the final release. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2507"">#2507</a>) Free-threading is no longer experimental in 3.14, so you have to skip it explicitly with <code>'cp31?t-*'</code> if you don't support it yet. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2503"">#2503</a>)</li>
<li>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#android"">build wheels for Android</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>android</code> on Linux or macOS to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2349"">#2349</a>)</li>
<li>üåü Adds Pyodide 0.28, which builds 3.13 wheels (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2487"">#2487</a>)</li>
<li>‚ú® Support for 32-bit <code>manylinux_2_28</code> (now a consistent default) and <code>manylinux_2_34</code> added (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2500"">#2500</a>)</li>
<li>üõ† Improved summary, will also use markdown summary output on GHA (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2469"">#2469</a>)</li>
<li>üõ† The riscv64 images now have a working default (as they are now part of pypy/manylinux), but are still experimental (and behind an <code>enable</code>) since you can't push them to PyPI yet (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2506"">#2506</a>)</li>
<li>üõ† Fixed a typo in the 3.9 MUSL riscv64 identifier (<code>cp39-musllinux_ricv64</code> -&gt; <code>cp39-musllinux_riscv64</code>) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2490"">#2490</a>)</li>
<li>üõ† Mistyping <code>--only</code> now shows the correct possibilities, and even suggests near matches on Python 3.14+ (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2499"">#2499</a>)</li>
<li>üõ† Only support one output from the repair step on linux like other platforms; auditwheel fixed this over four years ago! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2478"">#2478</a>)</li>
<li>üõ† We now use pattern matching extensively (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2434"">#2434</a>)</li>
<li>üìö We now have platform maintainers for our special platforms and interpreters! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2481"">#2481</a>)</li>
</ul>
<h2>v3.0.1</h2>
<ul>
<li>üõ† Updates CPython 3.14 prerelease to 3.14.0b3 (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2471"">#2471</a>)</li>
<li>‚ú® Adds a CPython 3.14 prerelease iOS build (only when prerelease builds are <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enabled</a>) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2475"">#2475</a>)</li>
</ul>
<h2>v3.0.0</h2>
<p>See <a href=""https://github.com/henryiii""><code>@‚Äãhenryiii</code></a>'s <a href=""https://iscinumpy.dev/post/cibuildwheel-3-0-0/"">release post</a> for more info on new features!</p>
<ul>
<li>
<p>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#ios"">build wheels for iOS</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>ios</code> on a Mac with the iOS toolchain to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2286"">#2286</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2363"">#2363</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2432"">#2432</a>)</p>
</li>
<li>
<p>üåü Adds support for the GraalPy interpreter! Enable for your project using the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1538"">#1538</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2411"">#2411</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2414"">#2414</a>)</p>
</li>
<li>
<p>‚ú® Adds CPython 3.14 support, under the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> <code>cpython-prerelease</code>. This version of cibuildwheel uses 3.14.0b2. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
<p><em>While CPython is in beta, the ABI can change, so your wheels might not be compatible with the final release. For this reason, we don't recommend distributing wheels until RC1, at which point 3.14 will be available in cibuildwheel without the flag.</em> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-sources"">test-sources option</a>, and changes the working directory for tests. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2062"">#2062</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2284"">#2284</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2437"">#2437</a>)</p>
<ul>
<li>If this option is set, cibuildwheel will copy the files and folders specified in <code>test-sources</code> into the temporary directory we run from. This is required for iOS builds, but also useful for other platforms, as it allows you to avoid placeholders.</li>
<li>If this option is not set, behaviour matches v2.x - cibuildwheel will run the tests from a temporary directory, and you can use the <code>{project}</code> placeholder in the <code>test-command</code> to refer to the project directory. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2420"">#2420</a>)</li>
</ul>
</li>
<li>
<p>‚ú® Adds <a href=""https://cibuildwheel.pypa.io/en/stable/options/#dependency-versions""><code>dependency-versions</code></a> inline syntax (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2122"">#2122</a>)</p>
</li>
<li>
<p>‚ú® Improves support for Pyodide builds and adds the experimental <a href=""https://cibuildwheel.pypa.io/en/stable/options/#pyodide-version""><code>pyodide-version</code></a> option, which allows you to specify the version of Pyodide to use for builds. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2002"">#2002</a>)</p>
</li>
<li>
<p>‚ú® Add <code>pyodide-prerelease</code> <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enable</a> option, with an early build of 0.28 (Python 3.13). (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2431"">#2431</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-environment""><code>test-environment</code></a> option, which allows you to set environment variables for the test command. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2388"">#2388</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#xbuild-tools""><code>xbuild-tools</code></a> option, which allows you to specify tools safe for cross-compilation. Currently only used on iOS; will be useful for Android in the future. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2317"">#2317</a>)</p>
</li>
<li>
<p>üõ† The default <a href=""https://cibuildwheel.pypa.io/en/stable/options/#linux-image"">manylinux image</a> has changed from <code>manylinux2014</code> to <code>manylinux_2_28</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2330"">#2330</a>)</p>
</li>
<li>
<p>üõ† EOL images <code>manylinux1</code>, <code>manylinux2010</code>, <code>manylinux_2_24</code> and <code>musllinux_1_1</code> can no longer be specified by their shortname. The full OCI name can still be used for these images, if you wish. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2316"">#2316</a>)</p>
</li>
<li>
<p>üõ† Invokes <code>build</code> rather than <code>pip wheel</code> to build wheels by default. You can control this via the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#build-frontend""><code>build-frontend</code></a> option. You might notice that you can see your build log output now! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2321"">#2321</a>)</p>
</li>
<li>
<p>üõ† Build verbosity settings have been reworked to have consistent meanings between build backends when non-zero. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2339"">#2339</a>)</p>
</li>
<li>
<p>üõ† Removed the <code>CIBW_PRERELEASE_PYTHONS</code> and <code>CIBW_FREE_THREADED_SUPPORT</code> options - these have been folded into the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code></a> option instead. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>üõ† Build environments no longer have setuptools and wheel preinstalled. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2329"">#2329</a>)</p>
</li>
<li>
<p>üõ† Use the standard Schema line for the integrated JSONSchema. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2433"">#2433</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped support for building Python 3.6 and 3.7 wheels. If you need to build wheels for these versions, use cibuildwheel v2.23.3 or earlier. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2282"">#2282</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è The minimum Python version required to run cibuildwheel is now Python 3.11. You can still build wheels for Python 3.8 and newer. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1912"">#1912</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è 32-bit Linux wheels no longer built by default - the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#archs"">arch</a> was removed from <code>&quot;auto&quot;</code>. It now requires explicit <code>&quot;auto32&quot;</code>. Note that modern manylinux images (like the new default, <code>manylinux_2_28</code>) do not have 32-bit versions. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2458"">#2458</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è PyPy wheels no longer built by default, due to a change to our options system. To continue building PyPy wheels, you'll now need to set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> to <code>pypy</code> or <code>pypy-eol</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/blob/main/docs/changelog.md"">pypa/cibuildwheel's changelog</a>.</em></p>
<blockquote>
<h3>v3.1.1</h3>
<p><em>24 July 2025</em></p>
<ul>
<li>üêõ Fix a bug showing an incorrect wheel count at the end of execution, and misrepresenting test-only runs in the GitHub Action summary (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2512"">#2512</a>)</li>
<li>üìö Docs fix (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2510"">#2510</a>)</li>
</ul>
<h3>v3.1.0</h3>
<p><em>23 July 2025</em></p>
<ul>
<li>üåü CPython 3.14 wheels are now built by default - without the <code>&quot;cpython-prerelease&quot;</code> <code>enable</code> set. It's time to build and upload these wheels to PyPI! This release includes CPython 3.14.0rc1, which is guaranteed to be ABI compatible with the final release. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2507"">#2507</a>) Free-threading is no longer experimental in 3.14, so you have to skip it explicitly with <code>'cp31?t-*'</code> if you don't support it yet. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2503"">#2503</a>)</li>
<li>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#android"">build wheels for Android</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>android</code> on Linux or macOS to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2349"">#2349</a>)</li>
<li>üåü Adds Pyodide 0.28, which builds 3.13 wheels (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2487"">#2487</a>)</li>
<li>‚ú® Support for 32-bit <code>manylinux_2_28</code> (now a consistent default) and <code>manylinux_2_34</code> added (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2500"">#2500</a>)</li>
<li>üõ† Improved summary, will also use markdown summary output on GHA (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2469"">#2469</a>)</li>
<li>üõ† The riscv64 images now have a working default (as they are now part of pypy/manylinux), but are still experimental (and behind an <code>enable</code>) since you can't push them to PyPI yet (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2506"">#2506</a>)</li>
<li>üõ† Fixed a typo in the 3.9 MUSL riscv64 identifier (<code>cp39-musllinux_ricv64</code> -&gt; <code>cp39-musllinux_riscv64</code>) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2490"">#2490</a>)</li>
<li>üõ† Mistyping <code>--only</code> now shows the correct possibilities, and even suggests near matches on Python 3.14+ (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2499"">#2499</a>)</li>
<li>üõ† Only support one output from the repair step on linux like other platforms; auditwheel fixed this over four years ago! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2478"">#2478</a>)</li>
<li>üõ† We now use pattern matching extensively (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2434"">#2434</a>)</li>
<li>üìö We now have platform maintainers for our special platforms and interpreters! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2481"">#2481</a>)</li>
</ul>
<h3>v3.0.1</h3>
<p><em>5 July 2025</em></p>
<ul>
<li>üõ† Updates CPython 3.14 prerelease to 3.14.0b3 (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2471"">#2471</a>)</li>
<li>‚ú® Adds a CPython 3.14 prerelease iOS build (only when prerelease builds are <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enabled</a>) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2475"">#2475</a>)</li>
</ul>
<h3>v3.0.0</h3>
<p><em>11 June 2025</em></p>
<p>See <a href=""https://github.com/henryiii""><code>@‚Äãhenryiii</code></a>'s <a href=""https://iscinumpy.dev/post/cibuildwheel-3-0-0/"">release post</a> for more info on new features!</p>
<ul>
<li>
<p>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#ios"">build wheels for iOS</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>ios</code> on a Mac with the iOS toolchain to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2286"">#2286</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2363"">#2363</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2432"">#2432</a>)</p>
</li>
<li>
<p>üåü Adds support for the GraalPy interpreter! Enable for your project using the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1538"">#1538</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2411"">#2411</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2414"">#2414</a>)</p>
</li>
<li>
<p>‚ú® Adds CPython 3.14 support, under the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> <code>cpython-prerelease</code>. This version of cibuildwheel uses 3.14.0b2. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
<p><em>While CPython is in beta, the ABI can change, so your wheels might not be compatible with the final release. For this reason, we don't recommend distributing wheels until RC1, at which point 3.14 will be available in cibuildwheel without the flag.</em> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-sources"">test-sources option</a>, which copies files and folders into the temporary working directory we run tests from. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2062"">#2062</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2284"">#2284</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2420"">#2420</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2437"">#2437</a>)</p>
<p>This is particularly important for iOS builds, which do not support placeholders in the <code>test-command</code>, but can also be useful for other platforms.</p>
</li>
<li>
<p>‚ú® Adds <a href=""https://cibuildwheel.pypa.io/en/stable/options/#dependency-versions""><code>dependency-versions</code></a> inline syntax (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2122"">#2122</a>)</p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/e6de07ed3921b51089aae6981989889cf1eddd0c""><code>e6de07e</code></a> Bump version: v3.1.1</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/2ca692b1e55a1f924bfb460099c9d7e015671a8d""><code>2ca692b</code></a> docs: iOS typo fix in docs (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2510"">#2510</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/1ac7fa7f004958fbde774ee89523c446a5d99934""><code>1ac7fa7</code></a> fix: report defects in logs and HTML summaries (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2512"">#2512</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/ffd835cef18fa11522f608fc0fa973b89f5ddc87""><code>ffd835c</code></a> Bump version: v3.1.0</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/3e2a9aa6e85824999f897fc2c060ca12a5113ef6""><code>3e2a9aa</code></a> fix: regenerate schema</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/10c727eed9fc962f75d33d472272e3ad78c3e707""><code>10c727e</code></a> feat: Python 3.14rc1 build by default (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2507"">#2507</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/f628c9dd23fe6e263cb91cef755a51a0af3bcddc""><code>f628c9d</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2505"">#2505</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/0f487ee2cb00876d95290da49d04208c91237857""><code>0f487ee</code></a> feat: add support for building Android wheels (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2349"">#2349</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/e2e24882d8422e974295b1b9079d4ce80a5098a4""><code>e2e2488</code></a> feat: add default riscv64 images (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2506"">#2506</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/a8bff94dbb5f3a4a914e29cf8353c2f6f1b9ab8b""><code>a8bff94</code></a> [Bot] Update dependencies (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2504"">#2504</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/cibuildwheel/compare/v2.23.3...v3.1.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/cibuildwheel&package-manager=github_actions&previous-version=2.23.3&new-version=3.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","['Build', 'CI', 'Dependencies']",,2025-07-28 12:59:24+00:00,2025-07-28 19:58:11+00:00,,0.29082175925925924
61979,DOC: Update documentation for using natural sort with `sort_values`,"The previous documentation recommended to use the lambda function `lambda x: np.argsort(index_natsorted(x))` as a key argument to `sort_values`. However, while this works when sorting on a single column, it causes incorrect sorting when sorting multiple columns with duplicated values. For example:
```
>>> df = pd.DataFrame(
...     {
...         ""hours"": [""0hr"", ""128hr"", ""0hr"", ""64hr"", ""64hr"", ""128hr""],
...         ""mins"": [""10mins"", ""40mins"", ""40mins"", ""40mins"", ""10mins"", ""10mins""],
...         ""value"": [10, 20, 30, 40, 50, 60],
...     }
... )
>>> df
   hours    mins  value
0    0hr  10mins     10
1  128hr  40mins     20
2    0hr  40mins     30
3   64hr  40mins     40
4   64hr  10mins     50
5  128hr  10mins     60
>>> from natsort import index_natsorted
>>> df.sort_values(
...     by=[""hours"", ""mins""],
...     key=lambda x: np.argsort(index_natsorted(x)),
... )
   hours    mins  value
0    0hr  10mins     10
2    0hr  40mins     30
3   64hr  40mins     40
4   64hr  10mins     50
1  128hr  40mins     20
5  128hr  10mins     60
```
Note how the `hours` column is sorted correctly, but the `mins` column isn't.

This PR updates the documentation to use `natsort_keygen`, which is robust to sorting on multiple columns.

Commit 2: Removes the calls to `natsort_keygen()` in the example code as the output generated was too long and doctest didn't seem to like having the tuple formatted.",['Docs'],,2025-07-28 09:32:19+00:00,2025-07-28 16:11:24+00:00,,0.2771412037037037
61977,BUG:  Fix infer_dtype result for complex with pd.NA,"- [x] closes #61976
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Fix a bug in `api.types.infer_dtype` returning ""mixed"" for complex and ``pd.NA`` mix.",['Dtype Conversions'],,2025-07-27 20:28:09+00:00,2025-07-28 16:13:41+00:00,,0.823287037037037
61976,"BUG: infer_dtype returns ""mixed"" for complex and pd.NA mix","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np
from pandas.api.types import infer_dtype

print(infer_dtype([1 + 1j, np.nan]))
# complex
print(infer_dtype([1 + 1j, pd.NA]))
# mixed
```

### Issue Description

`infer_dtype` on complex arrays with NA does not produce consistent results.
Similar to #61621, which has been fixed for the case of float type. I will submit a PR.

### Expected Behavior

Should return `complex`.

### Installed Versions

<details>


INSTALLED VERSIONS
------------------
commit                : 49ca01ba9023b677f2b2d1c42e99f45595258b74
python                : 3.10.16
python-bits           : 64
OS                    : Linux
OS-release            : 5.10.16.3-microsoft-standard-WSL2
Version               : #1 SMP Fri Apr 2 22:23:49 UTC 2021
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+1580.g68d9dcab5b.dirty
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : 3.0.11
sphinx                : 8.1.3
IPython               : 8.31.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2024.12.0
html5lib              : 1.1
hypothesis            : 6.124.7
gcsfs                 : 2024.12.0
jinja2                : 3.1.5
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : 0.60.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.9
pymysql               : 1.4.6
pyarrow               : 19.0.0
pyiceberg             : None
pyreadstat            : 1.2.8
pytest                : 8.3.4
python-calamine       : None
pytz                  : 2024.2
pyxlsb                : 1.0.10
s3fs                  : 2024.12.0
scipy                 : 1.15.1
sqlalchemy            : 2.0.37
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : 0.23.0
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Missing-data', 'Dtype Conversions']",,2025-07-27 20:14:57+00:00,2025-07-28 16:13:42+00:00,,0.8324652777777778
61975,BUG: 'Sphinx parallel build error' when building docs locally prevents index.html creation,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
python make.py html
```

### Issue Description

The following error prevents doc/build/html/index.html from getting created. Here are the steps to reproduce.

1. Pulled down from upstream/original Pandas
2. Created an environment using Option 2 (pip) from https://pandas.pydata.org/docs/dev/development/contributing_environment.html
3. Followed steps for building the documentation locally from https://pandas.pydata.org/docs/dev/development/contributing_documentation.html 
4. After running python make.py html, received a 'Sphinx parallel build error', 'Runtime unexpected exception' error in file `/doc/source/getting_started/comparison/comparison_with_sas.rst` line 135`

Screenshot of error

<img width=""2100"" height=""1500"" alt=""Image"" src=""https://github.com/user-attachments/assets/6ad9a45c-b4c5-47b5-aef2-f64917f01f44"" />

Machine:
2020 Macbook Pro 1.4 GHz Quad-Core Intel Core i5

### Expected Behavior

I expected the docs to be built and for doc/build/html/index.html to be created.

### Installed Versions

<details>

pandas 3.0.0.dev0+2267.ge4a03b6e47

INSTALLED VERSIONS
------------------
commit                : e4a03b6e47a8ef9cd045902916289cbc976d3d33
python                : 3.12.0
python-bits           : 64
OS                    : Darwin
OS-release            : 23.1.0
Version               : Darwin Kernel Version 23.1.0: Mon Oct  9 21:27:27 PDT 2023; root:xnu-10002.41.9~6/RELEASE_X86_64
machine               : x86_64
processor             : i386
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+2267.ge4a03b6e47
numpy                 : 2.2.6
dateutil              : 2.9.0.post0
pip                   : 23.2.1
Cython                : 3.1.2
sphinx                : 8.1.3
IPython               : 9.4.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
bottleneck            : 1.5.0
fastparquet           : 2024.11.0
fsspec                : 2025.7.0
html5lib              : 1.1
hypothesis            : 6.136.4
gcsfs                 : 2025.7.0
jinja2                : 3.1.6
lxml.etree            : 6.0.0
matplotlib            : 3.10.3
numba                 : 0.61.2
numexpr               : 2.11.0
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 21.0.0
pyiceberg             : 0.9.1
pyreadstat            : 1.3.0
pytest                : 8.4.1
python-calamine       : None
pytz                  : 2025.2
pyxlsb                : 1.0.10
s3fs                  : 2025.7.0
scipy                 : 1.16.0
sqlalchemy            : 2.0.41
tables                : 3.10.2
tabulate              : 0.9.0
xarray                : 2025.7.1
xlrd                  : 2.0.2
xlsxwriter            : 3.2.5
zstandard             : 0.23.0
qtpy                  : None
pyqt5                 : None

</details>
","['Docs', 'Needs Info', 'Closing Candidate']","{'login': 'jeffersbaxter', 'id': 14068353, 'node_id': 'MDQ6VXNlcjE0MDY4MzUz', 'avatar_url': 'https://avatars.githubusercontent.com/u/14068353?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/jeffersbaxter', 'html_url': 'https://github.com/jeffersbaxter', 'followers_url': 'https://api.github.com/users/jeffersbaxter/followers', 'following_url': 'https://api.github.com/users/jeffersbaxter/following{/other_user}', 'gists_url': 'https://api.github.com/users/jeffersbaxter/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/jeffersbaxter/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/jeffersbaxter/subscriptions', 'organizations_url': 'https://api.github.com/users/jeffersbaxter/orgs', 'repos_url': 'https://api.github.com/users/jeffersbaxter/repos', 'events_url': 'https://api.github.com/users/jeffersbaxter/events{/privacy}', 'received_events_url': 'https://api.github.com/users/jeffersbaxter/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-07-27 18:12:58+00:00,2025-08-05 16:05:55+00:00,jeffersbaxter,8.911770833333334
61974,"ENH: Include line number and number of fields when read_csv() callable with `engine=""python""` raises ParserWarning","- [X] closes #61838  
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

## Description of the change
`read_csv()` currently provides the description of an invalid row(expected_columns, actual_columns, number, text) when the row has too many elements where `engine=""pyarrow""`, but the callable can only include the contents of the row when `engine=""python""`.

(For more details on pyarrow.csv.InvalidRow, see [pyarrow documentation](https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html#pyarrow.csv.ParseOptions.invalid_row_handler))

This PR proposes to additionally pass `expected_columns`, `actual_columns` and `row` when `on_bad_lines` is a callable and `engine=""python""`, so that users can desribe the invalid row more in detail.

The order of the arguments has been aligned with `pyarrow`.",[],,2025-07-27 14:38:41+00:00,2025-07-28 16:21:26+00:00,,1.0713541666666666
61972,BUG: Series.replace with CoW when made from an Index,"- [x] closes #61622 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

When we create a Series from an Index, it's zero copy which means that with CoW there are weak refs to the Index. Comparison of these weak refs uses `Index.__eq__`, which operates on the array (unlike `Block.__eq__` which is merely `is`). This leads to failure in `Series.replace`.

Instead, we replace the equality checks with `is`, plus some additional logic for performance. I believe this is the only place where we are using `__eq__` on these references.","['Bug', 'replace', 'Copy / view semantics']",,2025-07-27 12:05:10+00:00,2025-07-28 16:24:07+00:00,,1.179826388888889
61971,contributing codebase is revised,"- Issue: #61968
- DOC: code coverage app provided in documentation is invalid #61968
Open
- [https://github.com/pandas-dev/pandas/blob/main/doc/source/development/contributing_codebase.rst](https://github.com/pandas-dev/pandas/blob/main/doc/source/development/contributing_codebase.rst)
",[],,2025-07-27 10:05:29+00:00,2025-07-27 17:40:46+00:00,,0.3161689814814815
61970,DOC: rephrase CoW ChainedAssignmentError message now CoW is always enabled,"The ""When using the Copy-on-Write mode"" can be updated now it is no longer a mode that is enabled opt-in, but the only behaviour.",['Docs'],,2025-07-27 08:47:36+00:00,2025-07-30 16:34:33+00:00,,3.3242708333333333
61968,DOC: code coverage app provided in documentation is invalid,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/development/contributing_codebase.html

### Documentation problem

The link to the pandas-coverage-app links to an empty page on heroku.

### Suggested fix for documentation

Either fix the doc to not mention the documentation coverage tool, rework the tool to be within the code base, or update the heroku link to contain the tool",['Docs'],,2025-07-26 20:18:56+00:00,2025-07-27 15:44:53+00:00,,0.8096875
61966,[backport 2.3.x] Output formatting: preserve quoting for string categories (#61891),Backport of #61891,[],,2025-07-26 19:13:47+00:00,2025-07-26 20:25:06+00:00,,0.049525462962962966
61965,[backport 2.3.x] BUG: fix to_json() with JSON Table Schema work correctly with string dtype (#61900),"
Backport of https://github.com/pandas-dev/pandas/pull/61900",[],,2025-07-26 14:15:09+00:00,2025-07-26 17:14:47+00:00,,0.12474537037037037
61961,Backport PR #61921 on branch 2.3.x (DOC: explicitly mention new str dtype is no longer a numpy dtype in migration guide),Backport PR #61921: DOC: explicitly mention new str dtype is no longer a numpy dtype in migration guide,['Docs'],,2025-07-26 09:19:28+00:00,2025-07-26 11:33:33+00:00,,0.09311342592592593
61960,DOC: update .str.contains/match/startswith docstring examples for default  behaviour,"Updating the docstrings of `.str.` predicate methods that have the `na` keyword. 

For the examples, the current text is no longer correct (because the default behaviour with str dtype is now to already return False). 
For now I just removed those examples. I could instead update the example to create an object-dtype Series to still show the `na` behaviour, but personally I feel that would make the docstring examples more complex than needed, and that it is fine to let they focus on just the default dtype. But no strong opinion ;)","['Docs', 'Strings']",,2025-07-26 09:04:32+00:00,2025-07-28 16:50:49+00:00,,2.3238078703703704
61959,Backport PR #61958 on branch 2.3.x (DOC: Add release notes template for 2.3.2),Backport PR #61958: DOC: Add release notes template for 2.3.2,['Docs'],,2025-07-26 08:53:23+00:00,2025-07-26 09:27:37+00:00,,0.023773148148148147
61958,DOC: Add release notes template for 2.3.2,"For the case we do another 2.3.x release, this makes it easier to already backport things (and if we end up not doing another release, we can just move the items later)

And going to merge this quickly, to unblock other PRs",['Docs'],,2025-07-26 08:19:40+00:00,2025-07-26 08:52:55+00:00,,0.02309027777777778
61957,Flattened footer,"Flattened the footer with pandas custom footer, sphinx-version, and theme-version in single line as shown
<img width=""1433"" height=""71"" alt=""Screenshot 2025-07-26 at 15 51 18"" src=""https://github.com/user-attachments/assets/f45acd94-dd78-44e9-b026-20191153a9e8"" />
",['Docs'],,2025-07-26 06:06:18+00:00,2025-08-02 03:09:15+00:00,,6.877048611111111
61954,docs: Improve README with helpful contributor resources,"Added a small section to the end of the README that provides useful resources for new contributors, including:

- Official Pandas cheat sheet
- Beginner tutorials
- ‚ÄúGood first issues‚Äù link
- Slack community link

This addition aims to encourage and guide new contributors without altering any of the existing README content.

Let me know if this fits the community guidelines ‚Äî happy to adjust!",[],,2025-07-25 18:00:22+00:00,2025-07-25 19:10:18+00:00,,0.04856481481481482
61953,docs: Improve README with helpful contributor resources,"Added a small section to the end of the README that provides useful resources for new contributors, including:

- Official Pandas cheat sheet
- Beginner tutorials
- ‚ÄúGood first issues‚Äù link
- Slack community link

This addition aims to encourage and guide new contributors without altering any of the existing README content.

Let me know if this fits the community guidelines ‚Äî happy to adjust!",[],,2025-07-25 17:54:00+00:00,2025-07-25 17:55:48+00:00,,0.00125
61948,BUG: Replacement fails after NA value with PyArrow-backed strings,"This does not occur on the main branch, only 2.3.x. I plan to run a git-bisect later today.

```python
pd.set_option(""infer_string"", True)
ser = pd.Series([""a"", np.nan, ""a"", ""a""])
print(ser.replace({""a"": ""b""}))
# 0      b
# 1    NaN
# 2      a
# 3      b
# dtype: str
```","['Bug', 'replace', 'Arrow']",,2025-07-25 14:28:33+00:00,2025-07-25 18:17:20+00:00,,0.15887731481481482
61947,CI: enable doctest errors again + fixup categorical examples,"Updating the categorical docstring examples after https://github.com/pandas-dev/pandas/pull/61891

This now closes https://github.com/pandas-dev/pandas/issues/61886 and enables the doctests again","['Docs', 'CI', 'Strings']",,2025-07-25 13:46:35+00:00,2025-07-26 17:14:21+00:00,,1.1442824074074074
61945,BUG: Fix Series.str.contains with compiled regex on Arrow strings (#61942),"#61942

This PR improves the handling of this case:
If the compiled regex has no flags, we extract the pattern string and proceed.
If the regex includes flags, a clear NotImplementedError is raised with guidance.
This avoids a confusing low-level PyArrow TypeError and ensures consistent behavior with non-Arrow strings.

Please , suggest feedback if my approach is not correct . I would love to improve and fix this.",[],,2025-07-25 10:32:26+00:00,2025-07-25 10:35:39+00:00,,0.0022337962962962962
61936,Issue #14601 fix - pytables.py put() and append() docstring fix,"**Problem Summary**

The current documentation for `min_itemsize` in HDFStore methods is unclear about:

1. How string length is calculated (bytes vs characters)
2. How encoding affects the required size
3. Proper usage with multi-byte characters

Proposed Changes

1. Enhanced `put()` method docstring

```python
def put(
    self,
    key: str,
    value: DataFrame | Series,
    format=None,
    index: bool = True,
    append: bool = False,
    complib=None,
    complevel: int | None = None,
    min_itemsize: int | dict[str, int] | None = None,
    nan_rep=None,
    data_columns: Literal[True] | list[str] | None = None,
    encoding=None,
    errors: str = ""strict"",
    track_times: bool = True,
    dropna: bool = False,
) -> None:
    """"""
    Store object in HDFStore.

    Parameters
    ----------
    key : str
    value : {Series, DataFrame}
    format : 'fixed(f)|table(t)', default is 'fixed'
        Format to use when storing object in HDFStore. Value can be one of:

        ``'fixed'``
            Fixed format.  Fast writing/reading. Not-appendable, nor searchable.
        ``'table'``
            Table format.  Write as a PyTables Table structure which may perform
            worse but allow more flexible operations like searching / selecting
            subsets of the data.
    index : bool, default True
        Write DataFrame index as a column.
    append : bool, default False
        This will force Table format, append the input data to the existing.
    min_itemsize : int, dict of str: int, or None, default None
        Minimum size in bytes for string columns. This parameter is only used when
        format='table'. Can be:
        
        - int: Apply the same minimum size to all string columns
        - dict: Map column names to their minimum sizes
        - None: Use default sizing
        
        **Important**: The size refers to the number of bytes after encoding, not
        the number of characters. For multi-byte characters (e.g., Chinese, Arabic),
        you need to account for the encoding. For example, the character 'È¶ô' is
        1 character but 3 bytes when encoded as UTF-8.
        
        See examples below for proper usage with encoded strings.
    data_columns : list of columns or True, default None
        List of columns to create as data columns, or True to use all columns.
        See `here
        <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#query-via-data-columns>`__.
    encoding : str, default None
        Provide an encoding for strings. When using multi-byte characters,
        this affects how min_itemsize should be calculated.
    track_times : bool, default True
        Parameter is propagated to 'create_table' method of 'PyTables'.
        If set to False it enables to have the same h5 files (same hashes)
        independent on creation time.
    dropna : bool, default False, optional
        Remove missing values.

    Examples
    --------
    Basic usage with ASCII strings:
    
    >>> df = pd.DataFrame([['hello', 'world']], columns=['A', 'B'])
    >>> store = pd.HDFStore(""store.h5"", 'w')  # doctest: +SKIP
    >>> store.put('data', df, format='table', min_itemsize={'A': 10, 'B': 10})  # doctest: +SKIP
    
    Usage with multi-byte characters:
    
    >>> df_unicode = pd.DataFrame([['È¶ôÊ∏Ø', 'Âåó‰∫¨']], columns=['city1', 'city2'])  # doctest: +SKIP
    >>> # Each Chinese character is 3 bytes in UTF-8, so 'È¶ôÊ∏Ø' needs 6 bytes
    >>> store.put('cities', df_unicode, format='table',  # doctest: +SKIP
    ...           min_itemsize={'city1': 12, 'city2': 12}, encoding='utf-8')  # doctest: +SKIP
    
    Determining the correct size for encoded strings:
    
    >>> text = 'È¶ôÊ∏Ø'  # doctest: +SKIP
    >>> len(text)  # Character length  # doctest: +SKIP
    2
    >>> len(text.encode('utf-8'))  # Byte length  # doctest: +SKIP
    6
    >>> # Use the byte length for min_itemsize
    """"""
```

2. Enhanced `append()` method docstring

```python
def append(
    self,
    key: str,
    value: DataFrame | Series,
    format=None,
    axes=None,
    index: bool | list[str] = True,
    append: bool = True,
    complib=None,
    complevel: int | None = None,
    columns=None,
    min_itemsize: int | dict[str, int] | None = None,
    nan_rep=None,
    chunksize: int | None = None,
    expectedrows=None,
    dropna: bool | None = None,
    data_columns: Literal[True] | list[str] | None = None,
    encoding=None,
    errors: str = ""strict"",
) -> None:
    """"""
    Append to Table in file.

    Node must already exist and be Table format.

    Parameters
    ----------
    key : str
    value : {Series, DataFrame}
    format : 'table' is the default
        Format to use when storing object in HDFStore.  Value can be one of:

        ``'table'``
            Table format. Write as a PyTables Table structure which may perform
            worse but allow more flexible operations like searching / selecting
            subsets of the data.
    index : bool, default True
        Write DataFrame index as a column.
    append : bool, default True
        Append the input data to the existing.
    data_columns : list of columns, or True, default None
        List of columns to create as indexed data columns for on-disk
        queries, or True to use all columns. By default only the axes
        of the object are indexed. See `here
        <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#query-via-data-columns>`__.
    min_itemsize : int, dict of str: int, or None, default None
        Minimum size in bytes for string columns. Can be:
        
        - int: Apply the same minimum size to all string columns
        - dict: Map column names to their minimum sizes  
        - None: Use the existing table's column sizes
        
        **Important**: This parameter is only effective when creating a new table.
        If the table already exists, the column sizes are fixed and cannot be
        changed. The size refers to the number of bytes after encoding, not
        the number of characters.
        
        For multi-byte characters, calculate the size using the encoded byte length.
        For example: len('È¶ô'.encode('utf-8')) returns 3, not len('È¶ô') which returns 1.
    nan_rep : str to use as str nan representation
    chunksize : size to chunk the writing
    expectedrows : expected TOTAL row size of this table
    encoding : str, default None
        Provide an encoding for strings. This should match the encoding used
        when the table was initially created.
    dropna : bool, default False, optional
        Do not write an ALL nan row to the store settable
        by the option 'io.hdf.dropna_table'.

    Notes
    -----
    Does *not* check if data being appended overlaps with existing
    data in the table, so be careful.
    
    When appending to an existing table, the min_itemsize parameter has no effect
    as column sizes are already fixed. Set min_itemsize when initially creating
    the table with put() or the first append() call.

    Examples
    --------
    Creating a table and appending data:
    
    >>> df1 = pd.DataFrame([['short', 'text']], columns=['A', 'B'])
    >>> store = pd.HDFStore(""store.h5"", 'w')  # doctest: +SKIP
    >>> # Set min_itemsize when creating the table
    >>> store.put('data', df1, format='table', min_itemsize={'A': 20, 'B': 20})  # doctest: +SKIP
    >>> 
    >>> df2 = pd.DataFrame([['longer text here', 'more text']], columns=['A', 'B'])
    >>> store.append('data', df2)  # doctest: +SKIP
    >>> store.close()  # doctest: +SKIP
    
    Handling multi-byte characters:
    
    >>> df_en = pd.DataFrame([['hello']], columns=['text'])
    >>> df_zh = pd.DataFrame([['‰Ω†Â•Ω‰∏ñÁïå']], columns=['text'])  # ""Hello World"" in Chinese
    >>> store = pd.HDFStore(""store.h5"", 'w')  # doctest: +SKIP
    >>> # Calculate size needed: len('‰Ω†Â•Ω‰∏ñÁïå'.encode('utf-8')) = 12 bytes
    >>> store.put('messages', df_en, format='table', 
    ...           min_itemsize={'text': 15}, encoding='utf-8')  # doctest: +SKIP
    >>> store.append('messages', df_zh)  # doctest: +SKIP
    >>> store.close()  # doctest: +SKIP
    
    Common error when min_itemsize is too small:
    
    >>> df = pd.DataFrame([['È¶ô']], columns=['char'])  # 3 bytes in UTF-8
    >>> store = pd.HDFStore(""store.h5"", 'w')  # doctest: +SKIP
    >>> # This will raise ValueError: string length [3] exceeds limit [1]
    >>> # store.put('test', df, format='table', min_itemsize={'char': 1})
    >>> # Correct usage:
    >>> store.put('test', df, format='table', min_itemsize={'char': 3})  # doctest: +SKIP
    >>> store.close()  # doctest: +SKIP
    """"""
```

Key Improvements Made

1. **Clear parameter type documentation**: Explicitly state that min_itemsize can be int, dict, or None
2. **Byte vs character clarification**: Emphasize that size refers to bytes after encoding
3. **Multi-byte character examples**: Show real examples with Chinese characters
4. **Encoding relationship**: Explain how encoding affects size calculations
5. **Timing clarification**: Explain when min_itemsize is effective vs ignored
6. **Error prevention**: Show common mistakes and how to avoid them
7. **Practical examples**: Include realistic use cases that users encounter

**Notes**
I'm a new contributor, I followed the [contribution guide](https://pandas.pydata.org/docs/dev/development/contributing.html#submitting-a-pull-request) and it looks like in that process other modifications were made to the pytables.py file. As far as manual changes go, what I noted above are the only changes I implemented. 
",[],,2025-07-24 20:08:56+00:00,2025-07-25 16:01:32+00:00,,0.8281944444444445
61934,Backport PR #61933 on branch 2.3.x (unpin scipy since statsmodels was fixed),Backport of #61933,['Dependencies'],,2025-07-24 17:29:41+00:00,2025-07-24 20:02:20+00:00,,0.10600694444444445
61933,unpin scipy since statsmodels was fixed,"In #61750 and #61754 @jorisvandenbossche pinned scipy due to a `statsmodels` issue.  That has apparently been fixed, so this unpins the upper bound on scipy.

",['Dependencies'],,2025-07-24 15:22:34+00:00,2025-07-24 16:14:39+00:00,,0.03616898148148148
61932,"BUG: Unexpected Code Segment Executed, Causing Logical Error","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# Á§∫‰æãÊï∞ÊçÆ
df = pd.DataFrame({
    'product_code': ['X', 'X', 'X', 'Y', 'Y'],
    'units': ['P', 'P', 'Q', 'Q', 'Q']
})

df2 = df.head(2)
df2 = df2.sort_values('product_code', ascending=False)\
            .groupby(['product_code',
                      'unit_name'])\
            .first().reset_index(drop=True)
print(df2)
```

### Issue Description

When there are only 2 lines of data in df, this code will run successfully, even if the fields do not exist. We have not found this situation in other rows so far

### Expected Behavior

It exists in version 2.2.2 of pandas„ÄÇ

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Groupby']",,2025-07-24 09:04:20+00:00,2025-07-24 20:04:05+00:00,,0.45815972222222223
61931,DOC: Add tzdata to README dependencies list,"- [x] closes #61927
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Added tzdata to the list of dependencies in the README in order to match official documentation.
",['Docs'],,2025-07-24 04:23:43+00:00,2025-07-25 16:37:24+00:00,,1.5095023148148148
61927,DOC: Add tzdata to dependencies section in README,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

[https://github.com/pandas-dev/pandas/blob/main/README.md](https://github.com/pandas-dev/pandas/blob/main/README.md)

### Documentation problem

tzdata is listed as a required dependency in the [installation documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#dependencies), but is not listed with the other required dependencies in the README.

### Suggested fix for documentation

Add tzdata to the list of dependencies in the README so that the README matches the most current and accurate documentation. I intend to work on this issue.",['Docs'],"{'login': 'n-dett', 'id': 124851780, 'node_id': 'U_kgDOB3EWRA', 'avatar_url': 'https://avatars.githubusercontent.com/u/124851780?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/n-dett', 'html_url': 'https://github.com/n-dett', 'followers_url': 'https://api.github.com/users/n-dett/followers', 'following_url': 'https://api.github.com/users/n-dett/following{/other_user}', 'gists_url': 'https://api.github.com/users/n-dett/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/n-dett/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/n-dett/subscriptions', 'organizations_url': 'https://api.github.com/users/n-dett/orgs', 'repos_url': 'https://api.github.com/users/n-dett/repos', 'events_url': 'https://api.github.com/users/n-dett/events{/privacy}', 'received_events_url': 'https://api.github.com/users/n-dett/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-07-23 03:11:10+00:00,2025-07-25 16:37:25+00:00,n-dett,2.5598958333333335
61924,BUG: Add min/max methods to ArrowExtensionArray GH#61311,"- [X] closes #61311 
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

The core problem is that when using .iloc with PyArrow-backed DataFrames, pandas' indexing validation calls min() and max() methods on the ArrowExtensionArray for bounds checking, but these methods were not implemented, resulting in AttributeError: 'ArrowExtensionArray' object has no attribute 'max'. This breaks basic indexing functionality that works with regular pandas DataFrames, creating an inconsistency in the PyArrow backend experience.

Proposed Solution - 
My proposed solution addresses the issue by modifying _validate_key in pandas/core/indexing.py to detect ExtensionArrays and convert them to numpy arrays using to_numpy() or np.asarray(). Included a test case in the file pandas/tests/indexing/test_iloc.py that reproduces the issue to verify the implementation.","['Bug', 'Indexing', 'Arrow']",,2025-07-22 20:52:12+00:00,2025-08-05 17:21:47+00:00,,13.853877314814815
61923,fix: list numbering in roadmap.md,"- [x] closes #60913 
",[],,2025-07-22 11:52:06+00:00,2025-07-22 16:28:28+00:00,,0.19192129629629628
61922,"BUG: `date_range` gives different output ends for fixed `end` and varying `start` when `freq=""B""`","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import datetime as dt

import pandas as pd

end = dt.datetime(2025, 7, 26, 6)  # Saturday early morning
for d in range(18, 22):  # Friday, Saturday, Sunday & Monday
    start = dt.datetime(2025, 7, d, 10)
    print(f""start={start}: {pd.date_range(start, end, freq=""B"")}\n"")
```

### Issue Description

Running `date_range` with varying `start` and fixed `end` gives outputs differing final entries when `freq=""B""`. Specifically, in the above example, the first and last iteration are missing an entry for `2025-07-25 10:00:00`.

### Expected Behavior

The last three iterations in the above code should produce the same output, and the first iteration should differ from the other three only in that it additionally includes `2025-07-18 10:00:00` as a first entry. Instead the output is the following:

```
start=2025-07-18 10:00:00: DatetimeIndex(['2025-07-18 10:00:00', '2025-07-21 10:00:00',
               '2025-07-22 10:00:00', '2025-07-23 10:00:00',
               '2025-07-24 10:00:00'],
              dtype='datetime64[ns]', freq='B')

start=2025-07-19 10:00:00: DatetimeIndex(['2025-07-21 10:00:00', '2025-07-22 10:00:00',
               '2025-07-23 10:00:00', '2025-07-24 10:00:00',
               '2025-07-25 10:00:00'],
              dtype='datetime64[ns]', freq='B')

start=2025-07-20 10:00:00: DatetimeIndex(['2025-07-21 10:00:00', '2025-07-22 10:00:00',
               '2025-07-23 10:00:00', '2025-07-24 10:00:00',
               '2025-07-25 10:00:00'],
              dtype='datetime64[ns]', freq='B')

start=2025-07-21 10:00:00: DatetimeIndex(['2025-07-21 10:00:00', '2025-07-22 10:00:00',
               '2025-07-23 10:00:00', '2025-07-24 10:00:00'],
              dtype='datetime64[ns]', freq='B')
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.9
python-bits           : 64
OS                    : Linux
OS-release            : 4.18.0-553.36.1.el8_10.x86_64
Version               : #1 SMP Wed Jan 22 03:07:54 EST 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.1.3
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 9.1.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.2
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.2
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : None
pyarrow               : 17.0.0
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.3.2
scipy                 : 1.15.2
sqlalchemy            : 2.0.40
tables                : 3.10.2
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Datetime']",,2025-07-22 10:30:51+00:00,2025-07-22 20:27:57+00:00,,0.41465277777777776
61921,DOC: explicitly mention new str dtype is no longer a numpy dtype in migration guide,"Triggered by https://github.com/pandas-dev/pandas/issues/61915, making it more explicit that the dtype is no longer a np.dtype object.",['Docs'],,2025-07-22 07:28:09+00:00,2025-07-26 09:19:22+00:00,,4.077233796296296
61919,"Update v3.0.0.rst to use Month XX, 2025 instead of 2024","2024 is over and pandas v3 hasn't happened yet, so update year to 2025",['Docs'],,2025-07-21 22:12:06+00:00,2025-07-22 02:14:12+00:00,,0.168125
61918,QST: Global future flag,"### Research

- [x] I have searched the [[pandas] tag](https://stackoverflow.com/questions/tagged/pandas) on StackOverflow for similar questions.

- [x] I have asked my usage related question on [StackOverflow](https://stackoverflow.com).


### Link to question on StackOverflow

N/A

### Question about pandas

I remember talking about it during the last contributor meeting, but have unfortunately forgotten the specifics. 

I know there is currently a 'future_stack' flag for future features to be activated in the future for the stack function. During the discussion, there was a consensus to use a global flag instead of function-specific variables to implement new functionalities to existing functions that would warrant a deprecation warning first. 

Is that implemented yet? I can't seem to find anything currently in the code but could've sworn we talked about one existing.",['Usage Question'],,2025-07-21 20:55:32+00:00,2025-07-21 21:27:25+00:00,,0.022141203703703705
61915,BUG: Cannot interpret string dtype as a valid data type,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np

df = pd.DataFrame([[1,2], [3,4]], columns=[""first"", ""second""])

np.dtype(df.columns.dtype)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[10], line 1
----> 1 np.dtype(df.columns.dtype)

TypeError: Cannot interpret '<StringDtype(storage='python', na_value=nan)>' as a data type
```

### Issue Description

Hi, this issue was caught in scikit-learn's CI (for instance [here](https://dev.azure.com/scikit-learn/scikit-learn/_build/results?buildId=78378&view=logs&jobId=dfe99b15-50db-5d7b-b1e9-4105c42527cf&j=dfe99b15-50db-5d7b-b1e9-4105c42527cf&t=ef785ae2-496b-5b02-9f0e-07a6c3ab3081)) a couple of days ago and only involves the dev version of pandas. It looks like there was a recent change in pandas string dtypes that make them not recognized as numpy dtypes.

ping @jorisvandenbossche, I saw that you merged several PRs about pandas strings last week :)

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 930c8a479d3e4644cb71de34770271f49f4862ff
python                : 3.13.5
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-60-generic
Version               : #63~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr 22 19:00:15 UTC 2
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : fr_FR.UTF-8
LOCALE                : fr_FR.UTF-8

pandas                : 3.0.0.dev0+2249.g930c8a479d
numpy                 : 2.3.1
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : 3.1.2
sphinx                : None
IPython               : 9.4.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
bottleneck            : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyiceberg             : None
pyreadstat            : None
pytest                : 8.4.1
python-calamine       : None
pytz                  : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.16.0
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
qtpy                  : None
pyqt5                 : None


</details>
",['Strings'],,2025-07-21 08:31:47+00:00,2025-07-26 09:20:33+00:00,,5.03386574074074
61913,CI: properly enable the string dtype also for custom CI builds,"Small follow-up on https://github.com/pandas-dev/pandas/pull/61722, where I forgot to set the default of the env variable to 1 if not specified in the matrix (I included it in the main matrix, but then all custom builds that were explicitly listed in the `include: ` section of the matrix would not have the variable, and therefore still default to turn off the string dtype)","['CI', 'Strings']",,2025-07-20 10:57:02+00:00,2025-07-21 16:34:21+00:00,,1.2342476851851851
61911,DOC: fix doctests for datetimelike.py files for the new string dtype,"~~- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)~~
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
~~- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
~~- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~

Part of #61886 
","['Docs', 'Strings']",,2025-07-20 06:50:55+00:00,2025-07-20 11:03:14+00:00,,0.1752199074074074
61909,BUG: fix fill value for gouped sum in case of unobserved categories for string dtype (empty string instead of 0),"I ran into one more case of the sum of empty / all-NaN to use ""0"" instead of empty string (https://github.com/pandas-dev/pandas/issues/60229), specifically when effectively introducing empty groups with categorical data with observed=False.

Follow-up on https://github.com/pandas-dev/pandas/pull/60936 

The passing through of `is_string` through several layers is a bit annoying, but effectively is needed to for now only changes this for string dtype, and not for object dtype in general (which in the other PR related to this, we did for now)","['Bug', 'Groupby', 'Strings']",,2025-07-19 18:28:34+00:00,2025-07-22 07:20:02+00:00,,2.535740740740741
61908,DOC: fix doctests for pandas/core/strings/accessor.py for new string dtype,"- [ ] ~closes #xxxx (Replace xxxx with the GitHub issue number)~
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~

Part of #61886",['Docs'],,2025-07-19 18:17:39+00:00,2025-07-25 13:28:58+00:00,,5.799525462962963
61907,DOC: fix doctests for pandas/core/generic.py for new string dtype,"- [ ] ~closes #xxxx (Replace xxxx with the GitHub issue number)~
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~

Part of #61886","['Docs', 'Strings']",,2025-07-19 17:49:17+00:00,2025-07-21 11:10:44+00:00,,1.7232291666666666
61906,ENH: Make attributes saved by default,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Hi,

When doing

```python
df.attrs['array'] = array

df.to_parquet('file.parquet')
```

I see that I am not saving the array, could this be implemented?

Cheers

### Feature Description

The code above would safe `array` and it would load it when loading the parquet file into a dataframe.

### Alternative Solutions

I guess doing it myself separately with some helper function

### Additional Context

_No response_","['Enhancement', 'IO Parquet', 'metadata', 'Needs Triage']",,2025-07-19 10:03:08+00:00,2025-07-21 03:02:18+00:00,,1.7077546296296295
61905,DOC: fix doctests for pandas/core/base.py for new string dtype,"This is an attempt to fixe the failing doctests for `pandas/core/base.py` referenced in issue #61886  


Test run

```
================================================================================================================================ test session starts =================================================================================================================================
platform darwin -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0
PyQt5 5.15.11 -- Qt runtime 5.15.17 -- Qt compiled 5.15.14
rootdir: /Users/paul/code/a/pandas
configfile: pyproject.toml
plugins: anyio-4.9.0, xdist-3.8.0, localserver-0.9.0.post0, cov-6.2.1, qt-4.5.0, hypothesis-6.135.32, cython-0.3.1
collected 21 items                                                                                                                                                                                                                                                                   

pandas/core/base.py .....................

------------------------------------------------------------------------------------------------------------ generated xml file: /Users/paul/code/a/pandas/test-data.xml -------------------------------------------------------------------------------------------------------------
================================================================================================================================ slowest 30 durations ================================================================================================================================

(30 durations < 0.005s hidden.  Use -vv to show these durations.)
================================================================================================================================= 21 passed in 0.03s =================================================================================================================================
```","['Docs', 'Strings']",,2025-07-19 08:38:03+00:00,2025-07-22 22:55:27+00:00,,3.5954166666666665
61904,DOC: Clarify to_numeric behavior for numeric dtypes,"- [x] closes #61903 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Downcasting']",,2025-07-19 06:46:56+00:00,2025-07-21 20:53:49+00:00,,2.588113425925926
61903,DOC: Clarify to_numeric behavior for numeric dtypes,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/reference/api/pandas.to_numeric.html#pandas-to-numeric

### Documentation problem

The docstring for the `to_numeric` function needs to be improved for clarity and accuracy. The current documentation states, ""The default return dtype is float64 or int64,"" which can be misleading. This statement doesn't account for cases where the input data is already of a numeric ExtensionDtype (e.g., Int32, Float32, or Arrow dtypes where `_is_numeric` is `True`). In these instances, `to_numeric` correctly preserves the original dtype rather than converting it, making the current documentation incomplete.

### Suggested fix for documentation

1. If the input is already of a numeric dtype, its dtype is preserved.
2. The conversion to a default float64 or int64 dtype primarily applies to non-numeric inputs.","['Docs', 'Downcasting']","{'login': 'chilin0525', 'id': 41913261, 'node_id': 'MDQ6VXNlcjQxOTEzMjYx', 'avatar_url': 'https://avatars.githubusercontent.com/u/41913261?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/chilin0525', 'html_url': 'https://github.com/chilin0525', 'followers_url': 'https://api.github.com/users/chilin0525/followers', 'following_url': 'https://api.github.com/users/chilin0525/following{/other_user}', 'gists_url': 'https://api.github.com/users/chilin0525/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/chilin0525/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/chilin0525/subscriptions', 'organizations_url': 'https://api.github.com/users/chilin0525/orgs', 'repos_url': 'https://api.github.com/users/chilin0525/repos', 'events_url': 'https://api.github.com/users/chilin0525/events{/privacy}', 'received_events_url': 'https://api.github.com/users/chilin0525/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-07-19 06:39:17+00:00,2025-07-21 20:53:50+00:00,chilin0525,2.5934375
61901,DEPR: maybe_infer_ndim,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Deprecate'],,2025-07-18 17:41:21+00:00,2025-07-21 16:44:14+00:00,,2.960335648148148
61900,BUG: fix to_json() with JSON Table Schema work correctly with string dtype,"Fixes:  #61889 

To ensure consistent behavior for to_json(), when dtype=""str"" is used, it will now output _""type"": ""string""_ instead of _""type"": ""any""_.

Before Fix:
```
>>> pd.Series([""a"", ""b"", None], dtype=""str"").to_json(orient=""table"", index=False)
'{""schema"":{""fields"":[{""name"":""values"",""type"":""any"",""extDtype"":""str""}],""pandas_version"":""1.4.0""},""data"":[{""values"":""a""},{""values"":""b""},{""values"":null}]}'
```

After Fix:
```
>>> pd.Series([""a"", ""b"", None], dtype=""str"").to_json(orient=""table"", index=False)
'{""schema"":{""fields"":[{""name"":""values"",""type"":""string"",""extDtype"":""str""}],""pandas_version"":""1.4.0""},""data"":[{""values"":""a""},{""values"":""b""},{""values"":null}]}'

```

- [x] closes #61889
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'IO JSON', 'Strings']",,2025-07-18 17:23:32+00:00,2025-07-26 11:27:37+00:00,,7.752835648148148
61899,FIX: Correct clip behavior test for lower > upper case,"## Description:
This PR adds a test case to verify the behavior of DataFrame.clip() when the lower bound is greater than the upper bound. The test confirms that the method applies clipping boundaries as-is without swapping them, which results in partially clipped values consistent with current pandas behavior.

## Issue:
This fixes the test logic related to issue [#61856](https://github.com/pandas-dev/pandas/issues/61856)",[],,2025-07-18 16:58:32+00:00,2025-07-19 03:35:22+00:00,,0.44224537037037037
61898,BUG: `AttributeError` in `pd.eval()` when calling attribute after binary operation,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd


series1 = pd.Series([1,2,3,4,5])
series2 = pd.Series([2,3,5,1,2])

pd.eval(
    ""(a / b).cumsum()"",
    local_dict={""a"": series1, ""b"": series2}
)
```

### Issue Description

```
AttributeError: 'BinOp' object has no attribute 'value'
```
raised.

### Expected Behavior

```
0    0.500000
1    1.166667
2    1.766667
3    5.766667
4    8.266667
dtype: float64
```

should yield this result.



### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.11.10
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.3.1
numpy                 : 2.3.1
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : 9.4.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : 2.11.0
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-07-18 16:08:05+00:00,2025-07-18 16:13:34+00:00,,0.0038078703703703703
61895,Adding examples _typing.py,"Added simple examples to Renamer
",[],,2025-07-18 02:18:23+00:00,2025-07-18 16:40:14+00:00,,0.5985069444444444
61894,BUG: fix padding for string categories in CategoricalIndex repr,"Resolving some xfails: getting back the same padding as we had before.

On current main with string dtype:
```
>>> pd.CategoricalIndex([""a"", ""bb"", ""ccc""] * 10)
CategoricalIndex([  'a',  'bb', 'ccc',   'a',  'bb', 'ccc',   'a',  'bb',
                  'ccc',   'a',  'bb', 'ccc',   'a',  'bb', 'ccc',   'a',
                   'bb', 'ccc',   'a',  'bb', 'ccc',   'a',  'bb', 'ccc',
                    'a',  'bb', 'ccc',   'a',  'bb', 'ccc'],
                 categories=['a', 'bb', 'ccc'], ordered=False, dtype='category')
```

With this PR and what it looks like with object dtype:

```
>>> pd.CategoricalIndex([""a"", ""bb"", ""ccc""] * 10)
CategoricalIndex(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a',
                  'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb',
                  'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc'],
                 categories=['a', 'bb', 'ccc'], ordered=False, dtype='category')
```
","['Bug', 'Output-Formatting']",,2025-07-17 19:10:04+00:00,2025-07-19 10:34:28+00:00,,1.6419444444444444
61893,BUG: Fix concat dtype preservation through concat,"- [x] closes #51362
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


---
Expected behavior:

- An empty categorical, and a categorical should concat as a categorical.


---
Linked issues:
#13524 see https://github.com/pandas-dev/pandas/issues/13524#issuecomment-233792648
https://github.com/pandas-dev/pandas/issues/39443

#14177 (seems a dev call agreed on putting this as an option in `concat`)

https://github.com/pandas-dev/pandas/pull/13767

","['Bug', 'Reshaping', 'Categorical']",,2025-07-17 18:53:02+00:00,2025-07-22 15:32:00+00:00,,4.860393518518518
61892,WEB: Remove Roadmap points pending a PDEP section from Roadmap,"closes https://github.com/pandas-dev/pandas/issues/60913

In https://github.com/pandas-dev/pandas/issues/51471#issuecomment-3075831365 @jbrockmendel wrote

> No evidence the ecosystem wants this, closing.

in https://pandas.pydata.org/about/roadmap.html#roadmap-points-pending-a-pdep

> pandas is in the process of moving roadmap points to PDEPs (implemented in August 2022). During the transition, some roadmap points will exist as PDEPs, while others will exist as sections below.

If we don't have actionable plans than can be written up as a PDEP, let's remove this from the roadmap.

---

In https://github.com/pandas-dev/pandas/pull/27478 @TomAugspurger wrote

> Do we want this? Roadmaps tend to go stale. How can we keep this up to date?

So maybe there are other sections that we also want to remove now?

@pandas-dev/pandas-core ","['Web', 'Roadmap']",,2025-07-17 14:16:07+00:00,2025-07-22 16:27:33+00:00,,5.091273148148148
61891,Output formatting: preserve quoting for string categories,POC for https://github.com/pandas-dev/pandas/issues/61890 if we want to keep the quoting behaviour,"['Output-Formatting', 'Strings', 'Categorical']",,2025-07-17 08:18:05+00:00,2025-07-25 13:26:36+00:00,,8.214247685185185
61889,BUG: make to_json with JSON Table Schema work correctly with string dtype,"(noticed because of some doctest failures cfr https://github.com/pandas-dev/pandas/issues/61886)

Currently, for the strings as object dtype, it seems that we assume that object dtype are actually strings, and encode that as such in the schema part of the JSON Table Schema output:

```python
>>> pd.Series([""a"", ""b"", None], dtype=object).to_json(orient=""table"", index=False)
'{""schema"":{""fields"":[{""name"":""values"",""type"":""string""}],""pandas_version"":""1.4.0""},""data"":[{""values"":""a""},{""values"":""b""},{""values"":null}]}'
```

But for the now-default string dtype, this is still seen as some custom extension dtype:

```python
>>> pd.Series([""a"", ""b"", None], dtype=""str"").to_json(orient=""table"", index=False)
'{""schema"":{""fields"":[{""name"":""values"",""type"":""any"",""extDtype"":""str""}],""pandas_version"":""1.4.0""},""data"":[{""values"":""a""},{""values"":""b""},{""values"":null}]}'
```

(note the `""type"":""string""` vs `""type"":""any"",""extDtype"":""str""`)

Given that the Table Schema spec has a ""string"" type, let's also use that when exporting our string dtype.

","['Bug', 'IO JSON', 'Strings']","{'login': 'khemkaran10', 'id': 168984037, 'node_id': 'U_kgDOChJ95Q', 'avatar_url': 'https://avatars.githubusercontent.com/u/168984037?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/khemkaran10', 'html_url': 'https://github.com/khemkaran10', 'followers_url': 'https://api.github.com/users/khemkaran10/followers', 'following_url': 'https://api.github.com/users/khemkaran10/following{/other_user}', 'gists_url': 'https://api.github.com/users/khemkaran10/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/khemkaran10/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/khemkaran10/subscriptions', 'organizations_url': 'https://api.github.com/users/khemkaran10/orgs', 'repos_url': 'https://api.github.com/users/khemkaran10/repos', 'events_url': 'https://api.github.com/users/khemkaran10/events{/privacy}', 'received_events_url': 'https://api.github.com/users/khemkaran10/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-07-17 07:30:55+00:00,2025-07-26 11:27:38+00:00,khemkaran10,9.164386574074074
61888,ENH: Images embedded in cells. The DISPIMG function of WPS,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Hi!
I found that there is an issue with the WPS image. The software allows images to be directly embedded into cells, and the format is similar to `=DISPIMG (""ID5BA4F81A0D674C7AA8849A79AC5645C8"", 1)`. 

<img width=""691"" height=""431"" alt=""Image"" src=""https://github.com/user-attachments/assets/e32caa36-9729-44ca-8a46-477aec421e79"" />

Therefore, it cannot be accessed through **worksheets. _images**

If we unzip Excel, we can find all the images under _xl/media_, and the image indexes are in _xl/-rels/cellimages.xml.rels_ and _xl/ellimages.xml_

This is a unique feature of WPS, at least I haven't found it in Office.


I found a similar [implementation](https://github.com/wangguanquan/eec/issues/363)

### Feature Description

This is my code, which will decompress Excel, read the file, and return an Id to address mapping

```pthon
def wps_embed_images(file_path, save_path) -> dict:
    img_map = {}

    with zipfile.ZipFile(file_path, ""r"") as zip_ref:
        zip_ref.extractall(save_path)

    id2target = {}
    rels = os.path.join(save_path, ""xl"", ""_rels"", ""cellimages.xml.rels"")
    tree = ET.parse(rels)
    root = tree.getroot()
    for child in root:
        id2target[child.attrib.get(""Id"")] = os.path.join(save_path, ""xl"", child.attrib.get(""Target""))

    namespaces = {
        'etc': 'http://www.wps.cn/officeDocument/2017/etCustomData',
        'xdr': 'http://schemas.openxmlformats.org/drawingml/2006/spreadsheetDrawing',
        'a': 'http://schemas.openxmlformats.org/drawingml/2006/main',
        'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships'
    }

    cellimages = os.path.join(save_path, ""xl"", ""cellimages.xml"")
    tree = ET.parse(cellimages)
    root = tree.getroot()
    for cell_image in root.findall('etc:cellImage', namespaces):
        c_nv_pr = cell_image.find('.//xdr:cNvPr', namespaces)
        image_name = c_nv_pr.get('name') if c_nv_pr is not None else None

        blip = cell_image.find('.//a:blip', namespaces)
        embed_id = blip.get(f'{{{namespaces[""r""]}}}embed') if blip is not None else None

        if image_name and embed_id:
            img_map[image_name] = id2target[embed_id]

    return img_map
```

### Alternative Solutions

We leave it as it is and I continue using the solution shown above.

### Additional Context

_No response_","['Enhancement', 'Needs Info', 'Needs Triage', 'Closing Candidate']",,2025-07-17 07:26:02+00:00,2025-08-05 16:28:29+00:00,,19.37670138888889
61887,DOC: fix doctests for string dtype changes (top-level),"Part of https://github.com/pandas-dev/pandas/issues/61886). Some first doctest fixes for the new string dtype, for things that pytest sees as part of `pandas/__init__.py` and some files that only had one failure.","['Docs', 'Strings']",,2025-07-17 07:08:32+00:00,2025-07-17 14:59:03+00:00,,0.3267476851851852
61886,DOC: fix doctests for repr changes with the new string dtype,"Now the string dtype is turned on by default (https://github.com/pandas-dev/pandas/pull/61722), we also have to fix the doctests to match the new behaviour (the doctests are currently, temporarily, allowed to fail to avoid red CI until this issue is fixed).

The failures can be seen in the current doctests logs, for example at https://github.com/pandas-dev/pandas/actions/runs/16332737970/job/46138722939#step:6:23

There are two main groups of failures:
- `dtype: object` that needs to become `dtype: str` in Series output (or object->str in some other reprs, and a few None->NaN changes)
- The representation of Categorical no longer using quoted values

I would propose to first start with the first bullet point (we should maybe reconsider if the categorical repr change is actually what we want -> https://github.com/pandas-dev/pandas/issues/61890), and the failing files are:

- [x] `pandas/core/base.py` (https://github.com/pandas-dev/pandas/pull/61905)
- [x] `pandas/core/generic.py`
- [x] `pandas/core/strings/accessor.py`
- [x] `pandas/core/arrays/datetimelike.py`, `pandas/core/arrays/datetimes.py` and `pandas/core/indexes/datetimelike.py`

Let's do one PR per bullet point here.

You can run the doctest and verify changes with for example:

```
pytest --doctest-modules pandas/core/base.py
```

Example PR for some fixes in other files: https://github.com/pandas-dev/pandas/pull/61887
","['Docs', 'Strings']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-07-17 07:06:43+00:00,2025-07-26 17:14:22+00:00,arthurlw,9.421979166666667
61885,Fix warning for extra fields in read_csv with on_bad_lines callable,"- [ ] closes #61837 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-17 05:01:15+00:00,2025-07-29 01:01:52+00:00,,11.833761574074074
61884,API: Index.__cmp__(Series) return NotImplemented,"- [x] closes #36759 (Replace xxxx with the GitHub issue number)
- [x] closes #54475
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Numeric Operations'],,2025-07-16 21:42:36+00:00,2025-07-16 23:50:26+00:00,,0.08877314814814814
61883,BUG: Timedelta with invalid keyword,"- [x] closes #53801 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Error Reporting', 'Timedelta']",,2025-07-16 20:38:53+00:00,2025-07-16 21:40:23+00:00,,0.042708333333333334
61882,BUG: disallow exotic np.datetime64 unit,"- [x] closes #25611 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This doesn't work locally for reasons described [here](https://github.com/pandas-dev/pandas/issues/25611#issuecomment-3079363946). @seberg says it should work, so let's see if the CI can prove him right.",['Datetime'],,2025-07-16 20:31:24+00:00,2025-07-17 19:21:20+00:00,,0.9513425925925926
61880,Set up ty in CI,"Hello,

This PR sets up [`ty`](https://github.com/astral-sh/ty), a type checker developed by the creator of `ruff`, in CI.

I'm aware that `ty` is still in preview but there can be a couple of benefits in adding it now. 
- It's already very fast and can help us debug faster. `mypy` is quite slow and disrupts the coding flow.
- The cost of setup is pretty cheap, as it's mostly similar to `mypy` and `pyright`. Currently I ignore all errors so that we can fix and enable them gradually, like the other linting and typing errors.
- This also allows us to evaluate if/when `ty` can be a replacement of `mypy` and `pyright`.

Let me know what you think.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['CI', 'Typing']",,2025-07-16 19:46:36+00:00,2025-07-28 17:14:13+00:00,,11.894178240740741
61878,DOC: update Parquet IO user guide on index handling and type support across engines,It seems this section of our documentation was quite outdated. Have updated it to the best of my knowledge and based on some testing.,"['Docs', 'IO Parquet']",,2025-07-16 18:16:55+00:00,2025-07-16 21:29:00+00:00,,0.1333912037037037
61877,DOC: show Parquet examples with default engine (without explicit pyarrow/fastparquet engine keyword),"Encountered this in https://github.com/pandas-dev/pandas/pull/61864, but in general for the readability of our doc page, I feel that it is not needed to show every single code example in this section with both pyarrow and fastparquet (certainly because in practice the fastparquet result is then ignored, and we only show the resulting dtypes for the pyarrow one). 
We already mention in the text itself the engine keyword and the different options.

","['Docs', 'IO Parquet']",,2025-07-16 17:54:14+00:00,2025-07-16 21:27:45+00:00,,0.14827546296296296
61876,ERR: improve exception message from timedelta64-datetime64,"- [x] closes #59571 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Error Reporting'],,2025-07-16 17:41:05+00:00,2025-07-16 21:30:16+00:00,,0.15915509259259258
61875,API: IncompatibleFrequency subclass TypeError,"- [x] closes #55782 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Error Reporting'],,2025-07-16 16:42:14+00:00,2025-07-18 00:53:24+00:00,,1.341087962962963
61874,API: np.isinf on Index return Index[bool],"- [x] closes #52676 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Index'],,2025-07-16 15:32:29+00:00,2025-07-16 16:26:06+00:00,,0.0372337962962963
61873,BUG:float_precision type hints differ in release version from github and docs pandas==2.3.1,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
python -m venv venv
source ./venv/scripts/activate
python -m pip install pandas==2.3.1


Open a modern ide like pycharm and type


pd.read_csv(path, float_precision='round_trip')

and you will see type check erroring because the code is different.
```

### Issue Description

This is probably a bug in distribution.

I currently have installed on my windows system pandas 2.3.1. When I open 
```
.venv/Lib/site-packages/pandas/io/parsers/readers.py
```
I see the following line in 3 different definitions for read_csv:

```
    float_precision: Literal[""high"", ""legacy""] | None = None,
```

However, the documentation specifies a third option, 'round_trip', and so does the code here on github

https://github.com/pandas-dev/pandas/blob/1d153bb1a4c6549958a20e04508967e2ed45159f/pandas/io/parsers/readers.py#L141

I don't understand how this line is different in a pip installed latest version, but not on github.com. This code was fixed back at the beginning of 2024, 18+ months ago.

https://github.com/pandas-dev/pandas/commit/37d7db4a1a1f6928a1541eaab05f51318d1d3344

Why does it not appear in pip installable distributions?

### Expected Behavior

I expect the line

    float_precision: Literal[""high"", ""legacy""] | None = None,

in pandas/io/parsers/readers.py to read

    float_precision: Literal[""high"", ""legacy"", ""round_trip""] | None = ...,



### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.13.2
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 170 Stepping 4, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252
pandas                : 2.3.1
numpy                 : 2.2.1
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : 9.2.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : 2.0.36
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'IO CSV', 'Typing', 'Closing Candidate']",,2025-07-16 13:01:08+00:00,2025-07-22 12:26:03+00:00,,5.975636574074074
61872,TST: add test for `dtype` argument in `str.decode`,"This PR adds a test case for `str.decode` and ensures it correctly infers the string datatype, when `dtype=None` and the option `future.infer_string` is used. This argument was introduced in PR https://github.com/pandas-dev/pandas/pull/60940 but has no test for None. This test adds coverage to the following line:


```py
    def decode(
        self, encoding, errors: str = ""strict"", dtype: str | DtypeObj | None = None
    ):
        ...
        if dtype is not None and not is_string_dtype(dtype):
            raise ValueError(f""dtype must be string or object, got {dtype=}"")
        if dtype is None and get_option(""future.infer_string""):
            dtype = ""str"" #‚úÖ NOW COVERED
        # TODO: Add a similar _bytes interface.
        if encoding in _cpython_optimized_decoders:
            # CPython optimized implementation
            f = lambda x: x.decode(encoding, errors)
        ...
```

Note: Parts of this test have been automatically generated by a novel technique that we're currently developing as part of an academic research project aiming at improving test coverage. *To not waste developer time, two researchers manually checked the test before submitting it.* We appreciate the developers' time and any feedback is welcomed.",['Testing'],,2025-07-16 10:08:10+00:00,2025-07-28 17:24:05+00:00,,12.302719907407408
61869,BUG: Fix logical method Non 1D Extension Arrays,"- [x] closes #61866 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-16 03:54:25+00:00,2025-07-16 15:41:18+00:00,,0.4908912037037037
61868,DOC: Add Raises section to to_numeric docstring,"- [x] closes #61811 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-07-15 23:14:46+00:00,2025-07-16 16:29:47+00:00,,0.718761574074074
61867,Fix logical operations broadcasting for 2D ExtensionArrays,"- [ ] closes #61866 
- [ ] Tests added and passed (local tests not run due to environment setup, but CI will run them)
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] No entry added to whatsnew since this is an internal bug fix
",[],,2025-07-15 21:16:38+00:00,2025-07-15 21:39:48+00:00,,0.016087962962962964
61865,DOC: Simplify footer wording in documentation (#51536),"This PR simplifies the wording in the pandas documentation footer for improved readability and clarity.

Fixes: #51536",[],,2025-07-15 15:45:11+00:00,2025-07-16 16:32:35+00:00,,1.0329166666666667
61864,DOC: make doc build run with string dtype enabled,"~First commit is from https://github.com/pandas-dev/pandas/pull/61722 (will be removed here after that PR is merged and this one is rebased)~, then subsequent commits enable errors on the doc build again and fix issues.",['Docs'],,2025-07-15 15:09:32+00:00,2025-07-17 08:31:08+00:00,,1.7233333333333334
61861,BUG: pd.eval raises AttributeError: 'BinOp' object has no attribute 'value',"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd

x = pd.DataFrame(np.empty((3, 4)))
y = pd.DataFrame(np.empty((3, 4)))

pd.eval(""(x * y).sum()"")
```

### Issue Description

The above code raises this error:

<img width=""1384"" height=""203"" alt=""Image"" src=""https://github.com/user-attachments/assets/38af2da0-9437-4638-8215-fe8a0f699fd3"" />

Related issue: #61175

### Expected Behavior

.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.12.11
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.0-122-generic
Version               : #132-Ubuntu SMP Thu Aug 29 13:45:52 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.0
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : 8.2.3
IPython               : 9.3.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.1
html5lib              : None
hypothesis            : 6.135.0
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.3
numba                 : 0.61.2
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : 8.4.0
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.41
tables                : 3.10.2
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Needs Triage']",,2025-07-15 08:32:29+00:00,2025-07-15 08:47:03+00:00,,0.010115740740740741
61860,"ENH: New method ""ends"" as a combination of ‚Äúhead‚Äù and ""tail""","### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I often work with time series and want to see at a glance where and how they begin and end.  

### Feature Description

That's why I registered an ""ends"" accessor, which provides me with both ends in one call as a combination of ""head"" and ""tail"". It's really simple, but very usefull to me:

```
class _EndsAccessor:
    def __init__(self, pandas_obj):
        self._obj = pandas_obj

    def __call__(self, n=2):
        return pd.concat([self._obj.head(n), self._obj.tail(n)])

@pd.api.extensions.register_dataframe_accessor(""ends"")
class EndsAccessorDataframe(_EndsAccessor):
    pass


@pd.api.extensions.register_series_accessor(""ends"")
class EndsAccessorSeries(_EndsAccessor):
    pass

```

### Alternative Solutions

We leave it as it is and I continue using the solution shown above.

### Additional Context

_No response_","['Enhancement', 'Needs Triage', 'Closing Candidate']",,2025-07-15 07:43:12+00:00,2025-08-05 16:28:53+00:00,,21.36505787037037
61859,Doc simplify footer,"[x] closes #51536 - Simplified pandas theme footer by removing custom template dependency
[x] Tests added and passed - Documentation changes don't require additional tests, but the build process validates the changes
[x] All code checks passed - Changes follow pandas documentation standards and use proper reStructuredText formatting
[x] Added type annotations - Not applicable for documentation-only changes
[x] Added an entry in the latest doc/source/whatsnew/vX.X.X.rst file - Entry already exists in doc/source/whatsnew/v3.0.0.rst under ""Documentation changes"" section",['Docs'],,2025-07-15 06:04:19+00:00,2025-07-28 17:24:56+00:00,,13.472650462962964
61858,Upgraded README.md,"Enhanced readability of the file's content

- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-14 21:50:23+00:00,2025-07-14 23:53:48+00:00,,0.08570601851851851
61857,CI: Add testing for Window ARM,"We added wheel support for `win_arm64` in https://github.com/pandas-dev/pandas/pull/61463, so we might as well be regularly testing this platform on CI.

Additionally ""pins"" the runner images we use to test Windows and Mac",['CI'],,2025-07-14 17:52:47+00:00,2025-07-14 17:58:22+00:00,,0.0038773148148148148
61855,"BUG: If both index and axis are passed to DataFrame.drop, raise a clear error",- [x] closes #61823,"['Bug', 'Error Reporting']",,2025-07-14 17:08:35+00:00,2025-07-18 02:18:16+00:00,,3.3817245370370372
61854,BUG: Reassigning .rolling().mean() returns NaNs (pandas-dev#61841),"

This pull request resolves a bug highlighted in issue [[#61841](https://github.com/pandas-dev/pandas/issues/61841)](https://github.com/pandas-dev/pandas/issues/61841), where reassigning the result of `.rolling().mean()` to the same column in a DataFrame results in all-NaN values after the first assignment.

#### üîú Root Cause:

The root cause was improper alignment when using the `step` parameter within the `Window._apply()` function. The rolling results were sliced using `self.step` before being fully aligned with the original index, which caused mismatches in the returned Series/DataFrame.

#### üîß Fix Implemented:

* Adjusted the logic in `Window._apply()` to apply `self.step` only after the result is completely constructed and aligned.
* Moved `Series` and `DataFrame` imports from inside a type-checking block (`if TYPE_CHECKING`) to the top of the file. This eliminates pre-commit CI errors related to inconsistent namespace usage.

#### üìÑ Verification:

The fix was verified by executing:

```python
import pandas as pd
import numpy as np

df = pd.DataFrame({""Close"": np.arange(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()
print(df.tail())
```

This now works as expected, and outputs the correct rolling mean values.

All relevant pre-commit hooks and CI checks pass after the changes.

---

Thank you for reviewing this fix!

<img width=""1269"" height=""377"" alt=""Screenshot 2025-07-13 201135"" src=""https://github.com/user-attachments/assets/0fb467e4-fb48-4d29-b294-c74abc7177f0"" />
",[],,2025-07-14 13:03:22+00:00,2025-07-14 13:07:11+00:00,,0.002650462962962963
61853,fix extension type check for ArrowDtype,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-14 11:58:50+00:00,2025-07-14 11:59:51+00:00,,0.0007060185185185185
61852,BUG: Fix .rolling().mean() reassignment returning NaNs (pandas-dev#61841),"
This pull request resolves a bug highlighted in issue [[#61841](https://github.com/pandas-dev/pandas/issues/61841)](https://github.com/pandas-dev/pandas/issues/61841), where reassigning the result of `.rolling().mean()` to the same column in a DataFrame results in all-NaN values after the first assignment.

#### üîú Root Cause:

The root cause was improper alignment when using the `step` parameter within the `Window._apply()` function. The rolling results were sliced using `self.step` before being fully aligned with the original index, which caused mismatches in the returned Series/DataFrame.

#### üîß Fix Implemented:

* Adjusted the logic in `Window._apply()` to apply `self.step` only after the result is completely constructed and aligned.
* Moved `Series` and `DataFrame` imports from inside a type-checking block (`if TYPE_CHECKING`) to the top of the file. This eliminates pre-commit CI errors related to inconsistent namespace usage.

#### üìÑ Verification:

The fix was verified by executing:

```python
import pandas as pd
import numpy as np

df = pd.DataFrame({""Close"": np.arange(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()
print(df.tail())
```

This now works as expected, and outputs the correct rolling mean values.

All relevant pre-commit hooks and CI checks pass after the changes.

---

Thank you for reviewing this fix!","['Bug', 'Window']",,2025-07-14 06:39:11+00:00,2025-07-25 17:57:46+00:00,,11.471238425925925
61851,BUG: Fix .rolling().mean() reassignment returning NaNs (pandas-dev#61841),"
This pull request resolves a bug highlighted in issue [[#61841](https://github.com/pandas-dev/pandas/issues/61841)](https://github.com/pandas-dev/pandas/issues/61841), where reassigning the result of `.rolling().mean()` to the same column in a DataFrame results in all-NaN values after the first assignment.

#### üîú Root Cause:

The root cause was improper alignment when using the `step` parameter within the `Window._apply()` function. The rolling results were sliced using `self.step` before being fully aligned with the original index, which caused mismatches in the returned Series/DataFrame.

#### üîß Fix Implemented:

* Adjusted the logic in `Window._apply()` to apply `self.step` only after the result is completely constructed and aligned.
* Moved `Series` and `DataFrame` imports from inside a type-checking block (`if TYPE_CHECKING`) to the top of the file. This eliminates pre-commit CI errors related to inconsistent namespace usage.

#### üìÑ Verification:

The fix was verified by executing:

```python
import pandas as pd
import numpy as np

df = pd.DataFrame({""Close"": np.arange(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()
print(df.tail())
```

This now works as expected, and outputs the correct rolling mean values.

All relevant pre-commit hooks and CI checks pass after the changes.

---

Thank you for reviewing this fix!",[],,2025-07-14 06:08:20+00:00,2025-07-14 16:39:17+00:00,,0.4381597222222222
61850,BUG: Fix issue #61841 - .rolling().mean() returns NaNs on reassignment,"
This pull request fixes **issue #61841**, where reassigning a `.rolling().mean()` result unexpectedly returns a Series of all NaNs, even after copying the DataFrame.

---

### üêõ Bug Reproduction Example

```python
import pandas as pd
import numpy as np

df = pd.DataFrame({""Close"": np.arange(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()  # ‚ùå Returns NaNs
```

---

### üîß What Was Fixed

* Modified logic in `Window._apply()`:

  * Previously, result slicing (`[:: self.step]`) broke shape/index alignment.
  * Now it checks for `self.step` and slices only *after* full shape result is returned.

```python
# ‚úÖ Fixed
result = self._apply_columnwise(...)
if self.step is not None and self.step > 1:
    if isinstance(result, Series):
        result = result.iloc[:: self.step]
    elif isinstance(result, DataFrame):
        result = result.iloc[:: self.step, :]
return result
```

* Moved `Series` and `DataFrame` imports to the top level of `rolling.py` to fix pre-commit check failures related to inconsistent namespace usage.

---

### üß™ How Verified

```python
import pandas as pd
import numpy as np

df = pd.DataFrame({""Close"": np.arange(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()
print(df.tail())  # ‚úÖ Correct output
```

---

### ‚úÖ Status

* [x] Bug fixed
* [x] Code passes all CI and pre-commit checks
* [x] Imports are consistently handled

Thanks for reviewing this PR!
",[],,2025-07-14 05:50:42+00:00,2025-07-14 05:54:19+00:00,,0.002511574074074074
61849,Remove incorrect line in Series init docstring,"- [x] closes #61848
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


Copied over from the issue for convenience
```
    dtype : str, numpy.dtype, or ExtensionDtype, optional
        Data type for the output Series. If not specified, this will be
        inferred from `data`.
        See the :ref:`user guide <basics.dtypes>` for more usages.
        If ``data`` is Series then is ignored.
```
The last line here is incorrect. specifying a dtype will override the default behavior. See this example
```
>>> import pandas as pd
>>> ser = pd.Series([1,2,3])
>>> ser
0    1
1    2
2    3
dtype: int64
>>> pd.Series(ser, dtype=float)
0    1.0
1    2.0
2    3.0
dtype: float64
```",['Docs'],,2025-07-14 02:01:35+00:00,2025-07-14 15:48:25+00:00,,0.5741898148148148
61848,DOC: Series.__init__ doc incorrectly says dtype is ignored if data is a Series,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/reference/api/pandas.Series.html

### Documentation problem

```
    dtype : str, numpy.dtype, or ExtensionDtype, optional
        Data type for the output Series. If not specified, this will be
        inferred from `data`.
        See the :ref:`user guide <basics.dtypes>` for more usages.
        If ``data`` is Series then is ignored.
```
The last line here is incorrect. specifying a dtype will override the default behavior. See this example

```
>>> import pandas as pd
>>> ser = pd.Series([1,2,3])
>>> ser
0    1
1    2
2    3
dtype: int64
>>> pd.Series(ser, dtype=float)
0    1.0
1    2.0
2    3.0
dtype: float64
```

### Suggested fix for documentation

Just remove that line","['Docs', 'Series']",,2025-07-14 02:00:43+00:00,2025-07-14 15:48:26+00:00,,0.5748032407407407
61847,BUG: Fix .rolling().mean() returning NaNs on reassignment (#61841),"### What does this PR do?

Fixes issue #61841 where `.rolling().mean()` unexpectedly returns all NaNs when the same assignment is executed more than once, even with `.copy()` used on the DataFrame.

---

### Problem

When using:

```python
df = pd.DataFrame({""Close"": range(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()  # ‚ùå Unexpectedly returns all NaNs
```

Only the first assignment works as expected. The second assignment results in a column full of NaNs. This bug is caused by slicing the output with `[:: self.step]` inside `_apply()`, which alters the result's shape and breaks alignment during reassignment.

---

### Fix

In `Window._apply()`, we updated the logic to apply slicing only when needed and only after the result is correctly shaped:

**Before (buggy):**

```python
return self._apply_columnwise(...)[:: self.step]
```

**After (fixed):**

```python
result = self._apply_columnwise(...)
if self.step is not None and self.step > 1:
    if isinstance(result, pd.Series):
        result = result.iloc[::self.step]
    elif isinstance(result, pd.DataFrame):
        result = result.iloc[::self.step, :]
return result
```

This change:

* Preserves result shape and index alignment
* Ensures `.rolling().mean()` works even on repeated assignment
* Matches behavior in Pandas 2.3.x and above

---

### Testing

Reproduced and verified the fix using both real-world and synthetic data:

```python
import pandas as pd
import numpy as np

df = pd.DataFrame({""Close"": np.arange(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
print(df[""SMA20""].tail())

df[""SMA20""] = df[""Close""].rolling(20).mean()
print(df[""SMA20""].tail())  # ‚úÖ Now works correctly
```

---

### Notes

* This was confirmed to be broken in Pandas 2.2.x and was still reproducible in `main` without this patch.
* Newer versions avoid the issue due to deeper internal refactors, but this fix explicitly prevents the bug in current code.

---

Let me know if anything needs improvement. Thanks for reviewing!
",[],,2025-07-13 17:48:15+00:00,2025-07-13 18:31:45+00:00,,0.030208333333333334
61846,BUG: Fix .rolling().mean() returning NaNs on reassignment (#61841),"### What does this PR do?

Fixes issue #61841 where `.rolling().mean()` unexpectedly returns all NaNs when the same assignment is executed more than once, even with `.copy()` used on the DataFrame.

---

### Problem

When using:

```python
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()  # Unexpectedly returns all NaNs
```

Only the first assignment works as expected. The second assignment results in a column full of NaNs. This bug is caused by slicing the output with `[:: self.step]` inside `_apply_columnwise()`, which alters the result's shape and breaks alignment during reassignment.

---

### Fix

This PR removes the problematic slicing from `_apply_columnwise()`:

**Before (buggy):**

```python
return self._apply_columnwise(...)[:: self.step]
```

**After (fixed):**

```python
result = self._apply_columnwise(...)
return result
```

This change:

* Preserves result shape and index alignment
* Ensures `.rolling().mean()` works even on repeated assignment
* Matches behavior in Pandas 2.3.x and above

---

### Testing

Reproduced and verified the fix using both real-world and synthetic data:

```python
import pandas as pd

df = pd.DataFrame({""Close"": range(1, 31)})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()  # ‚úÖ Now works correctly
```

---

### Notes

* This was confirmed to be broken in Pandas 2.2.x and still reproducible in `main` without this patch.
* Newer versions avoid the issue due to deeper internal refactors, but this fix explicitly prevents the bug in current code.

---

Let me know if anything needs improvement. Thanks for reviewing!
<img width=""1269"" height=""377"" alt=""Screenshot 2025-07-13 201135"" src=""https://github.com/user-attachments/assets/b1d9bf2b-9faa-4e28-83be-ecac8bf18934"" />
",[],,2025-07-13 16:39:51+00:00,2025-07-13 17:45:12+00:00,,0.04538194444444445
61845,BUG: Fix rolling().mean() returning NaNs on reassignment (#61841),"### Problem

Fixes issue #61841 ‚Äî calling `.rolling().mean()` twice on a copied DataFrame was returning all NaNs on the second run.

This happened due to a slicing operation (`[::self.step]`) in `_apply_columnwise`, which broke result alignment when overwriting the same column.

### Solution

Removed the `[:: self.step]` slicing from the return statement. This restores full alignment and fixes the regression.

### Test Case

Tested locally with this code:

```python
df = pd.DataFrame({""Close"": list(range(1, 31))})
df = df.copy()
df[""SMA20""] = df[""Close""].rolling(20).mean()
df[""SMA20""] = df[""Close""].rolling(20).mean()
print(df.tail())
<img width=""1269"" height=""377"" alt=""Screenshot 2025-07-13 201135"" src=""https://github.com/user-attachments/assets/c1cbe325-28c6-4a39-bf98-861492d9295c"" />
",[],,2025-07-13 14:42:18+00:00,2025-07-14 16:39:10+00:00,,1.0811574074074075
61843,DOC: Simplify pandas theme footer,"# üéØ DOC: Simplify pandas theme footer

## üìù Description
This pull request refactors the pandas documentation footer by tapping into the built-in templates in **pydata-sphinx-theme** v0.16. The result is a leaner, more maintainable setup with zero visual regressions‚Äîscience approved!

## üîß Changes Made
1. **`doc/source/conf.py`**
   - Updated the copyright line to include ‚Äúpandas‚Äù  
   - Swapped out custom footer bits for the theme‚Äôs built-in templates:
     ```python
     html_theme_options = {
         ""footer_start"": [
             ""copyright"",
             ""pandas_footer"",
             ""sphinx-version"",
         ],
         ‚Ä¶
     }
     ```
2. **`doc/_templates/pandas_footer.html`**
   - Removed the now-redundant copyright snippet  
   - Kept only the NumFOCUS & OVHcloud sponsor links  
3. **`doc/source/_static/css/pandas.css`**
   - Added horizontal layout rules for the new footer items  
   - Ensured consistent spacing & alignment  
4. **`doc/source/whatsnew/v3.0.0.rst`**
   - Added a ‚ÄúDocumentation changes‚Äù section  
   - Linked to issue [#51536](https://github.com/pandas-dev/pandas/issues/51536)

## ‚úÖ Benefits
- **DRY**: Eliminates duplicated footer code  
- **Maintainable**: Leverages standard theme hooks  
- **Consistent**: Visual appearance remains identical  
- **Future-proof**: Automatically picks up theme updates  

---

üöÄ All checks have passed and this PR is ready for merge! üéâ
",[],,2025-07-13 11:34:18+00:00,2025-07-14 16:37:15+00:00,,1.2103819444444444
61842,Create Vix,"Want backtest data Nifty 50 index data rsi

- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-13 06:20:40+00:00,2025-07-14 15:46:56+00:00,,1.3932407407407408
61840,DOC: Add unified code guideline document (#33851),"### Summary

This PR addresses Issue #33851 by adding a new consolidated documentation file named `code_guidelines.md` under `doc/source/development/`. The goal is to unify coding standards and make it easier for new contributors to find all code style rules in one place.

### Key Highlights

- Combines content from:
  - `code_style.html`
  - `contributing.html#code-standards`
- Covers formatting tools (`black`, `flake8`, `isort`)
- Includes naming conventions, testing rules, and docstring format
- Improves onboarding for new contributors
- Adds references and examples

Let me know if you'd like me to update links in `index.rst` or make any changes. Happy to collaborate on refinements.
",[],,2025-07-12 14:07:15+00:00,2025-07-12 18:33:51+00:00,,0.18513888888888888
61839,DOC: rm excessive backtick,"- [ ] ~~closes #xxxx (Replace xxxx with the GitHub issue number)~~ only fix sphinx syntax
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
---

I‚Äôm developing a new sphinx-lint rule to detect excessive backticks ([PR](https://github.com/sphinx-contrib/sphinx-lint/pull/139)), and it flagged some in the current document ([this GitHub search link](https://github.com/search?q=repo%3Apandas-dev%2Fpandas+%2F%5B%5E%60%5D%3A%28class%7Cmeth%29%3A%5C%60%5B%5E%5C%60%5Cs%5D*%5C%60%5C%60%2F&type=code) lists these occurences too).
This PR fixes detected cases.
",['Docs'],,2025-07-12 09:16:13+00:00,2025-07-12 18:36:28+00:00,,0.3890625
61836,DOC: Update README.md to reference issues related to 'good first issue' and 'Docs' properly,"- [x] closes #61835 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-07-12 02:55:59+00:00,2025-07-12 18:49:35+00:00,,0.6622222222222223
61835,DOC: README.md link for issues specified for Docs and good first issue doesn't reference properly,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://github.com/pandas-dev/pandas?tab=readme-ov-file#contributing-to-pandas

### Documentation problem

In the README.md, the links for 'Docs' and 'good first issue' doesn't reference to the appropriate labels.

### Suggested fix for documentation

Change the links so they reference the proper labels.","['Docs', 'Needs Triage']",,2025-07-12 02:55:35+00:00,2025-07-12 18:49:36+00:00,,0.6625115740740741
61833,DOC: Clarify str.cat output for Index object (GH35556),"- [x] closes #35556
- [x] Tests added and passed ‚Äî *N/A (doc-only change)*
- [x] All code checks passed ‚Äî *pre-commit and CI should pass*
- [x] Added type annotations ‚Äî *N/A (no new code added)*
- [x] Added an entry in the latest whatsnew ‚Äî *N/A (doc-only update)*

### Summary of Changes

This PR improves the docstring for `str.cat()` to clarify what happens when the caller is an `Index` and `others` is `None`.

Specifically, the doc now explains that in this case, the output is also an `Index` containing a single string, rather than a plain `str` as it is for `Series`.

### Example added:

```python
>>> idx = pd.Index([""a"", ""b"", np.nan])
>>> idx.str.cat(sep=""-"")
Index(['a-b'], dtype='object')
",['Docs'],,2025-07-11 16:10:36+00:00,2025-07-28 17:23:17+00:00,,17.050474537037037
61832,REF: separate out helpers in libparser,"Besides general code hygiene, I'm trying to isolate parts of the code that could be parallelized in a free-threading world xref #61825",['IO CSV'],,2025-07-11 14:51:21+00:00,2025-07-11 16:32:39+00:00,,0.07034722222222223
61831,BUG: Intersection of Pandas Index Object is not working properly,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
indA=pd.Index([1,3,5,7,9])
indB=pd.Index([2,3,5,7,11])

indA & indB
```

### Issue Description

the output i am getting is : 
Index([0, 3, 5, 7, 9], dtype='int64')



### Expected Behavior


but after intersection, i should get the output: 
Index([3, 5, 7], dtype='int64')

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Needs Triage']",,2025-07-11 09:57:14+00:00,2025-07-11 15:41:22+00:00,,0.2389814814814815
61830,TST: Fix `test_mask_stringdtype` ,"- [x] closes #61824
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
",['Testing'],,2025-07-11 03:33:52+00:00,2025-07-11 16:35:45+00:00,,0.542974537037037
61829,ENH: Add a function like PYQT signal,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I hope this function can use to keep two or more dataframe same like PyQt View and Model (if I revise model view will change )

### Feature Description

from typing import Callable


class Index():
    def __init__(self,column = -1,row = -1):
        self.column = column
        self.row = row
    def check(self,reviseRange):
        """"""if self.column,self.index in range return True""""""
        return True
class dataframe:
    def __init__(self):
        self.handlers = {Index:Callable}#index,function
    def _trigger(self,reviseRange):
        """"""use @ to adapt iloc loc __setitem__ """"""
        for i,f in self.handlers.items():
            if i.check():
                f(reviseRange)
        


### Alternative Solutions

pyqt singal

### Additional Context

_No response_","['Enhancement', 'Needs Triage', 'Closing Candidate']",,2025-07-11 01:25:12+00:00,2025-08-05 16:19:10+00:00,,25.620810185185185
61828,BUG: Dataframe arithmatic operators don't work with Series using fill_value,"- [x] closes #61581 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Removed a test which checked for expected error to be raised and a corner case. Added a test case to test multiple operators with Dataframe x Series operations while using fill_value
",[],,2025-07-10 22:54:01+00:00,2025-07-15 18:49:30+00:00,,4.830196759259259
61827,DOC: Correct error message in AbstractMethodError for methodtype argument,"Fixing an error message in the AbstractMethodError class found in pandas/errors/__init__.py.
Currently:
raise ValueError(
    f""methodtype must be one of {methodtype}, got {types} instead.""
)
Here, {methodtype} and {types} are swapped.
This means if you called this error with methodtype=""foo"", the message would read:
methodtype must be one of foo, got {'method', 'classmethod', 'staticmethod', 'property'} instead.

That‚Äôs confusing, because the set of valid types should be listed after ‚Äúmust be one of‚Äù, and the invalid value you passed should be listed after ‚Äúgot‚Äù.


Corrected:
=======
raise ValueError(
    f""methodtype must be one of {types}, got {methodtype} instead.""
)
Now, if you called this error with methodtype=""foo"", the message would read:
methodtype must be one of {'method', 'classmethod', 'staticmethod', 'property'}, got foo instead.

This is clearer and follows standard error message conventions.",['Error Reporting'],,2025-07-10 21:10:11+00:00,2025-07-11 22:50:19+00:00,,1.069537037037037
61826,"TST: enable 2D tests for MaskedArrays, fix+test shift","- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Testing', 'NA - MaskedArrays']",,2025-07-10 17:21:01+00:00,2025-07-11 16:41:58+00:00,,0.9728819444444444
61824,BUG: `mask` in `test_mask_stringdtype` would always return the same result regardless of `cond`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# test_mask_stringdtype
obj = pd.DataFrame(
    {""A"": [""foo"", ""bar"", ""baz"", pd.NA]},
    index=[""id1"", ""id2"", ""id3"", ""id4""],
    dtype=pd.StringDtype(),
)
filtered_obj = pd.DataFrame(
    {""A"": [""this"", ""that""]}, index=[""id2"", ""id3""], dtype=pd.StringDtype()
)
expected = pd.DataFrame(
    {""A"": [pd.NA, ""this"", ""that"", pd.NA]},
    index=[""id1"", ""id2"", ""id3"", ""id4""],
    dtype=pd.StringDtype(),
)

filter_ser = pd.Series([False, True, True, False])
obj.mask(filter_ser, filtered_obj)
#         A
# id1  <NA>
# id2  this
# id3  that
# id4  <NA>

filter_ser = pd.Series([True, False, False, True])
obj.mask(filter_ser, filtered_obj)
#         A
# id1  <NA>
# id2  this
# id3  that
# id4  <NA>

filter_ser = pd.Series([False, False, False, False])
obj.mask(filter_ser, filtered_obj)
#         A
# id1  <NA>
# id2  this
# id3  that
# id4  <NA>

filter_ser = pd.Series([True, True, True, True])
obj.mask(filter_ser, filtered_obj)
#         A
# id1  <NA>
# id2  this
# id3  that
# id4  <NA>
```

### Issue Description

Found during #60772 .
I suppose the purpose of this test is to check if `mask` works as expected with `pd.StringDtype()` (See #40824 ), but the test seems to return the same result regardless of `cond` since it fails to align in `_where`.

If we want to check if `mask` replaces with `other` only where `cond` is `True` and let `cond` propagate where `cond` is `False`, I think `filter_ser` should have `index` so that `mask` can recognize the corresponding `other` value.

### Expected Behavior

```python
filter_ser = pd.Series([False, True, True, False], index=[""id1"", ""id2"", ""id3"", ""id4""])
obj.mask(filter_ser, filtered_obj)
#         A
# id1   foo
# id2  this
# id3  that
# id4  <NA>
```

### Installed Versions

<details>

commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.12.7
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : AMD64 Family 25 Model 80 Stepping 0, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : Korean_Korea.949

pandas                : 2.3.1
numpy                 : 2.3.1
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Testing']",,2025-07-10 13:32:51+00:00,2025-07-11 16:35:47+00:00,,1.127037037037037
61823,BUG: drop doesn't recognise MultiIndexes,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
foo = pd.DataFrame({'a': [1, 2, 3], 'b': ['foo', 'foo', 'bar']})
foo = pd.concat([foo], keys=['foo'], axis=1)
foo.drop(index='b', level=1, axis=1)
```

### Issue Description

When drop is called, an AssertionError is raised `AssertionError: axis must be a MultiIndex`
On inspection of the dataframe, the columns are a MultiIndex

### Expected Behavior

Drop should not raise an incorrect AssertionError

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.10.8
python-bits           : 64
OS                    : Linux
OS-release            : 6.6.87.2-microsoft-standard-WSL2
Version               : #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.1
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : 8.37.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : 6.129.3
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : 8.1.1
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>

Also tested in a clean 3.13.5 environment:

<details>

INSTALLED VERSIONS
------------------
commit                : c888af6d0bb674932007623c0867e1fbd4bdc2c6
python                : 3.13.5
python-bits           : 64
OS                    : Linux
OS-release            : 6.6.87.2-microsoft-standard-WSL2
Version               : #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.3.1
numpy                 : 2.3.1
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
",['Bug'],"{'login': 'khemkaran10', 'id': 168984037, 'node_id': 'U_kgDOChJ95Q', 'avatar_url': 'https://avatars.githubusercontent.com/u/168984037?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/khemkaran10', 'html_url': 'https://github.com/khemkaran10', 'followers_url': 'https://api.github.com/users/khemkaran10/followers', 'following_url': 'https://api.github.com/users/khemkaran10/following{/other_user}', 'gists_url': 'https://api.github.com/users/khemkaran10/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/khemkaran10/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/khemkaran10/subscriptions', 'organizations_url': 'https://api.github.com/users/khemkaran10/orgs', 'repos_url': 'https://api.github.com/users/khemkaran10/repos', 'events_url': 'https://api.github.com/users/khemkaran10/events{/privacy}', 'received_events_url': 'https://api.github.com/users/khemkaran10/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-07-10 09:39:27+00:00,2025-07-18 02:18:17+00:00,khemkaran10,7.69363425925926
61822,TST: Adding tests for validating  DataFrame.__setitem__ and .loc behavior,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Following up from #61804, adding tests to test_api.py to validate the DataFrame.__setitem__ and .loc assignment from Series",['Testing'],,2025-07-10 06:33:10+00:00,2025-08-01 05:32:38+00:00,,21.957962962962963
61821,DOC: Update link to pytz documentation,"Pytz documentation:
https://pypi.org/project/pytz/

The original link does not work:
http://pytz.sourceforge.net/index.html

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-07-10 00:46:51+00:00,2025-07-11 16:21:30+00:00,,1.6490625
61818,Improved installation instruction in docs for clarity,"Made a small improvement in the installation section to improve clarity for new users.  
First open-source contribution 
",[],,2025-07-09 10:51:03+00:00,2025-07-09 14:37:34+00:00,,0.15730324074074073
61817,"To develop a machine learning model that accurately predicts house prices based on 
various features such as location, size, number of bedrooms, and other relevant factors.",,[],,2025-07-09 03:51:38+00:00,2025-07-09 16:03:02+00:00,,0.5079166666666667
61815,DOC: Add Raises section to pd.to_numeric docstring,"- [x ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-08 19:44:19+00:00,2025-07-16 16:30:29+00:00,,7.865393518518519
61814,CI: Remove PyPy references in CI testing,"We haven't had reliable PyPy testing in many years now and no one to champion supporting this platform. We only have 1 job that builds pandas with PyPy on Python 3.9 (already dropped). It's made more difficult that conda-forge no longer supports PyPy either, https://conda-forge.org/news/2024/08/14/sunsetting-pypy/ 

I don't think it's worth using resources for this job anymore. pandas can still have code for PyPy compatibility for those wanting to support PyPy independently.",['CI'],,2025-07-08 19:27:53+00:00,2025-07-09 21:47:42+00:00,,1.0970949074074074
61811,DOC: Lacking information on error type raised by pd.to_numeric,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html

### Documentation problem

There is no ""Raises"" section that describes *which* errors are raised when setting the argument ""errors"" to ""raise"". It is not immediately clear if a conversion error will cause a TypeError or ValueError, or both depending on how conversion failed. 

This would be useful when doing as recommended to ""Catch exceptions explicitly instead."", and writing a `try: except:` with specific errors caught to avoid an overly generic error-catch which is bad practice etc. etc.

### Suggested fix for documentation

Add a ""Raises:"" section or include specific error names instead of the generic ""Raises an exception"".

See for example: https://numpy.org/doc/2.1/reference/generated/numpy.array.html

> For False it raises a ValueError if a copy cannot be avoided. Default: True.","['Docs', 'Needs Triage']",,2025-07-08 08:46:42+00:00,2025-07-16 16:29:48+00:00,,8.321597222222222
61810,DOC: update release process maintainer guide,"A small things I noticed that could use some update or clarification while releasing 2.3.1. 

cc @mroeschke can you check that this confirms with your experience when releasing 2.3.0?",['Docs'],,2025-07-08 08:06:45+00:00,2025-07-22 09:34:20+00:00,,14.060821759259259
61808,CLN: remove doctest-ignores,"Found this old branch, no idea if past-me was right about these being removable.",[],,2025-07-07 22:39:49+00:00,2025-07-08 15:01:48+00:00,,0.6819328703703704
61806,DEPS: Bump NumPy and tzdata,"These dependencies should have been released ~2 years ago by the time we release pandas 3.0

closes https://github.com/pandas-dev/pandas/issues/61588",['Dependencies'],,2025-07-07 20:11:43+00:00,2025-07-08 15:44:42+00:00,,0.8145717592592593
61805,DOC: Improve clarity of GroupBy introduction sentence,"This small change clarifies the introductory sentence of the GroupBy user guide, as recommended for documentation improvements. It makes the definition of the ""group by"" process more direct and easier for new users to understand.

- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).",[],,2025-07-07 18:03:11+00:00,2025-07-15 22:25:12+00:00,,8.181956018518518
61804,DOC: Improve documentation for DataFrame.__setitem__ and .loc assignment from Series,"- [x] closes #61662
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

The core problem is that when assigning a Series, pandas aligns on index and values in the Series that don't match an index label will result in NaN [DOC: Improve documentation for DataFrame.__setitem__ and .loc assignment from Series ¬∑ Issue #61662 ¬∑ pandas-dev/pandas](https://github.com/pandas-dev/pandas/issues/61662), but this behavior is poorly documented.
My proposed solution addresses the issue comprehensively by:

- Adding a complete docstring for DataFrame.__setitem__ with clear explanations and examples
- Enhancing the .loc documentation with specific notes about Series alignment
- Expanding the user guide with a dedicated section on Series assignment and index alignment
- Including comprehensive test cases to ensure the behavior is well-tested

The fix emphasizes that pandas performs index-based alignment rather than positional assignment, which is the source of confusion for many users. The documentation will now clearly explain that when you assign a Series to a DataFrame column, pandas matches values by index labels, not by position, and missing labels result in NaN values.
This solution follows pandas' documentation conventions and provides both reference documentation and practical examples that will help users understand and correctly use this important feature.",['Docs'],,2025-07-07 17:27:16+00:00,2025-08-01 15:31:04+00:00,,24.919305555555557
61803,Backport PR #61794 on branch 2.3.x (DOC: prepare 2.3.1 whatsnew notes for release),Backport PR #61794: DOC: prepare 2.3.1 whatsnew notes for release,['Docs'],,2025-07-07 16:36:39+00:00,2025-07-07 17:09:22+00:00,,0.022719907407407407
61802,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.11.12 ‚Üí v0.12.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.11.12...v0.12.2)
- [github.com/MarcoGorelli/cython-lint: v0.16.6 ‚Üí v0.16.7](https://github.com/MarcoGorelli/cython-lint/compare/v0.16.6...v0.16.7)
- [github.com/pre-commit/mirrors-clang-format: v20.1.5 ‚Üí v20.1.7](https://github.com/pre-commit/mirrors-clang-format/compare/v20.1.5...v20.1.7)
- [github.com/trim21/pre-commit-mirror-meson: v1.8.1 ‚Üí v1.8.2](https://github.com/trim21/pre-commit-mirror-meson/compare/v1.8.1...v1.8.2)
<!--pre-commit.ci end-->",['Code Style'],,2025-07-07 16:30:08+00:00,2025-07-07 18:09:15+00:00,,0.06883101851851851
61801,[backport 2.3.x] TST: update expected dtype for sum of decimals with pyarrow 21+ (#61799),Backport of #61799,[],,2025-07-07 13:46:21+00:00,2025-07-07 14:56:23+00:00,,0.04863425925925926
61800,[backport 2.3.x] BUG[string]: incorrect index downcast in DataFrame.join (#61771),Backport of #61771,[],,2025-07-07 13:19:28+00:00,2025-07-07 15:40:37+00:00,,0.09802083333333333
61799,TST: update expected dtype for sum of decimals with pyarrow 21+,This should fix the failure we started having for the pyarrow nightly build (behaviour change in https://github.com/apache/arrow/pull/44184 to increase the precision of the resulting decimal for sum),"['Testing', 'Arrow']",,2025-07-07 12:50:39+00:00,2025-07-07 13:41:24+00:00,,0.035243055555555555
61798,"Backport PR #61795 on branch 2.3.x (DOC: add section about upcoming pandas 3.0 changes (string dtype, CoW) to 2.3 whatsnew notes)","Backport PR #61795: DOC: add section about upcoming pandas 3.0 changes (string dtype, CoW) to 2.3 whatsnew notes",['Docs'],,2025-07-07 12:16:00+00:00,2025-07-07 13:25:28+00:00,,0.048240740740740744
61797,Backport PR #61705 on branch 2.3.x (DOC: add pandas 3.0 migration guide for the string dtype),Backport PR #61705: DOC: add pandas 3.0 migration guide for the string dtype,"['Docs', 'Strings']",,2025-07-07 11:09:03+00:00,2025-07-07 11:37:30+00:00,,0.019756944444444445
61796,Bump pypa/cibuildwheel from 2.23.3 to 3.0.1,"Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 2.23.3 to 3.0.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/releases"">pypa/cibuildwheel's releases</a>.</em></p>
<blockquote>
<h2>v3.0.1</h2>
<ul>
<li>üõ† Updates CPython 3.14 prerelease to 3.14.0b3 (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2471"">#2471</a>)</li>
<li>‚ú® Adds a CPython 3.14 prerelease iOS build (only when prerelease builds are <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enabled</a>) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2475"">#2475</a>)</li>
</ul>
<h2>v3.0.0</h2>
<p>See <a href=""https://github.com/henryiii""><code>@‚Äãhenryiii</code></a>'s <a href=""https://iscinumpy.dev/post/cibuildwheel-3-0-0/"">release post</a> for more info on new features!</p>
<ul>
<li>
<p>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#ios"">build wheels for iOS</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>ios</code> on a Mac with the iOS toolchain to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2286"">#2286</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2363"">#2363</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2432"">#2432</a>)</p>
</li>
<li>
<p>üåü Adds support for the GraalPy interpreter! Enable for your project using the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1538"">#1538</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2411"">#2411</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2414"">#2414</a>)</p>
</li>
<li>
<p>‚ú® Adds CPython 3.14 support, under the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> <code>cpython-prerelease</code>. This version of cibuildwheel uses 3.14.0b2. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
<p><em>While CPython is in beta, the ABI can change, so your wheels might not be compatible with the final release. For this reason, we don't recommend distributing wheels until RC1, at which point 3.14 will be available in cibuildwheel without the flag.</em> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-sources"">test-sources option</a>, and changes the working directory for tests. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2062"">#2062</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2284"">#2284</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2437"">#2437</a>)</p>
<ul>
<li>If this option is set, cibuildwheel will copy the files and folders specified in <code>test-sources</code> into the temporary directory we run from. This is required for iOS builds, but also useful for other platforms, as it allows you to avoid placeholders.</li>
<li>If this option is not set, behaviour matches v2.x - cibuildwheel will run the tests from a temporary directory, and you can use the <code>{project}</code> placeholder in the <code>test-command</code> to refer to the project directory. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2420"">#2420</a>)</li>
</ul>
</li>
<li>
<p>‚ú® Adds <a href=""https://cibuildwheel.pypa.io/en/stable/options/#dependency-versions""><code>dependency-versions</code></a> inline syntax (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2122"">#2122</a>)</p>
</li>
<li>
<p>‚ú® Improves support for Pyodide builds and adds the experimental <a href=""https://cibuildwheel.pypa.io/en/stable/options/#pyodide-version""><code>pyodide-version</code></a> option, which allows you to specify the version of Pyodide to use for builds. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2002"">#2002</a>)</p>
</li>
<li>
<p>‚ú® Add <code>pyodide-prerelease</code> <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enable</a> option, with an early build of 0.28 (Python 3.13). (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2431"">#2431</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-environment""><code>test-environment</code></a> option, which allows you to set environment variables for the test command. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2388"">#2388</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#xbuild-tools""><code>xbuild-tools</code></a> option, which allows you to specify tools safe for cross-compilation. Currently only used on iOS; will be useful for Android in the future. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2317"">#2317</a>)</p>
</li>
<li>
<p>üõ† The default <a href=""https://cibuildwheel.pypa.io/en/stable/options/#linux-image"">manylinux image</a> has changed from <code>manylinux2014</code> to <code>manylinux_2_28</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2330"">#2330</a>)</p>
</li>
<li>
<p>üõ† EOL images <code>manylinux1</code>, <code>manylinux2010</code>, <code>manylinux_2_24</code> and <code>musllinux_1_1</code> can no longer be specified by their shortname. The full OCI name can still be used for these images, if you wish. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2316"">#2316</a>)</p>
</li>
<li>
<p>üõ† Invokes <code>build</code> rather than <code>pip wheel</code> to build wheels by default. You can control this via the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#build-frontend""><code>build-frontend</code></a> option. You might notice that you can see your build log output now! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2321"">#2321</a>)</p>
</li>
<li>
<p>üõ† Build verbosity settings have been reworked to have consistent meanings between build backends when non-zero. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2339"">#2339</a>)</p>
</li>
<li>
<p>üõ† Removed the <code>CIBW_PRERELEASE_PYTHONS</code> and <code>CIBW_FREE_THREADED_SUPPORT</code> options - these have been folded into the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code></a> option instead. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>üõ† Build environments no longer have setuptools and wheel preinstalled. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2329"">#2329</a>)</p>
</li>
<li>
<p>üõ† Use the standard Schema line for the integrated JSONSchema. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2433"">#2433</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped support for building Python 3.6 and 3.7 wheels. If you need to build wheels for these versions, use cibuildwheel v2.23.3 or earlier. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2282"">#2282</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è The minimum Python version required to run cibuildwheel is now Python 3.11. You can still build wheels for Python 3.8 and newer. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1912"">#1912</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è 32-bit Linux wheels no longer built by default - the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#archs"">arch</a> was removed from <code>&quot;auto&quot;</code>. It now requires explicit <code>&quot;auto32&quot;</code>. Note that modern manylinux images (like the new default, <code>manylinux_2_28</code>) do not have 32-bit versions. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2458"">#2458</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è PyPy wheels no longer built by default, due to a change to our options system. To continue building PyPy wheels, you'll now need to set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> to <code>pypy</code> or <code>pypy-eol</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped official support for Appveyor. If it was working for you before, it will probably continue to do so, but we can't be sure, because our CI doesn't run there anymore. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2386"">#2386</a>)</p>
</li>
<li>
<p>üìö A reorganisation of the docs, and numerous updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2280"">#2280</a>)</p>
</li>
<li>
<p>üìö Use Python 3.14 color output in docs CLI output. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2407"">#2407</a>)</p>
</li>
<li>
<p>üìö Docs now primarily use the pyproject.toml name of options, rather than the environment variable name. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2389"">#2389</a>)</p>
</li>
<li>
<p>üìö README table now matches docs and auto-updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2427"">#2427</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2428"">#2428</a>)</p>
</li>
</ul>
<h2>v3.0.0rc3</h2>
<p>Not yet released, but available for testing.</p>
<p>Note - when using a beta version, be sure to check the <a href=""https://cibuildwheel.pypa.io/en/latest/"">latest docs</a>, rather than the stable version, which is still on v2.X.</p>
<!-- raw HTML omitted -->
<p>If you've used previous versions of the beta:</p>
<ul>
<li>‚ö†Ô∏è Previous betas of v3.0 changed the working directory for tests. This has been rolled back to the v2.x behaviour, so you might need to change configs if you adapted to the beta 1 or 2 behaviour. See [issue <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2406"">#2406</a>](<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2406"">pypa/cibuildwheel#2406</a>) for more information.</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/blob/main/docs/changelog.md"">pypa/cibuildwheel's changelog</a>.</em></p>
<blockquote>
<h3>v3.0.1</h3>
<p><em>5 July 2025</em></p>
<ul>
<li>üõ† Updates CPython 3.14 prerelease to 3.14.0b3 (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2471"">#2471</a>)</li>
<li>‚ú® Adds a CPython 3.14 prerelease iOS build (only when prerelease builds are <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enabled</a>) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2475"">#2475</a>)</li>
</ul>
<h3>v3.0.0</h3>
<p><em>11 June 2025</em></p>
<p>See <a href=""https://github.com/henryiii""><code>@‚Äãhenryiii</code></a>'s <a href=""https://iscinumpy.dev/post/cibuildwheel-3-0-0/"">release post</a> for more info on new features!</p>
<ul>
<li>
<p>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#ios"">build wheels for iOS</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>ios</code> on a Mac with the iOS toolchain to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2286"">#2286</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2363"">#2363</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2432"">#2432</a>)</p>
</li>
<li>
<p>üåü Adds support for the GraalPy interpreter! Enable for your project using the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1538"">#1538</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2411"">#2411</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2414"">#2414</a>)</p>
</li>
<li>
<p>‚ú® Adds CPython 3.14 support, under the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> <code>cpython-prerelease</code>. This version of cibuildwheel uses 3.14.0b2. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
<p><em>While CPython is in beta, the ABI can change, so your wheels might not be compatible with the final release. For this reason, we don't recommend distributing wheels until RC1, at which point 3.14 will be available in cibuildwheel without the flag.</em> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-sources"">test-sources option</a>, and changes the working directory for tests. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2062"">#2062</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2284"">#2284</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2437"">#2437</a>)</p>
<ul>
<li>If this option is set, cibuildwheel will copy the files and folders specified in <code>test-sources</code> into the temporary directory we run from. This is required for iOS builds, but also useful for other platforms, as it allows you to avoid placeholders.</li>
<li>If this option is not set, behaviour matches v2.x - cibuildwheel will run the tests from a temporary directory, and you can use the <code>{project}</code> placeholder in the <code>test-command</code> to refer to the project directory. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2420"">#2420</a>)</li>
</ul>
</li>
<li>
<p>‚ú® Adds <a href=""https://cibuildwheel.pypa.io/en/stable/options/#dependency-versions""><code>dependency-versions</code></a> inline syntax (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2122"">#2122</a>)</p>
</li>
<li>
<p>‚ú® Improves support for Pyodide builds and adds the experimental <a href=""https://cibuildwheel.pypa.io/en/stable/options/#pyodide-version""><code>pyodide-version</code></a> option, which allows you to specify the version of Pyodide to use for builds. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2002"">#2002</a>)</p>
</li>
<li>
<p>‚ú® Add <code>pyodide-prerelease</code> <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enable</a> option, with an early build of 0.28 (Python 3.13). (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2431"">#2431</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-environment""><code>test-environment</code></a> option, which allows you to set environment variables for the test command. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2388"">#2388</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#xbuild-tools""><code>xbuild-tools</code></a> option, which allows you to specify tools safe for cross-compilation. Currently only used on iOS; will be useful for Android in the future. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2317"">#2317</a>)</p>
</li>
<li>
<p>üõ† The default <a href=""https://cibuildwheel.pypa.io/en/stable/options/#linux-image"">manylinux image</a> has changed from <code>manylinux2014</code> to <code>manylinux_2_28</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2330"">#2330</a>)</p>
</li>
<li>
<p>üõ† EOL images <code>manylinux1</code>, <code>manylinux2010</code>, <code>manylinux_2_24</code> and <code>musllinux_1_1</code> can no longer be specified by their shortname. The full OCI name can still be used for these images, if you wish. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2316"">#2316</a>)</p>
</li>
<li>
<p>üõ† Invokes <code>build</code> rather than <code>pip wheel</code> to build wheels by default. You can control this via the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#build-frontend""><code>build-frontend</code></a> option. You might notice that you can see your build log output now! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2321"">#2321</a>)</p>
</li>
<li>
<p>üõ† Build verbosity settings have been reworked to have consistent meanings between build backends when non-zero. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2339"">#2339</a>)</p>
</li>
<li>
<p>üõ† Removed the <code>CIBW_PRERELEASE_PYTHONS</code> and <code>CIBW_FREE_THREADED_SUPPORT</code> options - these have been folded into the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code></a> option instead. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>üõ† Build environments no longer have setuptools and wheel preinstalled. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2329"">#2329</a>)</p>
</li>
<li>
<p>üõ† Use the standard Schema line for the integrated JSONSchema. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2433"">#2433</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped support for building Python 3.6 and 3.7 wheels. If you need to build wheels for these versions, use cibuildwheel v2.23.3 or earlier. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2282"">#2282</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è The minimum Python version required to run cibuildwheel is now Python 3.11. You can still build wheels for Python 3.8 and newer. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1912"">#1912</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è 32-bit Linux wheels no longer built by default - the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#archs"">arch</a> was removed from <code>&quot;auto&quot;</code>. It now requires explicit <code>&quot;auto32&quot;</code>. Note that modern manylinux images (like the new default, <code>manylinux_2_28</code>) do not have 32-bit versions. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2458"">#2458</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è PyPy wheels no longer built by default, due to a change to our options system. To continue building PyPy wheels, you'll now need to set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> to <code>pypy</code> or <code>pypy-eol</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped official support for Appveyor. If it was working for you before, it will probably continue to do so, but we can't be sure, because our CI doesn't run there anymore. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2386"">#2386</a>)</p>
</li>
<li>
<p>üìö A reorganisation of the docs, and numerous updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2280"">#2280</a>)</p>
</li>
<li>
<p>üìö Use Python 3.14 color output in docs CLI output. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2407"">#2407</a>)</p>
</li>
<li>
<p>üìö Docs now primarily use the pyproject.toml name of options, rather than the environment variable name. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2389"">#2389</a>)</p>
</li>
<li>
<p>üìö README table now matches docs and auto-updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2427"">#2427</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2428"">#2428</a>)</p>
</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/95d2f3a92fbf80abe066b09418bbf128a8923df2""><code>95d2f3a</code></a> Bump version: v3.0.1</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/40de3fe51083fa91bc8804c5a8de5c496f61ed52""><code>40de3fe</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2483"">#2483</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/920081014e8b136b4565824771dee1d489e046ef""><code>9200810</code></a> feat: added Python 3.14 preview for iOS (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2475"">#2475</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/94fe0a212fa9c1bfabd54ee45473c28f30227c03""><code>94fe0a2</code></a> [Bot] Update dependencies (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2482"">#2482</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/405ddd5315d4df8a9ffc569790a05e19f4344d7d""><code>405ddd5</code></a> fix: pyodide missing some logging (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2477"">#2477</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/34b4f1e86e47792c683de9ef813ed4d614159846""><code>34b4f1e</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2474"">#2474</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/e69b5532ab01c9d7c73e8e376a4e1219307cd4bd""><code>e69b553</code></a> [Bot] Update dependencies (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2473"">#2473</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/3e86452449f29075a6e1fa3a165a532effacfdab""><code>3e86452</code></a> [Bot] Update dependencies (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2471"">#2471</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/e73749579b3347d39c4793da6f01e22ef6e4363e""><code>e737495</code></a> chore(deps): bump actions/attest-build-provenance from 2.3.0 to 2.4.0 in the ...</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/588dee0e0c7780ab3264dfd3fab3a197f50306d3""><code>588dee0</code></a> docs: include Windows ARM in examples (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2468"">#2468</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/cibuildwheel/compare/v2.23.3...v3.0.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/cibuildwheel&package-manager=github_actions&previous-version=2.23.3&new-version=3.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","['Build', 'CI', 'Dependencies']",,2025-07-07 10:46:14+00:00,2025-07-28 12:59:29+00:00,,21.092534722222222
61795,"DOC: add section about upcoming pandas 3.0 changes (string dtype, CoW) to 2.3 whatsnew notes","This is largely copied from the equivalent notes in the 2.2 release notes at https://pandas.pydata.org/pandas-docs/stable/whatsnew/v2.2.0.html#upcoming-changes-in-pandas-3-0, with some updates (and some new content copied from WIP 3.0 release notes in https://github.com/pandas-dev/pandas/pull/61724)",['Docs'],,2025-07-07 09:43:16+00:00,2025-07-07 12:15:54+00:00,,0.10599537037037036
61794,DOC: prepare 2.3.1 whatsnew notes for release,"Prepping for doing a 2.3.1 release today, xref https://github.com/pandas-dev/pandas/issues/61590",['Docs'],,2025-07-07 09:03:14+00:00,2025-07-07 16:36:05+00:00,,0.31447916666666664
61793,Backport PR #61770 on branch 2.3.x (BUG: Fix unpickling of string dtypes of legacy pandas versions),Backport PR #61770: BUG: Fix unpickling of string dtypes of legacy pandas versions,"['Bug', 'Strings', 'IO Pickle']",,2025-07-07 07:41:47+00:00,2025-07-07 13:14:39+00:00,,0.2311574074074074
61791,DOC: Improve text color in dark mode for tutorial navigation buttons,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/getting_started/index.html#intro-to-pandas

### Documentation problem

In dark mode, the text within the tutorial navigation boxes under ""Intro to pandas"" has low contrast against the background, making it difficult to read.

<img width=""741"" height=""578"" alt=""Image"" src=""https://github.com/user-attachments/assets/2d941542-05b3-40f9-b235-769bfda89c31"" />


### Suggested fix for documentation

Lighten the font color to `#CED6DD` which matches the color of other texts in dark mode.","['Docs', 'Duplicate Report', 'Web', 'Needs Triage']",,2025-07-07 04:28:05+00:00,2025-07-07 13:15:53+00:00,,0.3665277777777778
61790,DOC: Add link to WebGL in pandas ecosystem,"Add link to WebGL in pandas ecosystem.
https://www.khronos.org/webgl/

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-07-06 21:57:00+00:00,2025-07-07 16:21:14+00:00,,0.7668287037037037
61789,CLN: remove and udpate for outdated _item_cache,"- [x] closes #61746 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Testing'],,2025-07-06 09:01:28+00:00,2025-07-07 16:29:16+00:00,,1.3109722222222222
61788,"BUG: read_excel() converts the string ""None"" in an Excel file to ""NaN""","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas. (I am working on compiling and testing this.)


### Reproducible Example

```python
import pandas as pd

excel_file = ""string_list.xlsx""

df_openpyxl = pd.read_excel(excel_file, engine=""openpyxl"")
df_calamine = pd.read_excel(excel_file, engine=""calamine"")

print(""openpyxl engine"")
print(""==============="")
print(df_openpyxl)

print(""calamine engine"")
print(""==============="")
print(df_calamine)
```

### Issue Description

The attached excel file `string_list.xlsx` contains the following data:

```
  Header
0  Alone
1   Bone
2   None
3   Cone
4   Done
```
It looks like this:

<img width=""612"" height=""452"" alt=""Image"" src=""https://github.com/user-attachments/assets/f1633bf0-e09a-469b-beb4-784d77a9d5cc"" />

When read with `read_excel()` using either the `openpyxl` or `calamine` engine it converts the string cell ""None"" to a `NaN`. The output from the above program is:

```
openpyxl engine
===============
  Header
0  Alone
1   Bone
2    NaN
3   Cone
4   Done
calamine engine
===============
  Header
0  Alone
1   Bone
2    NaN
3   Cone
4   Done
```

Note that ""None"" has changed to `NaN`.

Sample file: 

[string_list.xlsx](https://github.com/user-attachments/files/21082151/string_list.xlsx)

I checked `openpyxl`, `calamine` and `python-calamine` outside of Pandas and they each print the expected string ""None"".

### Expected Behavior

The string ""None"" from an Excel file shouldn't be interpreted as Python `None` and/or converted to `NaN`.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.11.1
python-bits           : 64
OS                    : Darwin
OS-release            : 24.5.0
Version               : Darwin Kernel Version 24.5.0: Tue Apr 22 19:53:26 PDT 2025; root:xnu-11417.121.6~2/RELEASE_X86_64
machine               : x86_64
processor             : i386
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.0
numpy                 : 2.1.3
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : 3.2.5
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'IO Excel', 'Closing Candidate']",,2025-07-05 22:56:52+00:00,2025-07-08 22:06:33+00:00,,2.9650578703703703
61787,DOCS: Add detailed Windows build instructions,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-05 21:33:33+00:00,2025-07-05 21:33:47+00:00,,0.00016203703703703703
61786,PERF: avoid object-dtype path in ArrowEA._explode,Identified in #61732,['Arrow'],,2025-07-05 21:19:41+00:00,2025-07-07 16:39:58+00:00,,1.805752314814815
61785,"REF: remove unreachable, stronger typing in parsers.pyx","- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['IO CSV'],,2025-07-05 21:08:44+00:00,2025-07-07 17:09:59+00:00,,1.8342013888888888
61784,ENH: Add Coefficient of Variation to DataFrame.describe(),"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

The `DataFrame.describe()` method includes standard deviation (`std`), but its significance is hard to interpret without context, as it depends on the data‚Äôs scale. The coefficient of variation (CV = `std / mean * 100`) provides a relative measure of variability, making it easier to assess if `std` is ""big.""

### Feature Description

Add CV as a row in `DataFrame.describe()` output for numeric columns, optionally enabled via `df.describe(include_cv=True)`.

## Example
```python
import pandas as pd
data = {'A': [10, 12, 14, 15, 13], 'B': [1000, 1100, 900, 950, 1050]}
df = pd.DataFrame(data)
desc = df.describe()
desc.loc['CV (%)'] = (df.std() / df.mean() * 100)
print(desc)
```

**Output**:
```
               A            B
count   5.000000     5.000000
mean   12.800000  1000.000000
std     1.923538    79.056942
min    10.000000   900.000000
25%    12.000000   950.000000
50%    13.000000  1000.000000
75%    14.000000  1050.000000
max    15.000000  1100.000000
CV (%) 15.027641     7.905694
```

## Benefits
- **Interpretability**: CV shows relative variability, aiding comparison across columns.
- **Usability**: Simplifies exploratory data analysis.
- **Relevance**: Widely used in fields like finance and biology.

### Alternative Solutions

Users can compute CV manually, but this is less convenient.

### Additional Context

_No response_","['Enhancement', 'Closing Candidate']",,2025-07-05 19:51:00+00:00,2025-07-07 21:26:48+00:00,,2.066527777777778
61783,PERF: Unnecessary string interning in read_csv?,"Going through parsers.pyx, particularly _string_box_utf8, I'm trying to figure out what the point of the hashtable checks are:

```
        k = kh_get_strbox(table, word)

        # in the hash table
        if k != table.n_buckets:
            # this increments the refcount, but need to test
            pyval = <object>table.vals[k]
        else:
            # box it. new ref?
            pyval = PyUnicode_Decode(word, strlen(word), ""utf-8"", encoding_errors)

            k = kh_put_strbox(table, word, &ret)
            table.vals[k] = <PyObject *>pyval

        result[i] = pyval
```

This was introduced in 2012 a9db003.  I don't see a clear reason why this isn't just

```
result[i] = PyUnicode_Decode(word, strlen(word), ""utf-8"", encoding_errors)
```

<s>My best guess is that it involves string interning.  Prior to py37, only small strings were interned.  Now most strings up to 4096 I think are interned.  Under the old system, the hashtable could prevent a ton of memory allocation, but that may no longer be the case.</s> No, that doesn't apply to runtime-created strings. So that may be the reason why, but if so it is still a valid one.

Does anyone have a longer memory than me on this?
","['Performance', 'Needs Triage']",,2025-07-05 16:26:49+00:00,2025-07-08 14:52:42+00:00,,2.9346412037037037
61779,TST: option_context bug on Mac GH#58055,"- [x] closes #58055 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Testing']",,2025-07-04 14:50:58+00:00,2025-07-07 16:42:39+00:00,,3.0775578703703705
61776,Request For Help: unexplained ArrowInvalid overflow,"Because of #61775 and to address failures in #61732 I'm trying out calling pd.to_datetime in ArrowEA._box_pa_array when we have a timestamp type.  AFAICT this isn't breaking anything at construction-time (see the assertion this adds, which isn't failing in any tests).  What is breaking is subsequent subtraction operations, that are raising `pyarrow.lib.ArrowInvalid: overflow`.

```
pytest ""pandas/tests/extension/test_arrow.py::TestArrowArray::test_arith_series_with_scalar[__sub__-timestamp[s, tz=US/Eastern]]""
[...]
E   pyarrow.lib.ArrowInvalid: overflow
```

It is happening on both sub and rsub ops.  When I try operating with a subset of of the array it looks like the exception only happens when i use a slice that contains a null.

To examine the buffers, I added a breakpoint after the assertion in the diff.  In the relevant case, `alt[8]` is null:

```
left = alt[8:10]
right = pa_array[8:10]

lb = left.buffers()[1]
rb = right.buffers()[1]

(Pdb) np.asarray(lb[64:72]).view(""M8[ns]"")
array(['NaT'], dtype='datetime64[ns]')

(Pdb) np.asarray(rb[64:72]).view(""M8[ns]"")
array(['1970-01-01T00:00:00.000000000'], dtype='datetime64[ns]')
```

So my current hypothesis is that when we get to the pc.subtract_checked call, it isn't skipping the iNaT entry despite the null bit, and the subtraction for that entry is overflowing.  This seems likely unintentional and may be an upstream bug cc @jorisvandenbossche?

Regardless of if it is an upstream bug, I could use guidance on how to make the construction with to_datetime work.  Filtering out Decimal(NaN) manually would be pretty inefficient.",[],,2025-07-04 02:04:25+00:00,2025-07-04 14:10:31+00:00,,0.5042361111111111
61775,API/BUG: different constructor behavior for numpy vs pyarrow dt64tzs,"```python
import pandas as pd

dtype1 = ""datetime64[ns, US/Eastern]""
dtype2 = ""timestamp[ns, US/Eastern][pyarrow]""

ts = pd.Timestamp(""2025-07-03 18:10"")

>>> pd.Series([ts], dtype=dtype1)[0]
Timestamp('2025-07-03 18:10:00-0400', tz='US/Eastern')

>>> pd.Series([ts], dtype=dtype2)[0]
Timestamp('2025-07-03 14:10:00-0400', tz='US/Eastern')
```

Long ago we decided that when passing tznaive datetimes and specifying a tzaware dtype, we treat the input as a wall-time.  It looks like the pyarrow path (which I'm pretty sure just ends up calling `pa.array([ts], type=...)`) treats it as a UTC time.

cc @jorisvandenbossche ","['Bug', 'API - Consistency', 'Arrow']",,2025-07-04 01:16:30+00:00,2025-07-07 16:54:31+00:00,,3.651400462962963
61774,CI: Add NumPy 1.26 test job,"This PR adds a CI job to test Pandas with NumPy 1.26 to ensure compatibility with the latest version.

- Related to issue: [#61588](https://github.com/pandas-dev/pandas/issues/61588)
- Installs NumPy 1.26.0 explicitly and runs the full test suite
- Helps identify future compatibility issues with NumPy releases

### Checklist

- [x] Closes #61588
- [x] Tests added and passed (via CI job)
- [x] All code checks passed (linting, CI)
- [ ] No new type hints were added
- [ ] No doc entry needed (not a new feature or bugfix)","['CI', 'Dependencies']",,2025-07-03 22:53:51+00:00,2025-07-08 10:19:37+00:00,,4.476226851851852
61773,BUG: Decimal(NaN) incorrectly allowed in ArrowEA constructor with tim‚Ä¶,"‚Ä¶estamp type

- [x] closes #61775
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Surfaced by #61732",['Arrow'],,2025-07-03 22:48:01+00:00,2025-07-07 16:54:30+00:00,,3.7545023148148147
61771,BUG[string]: incorrect index downcast in DataFrame.join,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Strings'],,2025-07-03 21:38:28+00:00,2025-07-07 13:15:03+00:00,,3.6504050925925924
61770,BUG: Fix unpickling of string dtypes of legacy pandas versions,"- [x] closes #61763
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v2.3.1.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Strings', 'IO Pickle']",,2025-07-03 20:35:31+00:00,2025-07-07 07:41:22+00:00,,3.4623958333333333
61768,"BUG: NA.__and__, __or__, __xor__ with np.bool_ objects","- [x] closes #58427 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

I expected this to break some other tests, but nope.",['Missing-data'],,2025-07-03 17:38:42+00:00,2025-07-03 22:49:57+00:00,,0.21614583333333334
61767,"Revert ""ENH: Allow third-party packages to register IO engines""",Reverts pandas-dev/pandas#61642,[],,2025-07-03 17:07:31+00:00,2025-07-03 17:07:39+00:00,,9.259259259259259e-05
61766,BUG: ensure to_numeric down-casts to uint64 for large unsigned integers,"[to_numeric(..., downcast=""unsigned"")](cci:1://file:///d:/Github/pandas/pandas/core/tools/numeric.py:48:0-315:21) failed to honour the requested
[uint64](cci:1://file:///d:/Github/pandas/pandas/tests/tools/test_to_numeric.py:580:0-586:44) dtype when values exceeded `np.iinfo(np.int64).max`, returning
`float64` instead and losing integer precision (GH #14422 /
[test_downcast_uint64](cci:1://file:///d:/Github/pandas/pandas/tests/tools/test_to_numeric.py:580:0-586:44)).  
Added a fallback that detects integral, non-negative float results and
safely casts them to `np.uint64`.  All existing logic remains unchanged
for other code paths; the previously xfailed test now passes.
",['Dtype Conversions'],,2025-07-03 10:24:24+00:00,2025-07-28 17:21:36+00:00,,25.289722222222224
61765,chore: testing,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-07-03 09:50:20+00:00,2025-07-03 09:52:02+00:00,,0.0011805555555555556
61763,BUG: StringDtype objects from pandas <2.3.0 cannot be reliably unpickled in 2.3.0.,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
### Using pandas 2.2.3
import pandas as pd

pd.DataFrame([['a', 'b'], ['c', 'd']]).astype('string').to_pickle('G:/temp/test2.pkl')
```

```python
### Using pandas 2.3.0

import pandas as pd

df = pd.read_pickle('G:/temp/test2.pkl') # looks ok

df.dtypes # raises AttributeError: 'StringDtype' object has no attribute '_na_value'

df[0] + df[1] # also raises AttributeError
```

### Issue Description

The code in a StringDtype object in 2.3 refers to an internal _na_value representation that appears not to have existed prior to 2.3.0. Pickled objects containing StringDtype columns pickled in earlier versions, including 2.2.3, may initially appear to unpickle successfully. However, listing the dtypes or even implicitly checking the dtypes by doing an operation, raises an AttributeError.

### Expected Behavior

The documentation at read_pickle indicates backward compatibility to version 0.20.3, so a pickle from 2.2.3 should be readable and usable in 2.3.0.

A current workaround is something like this, to wrap the object in a freshly created 2.3.0-compatible dtype:

```
def unpickle_wrap(fn):
   df = pd.read_pickle(fn)
   for col, dtype in df.dtypes.items():
       if pd.api.types.is_string_dtype(dtype):
           df[col] = df[col].astype(object).astype('string')
   return df
```

### Installed Versions

<details>

In [55]: pd.show_versions()

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.11.12
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.3.0
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : 9.3.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : 1.5.0
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.1
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.4.0
matplotlib            : 3.10.3
numba                 : 0.61.2+0.g1e70d8ceb.dirty
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : 8.4.1
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.5.1
scipy                 : 1.15.2
sqlalchemy            : 2.0.41
tables                : None
tabulate              : 0.9.0
xarray                : 2025.6.1
xlrd                  : None
xlsxwriter            : 3.2.5
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>

(Edit: fixed example to make copy-pastable, and confirmed on main)","['Bug', 'Strings', 'IO Pickle']","{'login': 'Liam3851', 'id': 546210, 'node_id': 'MDQ6VXNlcjU0NjIxMA==', 'avatar_url': 'https://avatars.githubusercontent.com/u/546210?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Liam3851', 'html_url': 'https://github.com/Liam3851', 'followers_url': 'https://api.github.com/users/Liam3851/followers', 'following_url': 'https://api.github.com/users/Liam3851/following{/other_user}', 'gists_url': 'https://api.github.com/users/Liam3851/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Liam3851/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Liam3851/subscriptions', 'organizations_url': 'https://api.github.com/users/Liam3851/orgs', 'repos_url': 'https://api.github.com/users/Liam3851/repos', 'events_url': 'https://api.github.com/users/Liam3851/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Liam3851/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-07-02 21:35:45+00:00,2025-07-07 07:41:23+00:00,Liam3851,4.420578703703704
61762,Update __init__.py,"Added a quick explanation for Extension Arrays to better understand for new comers. 
DOC: Wrap long comment lines to fix E501 error
",[],,2025-07-02 17:28:32+00:00,2025-07-02 21:20:11+00:00,,0.16086805555555556
61761,Update __init__.py,"Added a quick explanation about Extension Arrays to better understand for the new users

",[],,2025-07-02 17:09:50+00:00,2025-07-02 17:17:06+00:00,,0.005046296296296296
61760,BUG: .describe() doesn't work for EAs #61707,"This PR fixes a bug where Series.describe() fails on certain `ExtensionArray` dtypes such as `pint[kg]`, due to attempting to cast the result to `Float64Dtype`. This is because some of the produced statistics are not castable to float, which raises errors like DimensionalityError.

We now avoid forcing a Float64Dtype return dtype when the EA‚Äôs scalar values cannot be safely cast. Instead:

If the EA produces outputs with mixed dtypes, the result is returned with `dtype=None`.

- [x] closes #61707 
- [x] Adds a regression test.
- [x] pre-commit checks passed
- [x] Adds type annotations
- [x] Adds a whatsnew entry
",[],,2025-07-02 11:41:36+00:00,2025-07-20 05:48:33+00:00,,17.75482638888889
61759,chore: remove redundant words in comment,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


remove redundant words in comment",['Docs'],,2025-07-02 08:02:05+00:00,2025-07-02 16:48:18+00:00,,0.36542824074074076
61757,TST (string dtype): resolve skip in misc test_memory_usage,"Addressing one of the remaining xfail/skips for the string dtype, see https://github.com/pandas-dev/pandas/pull/61727#issuecomment-3020456375 for context",['Strings'],,2025-07-01 20:16:37+00:00,2025-07-02 09:02:48+00:00,,0.5320717592592593
61756,DOC: Pass docstring validation for Index.infer_objects,"Currently failing on main.

Missed in https://github.com/pandas-dev/pandas/pull/61736","['Docs', 'Index']",,2025-07-01 18:12:29+00:00,2025-07-01 19:14:44+00:00,,0.043229166666666666
61755,"Revert ""[2.3.x] DEPS: Drop Python 3.9 (#60792)""","This reverts commit 2e617d36af3592a371fe09a1aec8282f9db550da.

Re-enables 3.9 wheels and testing for the 2.3.x branch
xref https://github.com/pandas-dev/pandas/issues/61590


- [ ] closes #61579 (Replace xxxx with the GitHub issue number)","['Build', 'CI']",,2025-07-01 18:00:36+00:00,2025-07-03 07:21:26+00:00,,1.5561342592592593
61754,[backport 2.3.x] TST/CI: temporary upper pin for scipy in downstream tests for compat with statsmodels (#61750),Backport of https://github.com/pandas-dev/pandas/pull/61750,[],,2025-07-01 16:56:26+00:00,2025-07-01 19:48:53+00:00,,0.11975694444444444
61753,BUG: Segmentation fault when misusing `VariableWindowIndexer.get_window_bounds`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
from pandas.core.indexers.objects import VariableWindowIndexer

variable_window_indexer = VariableWindowIndexer()
variable_window_indexer.get_window_bounds(1)
```

### Issue Description

Hi,

For a research paper, we carried out a large-scale benchmark of [Pynguin](https://www.pynguin.eu/), an Automatic Unit Test Generation Tool for Python, to test its new feature that can find Python interpreter crashes. In this benchmark, we found a potential bug in pandas, and we are making this issue to report it.

### Expected Behavior

In our opinion, pandas should not produce a segmentation fault when calling a public function. However, we don't know whether this function is part of pandas' public API so we just wanted to at least warn you that this behaviour exists, so that you can take the action that suits you best.

### Installed Versions

commit                : 0ab10aa1417f19ecf265ff9383b1aa851b02736b
python                : 3.10.16
python-bits           : 64
OS                    : Linux
OS-release            : 6.14.11-300.fc42.x86_64
Version               : #1 SMP PREEMPT_DYNAMIC Tue Jun 10 16:24:16 UTC 2025
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+2192.g0ab10aa141
numpy                 : 2.2.6
dateutil              : 2.9.0.post0
pip                   : 23.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
bottleneck            : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyiceberg             : None
pyreadstat            : None
pytest                : 8.4.1
python-calamine       : None
pytz                  : 2025.2
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : N/A
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None","['Bug', 'Window', 'Segfault', 'Needs Triage']",,2025-07-01 12:09:36+00:00,2025-07-02 16:46:47+00:00,,1.1924884259259259
61752,[backport 2.3.x] CI: clean up wheel build workarounds now that Cython 3.1.0 is out (#61446),Backport of https://github.com/pandas-dev/pandas/pull/61446,['Build'],,2025-07-01 08:27:22+00:00,2025-07-03 15:56:45+00:00,,2.3120717592592595
61751,[backport 2.3.x] DOC: move relevant whatsnew changes from 2.3.0 to 2.3.1 file (#61698),Backport of https://github.com/pandas-dev/pandas/pull/61698,[],,2025-07-01 08:16:13+00:00,2025-07-01 12:08:10+00:00,,0.1610763888888889
61750,TST/CI: temporary upper pin for scipy in downstream tests for compat with statsmodels,See https://github.com/statsmodels/statsmodels/issues/9542 / https://github.com/statsmodels/statsmodels/issues/9584,['CI'],,2025-07-01 07:59:53+00:00,2025-07-01 16:41:55+00:00,,0.3625231481481481
61749,TST: fix decimal cast error message for pyarrow nightly tests,"PyArrow seems to have updated the error message, this updates our assert to catch both ""Decimal"" and ""Decimal128""",['CI'],,2025-07-01 07:55:04+00:00,2025-07-01 16:07:11+00:00,,0.34174768518518517
61746,CLN: references/tests for item_cache,"test_to_dict_of_blocks_item_cache is about _item_cache invalidation, but IIRC we got rid of that cache a while back.  grepping for ""item_cache"" i see a bunch of comments that are no longer accurate and tests that are no longer testing anything.  These can be updated/removed.",['Clean'],"{'login': 'chilin0525', 'id': 41913261, 'node_id': 'MDQ6VXNlcjQxOTEzMjYx', 'avatar_url': 'https://avatars.githubusercontent.com/u/41913261?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/chilin0525', 'html_url': 'https://github.com/chilin0525', 'followers_url': 'https://api.github.com/users/chilin0525/followers', 'following_url': 'https://api.github.com/users/chilin0525/following{/other_user}', 'gists_url': 'https://api.github.com/users/chilin0525/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/chilin0525/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/chilin0525/subscriptions', 'organizations_url': 'https://api.github.com/users/chilin0525/orgs', 'repos_url': 'https://api.github.com/users/chilin0525/repos', 'events_url': 'https://api.github.com/users/chilin0525/events{/privacy}', 'received_events_url': 'https://api.github.com/users/chilin0525/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-30 17:44:51+00:00,2025-07-07 16:29:17+00:00,chilin0525,6.947523148148148
61745,"Backport PR #61744 on branch 2.3.x (CI: if no docstring, create error GL08 and don't validate - fix for numpydoc 1.9)","backporting the change related to `numpydoc` upgrade

Backport of #61744",[],,2025-06-30 17:41:40+00:00,2025-07-01 08:09:41+00:00,,0.6027893518518519
61744,"CI: if no docstring, create error GL08 and don't validate - fix for numpydoc 1.9","`validate_docstrings` was failing with `numpydoc` 1.9 on cython methods that have no docstrings.  When no docstring, there is nothing to validate.

Partially addresses the CI issue mentioned in #61740 
","['CI', 'Code Style']",,2025-06-30 01:34:01+00:00,2025-06-30 16:52:17+00:00,,0.6376851851851851
61743,BUG: Assigning boolean series with boolean indexer,"Supersedes #60127
- [x] closes #57338 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Indexing', 'PDEP6-related']",,2025-06-29 20:15:55+00:00,2025-07-01 17:47:12+00:00,,1.8967245370370371
61741,TST: Test coverage for Excel Formatter.py,"- ‚úÖ  [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- ‚úÖ  All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
Added tests to the ExcelFormatter class, which gets the file up to 93\% test coverage in total. The only exception is the `.write` function, (otherwise writing to excel in the first place is not tested) but is already most definitely covered, but should be tested further.


- Leo","['Testing', 'IO Excel']",,2025-06-29 19:07:46+00:00,2025-07-01 02:34:34+00:00,,1.3102777777777779
61739,DOC: Fix grammar in AUTHORS.md,This pull request fixes minor grammatical errors and improves clarity in the AUTHORS.md file to enhance the overall documentation quality. Thank you for considering this contribution!,['Docs'],,2025-06-29 12:56:53+00:00,2025-06-30 17:18:36+00:00,,1.1817476851851851
61738,ENH: Added features of issue 61691,"- [x] closes #61691 
- [ ] [Tests added]
- [ ] All [code checks passed]
",[],,2025-06-29 12:48:13+00:00,2025-06-30 17:19:19+00:00,,1.1882638888888888
61737,ENH: Parallelization support for pairwise correlation,"- [X] closes #40956
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


Used cython.parallel to parallelize the nancorr function. 
","['Enhancement', 'Multithreading', 'cov/corr']",,2025-06-29 09:44:11+00:00,2025-07-21 17:10:00+00:00,,22.30959490740741
61736,DOC: Add missing Index.infer_objects link to API reference,"- [x] closes #61733 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature - NA
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions - NA.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-06-29 04:30:29+00:00,2025-06-30 17:20:11+00:00,,1.534513888888889
61733,DOC: Index.infer_objects is missing from docs,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/reference/api/pandas.Index.html

### Documentation problem

While `infer_objects()` is listed as a method for `pandas.Index`, the link to the actual method documentation is missing.


### Suggested fix for documentation

Probably have to add `Index.infer_objects` into the conversion section of `pandas/doc/source/reference/indexing.rst`","['Docs', 'good first issue', 'Index']",,2025-06-28 18:12:20+00:00,2025-06-30 17:20:12+00:00,,1.9637962962962963
61731,ENH: Type support for variables in `DataFrame.query()`,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Now using variables inside `df.query(""col > @my_var"")` doesn‚Äôt produce strong typing:
IDEs don‚Äôt catch type mismatches (e.g. `my_var` is a string but `col` is numeric).

### Feature Description

Add type support in `pandas-stubs` so that functions like `query()`:

- Accept variables bound via `@`
- Validate that their types align with the DataFrame column dtype
- Offer **autocomplete** in IDEs

Example:
```python
from typing import TypedDict

class Record(TypedDict):
    a: int
    b: str

df: DataFrame[Record] = ...
my_var: int = 5
filtered = df.query(""a > @my_var"") 

other_var: str = ""foo""
df.query(""a > @other_var"")  
# Should flag type mismatch in IDE/type-checker

### Alternative Solutions

```python
# Validate variable type before calling query
from typing import assert_type

my_var = 5
assert_type(my_var, int)  # Mypy will enforce this
df.query(""a > @my_var"")
```
OR
```python
# Type-safe alternative using boolean indexing
df[df[""a""] > my_var]  # Fully type-checkable, no strings

### Additional Context

_No response_","['Enhancement', 'Needs Triage']",,2025-06-28 14:29:23+00:00,2025-06-29 05:00:09+00:00,,0.6046990740740741
61730,BUG: `read_csv()` : inconsistent dtype and content parsing.,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
""field1"" ,""field2"" ,""field3"" ,""field4"" ,""field5""      ,""field6"" ,""field7""
""1""      ,      14 ,       6 ,      21 ,""euia""        ,    0.54 ,    1
""2""      ,      30 ,       5 ,      26 ,""euia""        ,    0.82 ,    1
""2""      ,       1 ,       0 ,       0 ,""eua""         ,    0    ,    0
""3""      ,      27 ,       7 ,      17 ,""euia""        ,    1    ,    1
""4""      ,      14 ,       0 ,       9 ,""euia""        ,    0.64 ,    0.92
""4""      ,      10 ,       0 ,       0 ,""eua""         ,    0    ,    0
""9""      ,      17 ,       1 ,       6 ,""euia""        ,    0.65 ,    0.58
""10""     ,      27 ,       4 ,      13 ,""eu""          ,    1    ,     
""10""     ,         ,       0 ,       0 ,""euia""        ,    0    ,     
""12""     ,      14 ,       1 ,      13 ,""uia""         ,    1    ,    0.75
""12""     ,       5 ,       1 ,       4 ,""ui   eiuaea"" ,    1    ,    1
""13""     ,      22 ,       3 ,       7 ,"" euia""       ,    0.89 ,    1
""6""      ,      22 ,       3 ,       5 ,""euia""        ,    0.84 ,    0.79
""7""      ,      23 ,       5 ,       4 ,""uia""         ,    0.78 ,    1
""8""      ,      26 ,      11 ,       2 ,""euia""        ,    1.12 ,    1.30
""5""      ,      28 ,       3 ,       3 ,""euia""        ,    0.72 ,    0.68



import pandas as pd


pd.set_option('display.max_columns', 1000)
pd.set_option('display.max_rows', 1000)
pd.set_option('display.width', 1000)
pd.set_option(""display.max_colwidth"", None)

df = pd.read_csv(""exemple.csv"")
# df = pd.read_csv(""exemple.csv"", quoting=1)  # change nothing
list(df.columns)
df.dtypes
list(df[""field5      ""])

df = pd.read_csv(""exemple.csv"", sep=r""\s*,\s*"", engine=""python"")
list(df.columns)
df.dtypes
list(df[""field5""])

df = pd.read_csv(""exemple.csv"", quoting=2)
list(df.columns)
df.dtypes
list(df[""field5      ""])

df = pd.read_csv(""exemple.csv"", quoting=3)
list(df.columns)
df.dtypes
list(df['""field5""      '])

df = pd.read_csv(""exemple.csv"", quoting=2, dtype={""field1 "": ""object"",
                                                  ""field2 "": ""Int32"",  # fail
                                                  ""field3 "": ""int"",
                                                  ""field4 "": ""int"",
                                                  ""field5      "": ""object"",
                                                  ""field6 "": ""float"",
                                                  ""field7"": ""float""  # fail
                                                  })
```

### Issue Description

Hello,

I tried to parse a file like the exemple given, and I spent an afternoon just on this. Nothing looks logical to me. So I am sorry, I will make one ticket for everything, cause it would be to long to make one for each problem. Fill free to divide it in several task.

Expected colums dtypes look quite easy to guess to me¬†: the user used quotemarks on `field1` to force a string type. Fields 2-4 are expected to be integers. It could be almost understandable if `field2` was converted to a float because np.int dtype doesn‚Äôt manage NA values. But Pandas has a integer type which does. So there is no reason. `Field5` should be string containing text between quotemarks. Field 6 and 7 are expected to be float. Let see what happen

First try¬†: `df = pd.read_csv(""exemple.csv"")`

* Columns names quotemarks are removed, but trailing space are keeped. That‚Äôs quite surprising as there is no logic¬†:‚ÄØOr you consider quotemarks are text delimiters and should be removed, but in this case, why to keep characters outside the delimiters‚ÄØ? Or you consider a everything is part of the string and in this case you must keep everything.
* dtypes are problematic:
    - `field1` have been implicitly converted to `int64`. The user explicitly asked for a `str`. The convention ‚Äúwhat is between quotemarks is a string‚Äù is common to R, C++ and Python and wide spread. Why to not respect it
    - `field2` is converted to a string. Missing values are a common case to handle. I would understand a conversion to float, or an error raised. But why a conversion to a string ?
    - `field5` have the same problem than column names.
    - `field7` is converted to a string. Here it is not understandable at all as np.float handle NA values.
    - Other field are correct. Which is also a little surprising. So initials and trailing spaces pose problem in string fields and empty fields, but not in number field‚ÄØ?


Case¬†: `df = pd.read_csv(""exemple.csv"", sep=r""\s*,\s*"", engine=""python"")`

Here init and trailing spaces are removed, but not quotemarks. This ticket is probably already opened somewhere. Field types are ok, excepted for `field2`, which should be `Int32`.


Case¬†: `df = pd.read_csv(""exemple.csv"", quoting=2)`

Here I tried to explicitly tel the methods that quotemarks means string. Nonetheless it doesn‚Äôt work. But integer field are now floats. Excepted for `field2` and `field7` which are‚Ä¶ strings‚ÄØ!


Case¬†: `df = pd.read_csv(""exemple.csv"", quoting=3)`

Here, the parsing of column names and string fields is wrong, but at least logical. It just keep everything.
Fields containing NA values are still converted to string.


Case : `df = pd.read_csv(""exemple.csv"", quoting=2, dtype={""field1 "": ""object"",
                                                  ""field2 "": ""Int32"",  # fail
                                                  ""field3 "": ""int"",
                                                  ""field4 "": ""int"",
                                                  ""field5      "": ""object"",
                                                  ""field6 "": ""float"",
                                                  ""field7"": ""float""  # fail
                                                  })`

Raise errors and doesn‚Äôt handle fields names correctly.

### Expected Behavior

No implicit conversion. Never.

For string field¬†: I understand I may have to tweak the `quoting` and `quotechar` parameters, but once done, everything between quotemark should be string, not int or float, and white spaces outside should be ignored.

For float fields containing NA values¬†: should be float field with NA values.

For int field containing NA values¬†: ideally should be parsed as pandas `IntXX` which handle NA values. At minimum as a np.float. But never a string.

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.13.3
python-bits           : 64
OS                    : Linux
OS-release            : 6.12.34-1-MANJARO
Version               : #1 SMP PREEMPT_DYNAMIC Thu, 19 Jun 2025 15:49:06 +0000
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : fr_FR.UTF-8
LOCALE                : fr_FR.UTF-8

pandas                : 2.3.0
numpy                 : 2.3.1
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 9.3.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : 1.1
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.4.0
matplotlib            : 3.10.3
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.4.1
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.3
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'IO CSV']",,2025-06-28 10:24:36+00:00,2025-07-19 15:50:19+00:00,,21.22619212962963
61729,BUG: AttributeError in pandas.core.algorithms.diff when passing non-numeric types,"‚Ä¶g non-numeric types

- [ ] closes #61728
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-28 08:45:26+00:00,2025-06-30 17:32:52+00:00,,2.366273148148148
61728,BUG: AttributeError in pandas.core.algorithms.diff when passing non-numeric types,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
pd.Series([1, 2, 3]).diff(""hello"")


Raises:

AttributeError: 'str' object has no attribute 'is_integer'
```

### Issue Description

When passing non-numeric types (like strings, None, or other objects) to the `diff` function in `pandas/core/algorithms.py`, it raises an `AttributeError` instead of the expected `ValueError`. This affects any code that uses `Series.diff()`, `DataFrame.diff()`, or calls the `diff` function directly.

The issue occurs because the validation logic tries to call `n.is_integer()` on non-float objects that don't have this method, resulting in an `AttributeError`.

### Expected Behavior

```python
import pandas as pd
pd.Series([1, 2, 3]).diff(""hello"")
```

Should raise:
```
ValueError: periods must be an integer
```

### Installed Versions

<details>
python                  : 3.12.10

OS                         : Linux
OS-release            : 4.18.0-553.56.1.el8_10.x86_64
</details>
","['Bug', 'Needs Triage']",,2025-06-28 08:40:10+00:00,2025-06-30 17:32:41+00:00,,2.369803240740741
61727,TST[string]: update expecteds for using_string_dtype to fix xfails,"It isn't 100% obvious that the new repr for Categoricals is an improvement, but it's non-crazy.  One of the remaining xfails one is for `eval(repr(categorical_index))` round-tripping that won't be fixable unless we revert back to the old repr behavior.

I'm pretty sure that the fix in test_astype_dt64_to_string is correct and the test is just wrong, but merits a close look.

That leaves 12 xfails, including the one un-fixable round-trip one that we'll just remove.  Of those...
- [x] test_join_on_key i think is surfacing an unrelated bug that I'll take a look at (xref #61771)
- [x] test_to_dict_of_blocks_item_cache is failing because we don't make series.values read-only for ArrowStringArray.  I think @mroeschke can comment on how viable/important that is.
- [ ] test_string_categorical_index_repr is about CategoricalIndex repr that span multiple lines; with the StringDtype the padding is changed.
- [x] 4 in pandas/tests/io/json/test_pandas.py that im hoping @WillAyd can take point on 
- [ ] test_to_string_index_with_nan theres a MultiIndex level that reprs with a `nan` instead of `NaN`.  Not a huge deal but having mixed-and-matched nans/NaNs in the repr is weird.
- [ ] test_from_records_sequencelike i don't have a good read on
- [x] tests.base.test_misc::test_memory_usage is skipped instead of xfailed, but the reason says that it ""doesn't work properly"" for arrow strings which seems xfail-adjacent.  Instead of skipping can we update the expected behavior cc @jorisvandenbossche ?

(Update: looks like I missed one in test_http_headers and another in test_fsspec)",[],,2025-06-27 22:59:38+00:00,2025-07-10 16:47:38+00:00,,12.741666666666667
61726,CI: temporarily pin numpydoc<1.7 to unblock docstring validation (GH#61720),"Temporarily pin **numpydoc<1.7** to unblock the *docstring-validation* job.

`numpydoc` 1.7.0 raises  
`AttributeError: 'getset_descriptor' object has no attribute '__module__'`  
inside `numpydoc/validate.py`, causing pandas‚Äô *Code Checks / Docstring validation*
step to fail before any pandas code is run (see GH #61720).

This PR

* **pins** `numpydoc<1.7` in `environment.yml`  
  (propagated to `requirements-dev.txt`);
* **fixes** a duplicate **Returns / Yields** section in
  `pandas/_config/config.py::option_context`;
* **marks** an expected warning in `doc/user_guide/timeseries.rst`
  with `:okwarning:` so Sphinx no longer treats it as an error.

Together these changes restore a green CI across all jobs.

### Notes
* All changes are limited to **dev/CI and docs**‚Äîno impact on end users.
* Once an upstream fix lands in numpydoc, we‚Äôll remove the version pin.
* No new tests are required; a successful CI run itself demonstrates the fix.

---

- [x] closes #61720  
- [x] CI green locally (`pre-commit run --all-files` & `doc/make.py --warnings-are-errors`)  
- [ ] added to `doc/source/whatsnew/vX.X.X.rst` ‚Üí **not needed** (CI-only)

",[],,2025-06-27 21:50:17+00:00,2025-06-27 23:34:50+00:00,,0.07260416666666666
61725,DOC: Pin numpydoc=1.8.0,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Dependencies']",,2025-06-27 17:24:25+00:00,2025-06-30 16:53:34+00:00,,2.978576388888889
61723,DEPS: bump pyarrow minimum version from 10.0 to 12.0,"For our support window of 2 years, we can bump the minimum pyarrow version to 12.0.1 (see list of release dates here: https://arrow.apache.org/release/, we could also directly bump to 13 assuming the final 3.0 release will happen in 1-2 months).","['Dependencies', 'Arrow']",,2025-06-27 15:25:10+00:00,2025-07-03 08:18:42+00:00,,5.703842592592593
61722,String dtype: turn on by default,"Now that 2.3.0 is released, time to switch the default on main to prepare for a 3.0 release (and also such that people using nightlies get this)

I assume this might also still uncover some failing tests. And the docstrings will still fail for sure.",['Strings'],,2025-06-27 13:43:03+00:00,2025-07-16 17:07:20+00:00,,19.141863425925926
61721,DOC: https://pandas.pydata.org/pandas-docs/version/2.3 does not work,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/pandas-docs/version/2.3

### Documentation problem

https://pandas.pydata.org/pandas-docs/version/2.3 does not work, though https://pandas.pydata.org/pandas-docs/version/2.2 does; only https://pandas.pydata.org/pandas-docs/version/2.3.0 is available.

### Suggested fix for documentation

use https://pandas.pydata.org/pandas-docs/version/2.3 to be a floating release for the latest 2.3.x","['Docs', 'Web']",,2025-06-27 12:29:39+00:00,2025-07-08 07:47:11+00:00,,10.803842592592593
61720,BUG: CI docstring-validation fails with AttributeError in numpydoc validate.py,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.

### Reproducible Example

The failure is visible in GitHub Actions.

**Steps**
1. Push any branch that is up-to-date with `pandas-dev/main`, **or** open a fresh PR.
2. Observe workflow **Code Checks / Docstring validation, typing, and other manual pre-commit hooks**.
3. The job stops in step *Run docstring validation* with the traceback below.

**Example failing runs (public logs)** 
- https://github.com/pandas-dev/pandas/actions/runs/15921431436 ‚Üê PR #61718  
- https://github.com/pandas-dev/pandas/actions/runs/15886481522 ‚Üê another PR on latest main

```text
File "".../site-packages/numpydoc/validate.py"", line 234, in name
    return ""."".join([self.obj.__module__, self.obj.__name__])
AttributeError: 'getset_descriptor' object has no attribute '__module__'. Did you mean: '__reduce__'?
```

### Issue Description

* The *docstring-validation* job crashes before any pandas code is executed, so all current PRs fail.
* The stack trace originates inside **numpydoc/validate.py**; no pandas files are involved.

### Expected Behavior

The *docstring-validation* step should complete without errors, allowing the entire CI workflow to finish green.

### Installed Versions

<details>

* python : 3.11.13  (conda-forge)
* pandas : source checkout of current `main` (not installed / build failed locally)
* numpydoc: 1.8.0
* os : Ubuntu-22.04 (GitHub Actions runner)

</details>
","['Bug', 'CI']",,2025-06-27 10:00:20+00:00,2025-06-27 23:40:55+00:00,,0.569849537037037
61716,POC: PDEP16 default to masked nullable dtypes,"This is the second of several POCs stemming from the discussion in #61618 (see also #61708).  The main goal is to see how invasive it would be.

Specifically, this implements the part of PDEP16 #58988 that changes the default numeric/bool dtypes to use numpy-nullable dtypes.  So `pd.Series(foo)` will behave roughly like `pd.Series(pd.array(foo))` does in main.

Notes:
- For POC purposes this takes the stand that we _never_ give numpy numeric/bool dtypes and always map `dtype=np.int64` to the masked dtype.
- The get_option checks will need to be updated to user a more performant check like for `using_string_dtype`
- The simplification in core.internals.construction will eventually be reverted as the MaskedArrays are updated to support 2D.
- This does *not* incorporate #61708.
- Currently 16773 tests failing locally (with `-m ""not slow and not db""`).  705 in window, 2036 in io (almost all of pytables is failing), 1997 (plus a ton more I already xfailed bc they get RecursionError) in computation.  tests.groupby.test_raises has 1110 that look to be mostly about getting the wrong class of exception or exception message.  Many in sparse too, though I don't have a number ATM.  Some of these merit issues:
    - [ ] #61709
    - [ ] #30188
    - [ ] RangeIndex.equals issue, see comments in asserters.py diff.
",['PDEP missing values'],,2025-06-26 22:30:58+00:00,2025-07-29 16:09:42+00:00,,32.735231481481485
61715,BUG/API: floordiv by zero in Int64Dtype,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
ser = pd.Series([0, 1])
ser2 = ser.astype(""Int64"")

>>> ser // 0
0    NaN
1    inf
dtype: float64

>>> ser2 // 0
0    0
1    0
dtype: Int64

# with int64[pyarrow] this just raises pyarrow.lib.ArrowInvalid: divide by zero
```

### Issue Description

We patch the results of floordiv in dispatch_fill_zeros, but don't do this for the masked dtypes, and the pyarrow one raises.

### Expected Behavior

Ideally these would be consistent across backends.

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Needs Triage']","{'login': 'manikrishna-m', 'id': 119017734, 'node_id': 'U_kgDOBxgRBg', 'avatar_url': 'https://avatars.githubusercontent.com/u/119017734?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/manikrishna-m', 'html_url': 'https://github.com/manikrishna-m', 'followers_url': 'https://api.github.com/users/manikrishna-m/followers', 'following_url': 'https://api.github.com/users/manikrishna-m/following{/other_user}', 'gists_url': 'https://api.github.com/users/manikrishna-m/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/manikrishna-m/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/manikrishna-m/subscriptions', 'organizations_url': 'https://api.github.com/users/manikrishna-m/orgs', 'repos_url': 'https://api.github.com/users/manikrishna-m/repos', 'events_url': 'https://api.github.com/users/manikrishna-m/events{/privacy}', 'received_events_url': 'https://api.github.com/users/manikrishna-m/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-26 22:26:46+00:00,2025-06-27 01:50:40+00:00,manikrishna-m,0.14159722222222224
61713,BUG: Inconsitent behaviour for different backends due to nullable bool values,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
all(pd.Series([None, 3,5], dtype=float) > 3)
all(pd.Series([None, 3,5], dtype='float[pyarrow]') > 3)
```

### Issue Description

Do to the pyarrow nullable bool type, there is a TypeError and the behaviour is inconsistent:

```python
all(pd.Series([None, 3,5], dtype=float) > 3)
```
Out[10]: False`


```python 
all(pd.Series([None, 3,5], dtype='float[pyarrow]') > 3)
```
Traceback (most recent call last):
  File ""C:\Users\Schleehauf\PycharmProjects\viodata\viotools\.venv\Lib\site-packages\IPython\core\interactiveshell.py"", line 3672, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-9-43ea68ea33b1>"", line 1, in <module>
    all(pd.Series([None, 3,5], dtype='float[pyarrow]') > 3)
  File ""pandas/_libs/missing.pyx"", line 392, in pandas._libs.missing.NAType.__bool__
TypeError: boolean value of NA is ambiguous

### Expected Behavior

Be consitant, fill the bool NA value with False for the next xxx releases and maybe add a DeprecationWarning

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.12.10
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 186 Stepping 2, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : de_DE.cp1252
pandas                : 2.3.0
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : 9.3.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : 1.5.0
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.1
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.4.0
matplotlib            : 3.10.3
numba                 : 0.61.2
numexpr               : 2.11.0
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : 8.4.1
python-calamine       : None
pyxlsb                : 1.0.10
s3fs                  : 2025.5.1
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : 2.0.2
xlsxwriter            : 3.2.5
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'PDEP missing values']",,2025-06-26 14:25:31+00:00,2025-07-19 17:00:06+00:00,,23.107349537037038
61710,"ENH: Enabled prefix, suffix, and sep to DataFrame.shift ","‚Ä¶e periods (#61696)

- [X] closes #61696   
(Replace 61696 with the GitHub issue number)
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


- Enabled `prefix`, `suffix`, and `sep` arguments to `DataFrame.shift` for iterable periods
- Now it's cleaner and customizable column renaming
- Introduced new test in `test_shift_with_iterable_check_other_arguments`",[],,2025-06-26 08:59:20+00:00,2025-06-30 17:51:24+00:00,,4.369490740740741
61708,POC: NA-only behavior for numpy-nullable dtypes,"This is the first of several POCs stemming from the discussion in #61618.  The main goal is to see how invasive it would be.

Specifically, this implements the NaN behavior described in PDEP16 #58988.

Functionally this makes it so that:

1) With a Float64Dtype or Float32Dtype, you will *never* get a NaN, only a NA.
2) Users transitioning from numpy dtypes will be maximally-backwards-compatible

As a result, I expect implementing this would solve most issues labeled as ""PDEP missing values"".  e.g. I just checked and it does address #54876.

",['PDEP missing values'],,2025-06-25 22:06:31+00:00,2025-08-04 15:43:23+00:00,,39.73393518518518
61705,DOC: add pandas 3.0 migration guide for the string dtype,"This PR starts adding a migration guide with some typical issues one might run into regarding the new string dtype when upgrading to pandas 3.0 (or when enabling it in pandas 2.3).

(for now I just added it to the user guide, which is already a long list of pages, so we might need to think about better organizing this or putting it elsewhere)

Closes #59328","['Docs', 'Strings']",,2025-06-25 14:32:04+00:00,2025-07-07 11:08:56+00:00,,11.858935185185185
61704,DOC: update Slack invite link in community dos,"- [x] closes #61690
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
-- tested manually
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Slack Link was getting expired very 14 days, New link from #61690 is set to never expire.","['Docs', 'Community']",,2025-06-24 21:15:41+00:00,2025-06-25 11:23:02+00:00,,0.5884375
61703,TST: Refactor S3 tests,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Testing', 'IO Network']",,2025-06-24 20:24:49+00:00,2025-06-30 23:40:45+00:00,,6.136064814814815
61702,DOC: simplify theme footer config (fixes #60647),"This PR removes custom footer settings in `conf.py` to use the new default footer provided by the updated `pydata-sphinx-theme`.

- Commented out: `footer_start`
Added: Contribution_plan.md file

Fixes #60647",['Closing Candidate'],,2025-06-24 17:56:34+00:00,2025-06-25 15:55:40+00:00,,0.9160416666666666
61701,"Issue #28283, Finalize coverage for DataFrame.merge","- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


Issue #28283
# Evaluation and Solution Summary
## Issue Analysis:
The GitHub issue #28283 is about improving the coverage of NDFrame.__finalize__ in pandas. Specifically, many pandas methods (including DataFrame.merge) don't properly call __finalize__ to propagate metadata like attrs and flags from input DataFrames to the result.
## Problem:
When you perform a merge operation on DataFrames that have metadata (stored in .attrs), the resulting DataFrame loses this metadata because the merge methods don't call __finalize__.
Solution Components:

Core Fix: Modify the merge-related functions in pandas to call __finalize__ after creating the result DataFrame.
Key Files to Modify:

- pandas/core/frame.py - DataFrame.merge method
- pandas/core/reshape/merge.py - merge and merge_asof functions
- pandas/tests/generic/test_finalize.py - Add comprehensive tests

## Implementation Strategy:

Add result.__finalize__(left, method=""merge"") calls after merge operations
Use the left DataFrame as the primary source for metadata propagation
Ensure all merge variants (inner, outer, left, right, asof) are covered
Handle both DataFrame-DataFrame and DataFrame-Series merges


## Testing Strategy:

- Test all merge types (inner, outer, left, right)
- Test index-based merges
- Test merges with suffixes
- Test merge_asof functionality
- Test DataFrame-Series merges


## Benefits of the Fix:

Preserves important metadata during merge operations
Maintains consistency with other pandas operations that already call __finalize__
Enables better data lineage tracking
Supports custom metadata propagation workflows

## Implementation Notes:

The fix follows pandas' existing pattern of calling __finalize__ in similar operations
Metadata conflicts are resolved by preferring the left DataFrame's attributes
The solution is backward compatible and doesn't change the existing API
Performance impact is minimal since __finalize__ is only called once per operation

This solution addresses the specific DataFrame.merge part of the broader issue #28283 and provides a template for fixing other methods mentioned in the issue.

",[],,2025-06-24 17:29:09+00:00,2025-06-24 19:03:05+00:00,,0.06523148148148149
61699,[backport 2.3.x] BUG: DataFrame.explode fails with str dtype (#61623),Backport of https://github.com/pandas-dev/pandas/pull/61623,[],,2025-06-24 08:50:45+00:00,2025-06-24 13:46:47+00:00,,0.2055787037037037
61698,DOC: move relevant whatsnew changes from 2.3.0 to 2.3.1 file,"Follow-up on https://github.com/pandas-dev/pandas/pull/61654, now moving some content from 2.3.0 to the 2.3.1 file for changes that only got backported for 2.3.1",['Docs'],,2025-06-24 08:46:27+00:00,2025-06-30 17:51:54+00:00,,6.378784722222222
61697,TST: Increase test coverage for pandas.io.formats.excel.py,"Sorry for the appauling number of commits. Git was being unkind, and I accidentally pushed .venv/ to gitignore, which then when I tried to revert, would reinclude the venv on the commit, you get the picture. It won't happen again.


The purpose of this PR is to add some test coverage to the first class of pandas.io.formats.excel.py, in the CSSToExcelConverter class. This class is missing some coverage, and there were a few unused functions and lines of code that were also causing some code coverage problems, so they have been dealt with. 
<img width=""1345"" alt=""Screenshot 2025-06-23 at 6 58 27‚ÄØPM"" src=""https://github.com/user-attachments/assets/9610b4c6-ed5f-4323-9a9b-76de3ae0dcbd"" />

<img width=""1338"" alt=""Screenshot 2025-06-23 at 6 59 14‚ÄØPM"" src=""https://github.com/user-attachments/assets/11a159de-3ca4-40a9-ade0-49347cf12157"" />

<img width=""1303"" alt=""Screenshot 2025-06-23 at 6 59 24‚ÄØPM"" src=""https://github.com/user-attachments/assets/e3f967c1-9ef4-4927-b070-1c8af9ba00d1"" />

These screenshots show the areas I am adding coverage too.","['Testing', 'IO Excel']",,2025-06-23 23:59:42+00:00,2025-06-25 15:57:57+00:00,,1.6654513888888889
61695,Create contribution plan_1,"As part of use case presentation, following use case has been completed.",[],,2025-06-23 12:09:49+00:00,2025-06-23 19:26:48+00:00,,0.30346064814814816
61693,61636 ,"This PR addresses [#61636](https://github.com/pandas-dev/pandas/issues/61636), which reports inconsistent dtype coercion during groupby aggregation on PyArrow-backed DataFrames. Specifically, aggregations like 'sum' or 'first' on columns with Arrow dtypes (e.g., int32, uint64) may return outputs with unexpected pandas-native dtypes like float64.
",[],,2025-06-23 10:56:48+00:00,2025-06-23 19:24:31+00:00,,0.35258101851851853
61690,DOC: The Slack invite link to join the Pandas Dev community is broken,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/development/community.html#community-slack

### Documentation problem

This issue was raised before #61298 but I do not have permission to reopen the issue. On clicking the link, one lands on [this page](https://pandas-dev-community.slack.com/join/shared_invite/zt-2blg6u9k3-K6_XvMRDZWeH7Id274UeIg#/shared-invite/error)

![Image](https://github.com/user-attachments/assets/6eb48c88-0794-451e-b6ed-368b24dda377)

### Suggested fix for documentation

Someone from the Slack admin team needs to update the link to the documentation. ","['Docs', 'Needs Triage', 'Community']","{'login': 'niruta25', 'id': 18272425, 'node_id': 'MDQ6VXNlcjE4MjcyNDI1', 'avatar_url': 'https://avatars.githubusercontent.com/u/18272425?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/niruta25', 'html_url': 'https://github.com/niruta25', 'followers_url': 'https://api.github.com/users/niruta25/followers', 'following_url': 'https://api.github.com/users/niruta25/following{/other_user}', 'gists_url': 'https://api.github.com/users/niruta25/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/niruta25/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/niruta25/subscriptions', 'organizations_url': 'https://api.github.com/users/niruta25/orgs', 'repos_url': 'https://api.github.com/users/niruta25/repos', 'events_url': 'https://api.github.com/users/niruta25/events{/privacy}', 'received_events_url': 'https://api.github.com/users/niruta25/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-23 04:24:46+00:00,2025-06-25 11:23:03+00:00,niruta25,2.290474537037037
61689,G√úL,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-22 16:00:53+00:00,2025-06-22 16:01:10+00:00,,0.00019675925925925926
61687,BUG: DataFrame.mul() corrupts data by setting values to zero,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np
import sys


# Create DataFrame with datetime index and multiple columns
# This reproduces the bug with ~6 years of hourly data (2033-2038)
np.random.seed(42)
date_range = pd.date_range('2033-01-01', '2038-12-31 23:00:00', freq='H')
n_cols = 40
data = np.random.rand(len(date_range), n_cols) * 0.1  # Values between 0 and 0.1

df = pd.DataFrame(data, index=date_range, columns=range(n_cols))

# Create a Series of ones with the same index
ones_series = pd.Series(1.0, index=df.index)

print(f""DataFrame shape: {df.shape}"")
print(f""Memory usage (MB): {df.memory_usage(deep=True).sum() / 1024**2:.2f}"")
print(f""Original data sample (should be > 0):"")
print(df.iloc[32:37, 23])  # Show some sample values

# Perform the multiplication that causes corruption
print(""\nPerforming multiplication..."")
result = df.mul(ones_series, axis=0)

# Check for corruption
print(f""After multiplication (should be identical):"")
print(result.iloc[32:37, 23])

# Verify corruption
are_equal = df.equals(result)
print(f""\nDataFrames equal: {are_equal}"")

if not are_equal:
    # Count corrupted values
    diff_mask = df.values != result.values
    n_corrupted = diff_mask.sum()
    print(f""CORRUPTION DETECTED: {n_corrupted} values corrupted!"")
    
    # Show corruption details
    corrupted_rows, corrupted_cols = np.where(diff_mask)
    if len(corrupted_rows) > 0:
        print(f""\nCorruption sample:"")
        for i in range(min(5, len(corrupted_rows))):
            row, col = corrupted_rows[i], corrupted_cols[i]
            original = df.iloc[row, col]
            corrupted = result.iloc[row, col]
            date = df.index[row]
            print(f""  {date}, Col {col}: {original:.4f} -> {corrupted:.4f}"")
    
    # Verify that corrupted values are zeros
    corrupted_values = result.values[diff_mask]
    all_zeros = np.all(corrupted_values == 0.0)
    print(f""\nAre all corrupted values zero? {all_zeros}"")
    
    # Show which columns are affected
    unique_affected_cols = np.unique(corrupted_cols)
    print(f""Number of affected columns: {len(unique_affected_cols)}"")
    print(f""Affected columns: {unique_affected_cols}"")

# Demonstrate that numpy approach works correctly
print(f""\nTesting numpy workaround..."")
numpy_result = pd.DataFrame(
    df.to_numpy() * ones_series.to_numpy()[:, None],
    index=df.index,
    columns=df.columns
)

numpy_works = df.equals(numpy_result)
print(f""Numpy approach works correctly: {numpy_works}"")
```

### Issue Description

The DataFrame.mul() method is corrupting data by setting non-zero values to zero when multiplying a DataFrame with datetime index by a Series of ones. This occurs only under specific conditions related to DataFrame size and affects data integrity.

### Expected Behavior

When multiplying a DataFrame by a Series of ones using df.mul(ones_series, axis=0), all original values should be preserved (multiplied by 1.0).

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.11
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.14393
machine               : AMD64
processor             : Intel64 Family 6 Model 85 Stepping 4, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.3.0
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : 8.1.3
IPython               : 8.31.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : None
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : None
pyarrow               : 18.1.0
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : 1.0.10
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.37
tables                : 3.10.2
tabulate              : None
xarray                : 2025.1.1
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : 2.4.3
pyqt5                 : None

</details>
","['Bug', 'Numeric Operations', 'Needs Info', 'Closing Candidate']",,2025-06-22 10:03:03+00:00,2025-07-23 09:12:16+00:00,,30.964733796296297
61686,fix for building docs on Windows,"- [x] closes #60149

I was having two issues with building the docs on Windows.

1. Building a single page with `--single` was very slow because it was reading in lots of files.  So there is a fix in `conf.py` that changes any backslashes to `/` in the paths.  Probably a better fix is to not be using `os.join` and use `pathlib`, but that's a larger change.
2. For #60149, there are 2 issues with building `enhancingperf.rst`:
  - As mentioned in https://github.com/pandas-dev/pandas/issues/60149#issuecomment-2600578029 , having double quotes in the ipython strings messes up Windows, so changing them to single quotes makes it work
  - The cython functions expect `int64` dtypes, but the defaults coming from `numpy` when building the DF are `int32`, so the `astype(int)` calls fix that

","['Docs', 'Windows']",,2025-06-22 05:39:02+00:00,2025-06-22 17:34:50+00:00,,0.4970833333333333
61685,create contribution_plan.md file,"Created contribution_plan.md file
",[],,2025-06-21 12:23:44+00:00,2025-06-21 16:55:11+00:00,,0.18850694444444444
61684,add contribution_plan.md file,"Added add contribution_plan.md file
",[],,2025-06-21 10:53:28+00:00,2025-06-21 16:55:02+00:00,,0.251087962962963
61683,docs: Add CONTRIBUTION_PLAN.md for GitHub use case,"This Pull Request adds a detailed CONTRIBUTION_PLAN.md that documents the process of evaluating and contributing to the pandas-dev/pandas project. The plan includes environment setup, issue identification, and a step-by-step guide to raising a PR.

This is part of a simulated GitHub use case to demonstrate contribution readiness.",[],,2025-06-21 09:44:16+00:00,2025-06-21 16:54:54+00:00,,0.2990509259259259
61680,Backport PR #61654 on branch 2.3.x (DOC: Add release notes template for 2.3.1),Backport PR #61654: DOC: Add release notes template for 2.3.1,['Docs'],,2025-06-19 20:12:55+00:00,2025-06-20 15:54:28+00:00,,0.8205208333333334
61678,ENH #61033: Add coalesce_keys option to DataFrame.join for preserving join keys,"Add coalesce_keys option to DataFrame.join for preserving join keys

This adds a coalesce_keys keyword to DataFrame.join to allow preservation
of both join key columns (id and id_right), instead of automatically
coalescing them into a single column.

This is especially useful in full outer joins, where retaining information
about unmatched keys from both sides is important.

Example:
    df1.join(df2, on=id, coalesce_keys=False)

This will result in both id and id_right columns being preserved, rather
than merged into a single id.

Includes:
- Modifications to join internals (core/reshape/merge.py)
- A dedicated test file (test_merge_coalesce.py) covering:
    - Preservation of join keys when coalesce_keys=False
    - Comparison with default behavior (coalesce_keys=True)
    - Full outer joins with asymmetric key presence
","['Enhancement', 'Reshaping', 'Stale']",,2025-06-19 15:06:26+00:00,2025-07-28 17:25:52+00:00,,39.09682870370371
61674,BUG: fix: `list` as index item does not raise,"- [X] closes #60925
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

### Problem:
Index constructor was allowing creation of indexes where one of the index's item is a list (unhashable) while others are not lists.

- If all items are lists - like columns=[ ['a', 'b'], ['b', 'c'], ['b', 'c'] ], it will try to create a MultiIndex. **Correct**.
- If _any_ item is a list, but _NOT all_ - like the initial example, columns=[ 'a', ['b', 'c'], ['b', 'c'] ], there's no check for this condition, and the creation will follow as if all items, including the lists, are valid column names.

### Solution:
Added a check in the Index constructor for this case. Raise ValueError.
Added test to check if is raising correctly.
Changed a test that should raise.","['Bug', 'Index', 'Stale']",,2025-06-17 16:21:37+00:00,2025-07-28 17:25:29+00:00,,41.04435185185185
61673,DOC: Document two-issue limit for `take` command in contributing guide #61626,"- [ ] closes #61626 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-17 11:22:47+00:00,2025-06-22 11:23:04+00:00,,5.000196759259259
61672,BUG: Index allows one item to be `list` among others that are not,"- [X] closes #60925
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug.

Corrected test pandas/tests/frame/test_repr.py::[test_assign_index_sequences] that was passing when should be raising.
Added test to check if raises correctly.
",[],,2025-06-16 23:52:06+00:00,2025-06-17 02:36:43+00:00,,0.11431712962962963
61668,Bump pypa/cibuildwheel from 2.23.3 to 3.0.0,"Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 2.23.3 to 3.0.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/releases"">pypa/cibuildwheel's releases</a>.</em></p>
<blockquote>
<h2>v3.0.0</h2>
<p>See <a href=""https://github.com/henryiii""><code>@‚Äãhenryiii</code></a>'s <a href=""https://iscinumpy.dev/post/cibuildwheel-3-0-0/"">release post</a> for more info on new features!</p>
<ul>
<li>
<p>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#ios"">build wheels for iOS</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>ios</code> on a Mac with the iOS toolchain to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2286"">#2286</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2363"">#2363</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2432"">#2432</a>)</p>
</li>
<li>
<p>üåü Adds support for the GraalPy interpreter! Enable for your project using the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1538"">#1538</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2411"">#2411</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2414"">#2414</a>)</p>
</li>
<li>
<p>‚ú® Adds CPython 3.14 support, under the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> <code>cpython-prerelease</code>. This version of cibuildwheel uses 3.14.0b2. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
<p><em>While CPython is in beta, the ABI can change, so your wheels might not be compatible with the final release. For this reason, we don't recommend distributing wheels until RC1, at which point 3.14 will be available in cibuildwheel without the flag.</em> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-sources"">test-sources option</a>, and changes the working directory for tests. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2062"">#2062</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2284"">#2284</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2437"">#2437</a>)</p>
<ul>
<li>If this option is set, cibuildwheel will copy the files and folders specified in <code>test-sources</code> into the temporary directory we run from. This is required for iOS builds, but also useful for other platforms, as it allows you to avoid placeholders.</li>
<li>If this option is not set, behaviour matches v2.x - cibuildwheel will run the tests from a temporary directory, and you can use the <code>{project}</code> placeholder in the <code>test-command</code> to refer to the project directory. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2420"">#2420</a>)</li>
</ul>
</li>
<li>
<p>‚ú® Adds <a href=""https://cibuildwheel.pypa.io/en/stable/options/#dependency-versions""><code>dependency-versions</code></a> inline syntax (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2122"">#2122</a>)</p>
</li>
<li>
<p>‚ú® Improves support for Pyodide builds and adds the experimental <a href=""https://cibuildwheel.pypa.io/en/stable/options/#pyodide-version""><code>pyodide-version</code></a> option, which allows you to specify the version of Pyodide to use for builds. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2002"">#2002</a>)</p>
</li>
<li>
<p>‚ú® Add <code>pyodide-prerelease</code> <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enable</a> option, with an early build of 0.28 (Python 3.13). (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2431"">#2431</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-environment""><code>test-environment</code></a> option, which allows you to set environment variables for the test command. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2388"">#2388</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#xbuild-tools""><code>xbuild-tools</code></a> option, which allows you to specify tools safe for cross-compilation. Currently only used on iOS; will be useful for Android in the future. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2317"">#2317</a>)</p>
</li>
<li>
<p>üõ† The default <a href=""https://cibuildwheel.pypa.io/en/stable/options/#linux-image"">manylinux image</a> has changed from <code>manylinux2014</code> to <code>manylinux_2_28</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2330"">#2330</a>)</p>
</li>
<li>
<p>üõ† EOL images <code>manylinux1</code>, <code>manylinux2010</code>, <code>manylinux_2_24</code> and <code>musllinux_1_1</code> can no longer be specified by their shortname. The full OCI name can still be used for these images, if you wish. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2316"">#2316</a>)</p>
</li>
<li>
<p>üõ† Invokes <code>build</code> rather than <code>pip wheel</code> to build wheels by default. You can control this via the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#build-frontend""><code>build-frontend</code></a> option. You might notice that you can see your build log output now! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2321"">#2321</a>)</p>
</li>
<li>
<p>üõ† Build verbosity settings have been reworked to have consistent meanings between build backends when non-zero. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2339"">#2339</a>)</p>
</li>
<li>
<p>üõ† Removed the <code>CIBW_PRERELEASE_PYTHONS</code> and <code>CIBW_FREE_THREADED_SUPPORT</code> options - these have been folded into the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code></a> option instead. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>üõ† Build environments no longer have setuptools and wheel preinstalled. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2329"">#2329</a>)</p>
</li>
<li>
<p>üõ† Use the standard Schema line for the integrated JSONSchema. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2433"">#2433</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped support for building Python 3.6 and 3.7 wheels. If you need to build wheels for these versions, use cibuildwheel v2.23.3 or earlier. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2282"">#2282</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è The minimum Python version required to run cibuildwheel is now Python 3.11. You can still build wheels for Python 3.8 and newer. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1912"">#1912</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è 32-bit Linux wheels no longer built by default - the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#archs"">arch</a> was removed from <code>&quot;auto&quot;</code>. It now requires explicit <code>&quot;auto32&quot;</code>. Note that modern manylinux images (like the new default, <code>manylinux_2_28</code>) do not have 32-bit versions. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2458"">#2458</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è PyPy wheels no longer built by default, due to a change to our options system. To continue building PyPy wheels, you'll now need to set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> to <code>pypy</code> or <code>pypy-eol</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped official support for Appveyor. If it was working for you before, it will probably continue to do so, but we can't be sure, because our CI doesn't run there anymore. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2386"">#2386</a>)</p>
</li>
<li>
<p>üìö A reorganisation of the docs, and numerous updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2280"">#2280</a>)</p>
</li>
<li>
<p>üìö Use Python 3.14 color output in docs CLI output. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2407"">#2407</a>)</p>
</li>
<li>
<p>üìö Docs now primarily use the pyproject.toml name of options, rather than the environment variable name. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2389"">#2389</a>)</p>
</li>
<li>
<p>üìö README table now matches docs and auto-updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2427"">#2427</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2428"">#2428</a>)</p>
</li>
</ul>
<h2>v3.0.0rc3</h2>
<p>Not yet released, but available for testing.</p>
<p>Note - when using a beta version, be sure to check the <a href=""https://cibuildwheel.pypa.io/en/latest/"">latest docs</a>, rather than the stable version, which is still on v2.X.</p>
<!-- raw HTML omitted -->
<p>If you've used previous versions of the beta:</p>
<ul>
<li>‚ö†Ô∏è Previous betas of v3.0 changed the working directory for tests. This has been rolled back to the v2.x behaviour, so you might need to change configs if you adapted to the beta 1 or 2 behaviour. See [issue <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2406"">#2406</a>](<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2406"">pypa/cibuildwheel#2406</a>) for more information.</li>
<li>‚ö†Ô∏è GraalPy shipped with the identifier <code>gp242-*</code> in previous betas, this has been changed to <code>gp311_242-*</code> to be consistent with other interpreters, and to fix a bug with GraalPy and project requires-python detection. If you were using GraalPy, you might need to update your config to use the new identifier.</li>
<li>‚ö†Ô∏è <code>test-sources</code> now uses <code>project</code> directory instead of the <code>package</code> directory (matching the docs).</li>
<li>‚ö†Ô∏è 32-bit linux builds were removed from <code>&quot;auto&quot;</code> (the default), now require <code>&quot;auto32&quot;</code> or explicit archs, as modern manylinux images (including our new default) do not support them.</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/blob/main/docs/changelog.md"">pypa/cibuildwheel's changelog</a>.</em></p>
<blockquote>
<h3>v3.0.0</h3>
<p><em>11 June 2025</em></p>
<p>See <a href=""https://github.com/henryiii""><code>@‚Äãhenryiii</code></a>'s <a href=""https://iscinumpy.dev/post/cibuildwheel-3-0-0/"">release post</a> for more info on new features!</p>
<ul>
<li>
<p>üåü Adds the ability to <a href=""https://cibuildwheel.pypa.io/en/stable/platforms/#ios"">build wheels for iOS</a>! Set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#platform""><code>platform</code> option</a> to <code>ios</code> on a Mac with the iOS toolchain to try it out! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2286"">#2286</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2363"">#2363</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2432"">#2432</a>)</p>
</li>
<li>
<p>üåü Adds support for the GraalPy interpreter! Enable for your project using the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1538"">#1538</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2411"">#2411</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2414"">#2414</a>)</p>
</li>
<li>
<p>‚ú® Adds CPython 3.14 support, under the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> <code>cpython-prerelease</code>. This version of cibuildwheel uses 3.14.0b2. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
<p><em>While CPython is in beta, the ABI can change, so your wheels might not be compatible with the final release. For this reason, we don't recommend distributing wheels until RC1, at which point 3.14 will be available in cibuildwheel without the flag.</em> (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2390"">#2390</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-sources"">test-sources option</a>, and changes the working directory for tests. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2062"">#2062</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2284"">#2284</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2437"">#2437</a>)</p>
<ul>
<li>If this option is set, cibuildwheel will copy the files and folders specified in <code>test-sources</code> into the temporary directory we run from. This is required for iOS builds, but also useful for other platforms, as it allows you to avoid placeholders.</li>
<li>If this option is not set, behaviour matches v2.x - cibuildwheel will run the tests from a temporary directory, and you can use the <code>{project}</code> placeholder in the <code>test-command</code> to refer to the project directory. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2420"">#2420</a>)</li>
</ul>
</li>
<li>
<p>‚ú® Adds <a href=""https://cibuildwheel.pypa.io/en/stable/options/#dependency-versions""><code>dependency-versions</code></a> inline syntax (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2122"">#2122</a>)</p>
</li>
<li>
<p>‚ú® Improves support for Pyodide builds and adds the experimental <a href=""https://cibuildwheel.pypa.io/en/stable/options/#pyodide-version""><code>pyodide-version</code></a> option, which allows you to specify the version of Pyodide to use for builds. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2002"">#2002</a>)</p>
</li>
<li>
<p>‚ú® Add <code>pyodide-prerelease</code> <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable"">enable</a> option, with an early build of 0.28 (Python 3.13). (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2431"">#2431</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#test-environment""><code>test-environment</code></a> option, which allows you to set environment variables for the test command. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2388"">#2388</a>)</p>
</li>
<li>
<p>‚ú® Adds the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#xbuild-tools""><code>xbuild-tools</code></a> option, which allows you to specify tools safe for cross-compilation. Currently only used on iOS; will be useful for Android in the future. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2317"">#2317</a>)</p>
</li>
<li>
<p>üõ† The default <a href=""https://cibuildwheel.pypa.io/en/stable/options/#linux-image"">manylinux image</a> has changed from <code>manylinux2014</code> to <code>manylinux_2_28</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2330"">#2330</a>)</p>
</li>
<li>
<p>üõ† EOL images <code>manylinux1</code>, <code>manylinux2010</code>, <code>manylinux_2_24</code> and <code>musllinux_1_1</code> can no longer be specified by their shortname. The full OCI name can still be used for these images, if you wish. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2316"">#2316</a>)</p>
</li>
<li>
<p>üõ† Invokes <code>build</code> rather than <code>pip wheel</code> to build wheels by default. You can control this via the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#build-frontend""><code>build-frontend</code></a> option. You might notice that you can see your build log output now! (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2321"">#2321</a>)</p>
</li>
<li>
<p>üõ† Build verbosity settings have been reworked to have consistent meanings between build backends when non-zero. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2339"">#2339</a>)</p>
</li>
<li>
<p>üõ† Removed the <code>CIBW_PRERELEASE_PYTHONS</code> and <code>CIBW_FREE_THREADED_SUPPORT</code> options - these have been folded into the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code></a> option instead. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>üõ† Build environments no longer have setuptools and wheel preinstalled. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2329"">#2329</a>)</p>
</li>
<li>
<p>üõ† Use the standard Schema line for the integrated JSONSchema. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2433"">#2433</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped support for building Python 3.6 and 3.7 wheels. If you need to build wheels for these versions, use cibuildwheel v2.23.3 or earlier. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2282"">#2282</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è The minimum Python version required to run cibuildwheel is now Python 3.11. You can still build wheels for Python 3.8 and newer. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/1912"">#1912</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è 32-bit Linux wheels no longer built by default - the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#archs"">arch</a> was removed from <code>&quot;auto&quot;</code>. It now requires explicit <code>&quot;auto32&quot;</code>. Note that modern manylinux images (like the new default, <code>manylinux_2_28</code>) do not have 32-bit versions. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2458"">#2458</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è PyPy wheels no longer built by default, due to a change to our options system. To continue building PyPy wheels, you'll now need to set the <a href=""https://cibuildwheel.pypa.io/en/stable/options/#enable""><code>enable</code> option</a> to <code>pypy</code> or <code>pypy-eol</code>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2095"">#2095</a>)</p>
</li>
<li>
<p>‚ö†Ô∏è Dropped official support for Appveyor. If it was working for you before, it will probably continue to do so, but we can't be sure, because our CI doesn't run there anymore. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2386"">#2386</a>)</p>
</li>
<li>
<p>üìö A reorganisation of the docs, and numerous updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2280"">#2280</a>)</p>
</li>
<li>
<p>üìö Use Python 3.14 color output in docs CLI output. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2407"">#2407</a>)</p>
</li>
<li>
<p>üìö Docs now primarily use the pyproject.toml name of options, rather than the environment variable name. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2389"">#2389</a>)</p>
</li>
<li>
<p>üìö README table now matches docs and auto-updates. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2427"">#2427</a>, <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2428"">#2428</a>)</p>
</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/5f22145df44122af0f5a201f93cf0207171beca7""><code>5f22145</code></a> Bump version: v3.0.0</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/a73177515a438c947d6e6e7a7356dfe67991d740""><code>a731775</code></a> Docs: mobile layout fix (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2466"">#2466</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/ff86a6457781e53a6edbb60d3c2677c64be4f282""><code>ff86a64</code></a> docs: add tips for numpy (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2465"">#2465</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/6f5e480fec0d367f9230ee0be4bcb56136eeec43""><code>6f5e480</code></a> chore: use pip's groups in CI (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2463"">#2463</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/3c5ff0988806752c5a6502c845f9edc2d98095d6""><code>3c5ff09</code></a> Bump version: v3.0.0rc3</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/1b9a56e01487f7fd9146e622505ea22d4d35e954""><code>1b9a56e</code></a> [Bot] Update dependencies (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2455"">#2455</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/aa9fe2a24edd67db40cbd394e4621a479e9e69f1""><code>aa9fe2a</code></a> ci: use uv python for docs (binary b1) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2462"">#2462</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/e188d9e26007031c475bb5293b90c5f386ecb439""><code>e188d9e</code></a> feat: remove 32-bit linux from auto arch, fix auto32 on linux aarch64 (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2458"">#2458</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/3fa7bd1e72c565f4efc61363db6b2f14dbdbb198""><code>3fa7bd1</code></a> ci: fix cirrus and reduce rebuilds (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2460"">#2460</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/c6368be701a99f8315656f925236dbcec5b9b9c2""><code>c6368be</code></a> Move to the <code>OS-latest</code> image tags on Azure Pipelines (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2461"">#2461</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/cibuildwheel/compare/v2.23.3...v3.0.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/cibuildwheel&package-manager=github_actions&previous-version=2.23.3&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","['Build', 'CI', 'Dependencies']",,2025-06-16 09:05:45+00:00,2025-07-07 10:46:18+00:00,,21.069826388888888
61666,ENH: Support for Orthodox Easter,"- [X] closes #61665
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Frequency'],,2025-06-16 05:19:20+00:00,2025-06-16 19:39:27+00:00,,0.5973032407407407
61665,ENH: Support for Orthodox Easter,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

The [pandas.tseries.offsets.Easter](https://github.com/pandas-dev/pandas/blob/c067bcd701e6cb4125e869a2802ef867d8395800/pandas/_libs/tslibs/offsets.pyx#L4511) class currently calculates the date of Western Easter only. However, it does not support the calculation of Orthodox Easter.

This limitation makes it more difficult to work with holidays that are relative to Orthodox Easter, such as Orthodox Good Friday and Orthodox Easter Monday.


### Feature Description

With a small and fully backwards-compatible change to the [pandas.tseries.offsets.Easter](https://github.com/pandas-dev/pandas/blob/c067bcd701e6cb4125e869a2802ef867d8395800/pandas/_libs/tslibs/offsets.pyx#L4511) class, support for Orthodox Easter (and Julian Easter) can be added by introducing an optional `method` parameter to the `Easter` constructor.

This `method` parameter specifies the method to use for calculating easter and would then be passed to [dateutil.easter](https://dateutil.readthedocs.io/en/stable/easter.html), which is used internally by the Easter class.

Usage example:
```python
from dateutil.easter import EASTER_ORTHODOX

OrthodoxGoodFriday = Holiday(""Good Friday"", month=1, day=1, offset=[Easter(method=EASTER_ORTHODOX), Day(-2)])
OrthodoxEasterMonday = Holiday(""Easter Monday"", month=1, day=1, offset=[Easter(method=EASTER_ORTHODOX), Day(1)])
```

This is similar to how the [GoodFriday](https://github.com/pandas-dev/pandas/blob/c067bcd701e6cb4125e869a2802ef867d8395800/pandas/tseries/holiday.py#L609) and [EasterMonday](https://github.com/pandas-dev/pandas/blob/c067bcd701e6cb4125e869a2802ef867d8395800/pandas/tseries/holiday.py#L611)  holidays for Western Easter are implemented in the `pandas.tseries.holiday` module.

### Alternative Solutions

An alternative solution, without modifying the Easter class as suggested, is to use the observance parameter.

```python
def calculate_orthodox_good_friday(dt):
    offset = easter(dt.year, method=EASTER_ORTHODOX) - timedelta(days=2) - dt.date()
    return dt + offset

OrthodoxGoodFriday = Holiday(
    ""Good Friday"",
    month=1,
    day=1,
    observance=calculate_orthodox_good_friday)
```
","['Enhancement', 'Needs Triage']",,2025-06-16 05:17:43+00:00,2025-06-16 19:39:28+00:00,,0.5984375
61664,Fix some incorrect indents in development documentation,Incorrect indentations cause some texts to be misinterpreted as quoteblocks.,['Docs'],,2025-06-16 03:13:09+00:00,2025-06-17 16:52:30+00:00,,1.5689930555555556
61663,BUG: Incorrect guess_datetime_format response,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

print(pd.tseries.api.guess_datetime_format('2025-06-15T21:25:00.000000Z'))
print(pd.tseries.api.guess_datetime_format('2025-06-15T20:24:00.000000Z'))
print(pd.tseries.api.guess_datetime_format('2025-06-15T20:25:00.000000Z'))

# %Y-%m-%dT%H:%M:%S.%f%z
# %Y-%m-%dT%H:%M:%S.%f%z
# None
```

### Issue Description

I'm receiving a strange `None` from `guess_datetime_format` for a very particular string combination. I can change the hours and minutes separately and it works fine, but when I set the time to exactly `20:25` it produces a None result.

### Expected Behavior

It should produce the same `'%Y-%m-%dT%H:%M:%S.%f%z'` format as the other two examples.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.10.12
python-bits           : 64
OS                    : Linux
OS-release            : 6.15.1-061501-generic
Version               : #202506041425 SMP PREEMPT_DYNAMIC Wed Jun  4 18:01:32 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : C.UTF-8
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8
pandas                : 2.3.0
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 0.29.37
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.6.1
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.10.3
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.11.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Datetime', 'Duplicate Report', 'Needs Triage']",,2025-06-15 20:46:06+00:00,2025-06-16 18:53:51+00:00,,0.9220486111111111
61662,DOC: Improve documentation for DataFrame.__setitem__ and .loc assignment from Series,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

pandas.DataFrame.__setitem__
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__setitem__.html

pandas.core.indexing.IndexingMixin.loc
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html

User Guide: Indexing and Selecting Data
https://pandas.pydata.org/docs/user_guide/indexing.html


### Documentation problem

*Documentation Enhancement**

    The following behavior is not clearly explained in the documentation:

    ```python
    import pandas as pd

    df = pd.DataFrame({'a': [1, 2, 3]})
    df['b'] = pd.Series({1: 'b'})
    print(df)

    # Output:
    #    a    b
    # 0  1  NaN
    # 1  2    b
    # 2  3  NaN
    ```

    - The Series is **reindexed** to match the DataFrame index.
    - Values are inserted **by index label**, not by position.
    - Missing labels yield **NaN**, and the order is adjusted accordingly.

    This behavior is:
    - Not explained in the `__setitem__` documentation (which is missing entirely).
    - Only mentioned vaguely in `.loc` docs, with no example.
    - Absent from the ""Indexing and Selecting Data"" user guide when assigning Series with unordered or partial index.

### Suggested fix for documentation

1. **Add docstring for `DataFrame.__setitem__`** with clear explanation that:
       > When assigning a Series, pandas aligns on index. Values in the Series that don't match an index label will result in `NaN`.

    2. **Update `.loc` documentation**:
       Include a note that when assigning a Series to `.loc[row_labels, col]`, pandas aligns the Series by index and **not by order**.

    3. **Add example in the User Guide** under:
       [Indexing and Selecting Data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)
       > Assigning a Series with unordered/missing index keys to a DataFrame column.

    **Suggested example:**

    ```python
    df = pd.DataFrame({'a': [1, 2, 3]})
    s = pd.Series({2: 'zero', 1: 'one', 0: 'two'})
    df['d'] = s

    # Output:
    #    a     d
    # 0  1   two
    # 1  2   one
    # 2  3  zero
    ```

    ### üìà Why this is better:

    The current documentation is incomplete and vague about how Series alignment works in assignments. This fix:

    - Makes `__setitem__` behavior explicit and discoverable.
    - Improves `.loc` docs with better clarity and practical context.
    - Adds real-world examples to the user guide to reduce silent bugs and confusion.

    These improvements help all users‚Äîespecially beginners‚Äîunderstand how pandas handles Series assignment internally.","['Docs', 'Needs Triage']","{'login': 'niruta25', 'id': 18272425, 'node_id': 'MDQ6VXNlcjE4MjcyNDI1', 'avatar_url': 'https://avatars.githubusercontent.com/u/18272425?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/niruta25', 'html_url': 'https://github.com/niruta25', 'followers_url': 'https://api.github.com/users/niruta25/followers', 'following_url': 'https://api.github.com/users/niruta25/following{/other_user}', 'gists_url': 'https://api.github.com/users/niruta25/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/niruta25/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/niruta25/subscriptions', 'organizations_url': 'https://api.github.com/users/niruta25/orgs', 'repos_url': 'https://api.github.com/users/niruta25/repos', 'events_url': 'https://api.github.com/users/niruta25/events{/privacy}', 'received_events_url': 'https://api.github.com/users/niruta25/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-15 15:06:12+00:00,2025-08-01 15:31:05+00:00,niruta25,47.01728009259259
61661,DOC: Make the benchmarks URL clickable,"Make the benchmarks URL clickable.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-06-15 02:58:47+00:00,2025-06-16 16:57:28+00:00,,1.5824189814814815
61658,DOC/ENH: Holiday days_of_week value error,"Changed `Holiday` constructor argument `days_of_week` to raise a `ValueError` on input of the incorrect type as discussed in #61600
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Frequency'],,2025-06-14 12:50:04+00:00,2025-06-17 16:53:08+00:00,,3.1687962962962963
61657,WEB: Reorganization of the Ecosystem page,"I changed the sections of the Ecosystem page, in a way that the pandas extensions are grouped together first, and the other sections emphasize how packages they are related to pandas. I merged two separate IO sections, and the IDEs with the development tools.

I added line breaks to very long lines, and improved a bit the styles.

Probably better to check the preview when ready, than the diff, as the diff will be long and difficult to follow as mostly every library is moved.
",['Web'],,2025-06-13 22:04:43+00:00,2025-06-16 21:16:30+00:00,,2.9665162037037036
61656,WEB: Clean up Ecosystem page,"Removing projects from our Ecosystem page that don't seem maintained and much used (2+ years inactivity in their github)

Also, ArcticDB had a whole user guide in the page, leaving only the overview as other projects have, with the link to their docs for users who are interested.
",['Web'],,2025-06-13 17:46:33+00:00,2025-06-13 20:38:21+00:00,,0.11930555555555555
61655,WEB: Add table of contents to the Ecosystem,"Supersedes #61595

Changes to make the tables of contents in the website the same in all pages (we had customized the PDEP ones before).

Adding the ToC to Ecosystem. It renders like this:

![Screenshot at 2025-06-13 19-02-56](https://github.com/user-attachments/assets/a3471680-b9f9-46e6-b02d-0d379d75efec)


I can make it just one level if preferred. I think with one level looks nicer, but with two, it's uglier but more practical (and simpler since it's the same for all pages). But no strong preference from my side
",['Web'],,2025-06-13 17:09:07+00:00,2025-06-13 20:37:43+00:00,,0.1448611111111111
61654,DOC: Add release notes template for 2.3.1,"Starting the release notes for 2.3.1, so we can start adding things (for new PRs, but will also follow-up with moving some things from 2.3.0 to 2.3.1)",['Docs'],,2025-06-13 15:47:14+00:00,2025-06-19 20:12:26+00:00,,6.184166666666667
61653,[backport 2.3.x] CI: Fix slow mamba solver issue by limiting boto3 version (#61594),Backport of https://github.com/pandas-dev/pandas/pull/61594,[],,2025-06-13 15:33:41+00:00,2025-06-24 13:48:01+00:00,,10.92662037037037
61652,[backport 2.3.x] TST: update xfail xarray version check in to_xarray test (#61648),"Backport of #61648 

Probably not needed to backport because we might not get the latest xarray versions in the envs of the 2.3.x branch, but still useful in case someone runs the tests with more up to date xarray",[],,2025-06-13 15:28:54+00:00,2025-06-13 16:51:07+00:00,,0.05709490740740741
61650,feature #49580: support new-style float_format string in to_csv,"feat(to_csv): support new-style float_format strings using str.format

Detect and process new-style format strings (e.g., ""{:,.2f}"") in the float_format parameter of to_csv.

- Check if float_format is a string and matches new-style pattern
- Convert it to a callable (e.g., lambda x: float_format.format(x))
- Ensure compatibility with NaN values and mixed data types
- Improves formatting output for floats when exporting to CSV

Example:
df = pd.DataFrame([1234.56789, 9876.54321])
df.to_csv(float_format=""{:,.2f}"")  # now outputs formatted values like 1,234.57 and support new-style without .format

- [x] closes #49580
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
","['Enhancement', 'IO CSV']",,2025-06-13 13:35:01+00:00,2025-07-08 15:48:22+00:00,,25.092604166666668
61649,"[backport 2.3.x] API (string dtype): implement hierarchy (NA > NaN, pyarrow > python) for consistent comparisons between different string dtypes (#61138)",Backport of https://github.com/pandas-dev/pandas/pull/61138,[],,2025-06-13 12:29:23+00:00,2025-06-13 15:34:25+00:00,,0.12849537037037037
61648,TST: update xfail xarray version check in to_xarray test,"Started to see xpass in https://github.com/pandas-dev/pandas/pull/61594, so updating the version check here. Not sure this is entirely covered by CI, but tested this locally with a few different xarray versions.",['Testing'],,2025-06-13 12:13:46+00:00,2025-06-13 13:31:19+00:00,,0.05385416666666667
61647,WEB: Moving maintainers to inactive (no answer from them),"I couldn't get an answer from @jreback @topper-123 @alimcmaster1 regarding being active or unactive for some time.

I'll leave this open for few days, in case they see it an can confirm. But in the past we've been moving people to inactive if they didn't seem active for a long time and we couldn't get confirmation from them on whether they want to continue to be active or not.",['Web'],,2025-06-13 11:32:13+00:00,2025-06-20 20:30:45+00:00,,7.373981481481482
61646,fix std/var with complex array,"- [x] closes #61645
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Reduction Operations'],,2025-06-13 10:28:07+00:00,2025-06-16 17:13:26+00:00,,3.2814699074074074
61645,BUG: `Series.std` and `Series.var` give incorrect results for complex values.,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd

arr = np.array([-1j, 0j, 1j], dtype=complex)
s = pd.Series(arr, dtype=complex)

print(arr.std(ddof=0))  # 0.816496580927726
print(s.std(ddof=0))  # nan
print(arr.var(ddof=0))  # 0.666
print(s.var(ddof=0))  # -0.666
```

### Issue Description

1. The results diverge from numpy.
2. pandas yields nonsensical results like negative floats.

### Expected Behavior

For complex variables, `std` and `var` should give non-negative floating results. Recall that $` œÉ ‚âî \sqrt{ùîº|x-Œº|^2 } `$. Often, authors that only use real-valued variables leave out the absolute value, which I guess is what happened here.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.13.4
python-bits           : 64
OS                    : Linux
OS-release            : 6.11.0-26-generic
Version               : #26~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Apr 17 19:20:47 UTC 2
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.0
numpy                 : 2.3.0
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : 8.2.3
IPython               : 9.3.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.1
html5lib              : None
hypothesis            : 6.135.9
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.3
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : 8.4.0
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.3
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-06-13 09:27:37+00:00,2025-06-16 17:13:27+00:00,,3.3234953703703702
61643,BUG: replace value failed,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd

start_time = '2025-06-06'
end_time = '2025-06-09'

sig1 = pd.read_parquet('data1.par')
sig1 = sig1[(sig1.tradeDate >= start_time) & (sig1.tradeDate <= end_time)]
sig1 = sig1.pivot(index='tradeDate', columns='ticker', values='signal_value').fillna(0)

sig2 = pd.read_parquet('data2.par')
sig2 = sig2[(sig2.tradeDate >= start_time) & (sig2.tradeDate <= end_time)]
sig2 = sig2.pivot(index='tradeDate', columns='ticker', values='signal_value').fillna(0)

sig = sig1 + sig2

filt = pd.read_feather('filter.fea').set_index('tradeDate')
filt.index = pd.to_datetime(filt.index)
filt = filt.reindex(sig.index, columns=sig.columns)

# method 1: make a copy then filter
s1 = sig.copy()
s1.values[:] = np.where(filt == 1, s1, np.nan)
print(s1.count(axis=1))

# method 2: directly filter
sig.values[:] = np.where(filt == 1, sig, np.nan)
print(sig.count(axis=1))
```

### Issue Description

Why not workÔºö

    sig.values[:] = np.where(filt == 1, sig, np.nan)

If using a copy, the sentence above works:

    s1 = sig.copy()
    s1.values[:] = np.where(filt == 1, s1, np.nan)

### Expected Behavior

Both methods should work.

### Installed Versions

[data.zip](https://github.com/user-attachments/files/20718931/data.zip)

<details>

INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.12.7.final.0
python-bits           : 64
OS                    : Darwin
OS-release            : 24.5.0
Version               : Darwin Kernel Version 24.5.0: Tue Apr 22 19:48:46 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T8103
machine               : arm64
processor             : i386
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : None.UTF-8

pandas                : 2.2.2
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
setuptools            : 75.1.0
pip                   : 24.2
Cython                : None
pytest                : 7.4.4
hypothesis            : None
sphinx                : 7.3.7
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : 5.2.1
html5lib              : None
pymysql               : None
psycopg2              : None
jinja2                : 3.1.4
IPython               : 8.27.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
bottleneck            : 1.3.7
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.6.1
gcsfs                 : None
matplotlib            : 3.9.2
numba                 : 0.60.0
numexpr               : 2.8.7
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
pyarrow               : 16.1.0
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : 2024.6.1
scipy                 : 1.13.1
sqlalchemy            : 2.0.34
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2023.6.0
xlrd                  : None
zstandard             : 0.23.0
tzdata                : 2023.3
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Bug', 'Needs Info', 'replace']",,2025-06-13 03:08:09+00:00,2025-08-05 17:10:35+00:00,,53.585023148148146
61642,ENH: Allow third-party packages to register IO engines,"- [X] xref #61584 
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Added the new system to the Iceberg connection only to keep this smaller. The idea is to add the decorator to all other connectors, happy to do it here or in a follow up PR.","['IO Data', 'API Design']",,2025-06-12 21:58:17+00:00,2025-07-03 17:02:50+00:00,,20.79482638888889
61639,[backport 2.3.x] ENH(string dtype): fallback for HDF5 with UTF-8 surrogates (#60993),Backport of #60993,[],,2025-06-12 19:18:32+00:00,2025-06-13 12:25:01+00:00,,0.7128356481481481
61638,[2.3.x] CI: temporarily pin numpy to 2.2 until latest numexpr is available,"Some tests involving numexpr are failing in the CI of the backport PRs, which is happening since the release of numpy 2.3, I think.
On the main branch this is not happening (yet), because I think numpy gets restricted there to 2.2 because of the presence of numba in the env. In the 2.3.x branch however, mamba ends up getting numpy 2.3

I reported the wrong results from numexpr upstream (https://github.com/pydata/numexpr/issues/515), although it seems it might be solved with the latest numexpr release.

",['CI'],,2025-06-12 14:03:20+00:00,2025-06-12 16:51:37+00:00,,0.11686342592592593
61636,BUG: Groupby aggregate coersion of outputs inconsistency for pyarrow dtypes,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [ ] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
from pyarrow import string

df = pd.DataFrame([
    [0,""X"",""A""],
    [1,""X"",""A""],
    [2,""X"",""A""],
    [3,""X"",""B""],
    [4,""X"",""B""],
    [5,""X"",""B""],], columns = [""a"",""b"",""c""]).astype({""a"":int,
    ""b"":str,""c"":pd.ArrowDtype(string())})

df.set_index(""b"").groupby(""a"").agg(lambda df: df.to_dict())
```

### Issue Description

When applying groupby aggregate on a column with type defined using `pd.ArrowDtype()` the pandas tries to cast the output into the original type, which can raise an error (e.g. `pyarrow.lib.ArrowNotImplementedError: Unsupported cast from struct<location_abbreviation: string> to utf8 using function cast_string` for the example provided).


For example, if `string[pyarrow]` is used, then this behaviour doesn't occur:

```python
import pandas as pd


df = pd.DataFrame([
    [0,""X"",""A""],
    [1,""X"",""A""],
    [2,""X"",""A""],
    [3,""X"",""B""],
    [4,""X"",""B""],
    [5,""X"",""B""],], columns = [""a"",""b"",""c""]).astype({""a"":int,
    ""b"":str,""c"":""string[pyarrow]""})

df.set_index(""b"").groupby(""a"").agg(lambda df: df.to_dict())

```

Or if the user-defined function also has `*args` or `**kwargs`, this coercion is not applied:
```python
import pandas as pd


df = pd.DataFrame([
    [0,""X"",""A""],
    [1,""X"",""A""],
    [2,""X"",""A""],
    [3,""X"",""B""],
    [4,""X"",""B""],
    [5,""X"",""B""],], columns = [""a"",""b"",""c""]).astype({""a"":int,
    ""b"":str,""c"":pd.ArrowDtype(string()})

df.set_index(""b"").groupby(""a"").agg(lambda df, _: df.to_dict(), [])
```
both returns:

|   a | c          |
|----:|:-----------|
|   0 | {'X': 'A'} |
|   1 | {'X': 'A'} |
|   2 | {'X': 'A'} |
|   3 | {'X': 'B'} |
|   4 | {'X': 'B'} |
|   5 | {'X': 'B'} |


### Expected Behavior

I would expect the code from example to return:
|   a | c          |
|----:|:-----------|
|   0 | {'X': 'A'} |
|   1 | {'X': 'A'} |
|   2 | {'X': 'A'} |
|   3 | {'X': 'B'} |
|   4 | {'X': 'B'} |
|   5 | {'X': 'B'} |


### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.11.6
python-bits           : 64
OS                    : Linux
OS-release            : 5.10.223-211.872.amzn2.x86_64
Version               : #1 SMP Mon Jul 29 19:52:29 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.0
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : 9.3.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.1
html5lib              : None
hypothesis            : 6.135.0
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.4.0
matplotlib            : 3.10.3
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 18.1.0
pyreadstat            : None
pytest                : 7.4.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Groupby', 'Arrow']","{'login': 'heoh', 'id': 24520785, 'node_id': 'MDQ6VXNlcjI0NTIwNzg1', 'avatar_url': 'https://avatars.githubusercontent.com/u/24520785?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/heoh', 'html_url': 'https://github.com/heoh', 'followers_url': 'https://api.github.com/users/heoh/followers', 'following_url': 'https://api.github.com/users/heoh/following{/other_user}', 'gists_url': 'https://api.github.com/users/heoh/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/heoh/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/heoh/subscriptions', 'organizations_url': 'https://api.github.com/users/heoh/orgs', 'repos_url': 'https://api.github.com/users/heoh/repos', 'events_url': 'https://api.github.com/users/heoh/events{/privacy}', 'received_events_url': 'https://api.github.com/users/heoh/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-12 11:37:40+00:00,2025-07-29 16:13:54+00:00,heoh,47.191828703703706
61635,Description of pandas_datetime_exec function.,"Added the function description documentation for `pandas_datetime_exec` in the following location.

https://github.com/pandas-dev/pandas/blob/main/pandas/_libs/src/datetime/pd_datetime.c

- [x] closes #61631 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-06-11 19:15:00+00:00,2025-06-30 18:12:42+00:00,,18.956736111111113
61633,[backport 2.3.x] BUG(string dtype): groupby/resampler.min/max returns float on all NA strings (#60985),Backport of https://github.com/pandas-dev/pandas/pull/60985,[],,2025-06-11 13:59:17+00:00,2025-06-12 19:11:01+00:00,,1.2164814814814815
61631,DOC: Description of pandas_datetime_exec function,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://github.com/pandas-dev/pandas/blob/main/pandas/_libs/src/datetime/pd_datetime.c

### Documentation problem

The file pd_datetime.c has missing documentation on line 195 for the function static int pandas_datetime_exec(PyObject *Py_UNUSED(module)). We need to add documentation for what the role of this function is.

### Suggested fix for documentation

The suggested fix is to add documentation for the function that has been defined on line 195.

The function initializes and exposes a custom datetime C-API from the Pandas library by creating a PyCapsule that stores function pointers, which can be accessed later by other C code (or Cython code) that imports the capsule.","['Docs', 'Needs Triage']",,2025-06-11 04:32:00+00:00,2025-06-30 18:12:43+00:00,,19.56994212962963
61630,DOC: Title Capitalization and Grammar Fix,"Currrently the title of the repository in the README.md reads the following text: pandas: powerful Python data analysis toolkit

Since the title is grammatically incorrect and also has incorrect capitalization, this pull request was opened to ensure that the title is capitalized properly and there are no grammatical errors in the title.",['Docs'],,2025-06-11 04:17:22+00:00,2025-06-11 16:00:08+00:00,,0.4880324074074074
61629,BUG: to_stata erroring when encoded text and normal text have mismatched length,"- [x] closes #61583  (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

I removed the encoded check in stata.py and replaced it with a normal check, if the encoded check was there for any particular reason I can standardize them the other way","['Bug', 'IO Stata']",,2025-06-10 22:35:36+00:00,2025-06-30 18:14:29+00:00,,19.81866898148148
61627,"BUG: the behavior of DataFrameGroupBy.apply(..., include_groups=True) breaks post-mortem debugging","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

def f(df):
    df[""group""]
    raise TypeError(""a very subtle bug"")

pd.DataFrame({""group"": [""a"", ""a"", ""b"", ""b""], ""data"": [0, 1, 2, 3]}).groupby(""group"").apply(f)
```

### Issue Description

The argument in the title and the corresponding behavior is described like this:

```
When True, will attempt to apply func to the groupings in the case that they are columns of the DataFrame.
If this raises a TypeError, the result will be computed with the groupings excluded. When False,
the groupings will be excluded when applying func.
```

https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html

I think the described behavior is problematic and it renders close to impossible to use post-mortem debugging for the `TypeError(""a very subtle bug"")`. pandas should not swallow `TypeError` hoping that developers will figure it out in a pile of logs.

### Expected Behavior

There should be no ""attempts"" from the docs and pandas should not catch and swallow any exceptions from the payload.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.13.3
python-bits           : 64
OS                    : Linux
OS-release            : 6.14.9-300.fc42.x86_64
Version               : #1 SMP PREEMPT_DYNAMIC Thu May 29 14:27:53 UTC 2025
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.0
numpy                 : 2.3.0
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Groupby', 'Apply']",,2025-06-10 20:00:05+00:00,2025-07-31 02:07:16+00:00,,50.25498842592592
61626,DOC: Pandas contributor take limit,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/development/contributing.html#id2

### Documentation problem

I don't believe it is documented anywhere but I think there is a two assigned task limit for issues. Currently, whenever I type ""take"" the bot doesn't auto assign me a task.

I think this should be documented as I have one completed issue which is still waiting for a PR review, and another which needs further discussion during a meeting. It's not like I'm just randomly taking tasks. Other people could run into something similar. A maintainer should verify that there is a limit before we edit the documentation first though.

Example:
https://github.com/pandas-dev/pandas/issues/61583#issuecomment-2960369848
https://github.com/pandas-dev/pandas/issues/61511#issuecomment-2932438936

### Suggested fix for documentation

Just add that there is a limit to the number of issues you can concurrently take and to contact a maintainer if you run into issues and need more (up to maintainer discretion on the last part)",['Docs'],"{'login': 'SnehaDeshmukh28', 'id': 91473383, 'node_id': 'MDQ6VXNlcjkxNDczMzgz', 'avatar_url': 'https://avatars.githubusercontent.com/u/91473383?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/SnehaDeshmukh28', 'html_url': 'https://github.com/SnehaDeshmukh28', 'followers_url': 'https://api.github.com/users/SnehaDeshmukh28/followers', 'following_url': 'https://api.github.com/users/SnehaDeshmukh28/following{/other_user}', 'gists_url': 'https://api.github.com/users/SnehaDeshmukh28/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/SnehaDeshmukh28/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/SnehaDeshmukh28/subscriptions', 'organizations_url': 'https://api.github.com/users/SnehaDeshmukh28/orgs', 'repos_url': 'https://api.github.com/users/SnehaDeshmukh28/repos', 'events_url': 'https://api.github.com/users/SnehaDeshmukh28/events{/privacy}', 'received_events_url': 'https://api.github.com/users/SnehaDeshmukh28/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-10 19:38:27+00:00,2025-06-22 11:21:17+00:00,SnehaDeshmukh28,11.654745370370371
61625,[backport 2.3.x] BUG(string dtype): Empty sum produces incorrect result (#60936),Backport of https://github.com/pandas-dev/pandas/pull/60936,[],,2025-06-10 15:01:04+00:00,2025-06-12 14:05:15+00:00,,1.961238425925926
61624,BUG: Fix infer_dtype result for float with embedded pd.NA,"- [x] closes #61621
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

## Description
Fix a bug in :func:`api.types.infer_dtype` returning ""mixed-integer-float"" for float and ``pd.NA`` mix.

## Cause
This problem occurred because the existing `is_float_array` internally fixed `skipna=False`. It was solved by adding the `skipna` argument.
","['Bug', 'Missing-data', 'Dtype Conversions']",,2025-06-10 14:37:42+00:00,2025-07-11 19:08:56+00:00,,31.18835648148148
61623,BUG: DataFrame.explode fails with str dtype,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This operation works on all other dtypes, e.g.

```python
df = pd.DataFrame({""a"": [1, 2]})
print(df.explode(column=""a""))
#    a
# 0  1
# 1  2
```
","['Bug', 'Reshaping', 'Strings']",,2025-06-10 11:13:09+00:00,2025-06-24 07:35:49+00:00,,13.849074074074075
61622,BUG: CoW - eq not implemented for <class 'pandas.core.internals.blocks.ExtensionBlock'>,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
pd.options.mode.copy_on_write = True

idx = pd.Index(['a', 'b', 'c'], dtype=""string[pyarrow]"")
pd.Series(idx).replace({""z"": ""b"", ""a"": ""d""})
```

### Issue Description

The above code raises the following issue:
`NotImplementedError: eq not implemented for <class 'pandas.core.internals.blocks.ExtensionBlock'>`

### Expected Behavior

The code should run without raising any error as it does without the CoW clause, shouldn't it?

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.12.5
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en
LOCALE                : English_United Kingdom.1252

pandas                : 2.3.0
numpy                 : 2.1.3
pytz                  : 2024.1
dateutil              : 2.9.0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : 1.1
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : 5.3.0
matplotlib            : 3.9.2
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : None
pyarrow               : 17.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.0
sqlalchemy            : 2.0.35
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : 0.23.0
tzdata                : 2024.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'replace', 'Copy / view semantics']","{'login': 'rhshadrach', 'id': 45562402, 'node_id': 'MDQ6VXNlcjQ1NTYyNDAy', 'avatar_url': 'https://avatars.githubusercontent.com/u/45562402?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/rhshadrach', 'html_url': 'https://github.com/rhshadrach', 'followers_url': 'https://api.github.com/users/rhshadrach/followers', 'following_url': 'https://api.github.com/users/rhshadrach/following{/other_user}', 'gists_url': 'https://api.github.com/users/rhshadrach/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/rhshadrach/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/rhshadrach/subscriptions', 'organizations_url': 'https://api.github.com/users/rhshadrach/orgs', 'repos_url': 'https://api.github.com/users/rhshadrach/repos', 'events_url': 'https://api.github.com/users/rhshadrach/events{/privacy}', 'received_events_url': 'https://api.github.com/users/rhshadrach/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-10 11:01:53+00:00,2025-07-28 16:24:08+00:00,rhshadrach,48.22378472222222
61621,BUG: infer_dtype result for float with embedded pd.NA,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
from pandas.api.types import infer_dtype
assert infer_dtype(pd.Series([1.,2.,.3,pd.NA], dtype=object)) ==  infer_dtype(pd.Series([1.,2.,.3,np.nan], dtype=object))
```

### Issue Description

Dear pandas-folks,

This was checked for pandas V 2.3.0 and 2.2.X

When using pandas' `infer_dtype` on an object array consisting out of floats with embedded `pd.NA`, the result will be `mixed-integer-float` tough `skipna` is `True` as a default.

The same test for embedded `np.nan` returns `floating`.

```python
    >>> from pandas.api.types import infer_dtype
    >>> infer_dtype(pd.Series([1,2,3,pd.NA], dtype=object))
    'integer'
    >>> infer_dtype(pd.Series([1,2,3,np.nan], dtype=object))
    'integer'
    >>> infer_dtype(pd.Series([1.,2.,.3,pd.NA], dtype=object))
    'mixed-integer-float' v <<< should be `floating`
    >>> infer_dtype(pd.Series([1.,2.,.3,np.nan], dtype=object))
    'floating'
    >>> infer_dtype(pd.Series(['1.0', np.nan],dtype=object))
    'string'
    >>> infer_dtype(pd.Series(['1.0', pd.NA],dtype=object))
    'string'
```

In case of other types, like integer or strings, the function does not produce a false / different output w.r.t. the na-type.


Context, I am maintaining a small project which assures integers in columns to stay integers - a common known issue. I you know of a well established extension for this purpose, feel free to point me towards it. 

### Expected Behavior

`>>> infer_dtype(pd.Series([1.,2.,.3,pd.NA], dtype=object))` should return `floating`

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.13.3
python-bits           : 64
OS                    : Linux
OS-release            : 4.18.0-553.51.1.el8_10.x86_64
Version               : #1 SMP Fri Apr 25 00:55:37 EDT 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.0
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : 9.2.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Missing-data', 'Dtype Conversions']","{'login': 'heoh', 'id': 24520785, 'node_id': 'MDQ6VXNlcjI0NTIwNzg1', 'avatar_url': 'https://avatars.githubusercontent.com/u/24520785?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/heoh', 'html_url': 'https://github.com/heoh', 'followers_url': 'https://api.github.com/users/heoh/followers', 'following_url': 'https://api.github.com/users/heoh/following{/other_user}', 'gists_url': 'https://api.github.com/users/heoh/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/heoh/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/heoh/subscriptions', 'organizations_url': 'https://api.github.com/users/heoh/orgs', 'repos_url': 'https://api.github.com/users/heoh/repos', 'events_url': 'https://api.github.com/users/heoh/events{/privacy}', 'received_events_url': 'https://api.github.com/users/heoh/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-10 09:15:31+00:00,2025-07-11 19:08:58+00:00,heoh,31.412118055555556
61619,DOC: Clarify that 'names' is only used when constructing a MultiIndex,"- [x] closes #19082
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature  
      **(Not applicable ‚Äî this is a documentation-only change)**
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit)
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions  
      **(Not applicable ‚Äî no new functions or arguments were added)**
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature  
      **(Optional ‚Äî this change may be too minor, but can be added under ""Documentation"" if desired)**

### Description

Clarifies in the `Index` class docstring that the `names` parameter is only relevant when constructing a `MultiIndex`. This prevents confusion where users expect `names=('a',)` to behave like `name='a'` for regular Index objects.

No changes were made to the behavior of `Index`, only to the documentation for better clarity.
",[],,2025-06-10 03:14:48+00:00,2025-06-10 12:53:18+00:00,,0.4017361111111111
61615,BUG: Fix RecursionError when apply native container types as a func,"- [x] closes #61565
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
  - Nothing new added.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

## Description
Fixes a bug in `DataFrame.apply` raising `RecursionError` when passing `func=list[int]`.

## Cause
The existing code handled parameterized container types, but not native container types, yielding false positives. I also added a check for `types.GenericAlias` to handle native container types.

#### Reference: https://github.com/python/cpython/blob/3.12/Lib/typing.py#L1251
> ```py
> class _GenericAlias(_BaseGenericAlias, _root=True):
>     ...
>     # Objects which are instances of this class include:
>     # * Parameterized container types, e.g. `Tuple[int]`, `List[int]`.
>     #  * Note that native container types, e.g. `tuple`, `list`, use
>     #    `types.GenericAlias` instead.
> ```",['Dtype Conversions'],,2025-06-09 19:03:33+00:00,2025-06-16 23:13:25+00:00,,7.173518518518518
61614,feat(1.5.x): Add support for python 3.12,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-09 15:25:57+00:00,2025-06-09 16:53:46+00:00,,0.06098379629629629
61613,Fix type annotation issues in pandas/core/frame.py to resolve self-re‚Ä¶,"‚Ä¶ferences and pipe operator syntax

- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-09 11:14:56+00:00,2025-06-09 11:36:15+00:00,,0.01480324074074074
61612,Fix explode to preserve datetime unit in Series and DataFrame; update‚Ä¶,"
This PR fixes an issue where the explode method in both Series and DataFrame does not preserve the datetime unit information (such as milliseconds or microseconds) of DatetimeIndex or datetime-like data. Previously, exploding a datetime-like Series or DataFrame column would convert timestamps to nanosecond resolution, losing the original unit precision.

The fix ensures that after exploding, the resulting Series or DataFrame retains the original datetime unit dtype, maintaining consistency and avoiding unwanted dtype changes.

Additionally, relevant tests have been updated and extended to verify that the datetime unit is preserved through explode operations in both single- and multi-column cases.

- [x] closes #61610 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-08 21:27:32+00:00,2025-06-12 09:09:05+00:00,,3.4871875
61611,Fix/devcontainer qt deps,"- [x] closes #61037 
- [x] [Tests not added and not passed]Test: Manually ran pytest inside the devcontainer to confirm PyQt5 and pytest-qt are functional.
- Adding platform: linux/amd64 to the docker-compose.yml dev service to work around image compatibility issues on Apple Silicon.
- Switching from direct Dockerfile builds to docker-compose.yml via updates in .devcontainer/devcontainer.json:
Removed ""dockerFile"" setting
Added ""service"", ""workspaceFolder"", and ""dockerComposeFile""
- Installing qt5-qmake and qtbase5-dev via apt-get to support pytest-qt, which is required for the test suite. However this is commented in order to avoid redundant tools installed on not arm/Arch64 plattform just like the original file. The user should uncomment it.

These changes resolve build failures seen on Apple Silicon when using the VS Code Remote - Containers extension.

Why this matters:

Apple Silicon machines often encounter architecture compatibility issues when building development containers, especially when Python packages need to compile C/C++ or Qt-based code. These changes ensure a smooth devcontainer build experience on both ARM64 and x86_64 environments.

## Introduction

If you use mac Silicon, you should uncomment   ""# platform: linux/amd64"" of docker-compose.yml file and     #-y qt5-qmake qtbase5-dev\ of Dockerfile. If you use another plattform, just build dev container or docker container as usual, nothing was changed.
",['Build'],,2025-06-08 20:43:57+00:00,2025-07-28 17:19:51+00:00,,49.85826388888889
61610,BUG: `explode()` converts timestamps at millisecond resolution in DatetimeIndex to nanosecond resolution,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
test = pd.Series([pd.date_range(""2020-01-01T00:00:00Z"", ""2020-01-01T02:00:00Z"", freq=""1h"", unit=""ms"")])
test.explode().dtype
```

### Issue Description

The docs for `pd.date_range` state that the `unit` keyword argument is the resolution of timestamps in the returned DatetimeIndex, which is true---and counter to the usage of `unit` elsewhere, e.g. in `pd.to_datetime`. Regardless of this discrepancy, `explode` does not respect the millisecond resolution of timestamps in a DatetimeIndex, converting them to nanosecond resolution in the returned Series or DataFrame.

### Expected Behavior

dtypes should not be changed by `explode`.

### Installed Versions

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.11.13
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.0-139-generic
Version               : #149~20.04.1-Ubuntu SMP Wed Apr 16 08:29:56 UTC 2025
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.3.0
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : 8.2.3
IPython               : 9.3.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.1
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.3
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : 8.4.0
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.5.1
scipy                 : 1.15.3
sqlalchemy            : 2.0.41
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
","['Bug', 'Needs Triage']",,2025-06-08 18:02:53+00:00,2025-06-11 22:40:10+00:00,,3.1925578703703703
61609,CLN: Fix code formatting to address pre-commit and build failures,"Run ruff --fix and ruff format to fix style issues flagged by pre-commit.
This resolves common RUF003 errors (e.g., ambiguous hyphens) seen across multiple PRs.",[],,2025-06-08 16:07:29+00:00,2025-06-09 08:10:03+00:00,,0.6684490740740741
61608,BUG: Pandas concat raises RuntimeWarning: '<' not supported between i‚Ä¶,"# Fix GH-61477: Stop Spurious Warning When `concat(..., sort=False)` on Mixed-Type `MultiIndex`

## Overview

When you do something like:

```python
pd.concat([df1, df2], axis=1, sort=False)
```
and your two DataFrames have MultiIndex columns that mix tuples and integers, pandas used to try to sort those labels under the hood. Since Python cannot compare tuple < int, you‚Äôd see:
```
RuntimeWarning: '<' not supported between instances of 'int' and 'tuple'; sort order is undefined for incomparable objects with multilevel columns
```

This warning is confusing, and worse, you explicitly asked not to sort (sort=False), so pandas should never even try.

# What Changed
1. Short-circuit Index.union when sort=False
Before: Even with sort=False, pandas would call its normal union logic, which might attempt to compare labels.

Now: If you pass sort=False, we simply concatenate the two index arrays with:
``` 
np.concatenate([self._values, other._values])
```
and wrap that in a new Index. No comparisons, no warnings, and your original order is preserved.


2. Guard sorting in MultiIndex._union
Before: pandas would call ```result.sort_values()``` when sort wasn‚Äôt False, and if labels were unorderable it would warn you.

Now: We only call ```sort_values()``` when sort is truthy (True), and we wrap it in a ```try/except``` TypeError that silently falls back to the existing order on failure. No warning is emitted.

3. New Regression Test
A pytest test reproduces the original bug scenario, concatenating two small DataFrames with mixed-type MultiIndex columns and ```sort=False.``` The test asserts:

No RuntimeWarning is raised

Column order is exactly ‚Äúfirst DataFrame‚Äôs columns, then second DataFrame‚Äôs columns‚Äù

Respects sort=False: If a user explicitly disables sorting, pandas won‚Äôt try.

Silences spurious warnings: No more confusing messages about comparing tuples to ints.

Keeps existing behavior for sort=True: You still get a sort or a real error if the labels truly can‚Äôt be ordered.

For testing we can try 
```
import numpy as np, pandas as pd

left = pd.DataFrame(
    np.random.rand(5, 2),
    columns=pd.MultiIndex.from_tuples([(""A"", 1), (""B"", (2, 3))])
)
right = pd.DataFrame(
    np.random.rand(5, 1),
    columns=pd.MultiIndex.from_tuples([(""C"", 4)])
)

# No warning, order preserved:
out = pd.concat([left, right], axis=1, sort=False)
print(out.columns)  # [(""A"", 1), (""B"", (2, 3)), (""C"", 4)]

# Sorting still works if requested:
sorted_out = pd.concat([left, right], axis=1, sort=True)
print(sorted_out.columns)  # sorted order or TypeError if impossible
```
Implemented a new approach for concatenating indices with mixed data types using the 'union' method to resolve the previous failing test cases. This ensures correct merging of indices with different types, addressing the issue reported in the original pull request.
",[],,2025-06-08 15:15:25+00:00,2025-06-08 16:01:47+00:00,,0.032199074074074074
61606,DEP: update python-calamine to 0.3.2,"- [x] closes https://github.com/pandas-dev/pandas/issues/61186
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This PR updates the calamine engine dependency to version `0.3.2`, which includes the upstream fix for leading-zero truncation in VLOOKUP-derived Excel cells.
",['Dependencies'],,2025-06-08 07:05:47+00:00,2025-06-19 20:50:35+00:00,,11.572777777777778
61604,WEB: Replace os.path with pathlib.Path in pandas_web.py,"Replaces `os.path` with `pathlib.Path` in `pandas_web.py`, as suggested by @datapythonista in [61578](https://github.com/pandas-dev/pandas/pull/61578). No functional changes, verified site generation remains correct

- [x] Ran pre-commit check",['Web'],,2025-06-07 22:27:57+00:00,2025-06-13 16:21:39+00:00,,5.745625
61603,REF: Replace os.path with pathlib.Path in pandas_web.py,"Replaces `os.path `with `pathlib.Path` in `pandas_web.py`, as suggested by @datapythonista in [61578](https://github.com/pandas-dev/pandas/pull/61578). No functional changes, verified site generation remains correct
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
",[],,2025-06-07 22:00:23+00:00,2025-06-07 22:18:40+00:00,,0.01269675925925926
61602,BUG: Writing UUIDs fail,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
>>> df = pd.DataFrame({'id': [uuid.uuid4(), uuid.uuid4(), uuid.uuid4()]})
>>> df
                                     id
0  6f6303cd-516d-4a27-9165-bb703f9e2240
1  c250ba7f-31db-47de-b02b-54296ac6a4df
2  c523257a-51ab-4160-957b-619ce55c78f9
>>> df.to_parquet('sample_pandas_pa.parquet', engine='pyarrow')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File "".venv/lib/python3.12/site-packages/pandas/util/_decorators.py"", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "".venv/lib/python3.12/site-packages/pandas/core/frame.py"", line 3113, in to_parquet
    return to_parquet(
           ^^^^^^^^^^^
  File "".venv/lib/python3.12/site-packages/pandas/io/parquet.py"", line 480, in to_parquet
    impl.write(
  File "".venv/lib/python3.12/site-packages/pandas/io/parquet.py"", line 190, in write
    table = self.api.Table.from_pandas(df, **from_pandas_kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""pyarrow/table.pxi"", line 4793, in pyarrow.lib.Table.from_pandas
  File "".venv/lib/python3.12/site-packages/pyarrow/pandas_compat.py"", line 639, in dataframe_to_arrays
    arrays = [convert_column(c, f)
              ^^^^^^^^^^^^^^^^^^^^
  File "".venv/lib/python3.12/site-packages/pyarrow/pandas_compat.py"", line 626, in convert_column
    raise e
  File "".venv/lib/python3.12/site-packages/pyarrow/pandas_compat.py"", line 620, in convert_column
    result = pa.array(col, type=type_, from_pandas=True, safe=safe)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""pyarrow/array.pxi"", line 365, in pyarrow.lib.array
  File ""pyarrow/array.pxi"", line 90, in pyarrow.lib._ndarray_to_array
  File ""pyarrow/error.pxi"", line 92, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: (""Could not convert UUID('6f6303cd-516d-4a27-9165-bb703f9e2240') with type UUID: did not recognize Python value type when inferring an Arrow data type"", 'Conversion failed for column id with type object')
```

### Issue Description

Writing UUIDs fail. pyarrow supports writing UUIDs

### Expected Behavior

Writing UUIDs pass

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.9
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-57-generic
Version               : #59~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Mar 19 17:07:41 UTC 2
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.1
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.3
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'IO Parquet', 'Needs Triage', 'Upstream issue', 'Arrow']",,2025-06-07 21:30:22+00:00,2025-07-31 01:43:59+00:00,,53.176122685185184
61601,"WEB: remove ""String data type"" from ""Roadmap points pending a PDEP"" section.","> pandas is in the process of moving roadmap points to PDEPs (implemented in August 2022). During the transition, some roadmap points will exist as PDEPs, while others will exist as sections below.

This one is now covered by PDEP-14 which has been accepted and therefore no longer pending a PDEP.",['Web'],,2025-06-07 19:35:18+00:00,2025-06-08 16:00:49+00:00,,0.8510532407407407
61600,DOC/ENH: Holiday exclusion argument,"- [x] closes #54382 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Frequency'],,2025-06-07 17:07:21+00:00,2025-06-13 16:11:42+00:00,,5.961354166666666
61598,BUG: Dangerous inconsistency: `~` operator changes behavior based on context outside a target.,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df = pd.DataFrame({
   ...:     'A': [1, 9, 6, 2, 7],
   ...:     'B': [6, 1, 3, 6, 3],
   ...:     'C': [2, 8, 4, 4, 4]
   ...: }, index=list('abcde'))
df.apply(lambda x: ~((x['B'] > 3) & (x['C'] < 8)), axis=1)
df['vals'] = df.apply(lambda x: ~((x['B'] > 3) & (x['C'] < 8)), axis=1)
df.apply(lambda x: ~((x['B'] > 3) & (x['C'] < 8)), axis=1)
```

### Issue Description

This ia reprot about `~` opetarotr in pandas dataframe.

Here is the example on python=3.10.12, pandas=2.2.3.

```
python 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]
Type 'copyright', 'credits' or 'license' for more information
IPython 8.34.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import pandas as pd

In [2]: df = pd.DataFrame({
   ...:     'A': [1, 9, 6, 2, 7],
   ...:     'B': [6, 1, 3, 6, 3],
   ...:     'C': [2, 8, 4, 4, 4]
   ...: }, index=list('abcde'))

In [3]: df
Out[3]:
   A  B  C
a  1  6  2
b  9  1  8
c  6  3  4
d  2  6  4
e  7  3  4

In [3]: df
Out[3]:
   A  B  C
a  1  6  2
b  9  1  8
c  6  3  4
d  2  6  4
e  7  3  4

In [4]: df.apply(lambda x: ~((x['B'] > 3) & (x['C'] < 8)), axis=1)
Out[4]:
a    False
b     True
c     True
d    False
e     True
dtype: bool

In [5]: df['vals'] = df.apply(lambda x: ~((x['B'] > 3) & (x['C'] < 8)), axis=1)

In [6]: df
Out[6]:
   A  B  C   vals
a  1  6  2  False
b  9  1  8   True
c  6  3  4   True
d  2  6  4  False
e  7  3  4   True

In [7]: df.apply(lambda x: ~((x['B'] > 3) & (x['C'] < 8)), axis=1)
Out[7]:
a   -2
b   -1
c   -1
d   -2
e   -1
dtype: int64
```

In the above example, the same `df.apply(lambda x: ~((x['B'] > 3) & (x['C'] < 8)), axis=1)` is executed in step 4, 5, and 7.
However, the result of step 7 is ridiculous.
In spite of `~`, `not` operator returns a correct answer.
It seems that `~` operator in pandas dataframe quite dangerous and unreliable.

In the environment of python 3.13.3, panads=2.2.3, **only for the step 7**, python returns warning that `<ipython-input-7-7d5677ff0f59>:1: DeprecationWarning: Bitwise inversion '~' on bool is deprecated and will be removed in Python 3.16. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.`.
However, I think this is a warning by python (not by pandas) from a different point of view.



### Expected Behavior

The result of step 7 is same as step 4, 5.

### Installed Versions

python = 3.10.12
pandas = 2.2.3

</details>
",['Usage Question'],,2025-06-07 13:43:53+00:00,2025-06-13 08:35:04+00:00,,5.7855439814814815
61597,ENH: improve optional import error message,"- [x] closes #61521 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Error Reporting'],,2025-06-07 09:16:15+00:00,2025-06-30 18:16:14+00:00,,23.374988425925928
61596,VOTE: Voting issue for PDEP-15: Reject adding PyArrow as a required dependency,"### Locked issue

- [x] I locked this voting issue so that only voting members are able to cast their votes or comment on this issue.


### PDEP number and title

PDEP-15: Reject PDEP-10

### Pull request with discussion

https://github.com/pandas-dev/pandas/pull/58623

### Rendered PDEP for easy reading

https://github.com/pandas-dev/pandas/blob/c159851cc0762625f9e51f9d9bd1d18011b79aa7/web/pandas/pdeps/0015-do-not-require-pyarrow.md

### Discussion participants

5 voting members (active maintainers) participated in the discussion

### Voting will close in 15 days.

2025-06-22

### Vote

Cast your vote in a comment below.
* +1: approve.
* 0: abstain.
    * Reason: A one sentence reason is required.
* -1: disapprove
    * Reason: A one sentence reason is required.
A disapprove vote requires prior participation in the linked discussion PR.

@pandas-dev/pandas-core
",['Vote'],,2025-06-07 09:02:40+00:00,2025-07-17 10:40:25+00:00,,40.067881944444444
61595,Add table of contents support to ecosystem page,"This PR adds a table of contents to the Ecosystem page using the Markdown `TocExtension`.

- Inserted `[TOC]` placeholder in `ecosystem.md`
- Enabled `toc` extension in `web.py`
- Configured `toc_depth` for h2 and h3 headers
- Closes #61587
",['Web'],,2025-06-07 00:46:04+00:00,2025-06-13 17:11:48+00:00,,6.684537037037037
61594,CI: Fix slow mamba solver issue by limiting boto3 versions,"Closes #61531

Probably better to rerun the CI 3 or 4 times to be sure this is the problem and the solution. But based on local tests, seems like boto3 has a huge number of versions (they release almost every day), and that's the problem with the mamba solver. Limiting the number of versions provided to the solver should help. 1.27 is from 2 years ago, consistent with other packages. Why only fails for  3.13? No idea","['CI', 'Dependencies']",,2025-06-06 21:01:41+00:00,2025-06-13 14:34:12+00:00,,6.730914351851852
61593,WEB: Restore website width and improve table of contents style,"Follow up of #58791

This restore the website width (happy to make the content of PDEPs narrower, but it's a bit trickier so I'll leave it to another PR).

I also styled the table of contents more similar to the code blocks, which personally I think it looks a bit nicer.

Before:
![Screenshot at 2025-06-06 23-23-22](https://github.com/user-attachments/assets/7a025b7c-c5b6-4e6a-b921-627f4e3439cf)

After:
![Screenshot at 2025-06-06 23-22-37](https://github.com/user-attachments/assets/178642b6-8376-4992-bef0-224fddb2c97d)

CC @rhshadrach ",['Web'],,2025-06-06 19:28:04+00:00,2025-06-08 12:47:50+00:00,,1.722060185185185
61592,CI: Update Python version to 3.11 in environment.yml,"xref #61585

Let's pin to 3.11 for now (let's see if this doesn't break the CI), and we can continue the discussion on unpinning if needed.
","['CI', 'Dependencies']",,2025-06-06 19:01:57+00:00,2025-06-06 20:57:16+00:00,,0.08008101851851852
61591,WEB: Moving maintainers to inactive status,"A sad PR, but after checking with some maintainers, they confirmed that they became inactive and wish to be changed status. I think 3 more people will also be moved unfortunately, but still waiting for confirmation from them.
","['Admin', 'Web']",,2025-06-06 18:27:15+00:00,2025-06-06 22:09:23+00:00,,0.15425925925925926
61590,RLS: 2.3.1,"Placeholder issue _if_ we decide to release 2.3.1. At the time of writing this issue, it's expected that pandas 3.0 would be the next version https://github.com/pandas-dev/pandas/issues/57064

Notable tasks for 2.3.1:

- [x] Re-enable Python 3.9 support (https://github.com/pandas-dev/pandas/issues/61563, https://github.com/pandas-dev/pandas/issues/61579)
    - [x] Revert https://github.com/pandas-dev/pandas/pull/60792
    - [x] Merge https://github.com/pandas-dev/pandas/pull/61569 (without hardcoding version)
- [x] Re-enable musl-aarch64 wheels
    - [x] Merge https://github.com/pandas-dev/pandas/pull/61569 (without hardcoding version)
   ",['Release'],,2025-06-06 17:01:06+00:00,2025-07-28 16:12:16+00:00,,51.966087962962966
61589,Avoid re-enabling the GIL at runtime,"The GIL gets dynamically reenabled because the shared utility Cython build does not include the `freethreading_compatible` directive.

- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Build', 'Internals']",,2025-06-06 16:43:49+00:00,2025-06-06 18:36:09+00:00,,0.07800925925925926
61588,CI: Test pandas with numpy 1.26,"See #60154 

We should add the build and fix the existing errors","['Testing', 'CI', 'Dependencies', 'good first issue']","{'login': 'iabhi4', 'id': 61010675, 'node_id': 'MDQ6VXNlcjYxMDEwNjc1', 'avatar_url': 'https://avatars.githubusercontent.com/u/61010675?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/iabhi4', 'html_url': 'https://github.com/iabhi4', 'followers_url': 'https://api.github.com/users/iabhi4/followers', 'following_url': 'https://api.github.com/users/iabhi4/following{/other_user}', 'gists_url': 'https://api.github.com/users/iabhi4/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/iabhi4/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/iabhi4/subscriptions', 'organizations_url': 'https://api.github.com/users/iabhi4/orgs', 'repos_url': 'https://api.github.com/users/iabhi4/repos', 'events_url': 'https://api.github.com/users/iabhi4/events{/privacy}', 'received_events_url': 'https://api.github.com/users/iabhi4/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-06 14:17:38+00:00,2025-07-08 15:44:44+00:00,iabhi4,32.06048611111111
61587,WEB: Add table of content for the Ecosystem page,"We did it for the PDEP pages here: #58791

I don't think it should be difficult to also add a table of contents for the ecosystem page, which is quite large and not so easy to find things","['good first issue', 'Web']",,2025-06-06 13:56:03+00:00,2025-06-16 09:09:07+00:00,,9.800740740740741
61586,Update whatsnew for issue #53115,https://github.com/pandas-dev/pandas/pull/60898,['Docs'],,2025-06-06 12:56:51+00:00,2025-06-09 17:14:06+00:00,,3.1786458333333334
61583,"BUG: StataWriter returns ascii error when length of string is < 2045, but encoded length is > 2045","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

df = pd.DataFrame({'doubleByteCol': ['¬ß'*1500]})
df.to_stata('temp.dta', version=118)

len_encoded = df['doubleByteCol'].str.encode('utf-8').str.len()     # _encode_strings() count = 3000 -> no byte encoding because assumed will become strL (stata.py:2694)
len_typlist = df['doubleByteCol'].str.len()                         # _dtype_to_stata_type() = 1500 -> typ 1500 (stata.py:2193)
len_typlist < 2045      # True -> Tries to convert to np dtype S1500, but fails because unicode characters are not supported (normally no issue because encoded to bytes first) (stata.py:2945,2956)
```

### Issue Description

The StataWriter uses two different versions of the string column to check the same thing. During _encode_strings() it checks the length of the byte-encoded column `max_len_string_array(ensure_object(encoded._values))` but when assigning numpy types it checks the (potentially) unencoded version `itemsize = max_len_string_array(ensure_object(column._values))`. This then trips up the _prepare_data() section, which expects short columns to be byte-encoded already `typ <= self._max_string_length` based on the reported type, which is not true if the encoded column > 2045 due to unicode characters such as `¬ß` taking up two bytes.

### Expected Behavior

I don't know the internal workings of stata.py well enough to be sure, but I think the easiest fix is using the actual values when checking str length in _encode_strings(). That is, replace
```max_len_string_array(ensure_object(encoded._values))```
by
```max_len_string_array(ensure_object(self.data[col]._values))```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.12.1.final.0
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : AMD64 Family 25 Model 33 Stepping 0, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : English_Belgium.1252

pandas                : 2.2.2
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
setuptools            : None
pip                   : 23.2.1
Cython                : None
pytest                : 8.3.5
hypothesis            : None
sphinx                : None
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : 4.9.4
html5lib              : None
pymysql               : None
psycopg2              : None
jinja2                : None
IPython               : None
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
gcsfs                 : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
pyarrow               : 15.0.2
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
zstandard             : None
tzdata                : 2024.1
qtpy                  : None
pyqt5                 : None

</details>

### Temporary fix
For users finding this topic, this refers to the following Exception
```
Exception has occurred: UnicodeEncodeError       (note: full exception trace is shown but execution is paused at: <module>)
'ascii' codec can't encode characters in position 0-1499: ordinal not in range(128)
  File ""F:\datatog\junkyard\adhoc-scripts\mwes\pandas_asciiencoding.py"", line 4, in <module> (Current frame)
    df.to_stata('temp.dta', version=118)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1499: ordinal not in range(128)
```

You can workaround this issue by explicitly specifying the offending columns in the `convert_strL` option.","['Bug', 'IO Stata', 'Needs Triage']",,2025-06-06 10:14:19+00:00,2025-06-30 18:14:30+00:00,,24.333460648148147
61582,BUG: Require sample weights to sum to less than 1 when replace = True,"- [x] closes #61516
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Algos']",,2025-06-06 10:05:48+00:00,2025-07-11 02:27:15+00:00,,34.6815625
61580,DOC: Fix typos,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-06-06 06:01:54+00:00,2025-06-06 13:08:35+00:00,,0.2963078703703704
61579,"`pandas.__version__` is `2.3.0+4.g1dfc98e16a` in pandas 2.3.0 and python 3.9, not `2.3.0`","## How to reproduce:

```
docker run --rm python:3.9 bash -c ""pip install pandas && python -c 'import pandas; print(pandas.__version__)'""
```

## Output:

```sh
% docker run --rm python:3.9 bash -c ""pip install pandas && python -c 'import pandas; print(pandas.__version__)'""

... # pip install logs

2.3.0+4.g1dfc98e16a
```

Seems related to https://github.com/pandas-dev/pandas/issues/61563#issuecomment-2947099734",['Bug'],,2025-06-06 02:49:46+00:00,2025-07-07 19:28:56+00:00,,31.69386574074074
61578,DOC: Validate versions.json before building docs #61573,"Adds a JSON validity check for `versions.json` directly inside `pandas_web` during context generation. This ensures malformed JSON (e.g., trailing commas) is caught early, preventing issues like the broken version dropdown in #61572

- [x] Closes #61573","['CI', 'Web']",,2025-06-05 21:48:19+00:00,2025-06-07 10:00:46+00:00,,1.5086458333333332
61577,TST: Remove match= in test_setitem_invalid to avoid PytestWarning,"test only change - This PR removes the use of `match=""""` in `test_setitem_invalid` within `base/setitem.py`. 

Using an empty string as a match pattern triggers a `PytestWarning` in newer versions of pytest, so the `match` argument has been removed since the message was not being validated

- [x] closes #61557 
- [x] Ran pre-commit check",['Testing'],,2025-06-05 21:09:39+00:00,2025-06-13 17:44:31+00:00,,7.857546296296296
61576,DataFrames Class update,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-05 19:32:17+00:00,2025-06-13 09:55:40+00:00,,7.599571759259259
61575,DataFrame class update,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-05 19:30:08+00:00,2025-06-05 19:31:04+00:00,,0.0006481481481481481
61574,BUG: 2.3.0 didn't publish wheels for musl-aarch64 (arm),"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
https://pypi.org/project/pandas/2.3.0/#files
https://pypi.org/project/pandas/2.2.3/#files
```

### Issue Description

ctrl-f for musl on the first page gives 15 results
for the second page gives 36 results.
ctrl on the 2.3.0 page for ""-cp313-cp313-musllinux_1_2_aarch64.whl"" gives no results but there are results on the 2.2.3 page.j

### Expected Behavior

would like a wheel for musl / arm64

### Installed Versions

not relevant","['Bug', 'Needs Triage']",,2025-06-05 19:18:15+00:00,2025-06-06 16:36:53+00:00,,0.8879398148148148
61573,WEB: Test that our versions JSON is valid,"See #61572

I think this can be as simple as loading the file with `json.load` when calling `pandas_web.py`. This way, if the file is not valid JSON the CI should break. But we need to double check that `json.load` fails if an extra comma is present.","['good first issue', 'Web']",,2025-06-05 18:59:22+00:00,2025-06-07 10:00:47+00:00,,1.6259837962962962
61572,BUG: Fix JSON typo that breaks javascript in the docs,"Closes #61571 

As opposed to Python, JSON doesn't accept commas after the last element of a dict, and it's strict about it. We added this as a typo (I think I did the same during a release, I'll create an issue to validate this JSON in the CI) when updating the JSON that provides the versions for the documentation drop down. This seems to be breaking all the javascript in our docs.

@mroeschke I would merge this before waiting for the CI, but up to you.","['Bug', 'Docs']",,2025-06-05 18:55:44+00:00,2025-06-05 19:25:19+00:00,,0.020543981481481483
61571,DOC: Version dropdown not working,"Seems like the version dropdown is not working, at least for me, after the release: https://pandas.pydata.org/docs/

Can others confirm please?

Edit: Also the search. I guess there is a javascript error making all javascript code to not run","['Docs', 'good first issue']",,2025-06-05 18:40:11+00:00,2025-06-05 19:25:20+00:00,,0.03135416666666667
61570,BUG: comparing strings of different dtypes errors in 2.3,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd, numpy as np
arr1 = pd.array([],pd.StringDtype(""pyarrow"", na_value=pd.NA))
arr2 = pd.array([], pd.StringDtype(""python"", na_value=np.nan))
arr1 == arr2 # NotImplementedError: eq not implemented for <class 'pandas.core.arrays.string_.StringArrayNumpySemantics'>
```

### Issue Description

This appears to be the type of issue discussed in https://github.com/pandas-dev/pandas/issues/60639. That issue was closed, but I got an error when I tried running the above reproducer on the example given in the [whatsnew](https://pandas.pydata.org/pandas-docs/version/2.3.0/whatsnew/v2.3.0.html#notable-bug-fix1) for release 2.3.

My understanding was that the issue was closed when https://github.com/pandas-dev/pandas/pull/61138 was merged to main, but it's unclear if the fix was successfully backported to the 2.3.x branch. I haven't had the time yet to try when building pandas myself from main.

### Expected Behavior

Comparisons of string arrays/series with different dtypes should not error and the return dtype should follow the behavior laid out in #60639 .

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.12.2
python-bits           : 64
OS                    : Linux
OS-release            : 6.6.87.1-microsoft-standard-WSL2
Version               : #1 SMP PREEMPT_DYNAMIC Mon Apr 21 17:08:54 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.3.0
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 20.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Strings']",,2025-06-05 17:57:17+00:00,2025-07-02 16:35:31+00:00,,26.943217592592593
61569,BLD: Build wheels for 3.9 and musllinux-aarch64 for pandas 2.3,"@lithomas1 would I need to re-tag the 2.3.x branch if/when we merge this?

xref https://github.com/pandas-dev/pandas/issues/61563 https://github.com/pandas-dev/pandas/issues/61574",['Build'],,2025-06-05 17:29:26+00:00,2025-07-02 17:08:01+00:00,,26.985127314814815
61567,BUILD: Add wheels for musllinux_aarch64,"It seems the `musllinux_aarch64` wheels got accidentally removed in the transition from circleci to GHA.
Would be great if this could be backported to `2.3.x` as well.

- [x] closes https://github.com/pandas-dev/pandas/issues/55645#issuecomment-2943818815
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Build'],,2025-06-05 12:41:27+00:00,2025-06-06 16:43:24+00:00,,1.1680208333333333
61565,BUG: RecursionError when apply generic alias as a func,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
pd.DataFrame({'x': [1], 'y': [2]}).apply(list, axis=""columns"")
pd.DataFrame({'x': [1], 'y': [2]}).apply(list[int], axis=""columns"")
```

### Issue Description

Traceback:
```python
[... skipping similar frames: Series.apply at line 4935 (593 times), NDFrameApply.agg_or_apply_list_like at line 744 (592 times), SeriesApply.apply at line 1412 (592 times), Apply.apply_list_or_dict_like at line 630 (592 times), Apply.compute_list_like at line 369 (592 times)]

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/apply.py:1412, in SeriesApply.apply(self)
    ...

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/apply.py:630, in Apply.apply_list_or_dict_like(self)
    ...

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/apply.py:744, in NDFrameApply.agg_or_apply_list_like(self, op_name)
    ...

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/apply.py:369, in Apply.compute_list_like(self, op_name, selected_obj, kwargs)
    ...

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/series.py:4935, in Series.apply(self, func, convert_dtype, args, by_row, **kwargs)
    ...

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/apply.py:1407, in SeriesApply.apply(self)
   1404 def apply(self) -> DataFrame | Series:
   1405     obj = self.obj
-> 1407     if len(obj) == 0:
   1408         return self.apply_empty_result()
   1410     # dispatch to handle list-like or dict-like

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/series.py:918, in Series.__len__(self)
    914 def __len__(self) -> int:
    915     """"""
    916     Return the length of the Series.
    917     """"""
--> 918     return len(self._mgr)

File /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/internals/base.py:76, in DataManager.__len__(self)
     74 @final
     75 def __len__(self) -> int:
---> 76     return len(self.items)

RecursionError: maximum recursion depth exceeded
> /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/internals/base.py(76)__len__()
     74     @final
     75     def __len__(self) -> int:
---> 76         return len(self.items)
     77 
     78     @property

ipdb>
```

where `self.func` is regarded as list of funcs, which lead to the bug 

```python
> /opt/homebrew/envs/pandera/lib/python3.12/site-packages/pandas/core/apply.py(1412)apply()
   1410         # dispatch to handle list-like or dict-like
   1411         if is_list_like(self.func):
-> 1412             return self.apply_list_or_dict_like()
   1413 
   1414         if isinstance(self.func, str):

ipdb> p self.func
*list[int]
ipdb> p is_list_like(self.func)
True
ipdb>
```

### Expected Behavior

Expected output:
> 0    [1, 2]
> dtype: object

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 2cc37625532045f4ac55b27176454bbbc9baf213
python                : 3.12.9
python-bits           : 64
OS                    : Darwin
OS-release            : 24.5.0
Version               : Darwin Kernel Version 24.5.0: Tue Apr 22 19:54:33 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T8122
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : zh_CN.UTF-8
LOCALE                : zh_CN.UTF-8

pandas                : 2.3.0
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.31.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']","{'login': 'heoh', 'id': 24520785, 'node_id': 'MDQ6VXNlcjI0NTIwNzg1', 'avatar_url': 'https://avatars.githubusercontent.com/u/24520785?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/heoh', 'html_url': 'https://github.com/heoh', 'followers_url': 'https://api.github.com/users/heoh/followers', 'following_url': 'https://api.github.com/users/heoh/following{/other_user}', 'gists_url': 'https://api.github.com/users/heoh/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/heoh/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/heoh/subscriptions', 'organizations_url': 'https://api.github.com/users/heoh/orgs', 'repos_url': 'https://api.github.com/users/heoh/repos', 'events_url': 'https://api.github.com/users/heoh/events{/privacy}', 'received_events_url': 'https://api.github.com/users/heoh/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-05 09:30:30+00:00,2025-06-16 23:13:26+00:00,heoh,11.57148148148148
61564,Failed to install pandas BUILD: 2.3.0 Windows,"### Installation check

- [x] I have read the [installation guide](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-pandas).


### Platform

Windows-10-10.0.22631-SP0

### Installation Method

pip install

### pandas Version

2.3.0

### Python Version

3.9.13

### Installation Logs

<details>
C:\Users\tanishq>python -V
Python 3.9.13

C:\Users\tanishq>python -c ""import platform; print(platform.platform())""
Windows-10-10.0.22631-SP0

Collecting pandas
  Downloading pandas-2.3.0.tar.gz (4.5 MB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4.5/4.5 MB 4.9 MB/s eta 0:00:00
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Installing backend dependencies ... done
  Preparing metadata (pyproject.toml) ... error
  error: subprocess-exited-with-error

  √ó Preparing metadata (pyproject.toml) did not run successfully.
  ‚îÇ exit code: 1
  ‚ï∞‚îÄ> [10 lines of output]
      + meson setup C:\Users\tanishq\AppData\Local\Temp\pip-install-9lil68je\pandas_8d418a38654d41a19bef484e6372f854 C:\Users\tanishq\AppData\Local\Temp\pip-install-9lil68je\pandas_8d418a38654d41a19bef484e6372f854\.mesonpy-3s9nxbqg -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=C:\Users\tanishq\AppData\Local\Temp\pip-install-9lil68je\pandas_8d418a38654d41a19bef484e6372f854\.mesonpy-3s9nxbqg\meson-python-native-file.ini
      The Meson build system
      Version: 1.8.1
      Source dir: C:\Users\tanishq\AppData\Local\Temp\pip-install-9lil68je\pandas_8d418a38654d41a19bef484e6372f854
      Build dir: C:\Users\tanishq\AppData\Local\Temp\pip-install-9lil68je\pandas_8d418a38654d41a19bef484e6372f854\.mesonpy-3s9nxbqg
      Build type: native build

      ..\meson.build:2:0: ERROR: Could not find C:\Program Files (x86)\Microsoft Visual Studio\Installer\vswhere.exe

      A full log can be found at C:\Users\tanishq\AppData\Local\Temp\pip-install-9lil68je\pandas_8d418a38654d41a19bef484e6372f854\.mesonpy-3s9nxbqg\meson-logs\meson-log.txt
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

√ó Encountered error while generating package metadata.
‚ï∞‚îÄ> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.

</details>
","['Build', 'Needs Triage']",,2025-06-05 04:41:38+00:00,2025-06-05 16:58:11+00:00,,0.5114930555555556
61563,Failed to install pandas==2.3.0 with Python 3.9,"### Installation check

- [x] I have read the [installation guide](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-pandas).


### Platform

Linux-5.10.195-1.20230921.el7.x86_64-x86_64-with-glibc2.17

### Installation Method

pip install

### pandas Version

2.3.0

### Python Version

3.9.15

### Installation Logs

<details>
(base) [root@64bf929a621d7dafeb18b348 ~]# python -c 'import platform; print(platform.platform())'
Linux-5.10.195-1.20230921.el7.x86_64-x86_64-with-glibc2.17

(base) [root@64bf929a621d7dafeb18b348 ~]# pip install pandas -U
Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.5.0)
Collecting pandas
  Downloading pandas-2.3.0.tar.gz (4.5 MB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4.5/4.5 MB 90.9 MB/s eta 0:00:00
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Installing backend dependencies ... done
  Preparing metadata (pyproject.toml) ... error
  error: subprocess-exited-with-error

  √ó Preparing metadata (pyproject.toml) did not run successfully.
  ‚îÇ exit code: 1
  ‚ï∞‚îÄ> [152 lines of output]
      + meson setup /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86 /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/.mesonpy-lsu89q1a -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=/tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/.mesonpy-lsu89q1a/meson-python-native-file.ini
      The Meson build system
      Version: 1.8.1
      Source dir: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86
      Build dir: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/.mesonpy-lsu89q1a
      Build type: native build
      Project name: pandas
      Project version: 2.3.0
      C compiler for the host machine: cc (gcc 4.8.5 ""cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)"")
      C linker for the host machine: cc ld.bfd 2.27-44
      C++ compiler for the host machine: c++ (gcc 4.8.5 ""c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)"")
      C++ linker for the host machine: c++ ld.bfd 2.27-44
      Cython compiler for the host machine: cython (cython 3.1.1)
      Host machine cpu family: x86_64
      Host machine cpu: x86_64
      Program python found: YES (/opt/conda/bin/python)
      Found pkg-config: YES (/usr/bin/pkg-config) 0.27.1
      Run-time dependency python found: YES 3.9
      Build targets in project: 53

      pandas 2.3.0

        User defined options
          Native files: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/.mesonpy-lsu89q1a/meson-python-native-file.ini
          b_ndebug    : if-release
          b_vscrt     : md
          buildtype   : release
          vsenv       : true

      Found ninja-1.11.1.git.kitware.jobserver-1 at /tmp/pip-build-env-ltjugjgm/normal/bin/ninja

      Visual Studio environment is needed to run Ninja. It is recommended to use Meson wrapper:
      /tmp/pip-build-env-ltjugjgm/overlay/bin/meson compile -C .
      + /tmp/pip-build-env-ltjugjgm/normal/bin/ninja
      [1/151] Generating pandas/_libs/intervaltree_helper_pxi with a custom command
      [2/151] Generating pandas/_libs/hashtable_func_helper_pxi with a custom command
      [3/151] Generating pandas/_libs/algos_common_helper_pxi with a custom command
      [4/151] Generating pandas/_libs/khash_primitive_helper_pxi with a custom command
      [5/151] Generating pandas/_libs/index_class_helper_pxi with a custom command
      [6/151] Generating pandas/_libs/algos_take_helper_pxi with a custom command
      [7/151] Generating pandas/_libs/hashtable_class_helper_pxi with a custom command
      [8/151] Copying file pandas/__init__.py
      [9/151] Generating pandas/_libs/sparse_op_helper_pxi with a custom command
      [10/151] Compiling C object pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_lib_ultrajsonenc.c.o
      FAILED: pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_lib_ultrajsonenc.c.o
      cc -Ipandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p -Ipandas/_libs -I../pandas/_libs -I../../../pip-build-env-ltjugjgm/overlay/lib/python3.9/site-packages/numpy/_core/include -I../pandas/_libs/include -I/opt/conda/include/python3.9 -fvisibility=hidden -DNDEBUG -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -Wextra -std=c11 -O3 -DNPY_NO_DEPRECATED_API=0 -DNPY_TARGET_VERSION=NPY_1_21_API_VERSION -fPIC -MD -MQ pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_lib_ultrajsonenc.c.o -MF pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_lib_ultrajsonenc.c.o.d -o pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_lib_ultrajsonenc.c.o -c ../pandas/_libs/src/vendored/ujson/lib/ultrajsonenc.c
      In file included from ../pandas/_libs/src/vendored/ujson/lib/ultrajsonenc.c:43:0:
      ../pandas/_libs/include/pandas/portable.h:31:22: error: missing binary operator before token ""(""
       #elif __has_attribute(__fallthrough__)
                            ^
      [11/151] Compiling C object pandas/_libs/pandas_parser.cpython-39-x86_64-linux-gnu.so.p/src_parser_io.c.o
      [12/151] Compiling C object pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_vendored_numpy_datetime_np_datetime.c.o
      FAILED: pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_vendored_numpy_datetime_np_datetime.c.o
      cc -Ipandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p -Ipandas/_libs -I../pandas/_libs -I../../../pip-build-env-ltjugjgm/overlay/lib/python3.9/site-packages/numpy/_core/include -I../pandas/_libs/include -I/opt/conda/include/python3.9 -fvisibility=hidden -DNDEBUG -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -Wextra -std=c11 -O3 -DNPY_NO_DEPRECATED_API=0 -DNPY_TARGET_VERSION=NPY_1_21_API_VERSION -fPIC -MD -MQ pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_vendored_numpy_datetime_np_datetime.c.o -MF pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_vendored_numpy_datetime_np_datetime.c.o.d -o pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_vendored_numpy_datetime_np_datetime.c.o -c ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c
      ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c:57:1: error: static assertion failed: ""__has_builtin not detected; please try a newer compiler""
       _Static_assert(0, ""__has_builtin not detected; please try a newer compiler"");
       ^
      ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c: In function ‚ÄòscaleYearToEpoch‚Äô:
      ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c:343:3: warning: implicit declaration of function ‚Äòchecked_int64_sub‚Äô [-Wimplicit-function-declaration]
         return checked_int64_sub(year, 1970, result);
         ^
      ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c: In function ‚ÄòscaleYearsToMonths‚Äô:
      ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c:347:3: warning: implicit declaration of function ‚Äòchecked_int64_mul‚Äô [-Wimplicit-function-declaration]
         return checked_int64_mul(years, 12, result);
         ^
      ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c: In function ‚Äònpy_datetimestruct_to_datetime‚Äô:
      ../pandas/_libs/src/vendored/numpy/datetime/np_datetime.c:425:5: warning: implicit declaration of function ‚Äòchecked_int64_add‚Äô [-Wimplicit-function-declaration]
           PD_CHECK_OVERFLOW(checked_int64_add(months, months_adder, &months));
           ^
      [13/151] Compiling C object pandas/_libs/pandas_parser.cpython-39-x86_64-linux-gnu.so.p/src_parser_pd_parser.c.o
      [14/151] Compiling C object pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_datetime_date_conversions.c.o
      [15/151] Compiling C object pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_python_JSONtoObj.c.o
      [16/151] Compiling C object pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_datetime_pd_datetime.c.o
      [17/151] Compiling C object pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_python_ujson.c.o
      [18/151] Compiling C object pandas/_libs/pandas_datetime.cpython-39-x86_64-linux-gnu.so.p/src_vendored_numpy_datetime_np_datetime_strings.c.o
      [19/151] Compiling C object pandas/_libs/json.cpython-39-x86_64-linux-gnu.so.p/src_vendored_ujson_python_objToJSON.c.o
      [20/151] Compiling C object pandas/_libs/tslibs/parsing.cpython-39-x86_64-linux-gnu.so.p/.._src_parser_tokenizer.c.o
      [21/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/indexing.pyx
      [22/151] Compiling C object pandas/_libs/pandas_parser.cpython-39-x86_64-linux-gnu.so.p/src_parser_tokenizer.c.o
      [23/151] Compiling C object pandas/_libs/lib.cpython-39-x86_64-linux-gnu.so.p/src_parser_tokenizer.c.o
      [24/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/ccalendar.pyx
      [25/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/base.pyx
      [26/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/np_datetime.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [27/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/missing.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [28/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/dtypes.pyx
      [29/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/arrays.pyx
      [30/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/hashing.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [31/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/nattype.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/nattype.pyx:79:0: Global name __nat_unpickle matched from within class scope in contradiction to to Python 'class private name' rules. This may change in a future release.
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/nattype.pyx:79:0: Global name __nat_unpickle matched from within class scope in contradiction to to Python 'class private name' rules. This may change in a future release.
      [32/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/vectorized.pyx
      [33/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/fields.pyx
      [34/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/internals.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [35/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/conversion.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [36/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/parsing.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [37/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/timezones.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [38/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/tzconversion.pyx
      [39/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/strptime.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [40/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/parsers.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/parsers.pyx:1605:18: noexcept clause is ignored for function returning Python object
      [41/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/timestamps.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [42/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/period.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [43/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/timedeltas.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [44/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/offsets.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [45/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/lib.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [46/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/index.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [47/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/interval.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [48/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/join.pyx
      [49/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/hashtable.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [50/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/algos.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      [51/151] Compiling Cython source /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/groupby.pyx
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:188:38: noexcept clause is ignored for function returning Python object
      warning: /tmp/pip-install-gp_gpioe/pandas_8608342ddb164d0e8725d2463640de86/pandas/_libs/tslibs/util.pxd:193:40: noexcept clause is ignored for function returning Python object
      ninja: build stopped: subcommand failed.
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

√ó Encountered error while generating package metadata.
‚ï∞‚îÄ> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.


</details>
","['Build', 'Needs Triage']",,2025-06-05 04:11:02+00:00,2025-06-06 12:10:15+00:00,,1.3327893518518519
61562,WEB: Update versions.json for 2.3,,['Web'],,2025-06-05 03:41:48+00:00,2025-06-05 17:31:50+00:00,,0.576412037037037
61561,Backport PR #61560: DOC: Set date for v2.3.0.rst whatsnew,,['Docs'],,2025-06-04 22:32:29+00:00,2025-06-04 23:05:43+00:00,,0.023078703703703702
61560,DOC: Set date for v2.3.0.rst whatsnew,,['Docs'],,2025-06-04 21:03:56+00:00,2025-06-04 22:28:13+00:00,,0.05853009259259259
61559,Pandas DataFrame.query Code Injection (Unpatched),"Python pandas version 2.2.3 has a vulnerability on Pandas DataFrame.query 

In order to fix the function query on DataFrame python class what are the elements to review to resolve the vulnerability CVE-2024-9880.

Regards","['expressions', 'Closing Candidate']",,2025-06-04 18:45:13+00:00,2025-06-05 00:53:43+00:00,,0.25590277777777776
61558,Backport PR #61519: BUILD: Bump Cython to 3.1,https://github.com/pandas-dev/pandas/pull/61519,"['Build', 'Dependencies']",,2025-06-04 18:28:57+00:00,2025-06-04 20:45:43+00:00,,0.09497685185185185
61557,BUG: regex match in compliance tests no longer match pytest expected inputs,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
N/A
```

### Issue Description

When I run compliance tests in python-db-dtype-pandas (a support file used by python-bigquery) I am getting multiple warnings (which cause test failures) due to a recent update in how pytest handles regex matches.

In pandas release 2.2.3 there is a snippet of code:
```
def test_take_pandas_style_negative_raises(self, data, na_value):
    with pytest.raises(ValueError, match=""""):
```

Pytest returns this Warning:

```
pytest.PytestWarning: matching against an empty string will *always* pass. If you want to check for an empty message you need to pass '^$'. If you don't want to match you should pass `None` or leave out the parameter.
```

This warning shows up in association with each of these pandas tests (it may occur with other tests, but these are the only ones that my tests revealed.):
```
FAILED ...::TestGetitem::test_take_pandas_style_negative_raises
FAILED ...::TestMethods::test_argmax_argmin_no_skipna_notimplemented
FAILED ...::TestSetitem::test_setitem_invalid
FAILED ...::TestJSONArrayGetitem::test_take_pandas_style_negative_raises
FAILED ...::TestJSONArrayMethods::test_argmax_argmin_no_skipna_notimplemented
FAILED ...::TestJSONArraySetitem::test_setitem_invalid
```


### Expected Behavior

N/A

### Installed Versions

N/A","['Testing', 'Error Reporting', 'good first issue']",,2025-06-04 17:11:35+00:00,2025-06-13 17:44:32+00:00,,9.022881944444444
61556,Backport PR #61549 on branch 2.3.x (TST: Add error message for test_groupby_raises_category_on_category for quantile),Backport PR #61549: TST: Add error message for test_groupby_raises_category_on_category for quantile,['Testing'],,2025-06-04 12:52:13+00:00,2025-06-04 16:31:56+00:00,,0.15258101851851852
61555,DOC: Fix typo in to_html and to_string docs,"**UPDATE:** This started as an upgrade of Python in environment.yml, now it's just about fixing an issue with a period is duplicated in both the template and the variables.


I guess the only reason we require Python 3.10 for the development environments and run the docs is because it wasn't updated for a long time. Not sure if it'd be better to unpin, which I assume would get us the latest version of Python. Happy to do that here too.",['Docs'],,2025-06-04 09:04:21+00:00,2025-06-06 14:53:59+00:00,,2.242800925925926
61554,BUG: duplicated() raises error with singlton set as subset,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df = pd.DataFrame([{""a"": ""foo"", ""b"": ""bar""}])
df.duplicated(subset={""a""}) # raises error
df.duplicated(subset=[""a""]) # works
df.duplicated(subset=(""a"",)) # works
df.duplicates(subset={""a"",""b""}) # works
```

### Issue Description

Providing a singleton set to the subset parameter raises an error.

### Expected Behavior

Should work normally without having to convert the input to list or tuple.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.3
python-bits           : 64
OS                    : Linux
OS-release            : 6.11.0-26-generic
Version               : #26~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Apr 17 19:20:47 UTC 2
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : de_DE.UTF-8
LOCALE                : de_DE.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.0
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.0
Cython                : None
sphinx                : None
IPython               : 8.29.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : 5.3.0
matplotlib            : 3.9.2
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.3
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.36
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Needs Triage']",,2025-06-04 08:57:11+00:00,2025-06-11 17:52:35+00:00,,7.3718055555555555
61553,DOC: Move PyCapsule whatsnew note from v3.0.0 to v2.3.0,"follow-up from https://github.com/pandas-dev/pandas/pull/61488#pullrequestreview-2871730860

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-06-04 08:36:01+00:00,2025-06-04 11:31:38+00:00,,0.12195601851851852
61552,DOC: Add note on inference behavior of apply with result_type='expand',"Closes #61057

- This PR adds a docstring note about the inference behavior of apply with result_type='expand' when function returns NaN-like values, as discussed in issue #61057.
- Added docstring to distinguish behavior for 'apply' method.","['Docs', 'Apply', 'Stale']",,2025-06-04 05:20:11+00:00,2025-07-15 17:17:59+00:00,,41.49847222222222
61550,DOC: Remove and Update out of date Docker Image issue with  #61511,"- [ ] Addresses & closes [DOC: Docker image provided on ""Debugging C extensions"" is out of date #61511](https://github.com/pandas-dev/pandas/issues/61511)  
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).

","['Docs', 'Stale']",,2025-06-04 04:40:39+00:00,2025-07-28 17:20:48+00:00,,54.527881944444445
61549,TST: Add error message for test_groupby_raises_category_on_category for quantile,e.g. https://github.com/pandas-dev/pandas/actions/runs/15426735055/job/43415431095?pr=61519,['Testing'],,2025-06-04 01:25:16+00:00,2025-06-04 12:51:50+00:00,,0.4767824074074074
61548,changed the pydata-sphinx-theme dependency to the git version,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Dependencies'],,2025-06-04 01:25:15+00:00,2025-06-04 11:43:25+00:00,,0.4292824074074074
61547,CLN: Format comments in frame.py to comply with PEP8 line width,"Hello! While becoming acquainted with the code, I noticed that the frame.py file had a lot of comments with a length over PEP8's 79 character limit.

I reformatted all comments to the 79 character limit, unless they involve command-line related code examples.

Let me know if there is anything I can do to help.

Thank you!",[],,2025-06-04 00:53:34+00:00,2025-06-04 11:46:55+00:00,,0.45371527777777776
61546,ENH: Adding DataFrame plotting benchmarks for large datasets,"- [ ] related to #61532  - Adding in performance benchmarks for DataFrame plotting with large datasets.
- [ ] Description: Added 'DataFramePlottingLarge' benchmark class to track performance issues related to bottlenecks in #61398 and #61532. Tests multiple DataFrame sizes with/w/o DatetimeIndex & provides a baseline single-column comparison.
- [ ] Intended to cover:
          - DataFrame sizes: (1000,10) to (10000,10)
          - DatetimeIndex vs. regular index comparison
          - Multi-column vs. single-column plotting.
",['Benchmark'],,2025-06-04 00:21:17+00:00,2025-07-16 16:36:22+00:00,,42.677141203703705
61545,Fix WeekOfMonth offset constructor offsets.pyx,"Related to issue #52431, went and scanned the checklist commented previously by a user on Aug 4th, 2024. Noticed WeekOfMonth has incorrect offset constructors, and updated according to an earlier comment by @Dr-Irv  
",[],,2025-06-03 22:40:30+00:00,2025-06-04 14:52:42+00:00,,0.6751388888888888
61544,DOC: Fix WeekOfMonth offset constructor offsets.pyx,Related to #52431 ,[],,2025-06-03 22:30:19+00:00,2025-06-03 22:36:06+00:00,,0.004016203703703704
61543,DOC: Fix docs for BusinessDay constructor #52431,"fix constructor for offset BusinessDay

- [ ] addresses #52431 
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
","['Docs', 'Frequency']",,2025-06-03 19:50:59+00:00,2025-07-16 16:35:50+00:00,,42.86447916666667
61542,CI: Debug slow environment solve times,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-06-03 16:19:34+00:00,2025-06-06 16:45:18+00:00,,3.01787037037037
61541,BUG: Fix Index.equals between object and string,"- [X] closes #61099 
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

## Description of the code change on `Index.equals`

On the main branch, `Index.equals` casts `self` to `object` only when `self.dtype.na_value` is `np.nan`. The comparison actually succeeds when `self.dtype.na_value` is `np.nan` as below.
```python
>>> import pandas as pd
>>> import numpy as np

>>> s1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])
>>> s2 = pd.Series([4, 5, 6], index=['a', 'b', 'c'])
>>> s2.index = s2.index.astype(pd.StringDtype(storage=""pyarrow"", na_value=np.nan))

>>> print(s1 < s2)
a    True
b    True
c    True
dtype: bool
```
However, since doc stated that `dtype` is not compared, `self` should be casted regardless of `self.dtype.na_value` so that `self` could be compared with other dtypes as desired.


## Description of the code change on `test_mixed_col_index_dtype`

`using_infer_string` has been removed since I think that `result` should be `string` regardless of `using_infer_string`. This is becaus of the code change made on `Index.equals` - since `Index.equals` consider `df1.columns` is equal to `df2.colums`, `Index.intersection` returns `self`(which is `string`). You could see the result becomes `object`(which is the dtype of `df2`) in case of `result = df2 + df1`. On the main branch, on the other hand, `Index.intersection` returns `object` because `Index.equals` returns `False`, and then both `self` and `other` are cast to `object` by `_find_common_type_compat`. (see `L3287` at pandas/core/indexes/base.py)

https://github.com/pandas-dev/pandas/blob/25e64629ec317fba2fc1c2834b20362fa6c1fd89/pandas/core/indexes/base.py#L3286-L3290


* I created this pull request since @MayurKishorKumar doesn't seem to work on this issue anymore, but please let me know if there is going to be further actions on the previous PR and I am supposed to close this one.","['Bug', 'Strings', 'Index']",,2025-06-03 14:54:11+00:00,2025-07-10 20:58:43+00:00,,37.25314814814815
61540,ENH pandas-dev#60693: shift operations for Series and DataFrames,"This commit introduces the rshift and lshift method for both Series and DataFrames in pandas. It also adds the corresponding in-place methods.
These methdos don't work between a Series and a Dataframe, or if the two Series or DataFrames differ in size.

- [x] closes #60693
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Enhancement', 'Numeric Operations']",,2025-06-03 12:06:30+00:00,2025-06-30 18:17:58+00:00,,27.257962962962964
61538,usecols investigation for various I/O functions,"pasting my comment from #61386 for visibility with relevant decisionmakers

> As promised during the sync meeting today, I went and compiled how various read functions handle columns being specified. Functions that take usecols (read_csv, read_clipboard, read_excel, and read_hdf(undocumented)) don't take into account input order, whereas functions that ask for columns instead do (hdf, feather, parquet, orc, starata, sql).
> 
> Finally, there are also some that straight up don't take column specifiers.
> 
> I'd expect functions that use usecols to be using the same function in the backend, but I'd have to verify it if we're planning to standardize the parameter.
> 
> CSV attached below of functions tested (those with a read and write function in pandas)
> [does_it_use_order.csv](https://github.com/user-attachments/files/20558438/does_it_use_order.csv)","['IO CSV', 'Needs Discussion']",,2025-06-02 20:16:32+00:00,2025-06-03 16:04:24+00:00,,0.8249074074074074
61536,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.11.8 ‚Üí v0.11.12](https://github.com/astral-sh/ruff-pre-commit/compare/v0.11.8...v0.11.12)
- [github.com/asottile/pyupgrade: v3.19.1 ‚Üí v3.20.0](https://github.com/asottile/pyupgrade/compare/v3.19.1...v3.20.0)
- [github.com/pre-commit/mirrors-clang-format: v20.1.3 ‚Üí v20.1.5](https://github.com/pre-commit/mirrors-clang-format/compare/v20.1.3...v20.1.5)
- [github.com/trim21/pre-commit-mirror-meson: v1.8.0 ‚Üí v1.8.1](https://github.com/trim21/pre-commit-mirror-meson/compare/v1.8.0...v1.8.1)
<!--pre-commit.ci end-->",['Code Style'],,2025-06-02 16:29:49+00:00,2025-06-02 17:02:23+00:00,,0.022615740740740742
61535,ENH: read_csv tz option,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I use pd.read_csv to grab a series of timestamp'd links interactively from a remote website. 

### Feature Description

I would like it to convert the columns specified by parse_dates to the timezone specified by wherever the /etc/localtime link points to by default in a non-deprecated manner:

> [frame.loc[:,c].dt.tz_convert('/'.join([os.getenv('TZ', os.path.realpath('/etc/localtime').split('/')[-2:])][0])) for c in frame.select_dtypes('datetime64[ns, UTC]')]`

I'd like to propose this functionality as the tz parameter to read_csv. I suspect the implementation is not python, and can't find it in my git checkout of pandas. 

### Alternative Solutions

Covered above

### Additional Context","['Enhancement', 'IO CSV', 'Needs Triage', 'Closing Candidate']",,2025-06-02 05:57:05+00:00,2025-08-05 16:29:10+00:00,,64.43894675925925
61534,Add version constraints to reduce micromamba CI environment resolution time,"This PR updates the `environment.yml` file to add version constraints to several frequently resolved dependencies. These changes help reduce environment resolution time in CI workflows using micromamba, which was previously leading to timeouts (see #61531).

Updated packages:
- ipywidgets>=8.1.2
- nbformat>=5.9.2
- notebook>=7.0.6,<7.2.0
- dask-core>=2024.4.2
- seaborn-base>=0.13.2

Fixes: #61531","['CI', 'Dependencies']",,2025-06-01 23:59:29+00:00,2025-06-02 08:32:55+00:00,,0.3565509259259259
61531,CI: Micromamba taking too long to resolve the environments in the CI,"Our CI jobs are frequently failing now as they timeout after 90 minutes of execution. Of those 90 minutes, 25 are spent on micromamba resolving the environment.

In the past we have fixed this by limiting the number of packages to be considered. For example, if the environment just says `numpy`, maybe there are 200 versions that will be considered. While if we say `numpy >= 2` the number can be limited to few.

I'm not sure which packages have lots of options, and we don't want to filter out the versions that make sense to install. But we should have a look and see if by adding few constraints we can get a reasonable time to solve the environment.","['CI', 'Dependencies', 'good first issue']","{'login': 'microslaw', 'id': 91637238, 'node_id': 'U_kgDOBXZF9g', 'avatar_url': 'https://avatars.githubusercontent.com/u/91637238?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/microslaw', 'html_url': 'https://github.com/microslaw', 'followers_url': 'https://api.github.com/users/microslaw/followers', 'following_url': 'https://api.github.com/users/microslaw/following{/other_user}', 'gists_url': 'https://api.github.com/users/microslaw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/microslaw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/microslaw/subscriptions', 'organizations_url': 'https://api.github.com/users/microslaw/orgs', 'repos_url': 'https://api.github.com/users/microslaw/repos', 'events_url': 'https://api.github.com/users/microslaw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/microslaw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-06-01 14:08:04+00:00,2025-06-13 14:34:13+00:00,microslaw,12.018159722222222
61528,DOC: Typo fix for .astype() in cheatsheet,"- [x] Closes #61523
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-05-31 18:35:29+00:00,2025-06-02 16:28:55+00:00,,1.9121064814814814
61527,ENH: Implement DataFrame.select,"- [X] closes #61522
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Based on the feedback in  #61522 and on the last devs call, I implemented `DataFrame.select` in the most simple way. It does work with `MultiIndex`, but it does not support equivalents to `filter(regex=)` or `filter(like=`) directly. I added examples in the docs, so users can do that easily in Python (I can add one for regex if people think it's worth it).

The examples in the docs and the tests should make quite clear what's the behavior, feedback welcome.

For context, this is added so we can make `DataFrame.filter` focus on filtering rows, for example:

```python
df = df.select(""name"", ""age"")
df = df.filter(df.age >= 18)
```

or

```python
(df.select(""name"", ""age"")
   .filter(lambda df: df.age >= 18))
```

CC: @pandas-dev/pandas-core ","['Enhancement', 'Indexing', 'API Design']",,2025-05-31 13:10:03+00:00,2025-06-20 20:20:32+00:00,,20.29894675925926
61526,DOC: fix ES01 for pandas.plotting.autocorrelation_plot,"fixes

```
pandas.plotting.autocorrelation_plot ES01
```

This includes a crisp extended summary of the method which talks about what it does, how it does it and whats the value of it. 
","['Docs', 'Visualization']",,2025-05-31 07:08:00+00:00,2025-06-02 16:37:15+00:00,,2.3953125
61524,BUG: Fix pivot_table margins to include NaN groups when dropna=False,"Fix incorrect margin computation in `pivot_table` when index or columns contain NA values

This PR fixes an issue where the `""All""` row or column (i.e., `margins=True`) in `pd.pivot_table` does not account for rows that contain `NA` values in the index or column dimensions. These rows were incorrectly excluded from the overall aggregation used to compute the margin, leading to incorrect totals.

The fix modifies the margin calculation to ensure that rows with `NA` values are included in the aggregation, consistent with how the data is treated in the main table when `dropna=False`.

- [x] closes #61509 
- [x] Test added and passed
- [x] Ran pre-commit check
- [x] Added entry in `doc/source/whatsnew/v3.0.0.rst` under `Reshaping`","['Bug', 'Missing-data', 'Reshaping']",,2025-05-31 02:52:43+00:00,2025-07-13 12:10:06+00:00,,43.38707175925926
61523,"DOC: Official ""Cheat Sheet"" shows `as_type()` method, correct signature is `astype()`","### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://github.com/pandas-dev/pandas/blob/main/doc/cheatsheet/Pandas_Cheat_Sheet.pdf


### Documentation problem

The third page of the official ""Cheat Sheet"" at https://github.com/pandas-dev/pandas/blob/main/doc/cheatsheet/Pandas_Cheat_Sheet.pdf has a section called ""Changing Type"". It lists `df.as_type(type)`, however no such method exists; the correct method should be `df.astype(type)`.

### Suggested fix for documentation

The fix is straightforward: replace `as_type` with `astype`.",['Docs'],"{'login': 'brchristian', 'id': 2460418, 'node_id': 'MDQ6VXNlcjI0NjA0MTg=', 'avatar_url': 'https://avatars.githubusercontent.com/u/2460418?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/brchristian', 'html_url': 'https://github.com/brchristian', 'followers_url': 'https://api.github.com/users/brchristian/followers', 'following_url': 'https://api.github.com/users/brchristian/following{/other_user}', 'gists_url': 'https://api.github.com/users/brchristian/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/brchristian/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/brchristian/subscriptions', 'organizations_url': 'https://api.github.com/users/brchristian/orgs', 'repos_url': 'https://api.github.com/users/brchristian/repos', 'events_url': 'https://api.github.com/users/brchristian/events{/privacy}', 'received_events_url': 'https://api.github.com/users/brchristian/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-30 21:51:59+00:00,2025-06-02 16:28:56+00:00,brchristian,2.775659722222222
61521,Misleading error message when PyTables is not installed,"I tried reading an hd5 file with the latest pandas and got this import error:

`ImportError: Missing optional dependency 'pytables'.  Use pip or conda to install pytables.`

So I tried `pip install pytables` and got this error:

```
ERROR: Could not find a version that satisfies the requirement pytables (from versions: none)
ERROR: No matching distribution found for pytables
```

So then I went searching on PyPI and apparently there are no packages named `pytables`: https://pypi.org/search/?q=pytables

I did find the [PyTables](https://github.com/PyTables/PyTables) project on GitHub though, which says that we need to use `pip install tables` to install it. After installing `tables`, the hd5 read operation worked.

So, we need to install _tables_, not _pytables_, which is definitely confusing and not obvious. I think it would be very helpful if the error message indicated this to avoid having to go through the search process above.",['Error Reporting'],"{'login': 'KevsterAmp', 'id': 109636487, 'node_id': 'U_kgDOBojrhw', 'avatar_url': 'https://avatars.githubusercontent.com/u/109636487?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/KevsterAmp', 'html_url': 'https://github.com/KevsterAmp', 'followers_url': 'https://api.github.com/users/KevsterAmp/followers', 'following_url': 'https://api.github.com/users/KevsterAmp/following{/other_user}', 'gists_url': 'https://api.github.com/users/KevsterAmp/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/KevsterAmp/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/KevsterAmp/subscriptions', 'organizations_url': 'https://api.github.com/users/KevsterAmp/orgs', 'repos_url': 'https://api.github.com/users/KevsterAmp/repos', 'events_url': 'https://api.github.com/users/KevsterAmp/events{/privacy}', 'received_events_url': 'https://api.github.com/users/KevsterAmp/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-30 19:08:09+00:00,2025-06-30 18:16:15+00:00,KevsterAmp,30.963958333333334
61520,Backport PR #61518 on branch 2.3.x (TST: Use external_error_raised for numpy-raised test_error_invalid_values),Backport PR #61518: TST: Use external_error_raised for numpy-raised test_error_invalid_values,['Testing'],,2025-05-30 18:34:23+00:00,2025-05-30 21:06:07+00:00,,0.10537037037037036
61519,BUILD: Bump Cython to 3.1,"- [x] closes #60972 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

ASVs: https://github.com/pandas-dev/pandas/issues/60972#issuecomment-2906286143","['Build', 'Dependencies']",,2025-05-30 18:26:12+00:00,2025-06-04 18:16:55+00:00,,4.993553240740741
61518,TST: Use external_error_raised for numpy-raised test_error_invalid_values,Looks like numpy extended an error message that is failing `test_error_invalid_values` e.g https://github.com/pandas-dev/pandas/actions/runs/15331067593/job/43137707952,['Testing'],,2025-05-30 16:34:21+00:00,2025-05-30 18:33:49+00:00,,0.08296296296296296
61517,BUG: Fix sorting by column named None in DataFrame.sort_values (GH#61512),"Fixes a bug in `DataFrame.sort_values` where sorting by a column explicitly named None raised a `KeyError`. Added a conditional check to correctly retrieve and sort the column when `None` is used as a label.

- [x] closes #61512
- [x] Tests added and passed
- [x] All code checks passed via pre-commit
- [x] Added an entry to the latest whatsnew file",['Algos'],,2025-05-30 00:57:45+00:00,2025-06-02 16:45:44+00:00,,3.6583217592592594
61516,BUG: DataFrame.sample weights not required to sum to less than 1,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

data = {'w': [100, 1, 1]}
df = pd.DataFrame(data)

df.sample(n=2, weights=df.w, replace=False)
```

### Issue Description

In order for PPS sampling without replacement to be feasible, the selection probabilities must be less than 1, i.e.

$ \frac{n \cdot w_i}{\sum w_i}< 1$

where w is the weight and n is the total number of units to be sampled. This is often not the case if you are selecting a decent proportion of all units and there is wide variance in unit size. For example, suppose you want to select 2 units with PPS without replacement from a sampling frame of 3 units with sizes 100, 1, and 1. There is no way to make the probability of selection of the first unit 100x the probability of selection of the other two units (since the max prob for the first unit is 1 and at least one of the other units must have prob >= .5).

Unfortunately, pandas df.sampling function doesn't throw an error in this case. 

### Expected Behavior

The code above should throw some sort of error like ""Some unit probabilities are larger than 1 and thus PPS sampling without replacement cannot be performed""

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Algos']","{'login': 'microslaw', 'id': 91637238, 'node_id': 'U_kgDOBXZF9g', 'avatar_url': 'https://avatars.githubusercontent.com/u/91637238?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/microslaw', 'html_url': 'https://github.com/microslaw', 'followers_url': 'https://api.github.com/users/microslaw/followers', 'following_url': 'https://api.github.com/users/microslaw/following{/other_user}', 'gists_url': 'https://api.github.com/users/microslaw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/microslaw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/microslaw/subscriptions', 'organizations_url': 'https://api.github.com/users/microslaw/orgs', 'repos_url': 'https://api.github.com/users/microslaw/repos', 'events_url': 'https://api.github.com/users/microslaw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/microslaw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-29 22:14:58+00:00,2025-07-11 02:27:16+00:00,microslaw,42.17520833333333
61514,BUGFIX: escape `quotechar` when `escapechar` is not None (even if quoting=csv.QUOTE_NONE),"- [x] closes #61407 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
---
Found the issue on `CSVFormatter._initialize_quotechar`, wherein it only returns quotechar when `self.quoting` is not `csvlib.QUOTE_NONE`:
```python
if self.quoting != csvlib.QUOTE_NONE:
    # prevents crash in _csv
    return quotechar
return None
```
to follow the same behavior of `csv.writer` (escape when `escapechar is not None`), I improved the if function to **return quotechar when `self.escapechar is not None`**

in the `CSVFormatter.__init__`, moved the initialization of `self.escapechar` higher than `self.quotechar` since the initial solution was returning errors from calling `self.escapechar` before its initialization

initially marked as draft to let the CIs run & check if there are tests affected by this change",['IO CSV'],,2025-05-29 11:53:41+00:00,2025-05-30 16:36:42+00:00,,1.196539351851852
61512,BUG: Cannot sort by columns named None,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

df = pd.DataFrame([[1, 2], [3, 4]], columns=['C1', None])
df.sort_values(None) # KeyError: None
```

### Issue Description

Sorting a DataFrame by a column named `None` results in the error `KeyError: None`. This breaks e.g. plugins that depend on Pandas for viewing and sorting DataFrames (see a related DataWrangler issue [here](https://github.com/microsoft/vscode-data-wrangler/issues/496), where inconsistent behavior with columns named None has also been reported).

### Expected Behavior

A column named None should not result in inconsistent behavior where some operations work but some others don't.

### Installed Versions

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.2
python-bits           : 64
OS                    : Linux
OS-release            : 6.1.0-32-amd64
Version               : #1 SMP PREEMPT_DYNAMIC Debian 6.1.129-1 (2025-03-06)
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.6
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : 9.2.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : 3.10.3
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None","['Bug', 'Indexing', 'Sorting']",,2025-05-28 19:30:52+00:00,2025-06-02 16:45:45+00:00,,4.885335648148148
61510,BUG: VSCode go to definition doesn't work with pandas.api.extensions.register_dataframe_accessor,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

Create a pandas.api.extensions.register_dataframe_accessor, then when using try to command + click in VSCode to jump to the definition. Either no definition is found or it jumps to a file like series.pyi



Create a pandas.api.extensions.register_dataframe_accessor, then when using try to command + click in VSCode to jump to the definition. Either no definition is found or it jumps to a file like series.pyi

`my_utils/my_accessor.py`

```python
import pandas as pd

@pd.api.extensions.register_dataframe_accessor(""demo"")
class DemoAccessor:
    def __init__(self, pandas_obj):
        self._obj = pandas_obj

    def say_hello(self):
        print(""Hello from accessor!"")
```

`main.py`
```python
import pandas as pd
import sys
import importlib

# Ensure the path to the module is in sys.path
sys.path.append(""my_utils"")  # Adjust this path as needed

import my_accessor
importlib.reload(my_accessor)

# Create DataFrame and use accessor
df = pd.DataFrame({""A"": [1, 2, 3]})
df.demo.say_hello()  # This runs fine, but ""jump to definition"" doesn't work
```

### Issue Description

VSCode go to definition doesn't work with pandas.api.extensions.register_dataframe_accessor

### Expected Behavior

I can jump to the definition when command clicking and see the documentation in VSCode

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.11.6.final.0
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:16 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6000
machine               : x86_64
processor             : i386
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.2
numpy                 : 2.0.2
pytz                  : 2025.2
dateutil              : 2.9.0.post0
setuptools            : 80.7.1
pip                   : 25.1.1
Cython                : None
pytest                : None
hypothesis            : None
sphinx                : None
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : None
html5lib              : None
pymysql               : None
psycopg2              : None
jinja2                : 3.1.6
IPython               : 7.34.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
gcsfs                 : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
pyarrow               : None
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.3
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Closing Candidate', 'Accessors']",,2025-05-28 15:04:19+00:00,2025-06-02 16:27:31+00:00,,5.057777777777778
61509,BUG: margin for pivot_table is incorrect with NA column/index values,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
#%%
import pandas as pd

df = pd.DataFrame({""i"": [1, 2, 3],
                   ""g1"": [""a"", ""b"", ""b""],
                   ""g2"": [""x"", None, None],
                   })

df.pivot_table(index=""g1"",
               columns=""g2"",
               values=""i"",
               aggfunc=""count"",
               dropna=False, margins=True)
```

### Issue Description

The margins of a `pivot_table` are incorrect when the `index` or `columns` variables contains missing variables. In particular, for the variable with the missing value, the total is missing.

| g1  | x   | nan | Total
|-----|-----|-----|------
| a   | 1.0 |     | 1
| b   |     | 2.0 | 2
| All | 1.0 |     | 3

### Expected Behavior

Margins should also be included for columns/indices with missing values.

In particular, the table should look like this

| g1  | x   | nan | Total
|-----|-----|-----|------
| a   | 1.0 |     | 1
| b   |     | 2.0 | 2
| All | 1.0 | 2.0 | 3

### Installed Versions

<details>


INSTALLED VERSIONS
------------------
commit                : f538741432edf55c6b9fb5d0d496d2dd1d7c2457
python                : 3.12.8.final.0
python-bits           : 64
OS                    : Linux
OS-release            : 6.11.0-26-generic
Version               : #26~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Apr 17 19:20:47 UTC 2
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.0
numpy                 : 1.26.4
pytz                  : 2025.1
dateutil              : 2.9.0.post0
setuptools            : 75.8.0
pip                   : 25.0
Cython                : None
pytest                : None
hypothesis            : None
sphinx                : 8.1.3
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : None
html5lib              : None
pymysql               : None
psycopg2              : None
jinja2                : 3.1.5
IPython               : 8.22.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.0
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
gcsfs                 : None
matplotlib            : 3.9.4
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.4
pandas_gbq            : None
pyarrow               : 16.1.0
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.0
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : 2.4.2
pyqt5                 : None

</details>
","['Bug', 'Missing-data', 'Reshaping']",,2025-05-28 13:26:06+00:00,2025-07-13 12:10:06+00:00,,45.94722222222222
61508,BUG: Fix inconsistent returned objects when applying groupby aggregations,"- [x] closes #61503 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
","['Bug', 'Apply']",,2025-05-28 10:42:19+00:00,2025-05-30 16:40:42+00:00,,2.248877314814815
61507,ENH: Implement to_iceberg,"- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['IO Data'],,2025-05-27 21:35:59+00:00,2025-06-09 18:18:25+00:00,,12.862800925925926
61506,CLN Replace direct import of closing with qualified contextlib usage,"There were 4 uses of `contextlib.closing` and 2 of `closing`.

This PR converts the use of `closing` to `contextlib.closing` and removes the extra import statement.",['Testing'],,2025-05-27 20:25:03+00:00,2025-05-27 21:24:33+00:00,,0.04131944444444444
61505,BUG: Mask changing value despite of no True return,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

data = {'cd_tip_fma_pgto': [pd.NA]}
df = pd.DataFrame(data, dtype='double[pyarrow]')
df['payment'] = np.nan
df['payment'] = df['payment'].mask(cond=(df['cd_tip_fma_pgto'] == 6), other='Livelo')
```

### Issue Description

Evaluating the mask method under a pd.NA, when using pyarrow, is changing the target value!

![Image](https://github.com/user-attachments/assets/c51b5acd-d68c-4d40-882e-bb6111592c66)


### Expected Behavior

The results of the compasison should not cause any change of the target value, as you see in this example :

```
data = {'cd_tip_fma_pgto': [pd.NA]}
df = pd.DataFrame(data)
df['payment'] = np.nan
df['payment'] = df['payment'].mask(cond=(df['cd_tip_fma_pgto'] == 6), other='Livelo')
```

![Image](https://github.com/user-attachments/assets/49b9b3f9-a16f-421a-8b5a-85d3da613d16)

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.0
python-bits           : 64
OS                    : Linux
OS-release            : 3.10.0-1127.19.1.el7.x86_64
Version               : #1 SMP Tue Aug 25 17:23:54 UTC 2020
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.24.2
pytz                  : 2022.7.1
dateutil              : 2.8.2
pip                   : 25.1.1
Cython                : 0.29.33
sphinx                : None
IPython               : 8.10.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.11.2
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.5.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.2
lxml.etree            : 4.9.2
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.3
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 17.0.0
pyreadstat            : None
pytest                : 7.4.3
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.10.1
sqlalchemy            : 2.0.30
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.1
qtpy                  : N/A
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-05-27 16:19:19+00:00,2025-05-27 16:42:11+00:00,,0.01587962962962963
61504,Use `TypeAlias` in code where types are declared,"After introducing `TypeAlias` in `_typing.py`, goal of this PR is to use it in any other source files that are creating types in this way.  ~~Also, make all of those types private.~~

I believe that I caught them all via some searching, but may have missed a few.  Couldn't find a rule that enforces use of `TypeAlias`.  Note that in 3.12, the recommendation is to do a `type` declaration, which is probably why there isn't such a rule.
","['Clean', 'Typing']",,2025-05-27 14:36:54+00:00,2025-07-01 10:35:58+00:00,,34.832685185185184
61503,BUG: Inconsistent returned objects when applying groupby aggregations,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df = pd.DataFrame(columns=['Group', 'Data'])
df.groupby(['Group'], as_index=False)['Data'].agg('sum')
# Returns:
# Empty DataFrame
# Columns: [Group, Data]
# Index: []
def mysum(x):
  return sum(x)
df.groupby(['Group'], as_index=False)['Data'].agg(mysum)
# Returns:
# Series([], Name: Data, dtype: object)
```

### Issue Description

When performing groupby aggregations on empty dataframe (with labeled columns), the outcome differs whether we use an internal aggregator or a custom function.
The difference of behaviour is problematic because when using internal aggregators (like 'sum'), the returned object is a dataframe with proper columns that we can select. However with custom functions, the returned object with an empty Series from which we cannot select columns.

This forces developers in this situation to check emptiness of the dataframe first.
This is not desirable from code conciseness point of view, but more importantly, we easily forget to check it and can therefore lead to errors.

### Expected Behavior

Both approaches to apply groupby aggregations should return the same object, preferably a dataframe form which we can select columns.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.10
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 170 Stepping 4, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United Kingdom.1252

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : 9.2.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 18.1.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Apply']",,2025-05-27 12:05:42+00:00,2025-05-30 16:40:43+00:00,,3.190983796296296
61501,DOC: Fixes dangling parenthesis in `.rst` files,"- [ ] ~closes #xxxx (Replace xxxx with the GitHub issue number)~
- [ ] ~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~

I initially found a missing closing parenthesis in the documentation, then I decided to write a script to find others. This MR fixes them to the best of my ability. 
",['Docs'],,2025-05-26 20:42:44+00:00,2025-05-27 15:23:03+00:00,,0.7779976851851852
61500,DOC: use Hashable instead of label,"In https://github.com/pandas-dev/pandas/pull/61455#discussion_r2096069007:
> we should actually be using `Hashable` everywhere as since it's an actual Python type unlike `label`.

- <del>[ ] closes #xxxx (Replace xxxx with the GitHub issue number)</del>
- <del>[ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- <del>[ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.</del>
- <del>[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.</del>
",['Docs'],,2025-05-26 20:31:45+00:00,2025-05-27 15:59:46+00:00,,0.8111226851851852
61497,DOC: Typo in shared_docs,"""regexs"" ‚Üí ""regexes""",['Docs'],,2025-05-26 17:15:34+00:00,2025-05-27 16:00:16+00:00,,0.9477083333333334
61495,DOC: Fix sparse and dense array memory usage comparison.,"This MR fixes misleading part of sparse user guide, which suggests that dataframes consume far less memory than they really do, due to wrong units calculation.

Also changed usage of `str.format()` to more modern f-string syntax in part of guide which was mentioned above.",['Docs'],,2025-05-26 09:48:10+00:00,2025-05-26 17:03:31+00:00,,0.3023263888888889
61494,DOC: kwargs naming in pd.Series.interpolate,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.interpolate.html

### Documentation problem

Display of the `**kwargs` is looking like `''**kwargs''`

### Suggested fix for documentation

Remove the backquotes.","['Docs', 'Needs Triage']",,2025-05-25 19:20:56+00:00,2025-05-25 19:23:35+00:00,,0.0018402777777777777
61493,ENH: Supporting a `mapper` function as the 1st argument in `DataFrame.set_axis`,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

At the moment, `DataFrame.set_axis()` only accepts `labels`:

```python
df = (
    pd.DataFrame({'A': range(3), 'B': range(10, 13)})
    .set_axis(['a', 'b'], axis=1)
)
print(df)

#    a   b
# 0  0  10
# 1  1  11
# 2  2  12
```
Which makes it difficult (or more precisely verbose, using workarounds) to use during method chaining (where available columns could be dynamic and unknown at the begining of the chain). 


### Feature Description
I suggest to allow `.set_axis` method to accept a ""mapper"" (either a `function`, `dict` or `series`) that could be used to convert an axis to another preferred axis.
The proposed enhancement could get inspiration from how `.rename_axis` works. For example,  `.set_axis` could support receiving a function to apply on the current axis of the `DataFrame` (either its `index` or `columns`, depending on the `axis` argument) and set the axis to the labels that are returned by the function (see below for an example).

Example:
```python
df = (
    pd.DataFrame({'A': range(3), 'B': range(10, 13)})
    .set_axis(lambda df: 'col' + df.columns, axis=1)

   # or an alternative signature to support
   .set_axis({'A': 'colA', 'B': 'colB'}, axis='columns')
)

#    colA  colB
# 0     0    10
# 1     1    11
# 2     2    12
```

### Alternative Solutions

There is of course a workaround for this but, it is slightly verbose to use it during method chaining:

```python
df = (
    pd.DataFrame({'A': range(3), 'B': range(10, 13)})
    .pipe(lambda df: df.set_axis('col' + df.columns, axis=1))
)
print(df)

#    colA  colB
# 0     0    10
# 1     1    11
# 2     2    12
```

### Additional Context

I think `.set_axis` in general needs a bit of API consistency update.
For example, in `DataFrame.rename_axis` arguments can be provided in two ways:
```python
df.rename_axis(index=index_mapper, columns=columns_mapper)
df.rename_axis(mapper, axis='index')
```

But, `.set_axis` does not support such calling signatures. I propose to additionally support `index=` and `columns=` calling arguments to clarify the intent and increase readability.","['Enhancement', 'Needs Triage', 'Closing Candidate']",,2025-05-25 12:02:15+00:00,2025-05-27 06:37:44+00:00,,1.7746412037037036
61492,DOC: Fix incorrect reST markups in What's new,Fixed some markups so as to render HTML correctly.,['Docs'],,2025-05-24 23:38:01+00:00,2025-05-26 16:53:01+00:00,,1.71875
61490,Fix GH-61477: Prevent spurious sort warning in concat with unorderable MultiIndex,"# Fix GH-61477: Stop Spurious Warning When `concat(..., sort=False)` on Mixed-Type `MultiIndex`

## Overview

When you do something like:

```python
pd.concat([df1, df2], axis=1, sort=False)
```
and your two DataFrames have MultiIndex columns that mix tuples and integers, pandas used to try to sort those labels under the hood. Since Python cannot compare tuple < int, you‚Äôd see:
```
RuntimeWarning: '<' not supported between instances of 'int' and 'tuple'; sort order is undefined for incomparable objects with multilevel columns
```

This warning is confusing, and worse, you explicitly asked not to sort (sort=False), so pandas should never even try.

# What Changed
1. Short-circuit Index.union when sort=False
Before: Even with sort=False, pandas would call its normal union logic, which might attempt to compare labels.

Now: If you pass sort=False, we simply concatenate the two index arrays with:
``` 
np.concatenate([self._values, other._values])
```
and wrap that in a new Index. No comparisons, no warnings, and your original order is preserved.


2. Guard sorting in MultiIndex._union
Before: pandas would call ```result.sort_values()``` when sort wasn‚Äôt False, and if labels were unorderable it would warn you.

Now: We only call ```sort_values()``` when sort is truthy (True), and we wrap it in a ```try/except``` TypeError that silently falls back to the existing order on failure. No warning is emitted.

3. New Regression Test
A pytest test reproduces the original bug scenario, concatenating two small DataFrames with mixed-type MultiIndex columns and ```sort=False.``` The test asserts:

No RuntimeWarning is raised

Column order is exactly ‚Äúfirst DataFrame‚Äôs columns, then second DataFrame‚Äôs columns‚Äù

Respects sort=False: If a user explicitly disables sorting, pandas won‚Äôt try.

Silences spurious warnings: No more confusing messages about comparing tuples to ints.

Keeps existing behavior for sort=True: You still get a sort or a real error if the labels truly can‚Äôt be ordered.

For testing we can try 
```
import numpy as np, pandas as pd

left = pd.DataFrame(
    np.random.rand(5, 2),
    columns=pd.MultiIndex.from_tuples([(""A"", 1), (""B"", (2, 3))])
)
right = pd.DataFrame(
    np.random.rand(5, 1),
    columns=pd.MultiIndex.from_tuples([(""C"", 4)])
)

# No warning, order preserved:
out = pd.concat([left, right], axis=1, sort=False)
print(out.columns)  # [(""A"", 1), (""B"", (2, 3)), (""C"", 4)]

# Sorting still works if requested:
sorted_out = pd.concat([left, right], axis=1, sort=True)
print(sorted_out.columns)  # sorted order or TypeError if impossible
```
",[],,2025-05-24 13:36:24+00:00,2025-06-02 16:53:43+00:00,,9.137025462962963
61489,BUG: Raise on coercion of ambiguous datetime strings to datetime64,"This PR addresses a bug where object-dtype arrays containing ambiguous datetime strings (e.g., `""12/01/2020""`, `""13/01/2020""`) were being silently coerced to `datetime64[ns]`, potentially resulting in inconsistent or unintended parsing.

- Introduced stricter input validation during coercion to detect and raise a `ValueError` when an ambiguous format is inferred but cannot be consistently parsed.
- Added tests to cover both direct assignment and constructor-based coercion scenarios.

- [x] closes 61353  
- [x] Tests added and passed
- [ ]  All code checks passed
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file  ",[],,2025-05-24 09:28:07+00:00,2025-05-25 06:43:54+00:00,,0.8859606481481481
61488,"Backport PR #60739 on branch 2.3.x (ENH: pandas.api.interchange.from_dataframe now uses the Arrow PyCapsule Interface if available, only falling back to the Dataframe Interchange Protocol if that fails)","OK to backport https://github.com/pandas-dev/pandas/pull/60739/files?

One thing to check is:
- #60739 has the release note in 3.0
- but if it gets backported, then the change will have happened in 2.3

So, not sure how to do this. Is it OK to backport, and then change the whatsnew note on `main`?",['Interchange'],,2025-05-24 07:37:43+00:00,2025-05-27 16:10:36+00:00,,3.3561689814814817
61484,BUG: Raise clear error for duplicate id_vars in melt (GH61475),"- [x] closes #61475 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Reshaping', 'Error Reporting']",,2025-05-23 18:46:55+00:00,2025-05-30 16:43:55+00:00,,6.914583333333334
61482,BUG: Raise error when filtering HDF5 with tz-aware index (GH#61479),"This PR addresses a bug where applying a .select(where=...) query on an HDF5 store with a timezone-aware DatetimeIndex raised a confusing or incorrect error. Since tz-aware filtering isn't currently supported, we now raise a clear ValueError when such filtering is attempted.
What‚Äôs included:

-Adds a specific check in select() to detect and error on tz-aware index queries

-Includes a minimal test case reproducing the issue in test_timezone_bug.py

Closes: #61479","['IO HDF5', 'Stale']",,2025-05-23 15:13:54+00:00,2025-06-16 19:44:04+00:00,,24.18761574074074
61480,DOC: Fix formatting in indexing.rst,"Don't use code formatting for non-code. To mention a term, use italics.",['Docs'],,2025-05-22 16:45:47+00:00,2025-05-22 17:40:26+00:00,,0.03795138888888889
61479,BUG: read_hdf() doesn't handle datetime64[ms] properly,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd


df = pd.DataFrame(
    {
        ""dates"": [
            pd.to_datetime(""2025-05-21 18:44:22""),
            pd.to_datetime(""2025-05-21 19:12:42""),
        ],
        ""tags"": [
            12,
            45,
        ]
    },
)
df[""dates""] = df[""dates""].astype(""datetime64[ms]"")
print(df.dtypes)
print(df)

df.to_hdf(""dates.h5"", key=""dates"")
df2 = pd.read_hdf(""dates.h5"", key=""dates"")
print(df2)

df2[""corrected""] = df2[""dates""].astype(""i8"").astype(""datetime64[ms]"")
print(df2)
```

### Issue Description

Dataframes containing dtype of ""datetime64[ms]"" seem to be correctly written in hdf format, but the readback is misinterpreted as ‚Äúdatetime64[ns]‚Äù.

The output of the code above is:

```dates    datetime64[ms]
tags              int64
dtype: object
                dates  tags
0 2025-05-21 18:44:22    12
1 2025-05-21 19:12:42    45
                       dates  tags
0 1970-01-01 00:29:07.853062    12
1 1970-01-01 00:29:07.854762    45
                       dates  tags           corrected
0 1970-01-01 00:29:07.853062    12 2025-05-21 18:44:22
1 1970-01-01 00:29:07.854762    45 2025-05-21 19:12:42```

### Expected Behavior

Correct dates when read back.

### Installed Versions

```INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.11.9.final.0
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.22631
machine               : AMD64
processor             : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : de_DE.cp1252

pandas                : 2.2.2
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
setuptools            : 80.8.0
pip                   : 25.1.1
Cython                : 3.1.1
pytest                : 8.3.5
hypothesis            : 6.131.20
sphinx                : 8.2.3
blosc                 : None
feather               : None
xlsxwriter            : 3.2.3
lxml.etree            : 5.4.0
html5lib              : 1.1
pymysql               : None
psycopg2              : None
jinja2                : 3.1.6
IPython               : 8.36.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
bottleneck            : 1.5.0
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.5.0
gcsfs                 : None
matplotlib            : 3.8.4
numba                 : 0.61.2
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.2
pandas_gbq            : None
pyarrow               : 17.0.0
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.3
sqlalchemy            : 2.0.30
tables                : 3.10.2
tabulate              : None
xarray                : 2025.4.0
xlrd                  : 2.0.1
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : 2.4.3
pyqt5                 : None```
","['Bug', 'IO HDF5', 'Needs Info', 'Closing Candidate']",,2025-05-22 12:34:28+00:00,2025-05-23 17:26:53+00:00,,1.2030671296296296
61478,BUG: to_latex does not escape % with percent formatter,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
print(pd.DataFrame({""x"": [0.1, 0.5, 1.0]}).to_latex(formatters={""x"": ""{:.0%}""}, escape=True))
print(pd.DataFrame({""x"": [0.1, 0.5, 1.0]}).style.format(""{:.0%}"", escape=""latex"").to_latex())
```

### Issue Description

When using `""{:.0%}""` to format floating point values as percentages, the percent signs are not correctly escaped even if explicitly specified. This applies to `DataFrame.to_latex` and `Styler.to_latex`.

Output:
```latex
\begin{tabular}{lr}
\toprule
 & x \\
\midrule
0 & 10% \\
1 & 50% \\
2 & 100% \\
\bottomrule
\end{tabular}

\begin{tabular}{lr}
 & x \\
0 & 10% \\
1 & 50% \\
2 & 100% \\
\end{tabular}
```

### Expected Behavior

```latex
\begin{tabular}{lr}
\toprule
 & x \\
\midrule
0 & 10\% \\
1 & 50\% \\
2 & 100\% \\
\bottomrule
\end{tabular}

\begin{tabular}{lr}
 & x \\
0 & 10\% \\
1 & 50\% \\
2 & 100\% \\
\end{tabular}
```

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.10
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 165 Stepping 2, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : de_DE.cp1252

pandas                : 2.2.3
numpy                 : 2.0.2
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.11
sphinx                : None
IPython               : 8.30.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.10.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : 0.60.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : 18.1.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : 2.0.36
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'IO LaTeX']",,2025-05-22 12:02:17+00:00,2025-05-30 18:24:32+00:00,,8.26545138888889
61476,DOC: Improve DateOffset docstring with constructor and examples (#52431),"Updates the docstring for the `DateOffset` class in `offsets.pyx`.

Changes:
- Added a constructor signature and parameter documentation

This addresses part of issue #52431 (documentation improvements for offset constructors).","['Docs', 'Frequency', 'Stale']",,2025-05-22 06:45:30+00:00,2025-06-30 18:18:47+00:00,,39.481446759259256
61475,BUG: More Indicative Error when pd.melt with duplicate columns,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

x = pd.DataFrame([[1, 2, 3], [3, 4, 5]], columns=[""A"", ""A"", ""B""])
pd.melt(x, id_vars=[""A""], value_vars=[""B""])
```

### Issue Description

Error raised when melting on DataFrame with duplicate column headers

```
import pandas as pd

x = pd.DataFrame([[1, 2, 3], [3, 4, 5]], columns=[""A"", ""A"", ""B""])
pd.melt(x, id_vars=[""A""], value_vars=[""B""])
```

Above raises:
```
File ""pandas\core\reshape\melt.py"", line 110, in melt
  if not isinstance(id_data.dtype, np.dtype):
                    ^^^^^^^^^^^^^
File ""pandas\core\generic.py"", line 6286, in __getattr__
  return object.__getattribute__(self, name)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'DataFrame' object has no attribute 'dtype'. Did you mean: 'dtypes'?
```

From pandas\core\reshape\melt.py:108 pop method causes id_data to be assigned to a DataFrame object rather causing above AttributeError
```
for col in id_vars:
  id_data = frame.pop(col)
  if not isinstance(id_data.dtype, np.dtype):
```

When having duplicate column headers in a dataframe it raises an AttributeError, should this instead indicate a hint about melting on duplicated column headers? Possibly implement a check prior to .dtype being called?


### Expected Behavior

Error raised should be indicative of duplicated column headers.

```
for col in id_vars:
  id_data = frame.pop(col)
  if isinstance(id_data, pd.DataFrame):
    raise Exception(f""{col} is a duplicate column header"")
  if not isinstance(id_data.dtype, np.dtype):
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.4
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United Kingdom.1252
pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.9.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.1
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 17.0.0
pyreadstat            : None
pytest                : 8.3.3
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Reshaping', 'Error Reporting', 'good first issue']","{'login': 'ZanirP', 'id': 46696445, 'node_id': 'MDQ6VXNlcjQ2Njk2NDQ1', 'avatar_url': 'https://avatars.githubusercontent.com/u/46696445?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ZanirP', 'html_url': 'https://github.com/ZanirP', 'followers_url': 'https://api.github.com/users/ZanirP/followers', 'following_url': 'https://api.github.com/users/ZanirP/following{/other_user}', 'gists_url': 'https://api.github.com/users/ZanirP/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ZanirP/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ZanirP/subscriptions', 'organizations_url': 'https://api.github.com/users/ZanirP/orgs', 'repos_url': 'https://api.github.com/users/ZanirP/repos', 'events_url': 'https://api.github.com/users/ZanirP/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ZanirP/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-21 22:01:23+00:00,2025-05-30 16:43:56+00:00,ZanirP,8.77954861111111
61474,"BUG: dataframe.to_csv calls defauly numpy to_string function, resulting in","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np

array = np.ones((1000, 1000))
df = pd.DataFrame({""Data"": [array]})
df.to_csv('test.csv', index=False)
```

### Issue Description

The output file will then have the following in the cell:

array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       ...,
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]])

### Expected Behavior

I would expect the code to run like the following code does:

import pandas as pd
import numpy as np

array = np.ones((1000, 1000))
df = pd.DataFrame({""Data"": [array]})
with np.printoptions(linewidth=1000000, threshold=np.inf):
    df.to_csv('corrected_test.csv', index=False)

Where the df.to_csv function does not call the default numpy print statement. 

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.9.20.final.0
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 165 Stepping 5, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.2
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
setuptools            : 75.1.0
pip                   : 24.2
Cython                : None
pytest                : None
hypothesis            : None
sphinx                : None
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : None
html5lib              : None
pymysql               : None
psycopg2              : None
jinja2                : 3.1.4
IPython               : 8.15.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
gcsfs                 : None
matplotlib            : 3.9.2
numba                 : None
numexpr               : 2.10.1
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
pyarrow               : None
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.13.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
zstandard             : None
tzdata                : 2023.3
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Bug', 'IO CSV', 'Closing Candidate']","{'login': 'Jahanvi-vy', 'id': 104501132, 'node_id': 'U_kgDOBjqPjA', 'avatar_url': 'https://avatars.githubusercontent.com/u/104501132?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Jahanvi-vy', 'html_url': 'https://github.com/Jahanvi-vy', 'followers_url': 'https://api.github.com/users/Jahanvi-vy/followers', 'following_url': 'https://api.github.com/users/Jahanvi-vy/following{/other_user}', 'gists_url': 'https://api.github.com/users/Jahanvi-vy/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Jahanvi-vy/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Jahanvi-vy/subscriptions', 'organizations_url': 'https://api.github.com/users/Jahanvi-vy/orgs', 'repos_url': 'https://api.github.com/users/Jahanvi-vy/repos', 'events_url': 'https://api.github.com/users/Jahanvi-vy/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Jahanvi-vy/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-21 20:09:11+00:00,2025-05-23 17:28:18+00:00,Jahanvi-vy,1.888275462962963
61472,Backport PR #61399: BUG: round on object columns no longer raises a TypeError,xref https://github.com/pandas-dev/pandas/pull/61399,['Error Reporting'],,2025-05-21 15:56:04+00:00,2025-05-21 17:06:16+00:00,,0.04875
61471,DOC: Improve lookup documentation,"- [ ] closes #40140
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Follows from #61185 

Examples available at https://colab.research.google.com/drive/1MGWX6JVJL5yHyK7BeEBPQAW4tLM3TZL9#scrollTo=DjWfk4i1SiOY","['Docs', 'Indexing']",,2025-05-21 15:04:30+00:00,2025-06-02 16:57:09+00:00,,12.078229166666667
61470,DOC: Restructure and expand UDF page,"I changed the order in which the methods are presented,both in the table and in the sections, to be:

- map
- apply
- pipe
- filter
- agg
- transform

I find it easier to explain them in this order.

And I expanded the method sections with examples and a bit more of information.

I removed the most complex example in the intro, as I think the examples in the sections will make a better job now at explaining the most complex cases.

@arthurlw @rhshadrach do you mind having a look?","['Docs', 'Apply']",,2025-05-21 11:34:50+00:00,2025-05-27 15:15:22+00:00,,6.153148148148148
61469,"BUG: pandas.pivot_table margins, dropna and observed parameters not producing expected result","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

data = {
    'column_A_1': ['A', 'B', 'A', None, 'D', 'B', 'A'],
    'column_A_2': ['G', 'F', 'J', 'J', 'J', 'F', 'G'],
    'column_A_3': ['6602', '7059', '9805', '3080', '8625', '5741', '9685'],
    'column_A_4': ['A', 'B', 'A', None, 'A', None, 'B'],
    'column_A_4': ['X', None, 'Y', None, 'Z', 'X', 'Y'],
    'column_B_1': ['1', '2', '3', '4', '5', '6', '7'],
    'column_C_1': [0, 2, 5, 9, 8, 3, 7],
    'column_C_2': [12, 75, None, 93, 89, 23, 97],
    'column_C_3': [789, 102, 425, 895, None, 795, None],
    'column_C_3': [15886, 49828, None, 9898, 8085, 9707, 8049]
}
df = pd.DataFrame(data)

pd.pivot_table(df, index=['column_A_1', 'column_A_2', 'column_A_3', 'column_A_4'], columns=['column_B_1'], values=['column_C_1', 'column_C_2', 'column_C_3'], aggfunc={'column_C_1': 'max', 'column_C_2': 'min', 'column_C_3': 'count'}, dropna=False, margins=False, observed=True)
```

### Issue Description

I have a huge dataset with similar structure to the example. I want to pivot the table grouping using the columns A as the index, the values of the columns B as the new columns and aggregate the values of the columns C. I want all columns B values to appear as columns, even if the entire column is NaN. This is because I want to coalesce values from multiple columns into one. Therefore, the parameter dropna should be equal to False. But the DataFrame I get has 336 rows with impossible combinations. For example, the first row A, F, 3080, X has the entire row filled with NaNs since this combination does not exist. 

![Image](https://github.com/user-attachments/assets/578d93a9-e906-49e6-83d6-19b49f9d1073)

This is a problem because with a small dataset I wouldn't mind. But with a fairly large dataset, numpy returns an error because it has reached the maximum list size. While reading the documentation, I noticed the parameter:

![Image](https://github.com/user-attachments/assets/a30d2b3a-2a37-46aa-954e-2422ee610d16)

I thought this parameter fixed this issue. Playing around with this parameter, it does not affect the result, it only adds a row. Here is a result of combining these two parameters.

dropna=False, margins=False (Too many rows)

![Image](https://github.com/user-attachments/assets/111b43b9-8e08-46b0-8209-ec951b0ccb5f)

dropna=True, margins=False (Missing Column B values)

![Image](https://github.com/user-attachments/assets/1739d439-380b-471f-903d-806d8df8e63b)

dropna=False, margins=True (Same as dropna=False, margins=False?)

![Image](https://github.com/user-attachments/assets/39ca067f-99e2-4079-8778-04d230e1068d)

dropna=True, margins=True (Same as dropna=True, margins=False?)

![Image](https://github.com/user-attachments/assets/6a7c7cd3-ab08-4202-b314-ac0f2b7d81b9)

I also noticed this parameter:

![Image](https://github.com/user-attachments/assets/586030fe-b167-4085-963f-3bd21c718e7d)

But it is deprecated, and the default value of True seems to be the value that I need. Forcing this parameter to True does not change the result.

![Image](https://github.com/user-attachments/assets/c43f38cd-71fc-46f7-8f5e-05eeddf48fad)

### Expected Behavior

I expect with the parameter's combination dropna=False, margins=False and observed=True to get all the rows with plausible combinations (like if I was grouping by) and all the columns with column B values and columns C values.

I don't know if this is a bug or if it is the intended way for the pivot table to work and this is an enhancement.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.6
python-bits           : 64
OS                    : Linux
OS-release            : 5.10.235-227.919.amzn2.x86_64
Version               : #1 SMP Sat Apr 5 16:59:05 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0
pip                   : 24.0
Cython                : None
sphinx                : 7.2.6
IPython               : 8.23.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.3.1
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.3
lxml.etree            : 5.1.0
matplotlib            : 3.8.4
numba                 : 0.59.1
numexpr               : 2.9.0
odfpy                 : None
openpyxl              : 3.1.2
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 15.0.2
pyreadstat            : None
pytest                : 8.1.1
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.13.0
sqlalchemy            : 2.0.29
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : 0.22.0
tzdata                : 2024.1
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Bug', 'Reshaping', 'Duplicate Report']",,2025-05-21 08:58:05+00:00,2025-06-21 14:38:09+00:00,,31.236157407407408
61467,ENH: Support third-party execution engines in Series.map,"- [X] xref #61125
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Apply'],,2025-05-20 22:07:21+00:00,2025-05-27 21:37:34+00:00,,6.97931712962963
61463,Wheels for win_arm64,"- [ ] closes #61462
- [x] no new code was added to pandas",['Build'],,2025-05-19 21:22:13+00:00,2025-05-21 20:25:01+00:00,,1.9602777777777778
61462,BUILD: Provide wheel for Windows ARM64,"### What is the current behavior?

Installation via pip requires local build.

### What is the desired behavior?

To have [native wheel for WoA](https://blogs.windows.com/windowsdeveloper/2025/04/14/github-actions-now-supports-windows-on-arm-runners-for-all-public-repos/). GitHub Actions now supports win-arm64 for free.

### How would this improve `pandas`?

Due to the library's popularity, a native version for the growing number of Windows on ARM (WoA) devices offers a better user experience.","['Build', 'Windows', 'ARM']",,2025-05-19 21:21:52+00:00,2025-05-21 20:25:02+00:00,,1.9605324074074073
61461,DOC: fix two mistakes in missing_data.rst,"Small documentation improvements on `missing_data.rst`:
- The referenced example no longer exists
- Add space after full stop.","['Docs', 'Missing-data']",,2025-05-19 19:17:16+00:00,2025-05-19 19:45:53+00:00,,0.019872685185185184
61460,PERF: Slow Windows / Ubuntu Unit Tests during Status Checks,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this issue exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this issue exists on the main branch of pandas.


### Reproducible Example

The Windows Unit tests are dangerously close to time out when running the checks that validate a PR.
The last unit test from a merged PR took 83 minutes, out of the 90 minutes before timeout: 
https://github.com/pandas-dev/pandas/actions/runs/15019196064/job/42204122221

Furthermore, the checks in the open PR below are failing due to timeout in one of the Windows Unit tests.
https://github.com/pandas-dev/pandas/pull/61457/checks?check_run_id=42474035590
As there is only one unit test failing among all the PR checks and the Ubuntu Unit test is taking the same time in this PR as in the merged PR above, it strongly suggests that there is no issue intrinsic to the code change in the PR and that the way forward is:

- To increase the 90-min timeout in the unit test config yaml
- Or, and maybe better, to reduce the total time to run unit tests; this obviously might require a lot of work, unless some low-hanging fruits are still up for grab.

~If this issue appears in all new PRs triggering the core unit tests, this requires immediate attention.~

### Installed Versions

<details>

Version independent

</details>


### Prior Performance

_No response_","['Performance', 'CI', 'Windows', 'Needs Discussion']",,2025-05-19 13:37:43+00:00,2025-06-02 16:26:11+00:00,,14.116990740740741
61459,DOC: change `pandas.DataFrame.unstack`'s `fill_value` param to scalar,"- [x] closes #61445 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

<img width=""796"" alt=""image"" src=""https://github.com/user-attachments/assets/2540c012-dc39-47bd-81f9-263855a2c69d"" />
",['Docs'],,2025-05-19 13:13:36+00:00,2025-05-19 16:00:40+00:00,,0.11601851851851852
61456,PERF: Setting an item of incompatible dtype,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this issue exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this issue exists on the main branch of pandas.


### Reproducible Example

df[""feature""] = np.nan
for cluster in df[""cluster""].unique():
    df.loc[df[""cluster""] == cluster, ""feature""] = ""string""


### Installed Versions

<details>


INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.12
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.0-138-generic
Version               : #148-Ubuntu SMP Fri Mar 14 19:05:48 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_GB.utf8
LOCALE                : en_GB.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.34.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2023.6.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 4.9.4
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : 2023.6.0
scipy                 : 1.15.2
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : 2025.1.2
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>


### Prior Performance

Setup

    Dataset: df with 148,858 rows

    Task: Assign ""string"" to a new column ""feature"" based on unique values in the ""cluster"" column.

    Environment: Running on LSF

Test 1: Initialize with np.nan

import numpy as np

df[""feature""] = np.nan
for cluster in df[""cluster""].unique():
    df.loc[df[""cluster""] == cluster, ""feature""] = ""string""

    Runtime: ~52.5 seconds

    Warning:

    FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. 
    Value 'string' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.

Test 2: Initialize with ""None""

df[""feature""] = ""None""
for cluster in df[""cluster""].unique():
    df.loc[df[""cluster""] == cluster, ""feature""] = ""string""

    Runtime: ~1 minute 35 seconds

    No warnings

    Observation: Slower performance despite avoiding the dtype mismatch warning.","['Indexing', 'Performance', 'Needs Info']",,2025-05-19 10:55:32+00:00,2025-08-05 17:04:22+00:00,,78.25613425925926
61455,fix(doc): #61432 typing,"- [x] closes #61432
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Reshaping']",,2025-05-19 07:34:54+00:00,2025-05-20 21:40:31+00:00,,1.5872337962962964
61453,TYP: Update typing for 3.10,"- Ran `pyupgrade` so that typing is updated to python 3.10 - that modified files in `pandas/_libs`
- Updated `pandas/_typing.py` to have the following:
  - Use `TypeAlias` to declare all types
  - Change `Type` to use `builtins.type`
  - Remove `Optional`
  - Remove use of `Union` *except* for when it is used on a pandas type

Also fixed some other typing issues as well as an issue with running `stubtest` locally.
",['Typing'],,2025-05-18 21:38:17+00:00,2025-05-19 16:11:23+00:00,,0.7729861111111112
61452,BUG: Compiler Flag Drift May Affect Pandas ABI Stability via Memory Assumptions,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np

# Create a structured array with alignment-sensitive types
dtype = np.dtype([('x', np.int64), ('y', np.float64)])
arr = np.zeros(10, dtype=dtype)

# Wrap into DataFrame
df = pd.DataFrame(arr)

# Trigger complex alignment path
try:
    # Operation that depends on consistent field layout
    df_sum = df.sum(numeric_only=True)
    print(""Sum result:"", df_sum)
except Exception as e:
    print(""Failure during structured alignment test:"", e)
```

### Issue Description

### Summary
Pandas may be vulnerable to ABI and memory alignment issues caused by C23 default behaviors in GCC 15.1. Silent adoption of padding behavior changes ‚Äî particularly in union or struct definitions used in NumPy or Pandas C extensions ‚Äî may lead to unpredictable runtime behavior.

This issue was originally identified in NumPy and Cython. As Pandas includes both compiled Cython code and relies on NumPy for internal memory layout, it is downstream vulnerable.

These compiled pieces are sensitive to pointer alignment, ABI expectations, or padding behaviors ‚Äî especially across environments.

### Reproducible Example
Please see section below

Possibly related to:
- [BUG: DataFrame constructor not compatible with array-like classes that have a 'name' attribute](https://github.com/pandas-dev/pandas/issues/61443)
- [BUG: Confusing Behavior When Assigning DataFrame Columns Using omegaconf.ListConfig](https://github.com/pandas-dev/pandas/issues/61439)
- [BUG: Some ExtensionArrays can return 0-d Elements](https://github.com/pandas-dev/pandas/issues/61433)
- [BUG: Joining Pandas with Polars dataframe produces fuzzy errormessage](https://github.com/pandas-dev/pandas/issues/61434)
- [BUG: documented usage of of str.split(...).str.get fails on dtype large_string[pyarrow]](https://github.com/pandas-dev/pandas/issues/61431)

Report for more context:
[Report](https://brytelite.github.io/BryteLite/supply-chain-report)


### Expected Behavior

Recompile NumPy and Pandas with mismatched flags.

Then run the If padding bits are not cleared correctly in C structs, or if a layout mismatch occurs due to vendor/flag drift, crashes or incorrect math results may emerge.

`CFLAGS=""-std=c23"" pip install numpy pandas --force-reinstall --no-cache-dir when #building`

### Installed Versions

NumPy latest 3.13 release, Pandas latest 3.13 release are suitable.","['Bug', 'Build']",,2025-05-18 00:17:59+00:00,2025-05-18 10:21:00+00:00,,0.41876157407407405
61451,BUG: Fix DataFrame constructor misclassification of array-like with 'name' attribute (#61443),"BUG: Fix DataFrame constructor misclassification of array-like with 'name' attribute

Previously, any object with a `.name` attribute (like some `vtkArray`-like objects) was assumed to be a `Series` or `Index`, causing the DataFrame constructor to misinterpret the input and raise errors when passed valid 2D array-likes.

This fix ensures we only apply the named-Series/Index logic when the input is **actually** an instance of `ABCSeries` or `ABCIndex`, and the `name` is not `None`.

A new test was added to ensure array-like subclasses with `.name` are handled correctly.

---

- [x] Closes #61443
- [x] Tests added and passing
- [x] Code passes all checks via `pre-commit`
- [x] Behavior verified with array-like + `.name` case
- [x] Entry added in `doc/source/whatsnew/v3.0.0.rst`","['Bug', 'Constructors']",,2025-05-17 22:30:43+00:00,2025-05-19 15:54:49+00:00,,1.7250694444444445
61450,BUG: Fix Dataframe handling of scalar Timestamp #61444,"closes #61444
Tests developed, but validating against test suite to ensure full compliance.  Will update pull request with submission notes and unit test after validation this doesn't disrupt other functions.

TODO:
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Stale', 'Timestamp']",,2025-05-17 01:42:15+00:00,2025-06-30 18:26:20+00:00,,44.69728009259259
61449,DOC: fix typo in merging.rst,"""order data""

- ~~[ ] closes #xxxx (Replace xxxx with the GitHub issue number)~~
- ~~[ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~~
- ~~[ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).~~
- ~~[ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- ~~[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~",['Docs'],,2025-05-16 23:56:46+00:00,2025-05-17 00:21:58+00:00,,0.0175
61448,"DOC: Skip parallel_coordinaes, andrews_curves doctests","The method calls are skipped in these doctest, so we should skip the `DataFrame` setup that makes a network call

e.g where this can fail https://github.com/pandas-dev/pandas/actions/runs/15072461295/job/42371956167",['Docs'],,2025-05-16 19:00:05+00:00,2025-05-16 20:59:16+00:00,,0.0827662037037037
61447,BUG: read_csv silently ignores out of bounds errors when parsing date columns,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import tempfile as tmp

with tmp.TemporaryFile(mode='r+') as csv_file:
    pd.DataFrame({
        'over_and_under': [
            '2262-04-12',
            '1677-09-20',
        ]
    }).to_csv(csv_file, index=False)
    csv_file.seek(0)
    df = pd.read_csv(csv_file, parse_dates=['over_and_under'], date_format='%Y-%m-%d')
    print(df.info())
    pd.to_datetime(df['over_and_under'], format='%Y-%m-%d')
```

### Issue Description

pandas 2.2.3 `read_csv` does not raise an Exception when parsing a date column with specified _date_format_ if values are out of bounds and silently keeps the column as object dtype.
An explicit call of `to_datetime` on the column reveals the out of bounds problem which I expected to get from `read_csv`

### Expected Behavior

`read_csv` should propagate or raise an OutOfBoundsDatetime exception like `to_datetime`.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.9
python-bits           : 64
OS                    : Darwin
OS-release            : 24.4.0
Version               : Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:47 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : en_US.UTF-8
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.5
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : 9.2.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Datetime', 'IO CSV', 'Non-Nano']","{'login': 'Farsidetfs', 'id': 78942810, 'node_id': 'MDQ6VXNlcjc4OTQyODEw', 'avatar_url': 'https://avatars.githubusercontent.com/u/78942810?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Farsidetfs', 'html_url': 'https://github.com/Farsidetfs', 'followers_url': 'https://api.github.com/users/Farsidetfs/followers', 'following_url': 'https://api.github.com/users/Farsidetfs/following{/other_user}', 'gists_url': 'https://api.github.com/users/Farsidetfs/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Farsidetfs/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Farsidetfs/subscriptions', 'organizations_url': 'https://api.github.com/users/Farsidetfs/orgs', 'repos_url': 'https://api.github.com/users/Farsidetfs/repos', 'events_url': 'https://api.github.com/users/Farsidetfs/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Farsidetfs/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-16 08:42:56+00:00,2025-05-17 21:05:50+00:00,Farsidetfs,1.5159027777777778
61446,CI: clean up wheel build workarounds now that Cython 3.1.0 is out,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This simplifiers wheel builds for free-threaded CPython, which is useful in itself and I thought was a good idea before backporting the Windows cp313t wheel support to the 2.3.x branch, as just discussed at https://github.com/pandas-dev/pandas/pull/61249#issuecomment-2885514360.

This should have no changes in behavior, and mostly reverts the workarounds for unreleased Cython added initially in gh-60146. Other notes:
- Changes the `free-threaded-support` cibuildwheel setting to `enable`, because the former is now deprecated.
- This leaves the license concatenation behavior unchanged. Note that it's skipped on Windows, and happens on other platforms. This was added without any discussion in gh-60146. It looks inconsistent, but the bash invocation doesn't work on Windows so I'd like to leave it unchanged in this PR. A useful follow-up PR may be to remove the ad-hoc concatenation in favor of starting to use [PEP 639](https://peps.python.org/pep-0639/).

I ran the wheel builds on my fork before opening this PR, they're passing ([CI logs](https://github.com/rgommers/pandas/actions/runs/15060502913)).",['Build'],,2025-05-16 04:44:14+00:00,2025-05-16 15:54:59+00:00,,0.4657986111111111
61445,DOC: DataFrame.unstack should accept fill_value with more types than just int/str/dict,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack

### Documentation problem

Currently the docs stipulate that only `int`, `str` and `dict` are allowed for the `fill_value`, yet it seems like all the types that could be used when creating a `DataFrame` seem to pass at runtime. I have not tried them all yet but int, float, complex, timestamp are working fine.

### Suggested fix for documentation

Add all allowed types for dataframe elements for the `fill_value` field.
Happy to create the PR if this is agreed by the maintainers. I will raise the issue in the pandas-stubs repo.","['Docs', 'Reshaping']","{'login': 'KevsterAmp', 'id': 109636487, 'node_id': 'U_kgDOBojrhw', 'avatar_url': 'https://avatars.githubusercontent.com/u/109636487?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/KevsterAmp', 'html_url': 'https://github.com/KevsterAmp', 'followers_url': 'https://api.github.com/users/KevsterAmp/followers', 'following_url': 'https://api.github.com/users/KevsterAmp/following{/other_user}', 'gists_url': 'https://api.github.com/users/KevsterAmp/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/KevsterAmp/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/KevsterAmp/subscriptions', 'organizations_url': 'https://api.github.com/users/KevsterAmp/orgs', 'repos_url': 'https://api.github.com/users/KevsterAmp/repos', 'events_url': 'https://api.github.com/users/KevsterAmp/events{/privacy}', 'received_events_url': 'https://api.github.com/users/KevsterAmp/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-16 00:12:57+00:00,2025-05-19 16:00:41+00:00,KevsterAmp,3.658148148148148
61444,BUG: DataFrame column assignment with pd.Timestamp leads to unexpected dtype and incorrect JSON output,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

date = pd.Timestamp(""2025-01-01"")
df = pd.DataFrame(columns=[""date""], index=[""a"", ""b"", ""c""])
df[""date""] = date
print(df[""date""].dtype)  # Output: datetime64[s] Expected: datetime64[ns]
print(df.to_json())  # Output: {""date"":{""a"":1696,""b"":1696,""c"":1696}}
# Expected: {""date"":{""a"":1735689600000,""b"":1735689600000,""c"":1735689600000}}
```

### Issue Description

When assigning a pd.Timestamp to a column in a DataFrame, the resulting dtype of the column is not as expected, and the output of to_json() is incorrect.

### Expected Behavior

The dtype of the date column should default to datetime64[ns] after assignment.
The output of df.to_json() should correctly represent the timestamp in milliseconds since the epoch.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.4
python-bits           : 64
OS                    : Darwin
OS-release            : 24.4.0
Version               : Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:47 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
None

</details>
","['Bug', 'Non-Nano', 'Timestamp']","{'login': 'Farsidetfs', 'id': 78942810, 'node_id': 'MDQ6VXNlcjc4OTQyODEw', 'avatar_url': 'https://avatars.githubusercontent.com/u/78942810?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Farsidetfs', 'html_url': 'https://github.com/Farsidetfs', 'followers_url': 'https://api.github.com/users/Farsidetfs/followers', 'following_url': 'https://api.github.com/users/Farsidetfs/following{/other_user}', 'gists_url': 'https://api.github.com/users/Farsidetfs/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Farsidetfs/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Farsidetfs/subscriptions', 'organizations_url': 'https://api.github.com/users/Farsidetfs/orgs', 'repos_url': 'https://api.github.com/users/Farsidetfs/repos', 'events_url': 'https://api.github.com/users/Farsidetfs/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Farsidetfs/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-15 07:58:40+00:00,2025-05-17 21:15:26+00:00,Farsidetfs,2.553310185185185
61443,BUG: `DataFrame` constructor not compatible with array-like classes that have a `'name'`  attribute,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd
import vtk

poly = vtk.vtkPolyData(points=np.eye(3))
pd.DataFrame(poly.points)
```

``` python
ValueError: Per-column arrays must each be 1-dimensional

```
Originally posted in https://github.com/pyvista/pyvista/issues/7519

### Issue Description

Wrapping a `DataFrame` with the array-like object above results in an unexpected `ValueError` being raised. The cause is this line, which assumes that the input object must be a `Series` or `Index` type based on having a `'name'` attribute.

https://github.com/pandas-dev/pandas/blob/41968a550a159ec0e5ef541a610b7007003bab5b/pandas/core/frame.py#L798-L799

This assumption fails for the `VTKArray` `poly.points`, which also has a `'name'` attribute.

### Expected Behavior

No error should be raised, and the array-like input should be wrapped correctly by `DataFrame`

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.2
python-bits           : 64
OS                    : Darwin
OS-release            : 23.4.0
Version               : Darwin Kernel Version 23.4.0: Fri Mar 15 00:19:22 PDT 2024; root:xnu-10063.101.17~1/RELEASE_ARM64_T8112
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : en_CA.UTF-8
pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1.1
Cython                : None
sphinx                : 8.1.3
IPython               : 8.36.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : 6.131.9
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Constructors']",,2025-05-14 22:02:04+00:00,2025-05-19 15:54:50+00:00,,4.744976851851852
61441,BUG: Raise ValueError on integer indexers containing NA; skip test for unsupported EAs,"- [ ] closes #56727
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
This PR addresses missing validation in `_setitem_with_indexer`, where indexing with integer indexers containing `pd.NA` (e.g., `Int64` arrays with missing values) would silently fail or misbehave.

### What this PR changes:

- Adds a check to `_setitem_with_indexer` to raise a `ValueError` when NA is present in the indexer.
- Updates `test_setitem_integer_with_missing_raises` to skip test cases for known `ExtensionArray` types (`PeriodArray`, `DatetimeArray`, `IntervalArray`) that do not support indexing with NA in integer indexers.

",[],,2025-05-14 08:30:32+00:00,2025-05-20 18:02:28+00:00,,6.397175925925926
61440,ENH: Broaden `dict` to `Mapping` as replace argument,"### Feature Type

- [ ] Adding new functionality to pandas

- [x] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Currently the `replace` method of `Series` allows only `dict`, but not `Mapping` inputs, as the `DataFrame` one does.

For example:

```py
from collections.abc import Mapping
import pandas as pd


df = pd.DataFrame({""A"": [1, 2, 3], ""B"": [4, 5, 6]})

d: Mapping[int, str] = {1: ""a"", 2: ""b"", 3: ""c""}

d2: Mapping[str, Mapping[int, str]] = {""A"": d}
print(df.replace(d2))  # typechecks

print(df[""A""].replace(d))  # works but doesn't typecheck
```

### Feature Description

I guess it's enough to change from `dict` to `Mapping` in the type signature, since it seems to work even if the argument is not a dict (for example if it's a `MappingProxyType` instance).

### Alternative Solutions

I guess an alternative solution is just to type ignore the replace invocation.

### Additional Context

_No response_","['Enhancement', 'Needs Triage']",,2025-05-14 08:29:11+00:00,2025-05-27 15:26:33+00:00,,13.289837962962963
61438,BUG:  ImportError: cannot import name 'NaN' from 'numpy' in squeeze_pro.py,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas_ta as ta
```

### Issue Description

D:\t70\duanxian>python duanxian_TDI_TSI_DIV.py

Traceback (most recent call last):

¬† File ""D:\t70\duanxian\duanxian_TDI_TSI_DIV.py"", line 11, in <module>

¬† ¬† import pandas_ta as ta # Êñ∞Â¢ûÔºöÁî®‰∫é ALMA Á≠âÊåáÊ†á

¬† ¬† ^^^^^^^^^^^^^^^^^^^^^^

¬† File ""D:\veighna_studio\Lib\site-packages\pandas_ta\__init__.py"", line 116, in <module>

¬† ¬† from pandas_ta.core import *

¬† File ""D:\veighna_studio\Lib\site-packages\pandas_ta\core.py"", line 18, in <module>

¬† ¬† from pandas_ta.momentum import *

¬† File ""D:\veighna_studio\Lib\site-packages\pandas_ta\momentum\__init__.py"", line 34, in <module>

¬† ¬† from .squeeze_pro import squeeze_pro

¬† File ""D:\veighna_studio\Lib\site-packages\pandas_ta\momentum\squeeze_pro.py"", line 2, in <module>

¬† ¬† from numpy import NaN as npNaN

ImportError: cannot import name 'NaN' from 'numpy' (D:\veighna_studio\Lib\site-packages\numpy\__init__.py). Did you mean: 'nan'?

### Expected Behavior

import pandas_ta success

### Installed Versions

Operating System: [Your OS, e.g., Windows 10/11]
Python Version: [Your Python version, e.g., 3.9, 3.10, 3.11 - based on your traceback, it seems like Python 3.13 based on ""cp313"" in numpy download, please confirm]
pandas_ta Version: 0.3.14b0 (Confirmed via pip show pandas_ta)
numpy Version: 2.2.5 (Confirmed via pip show numpy)
pandas Version: 2.2.3 (Confirmed via pip show pandas)","['Bug', 'Needs Triage']",,2025-05-14 02:50:31+00:00,2025-05-14 16:19:36+00:00,,0.561863425925926
61437,Backport PR #61423: CI: Fix test failures in 32-bit environment,,"['CI', 'Dependencies']",,2025-05-13 23:25:43+00:00,2025-05-13 23:57:38+00:00,,0.022164351851851852
61436,change readme,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-05-13 08:18:06+00:00,2025-05-13 08:20:01+00:00,,0.0013310185185185185
61432,"DOC: Series.name is just Hashable, but many column arguments require str","### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

* https://pandas.pydata.org/docs/dev/reference/api/pandas.Series.name.html
* https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.pivot.html

### Documentation problem

In the documentation, `Series.name` is [just required to be](https://pandas.pydata.org/docs/dev/reference/api/pandas.Series.name.html) a `Hashable`. When `pandas` functions ask for a column label, however, it often asks for an `str`, e.g. in [DataFrame.pivot](https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.pivot.html), where it says
> **columns**: *str or object or a list of str*

### Suggested fix for documentation

Use `Hashable` everywhere to column labels as a function argument","['Docs', 'Reshaping', 'good first issue']",,2025-05-12 15:45:47+00:00,2025-05-20 21:40:33+00:00,,8.24636574074074
61430,BLD: Decrease size of docker image,"This PR reduces the size of the docker image by:
- combining RUN commands to minimise the number of layers 
- removing the apt lists files to reduce total size 
- use --no-cache-dir when installing with pip

In my tests it reduced the size of the final image with approximately 0.47GB (most of it due to the --no-cache-dir). 

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-05-11 16:25:28+00:00,2025-05-12 19:10:38+00:00,,1.114699074074074
61429,DOC: Updates to documentation - io.rst,"updating hdf5 data description link due to 404 error

- [x] closes #61428 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-05-11 14:17:41+00:00,2025-05-12 16:55:16+00:00,,1.1094328703703704
61428,DOC: Broken Link in IO Tools - HDF5 Data Description,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/user_guide/io.html

### Documentation problem

The link for HDF5 data description is broken and leads to a 404 error.

Current [HDF5 link](https://support.hdfgroup.org/HDF5/whatishdf5.html#gsc.tab=0)

### Suggested fix for documentation

I believe a good replacement link would be to this [Introduction to HDF5](https://support.hdfgroup.org/documentation/hdf5/latest/_intro_h_d_f5.html).

I would like to update the documentation with this link and create a pull request.","['Docs', 'IO HDF5']","{'login': 'ConnorWallace15', 'id': 146393496, 'node_id': 'U_kgDOCLnJmA', 'avatar_url': 'https://avatars.githubusercontent.com/u/146393496?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ConnorWallace15', 'html_url': 'https://github.com/ConnorWallace15', 'followers_url': 'https://api.github.com/users/ConnorWallace15/followers', 'following_url': 'https://api.github.com/users/ConnorWallace15/following{/other_user}', 'gists_url': 'https://api.github.com/users/ConnorWallace15/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ConnorWallace15/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ConnorWallace15/subscriptions', 'organizations_url': 'https://api.github.com/users/ConnorWallace15/orgs', 'repos_url': 'https://api.github.com/users/ConnorWallace15/repos', 'events_url': 'https://api.github.com/users/ConnorWallace15/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ConnorWallace15/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-11 00:23:23+00:00,2025-05-12 16:55:17+00:00,ConnorWallace15,1.6888194444444444
61426,BUG: Fix memory leak when slicing Series and assigning to self,"This PR fixes a memory leak that occurs when a Series is sliced and reassigned to itself, e.g., a = a[-1:].

The underlying BlockManager retained references to the original data, preventing garbage collection. This is resolved by ensuring the sliced result copies the backing data.

Closes #60640.",[],,2025-05-10 16:36:04+00:00,2025-06-02 16:54:59+00:00,,23.013136574074075
61424,i want to develop one feature in pandas,"### Research

- [x] I have searched the [[pandas] tag](https://stackoverflow.com/questions/tagged/pandas) on StackOverflow for similar questions.

- [x] I have asked my usage related question on [StackOverflow](https://stackoverflow.com).


### Link to question on StackOverflow

i want to develop one feature in pandas 

### Question about pandas

_No response_","['Usage Question', 'Needs Triage']",,2025-05-10 14:14:16+00:00,2025-05-10 14:31:47+00:00,,0.012164351851851852
61423,CI: Fix test failures in 32-bit environment,"I noticed that some CI failures are due to the same test errors appearing in several recent PRs.
After comparing multiple failed and successful CI runs, it seems that the unit tests fail when using `cython==3.1.0` in the Linux 32-bit environment.


* Faliure unittest case:
  ```python
  FAILED pandas/tests/window/test_rolling.py::test_rolling_var_numerical_issues[var-1-values0] - AssertionError: Series are different
  
  Series values are different (42.85714 %)
  [index]: [0, 1, 2, 3, 4, 5, 6]
  [left]:  [nan, 5e+33, 0.0, -1.7226268574692147e+17, -1.7226268574692147e+17, -1.7226268574692147e+17, 0.0]
  [right]: [nan, 5e+33, 0.0, 0.5, 0.5, 2.0, 0.0]
  At positional index 3, first diff: -1.7226268574692147e+17 != 0.5
  FAILED pandas/tests/window/test_rolling.py::test_rolling_var_numerical_issues[std-1-values1] - AssertionError: Series are different
  
  Series values are different (42.85714 %)
  [index]: [0, 1, 2, 3, 4, 5, 6]
  [left]:  [nan, 7.071067811865475e+16, 0.0, 0.0, 0.0, 0.0, 0.0]
  [right]: [nan, 7.071068e+16, 0.0, 0.7071068, 0.7071068, 1.414214, 0.0]
  At positional index 3, first diff: 0.0 != 0.7071068
  FAILED pandas/tests/window/test_rolling.py::test_rolling_var_numerical_issues[var-2-values2] - AssertionError: Series are different
  
  Series values are different (42.85714 %)
  [index]: [0, 1, 2, 3, 4, 5, 6]
  [left]:  [nan, 5e+33, -1.7226268574692147e+17, 0.0, -1.7226268574692147e+17, -1.7226268574692147e+17, 0.0]
  [right]: [nan, 5e+33, 0.5, 0.0, 0.5, 2.0, 0.0]
  At positional index 2, first diff: -1.7226268574692147e+17 != 0.5
  FAILED pandas/tests/window/test_rolling.py::test_rolling_var_numerical_issues[std-2-values3] - AssertionError: Series are different
  
  Series values are different (42.85714 %)
  [index]: [0, 1, 2, 3, 4, 5, 6]
  [left]:  [nan, 7.071067811865475e+16, 0.0, 0.0, 0.0, 0.0, 0.0]
  [right]: [nan, 7.071068e+16, 0.7071068, 0.0, 0.7071068, 1.414214, 0.0]
  At positional index 2, first diff: 0.0 != 0.7071068
  = 4 failed, 166839 passed, 24850 skipped, 5388 deselected, 795 xfailed, 92 xpassed, 2 warnings in 554.17s (0:09:14) =
  ```
* using `cython==3.0.10`:
  ```python
  >>> import numpy as np
  ... from pandas import Series
  ...
  ... def debug_rolling_var():
  ...     ds = Series([99999999999999999, 1, 1, 2, 3, 1, 1])
  ...     print(""Rolling(2).var():\n"", ds.rolling(2).var())
  ...     print(""Numpy var:"", np.var([99999999999999999, 1], ddof=0))
  ...
  >>> debug_rolling_var()
  Rolling(2).var():
   0             NaN
  1    5.000000e+33
  2    0.000000e+00
  3    5.000000e-01
  4    5.000000e-01
  5    2.000000e+00
  6    0.000000e+00
  dtype: float64
  Numpy var: 2.5e+33
  ```
* using `cython==3.1.0`:
  ```python
  >>> import numpy as np
  ... from pandas import Series
  ...
  ... def debug_rolling_var():
  ...     ds = Series([99999999999999999, 1, 1, 2, 3, 1, 1])
  ...     print(""Rolling(2).var():\n"", ds.rolling(2).var())
  ...     print(""Numpy var:"", np.var([99999999999999999, 1], ddof=0))
  ...
  >>> debug_rolling_var()
  Rolling(2).var():
   0             NaN
  1    5.000000e+33
  2    0.000000e+00
  3   -1.722627e+17
  4   -1.722627e+17
  5   -1.722627e+17
  6    0.000000e+00
  dtype: float64
  Numpy var: 2.5e+33
  ```","['CI', 'Dependencies', '32bit']",,2025-05-10 06:43:45+00:00,2025-05-13 23:09:01+00:00,,3.6842129629629627
61422,BUG: Raise MergeError when suffixes result in duplicate column names ‚Ä¶,"closes #61402 

 All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
 Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
 Added an entry in the latest doc/source/whatsnew/vX.X.X.rst file if fixing a bug or adding a new feature.
","['Bug', 'Reshaping']",,2025-05-09 23:21:41+00:00,2025-06-06 14:12:20+00:00,,27.618506944444444
61421,DOC: Updated titanic.rst survived description,"- [x] closes #61412
- [ ] ~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
",['Docs'],,2025-05-09 18:01:36+00:00,2025-05-09 18:36:07+00:00,,0.02396990740740741
61420,ENH: Add smart_groupby() method for automatic grouping by categorical columns and aggregating numerics,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Currently, pandas.DataFrame.groupby() requires users to explicitly specify both the grouping columns and the aggregation functions. This can be repetitive and inefficient, especially during exploratory data analysis on large DataFrames with many columns. A common use case like ‚Äúgroup by all categorical columns and compute the mean of numeric columns‚Äù requires verbose, manual setup.

### Feature Description

Add a new method to DataFrame called smart_groupby(), which intelligently infers grouping and aggregation behavior based on the column types of the DataFrame.

Proposed behavior:
- If no parameters are passed:
  - Group by all columns of type object, category, or bool
  - Aggregate all remaining numeric columns using the mean
- Optional keyword parameters:
  -  by: specify grouping columns explicitly
  - agg: specify aggregation function(s) (default is ""mean"")
  - exclude: exclude specific columns from grouping or aggregation

### Alternative Solutions

Currently, users must write verbose code to accomplish the same:
```
group_cols = [col for col in df.columns if df[col].dtype == 'category']
agg_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col])]
df.groupby(group_cols)[agg_cols].mean()
```

### Additional Context

_No response_","['Enhancement', 'Groupby', 'Closing Candidate']",,2025-05-09 13:27:40+00:00,2025-05-14 18:59:15+00:00,,5.230266203703704
61419,BUILD: Missing Windows free-threading wheel,"### Installation check

- [x] I have read the [installation guide](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-pandas).


### Platform

Windows-2022Server-10.0.20348-SP0

### Installation Method

pip install

### pandas Version

2.2.3

### Python Version

3.13.3 free-threading

### Installation Logs

<details>
$ which pip
/home/Administrator/venv/Scripts/pip
$ pip install pandas
Collecting pandas
  Downloading pandas-2.2.3.tar.gz (4.4 MB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4.4/4.4 MB 144.5 MB/s eta 0:00:00
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... error
  error: subprocess-exited-with-error

  √ó Preparing metadata (pyproject.toml) did not run successfully.
  ‚îÇ exit code: 1
  ‚ï∞‚îÄ> [12 lines of output]
      + meson setup Z:\data\tmp\pip-install-niaom8mt\pandas_620816291b0449be8d128c83a9a99222 Z:\data\tmp\pip-install-niaom8mt\pandas_620816291b0449be8d128c83a9a99222\.mesonpy-ulxgqp76\build -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=Z:\data\tmp\pip-install-niaom8mt\pandas_620816291b0449be8d128c83a9a99222\.mesonpy-ulxgqp76\build\meson-python-native-file.ini
      The Meson build system
      Version: 1.2.1
      Source dir: Z:\data\tmp\pip-install-niaom8mt\pandas_620816291b0449be8d128c83a9a99222
      Build dir: Z:\data\tmp\pip-install-niaom8mt\pandas_620816291b0449be8d128c83a9a99222\.mesonpy-ulxgqp76\build
      Build type: native build
      Project name: pandas
      Project version: 2.2.3

      ..\..\meson.build:2:0: ERROR: Could not find C:\Program Files\Microsoft Visual Studio\Installer\vswhere.exe

      A full log can be found at Z:\data\tmp\pip-install-niaom8mt\pandas_620816291b0449be8d128c83a9a99222\.mesonpy-ulxgqp76\build\meson-logs\meson-log.txt
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.

[notice] A new release of pip is available: 25.0.1 -> 25.1.1
[notice] To update, run: python.exe -m pip install --upgrade pip
error: metadata-generation-failed

√ó Encountered error while generating package metadata.
‚ï∞‚îÄ> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.

</details>

I don't see a wheel for Windows cp313t in the list of release files  https://pypi.org/project/pandas/2.2.3/#files.
I see a job is running that should produce the wheel: https://github.com/pandas-dev/pandas/actions/runs/14920899116/job/41915964757
Perhaps the wheel was accidentally omitted in the release process?
","['Build', 'Needs Triage']",,2025-05-09 12:40:24+00:00,2025-05-10 14:36:30+00:00,,1.080625
61415,BUG: ImportError: cannot import name 'NaN' from 'numpy',"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
ImportError: cannot import name 'NaN' from 'numpy'
```

### Issue Description

ImportError: cannot import name 'NaN' from 'numpy' 



### Expected Behavior

ImportError: cannot import name 'NaN' from 'numpy' 



### Installed Versions

<details>

ImportError: cannot import name 'NaN' from 'numpy' 


</details>
","['Bug', 'Needs Triage']",,2025-05-09 07:40:07+00:00,2025-05-09 17:37:22+00:00,,0.41475694444444444
61414,Bug fix slow plot with datetimeindex,"- [x] closes [#61398](https://github.com/pandas-dev/pandas/issues/61398)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests)
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions. (N/A - no new methods/functions added)
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.",[],,2025-05-09 03:55:17+00:00,2025-06-02 16:55:28+00:00,,24.541793981481483
61413,CLN: Expose arguments in DataFrame.query,"- [x] closes #61405 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Clean', 'expressions']",,2025-05-09 03:18:15+00:00,2025-05-20 02:35:31+00:00,,10.970324074074075
61412,DOC: Error in Getting started tutorials > How do I read and write tabular data?,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html

### Documentation problem

In the documentation for the Titanic dataset on this page:

https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html

It currently says:

>  ""Survived: Indication whether passenger survived. 0 for yes and 1 for no.""

This appears to be incorrect. The correct meaning is:

>  0 = did not survive
>  1 = survived

You can verify this, for example, with the entry for ""McCarthy, Mr. Timothy J."", who is listed with a 0 in the dataset and was confirmed deceased (source: https://de.wikipedia.org/wiki/Passagiere_der_Titanic).

Thanks for your great work and for maintaining the documentation!

### Suggested fix for documentation

Survived: Indication whether passenger survived. 0 for no and 1 for yes.",['Docs'],,2025-05-08 21:59:48+00:00,2025-05-09 18:36:08+00:00,,0.8585648148148148
61411,DOC: removed none from docstring,"- [x] closes #61408
- [ ] ~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
","['Docs', 'Algos']",,2025-05-08 18:38:30+00:00,2025-05-08 22:27:22+00:00,,0.15893518518518518
61410,"CI: Upgrade to ubuntu-24.04, install Python free threading from conda-forge",,['CI'],,2025-05-08 16:50:51+00:00,2025-05-15 18:59:46+00:00,,7.089525462962963
61409,BUG: CVE-2020-13091,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
When will this bug be fixed?
```

### Issue Description

Bug since 2020 

### Expected Behavior

No Bug

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Needs Triage']",,2025-05-08 15:40:20+00:00,2025-05-08 15:59:45+00:00,,0.013483796296296296
61408,"DOC: axis argument for take says `None` is acceptable, but that is incorrect.","### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.take.html#pandas.DataFrame.take

### Documentation problem

The `axis` argument is documented as:  ""axis {0 or ‚Äòindex‚Äô, 1 or ‚Äòcolumns‚Äô, None}, default 0"" .  But `None` is not accepted.  So it should be removed from the docs.

See https://github.com/pandas-dev/pandas-stubs/pull/1209#discussion_r2079740441 for an example.

### Suggested fix for documentation

Remove `None` from that sentence.

","['Docs', 'Algos']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-08 13:54:54+00:00,2025-05-08 22:27:23+00:00,arthurlw,0.3558912037037037
61407,BUG: to_csv() quotechar/escapechar behavior differs from csv module,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import csv
import sys

data = [['a', 'b""c', 'def""'], ['a2', None, '""c']]

# no escaping
df = pd.DataFrame(data)
print(df.to_csv(sep='\t', index=False, header=False, quotechar='""', escapechar='\\', quoting=csv.QUOTE_NONE))
print(df.to_csv(sep='\t', index=False, header=False, quotechar='""', escapechar='\\', quoting=csv.QUOTE_NONE, doublequote=False))

# escaping
csv_writer = csv.writer(sys.stdout, delimiter='\t', quotechar='""', escapechar='\\', quoting=csv.QUOTE_NONE)
for r in data:
    _ = csv_writer.writerow(r)
```

### Issue Description

`to_csv()` doesn't escape `quotechar` when `quoting=csv.QUOTE_NONE`.
````
a       b""c     def""
a2              ""c
````

### Expected Behavior

`quotechar` gets escaped using `escapechar` even when `quoting=csv.QUOTE_NONE`.
This is the behavior of the csv module.
````
a       b\""c    def\""
a2              \""c
````

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.2
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.22621
machine               : AMD64
processor             : Intel64 Family 6 Model 140 Stepping 1, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 1.26.2
pytz                  : 2023.3.post1
dateutil              : 2.8.2
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.24.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.23
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2023.3
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'IO CSV']","{'login': 'omarraf', 'id': 119431390, 'node_id': 'U_kgDOBx5g3g', 'avatar_url': 'https://avatars.githubusercontent.com/u/119431390?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/omarraf', 'html_url': 'https://github.com/omarraf', 'followers_url': 'https://api.github.com/users/omarraf/followers', 'following_url': 'https://api.github.com/users/omarraf/following{/other_user}', 'gists_url': 'https://api.github.com/users/omarraf/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/omarraf/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/omarraf/subscriptions', 'organizations_url': 'https://api.github.com/users/omarraf/orgs', 'repos_url': 'https://api.github.com/users/omarraf/repos', 'events_url': 'https://api.github.com/users/omarraf/events{/privacy}', 'received_events_url': 'https://api.github.com/users/omarraf/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-08 13:40:42+00:00,2025-05-30 16:36:43+00:00,omarraf,22.122233796296296
61405,DOC/ENH: Add full list of argument for DataFrame.query,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query

### Documentation problem

This question arises when @MarcoGorelli wanted to fully type `DataFrame.query` in the stubs repo https://github.com/pandas-dev/pandas-stubs/issues/1173. Right now the extra arguments are passed through `**kwargs` but when we go through the code we see that they are the same as the ones in `pd.eval` (https://pandas.pydata.org/docs/reference/api/pandas.eval.html#pandas.eval).

### Suggested fix for documentation

Considering that this would help to expand the typehinting in that area and that the number of arguments is limited, would it be conceivable to expose all the arguments instead of relying on `**kwargs`?

For information this is the list of arguments that would need to be added:
```python
parser: Literal[""pandas"", ""python""] = ...,
engine: Literal[""python"", ""numexpr""] | None = ...,
local_dict: dict[_str, Any] | None = ...,
global_dict: dict[_str, Any] | None = ...,
resolvers: list[Mapping] | None = ...,
level: int = ...,
target: object | None = ...,
```

See https://github.com/pandas-dev/pandas-stubs/pull/1193 for the potential typehinting.",['Docs'],,2025-05-08 01:16:47+00:00,2025-05-20 02:35:33+00:00,,12.054699074074074
61404,BLD: allow to build with non-MSVC compilers on Windows,"Always passing --vsenv to meson means pandas can't be built with gcc/clang
on Windows.

Instead add it to the cibuildwheel config so MSVC is still forced in CI
when building wheels, and in various places where it is built via pip.",['Stale'],,2025-05-07 21:25:47+00:00,2025-06-16 19:44:46+00:00,,39.929849537037036
61403,BUG: guess_datetime_format cannot infer iso 8601 format,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd 

# UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
pd.to_datetime(
    pd.Series(['2025-05-05 20:25:22+00:00', '2025-05-05 12:04:52+00:00'])
)

# no warning
pd.to_datetime(
    pd.Series(['2025-05-05 20:25:22+00:00'])
)

# No warning
pd.to_datetime(
    pd.Series(['2025-05-05 12:03:08+00:00', '2025-05-05 12:04:52+00:00']),
)
```

### Issue Description

When running `pd.to_datetime(pd.Series(['2025-05-05 20:25:22+00:00', '2025-05-05 12:04:52+00:00']))` the following warning is risen:

> UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.

This is because `guess_datetime_format` cannot infer a format for the first given timestamp '2025-05-05 20:25:22+00:00'. 

### Expected Behavior

No warning is risen.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.10
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-58-generic
Version               : #60~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Mar 28 16:09:21 UTC 2
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.40
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Datetime', 'Warnings']",,2025-05-07 09:41:27+00:00,2025-05-07 17:04:01+00:00,,0.30733796296296295
61402,BUG: Duplicate columns allowed on `merge` if originating from separate dataframes,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df1 = pd.DataFrame({""col1"":[1], ""col2"":[2]})
df2 = pd.DataFrame({""col1"":[1], ""col2"":[2], ""col2_dup"":[3]})

pd.merge(df1, df2, on=""col1"", suffixes=(""_dup"", """"))
# Observe (1)

pd.merge(df1, df2, on=""col1"", suffixes=("""", ""_dup""))
# Observe (2)
```

### Issue Description

Case 1 provides the following result:
```
   col1  col2_dup  col2  col2_dup
0     1         2     2         3
```

Case 2 results in an exception:
```
pandas.errors.MergeError: Passing 'suffixes' which cause duplicate columns {'col2_dup'} is not allowed.
```

While the MergeError in this case does make sense (ideally duplicate columns should not be allowed as they might cause confusion), the same issue is observed in the first case and no exception is raised.


### Expected Behavior

Since this bug is about consistency, either of the following 2 should happen:

- An error should be raised in both cases.
- An error should not be raised in any case, and the duplicate column should be allowed.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.7
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.22631
machine               : AMD64
processor             : Intel64 Family 6 Model 170 Stepping 4, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.2.5
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 23.2.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Reshaping']","{'login': 'samruddhibaviskar11', 'id': 79337465, 'node_id': 'MDQ6VXNlcjc5MzM3NDY1', 'avatar_url': 'https://avatars.githubusercontent.com/u/79337465?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/samruddhibaviskar11', 'html_url': 'https://github.com/samruddhibaviskar11', 'followers_url': 'https://api.github.com/users/samruddhibaviskar11/followers', 'following_url': 'https://api.github.com/users/samruddhibaviskar11/following{/other_user}', 'gists_url': 'https://api.github.com/users/samruddhibaviskar11/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/samruddhibaviskar11/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/samruddhibaviskar11/subscriptions', 'organizations_url': 'https://api.github.com/users/samruddhibaviskar11/orgs', 'repos_url': 'https://api.github.com/users/samruddhibaviskar11/repos', 'events_url': 'https://api.github.com/users/samruddhibaviskar11/events{/privacy}', 'received_events_url': 'https://api.github.com/users/samruddhibaviskar11/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-07 08:50:02+00:00,2025-06-06 14:12:22+00:00,samruddhibaviskar11,30.223842592592593
61400,BUG: Fix naive timestamps inheriting timezone from previous timestamps in to_datetime with ISO8601 format,"- [x] closes #61389 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Timezones'],,2025-05-06 14:50:19+00:00,2025-05-06 18:29:19+00:00,,0.15208333333333332
61399,BUG: round on object columns no longer raises a TypeError,"- [x] closes #61206 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Regression', 'Numeric Operations']",,2025-05-06 13:24:43+00:00,2025-05-21 00:33:33+00:00,,14.464467592592593
61397,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.11.4 ‚Üí v0.11.8](https://github.com/astral-sh/ruff-pre-commit/compare/v0.11.4...v0.11.8)
- [github.com/pre-commit/mirrors-clang-format: v20.1.0 ‚Üí v20.1.3](https://github.com/pre-commit/mirrors-clang-format/compare/v20.1.0...v20.1.3)
- [github.com/trim21/pre-commit-mirror-meson: v1.7.2 ‚Üí v1.8.0](https://github.com/trim21/pre-commit-mirror-meson/compare/v1.7.2...v1.8.0)
<!--pre-commit.ci end-->",['Code Style'],,2025-05-05 16:29:15+00:00,2025-05-05 17:24:05+00:00,,0.038078703703703705
61395,BUG: pd.to_datetime failing to parse with exception error 01-Jun-2025 in sequence with 31-May-2025,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import sys

print(f""Pandas version: {pd.__version__}"")
print(f""Python version: {sys.version}"")

df = pd.DataFrame({'day': [""31-May-2025"",""01-Jun-2025"",""02-Jun-2025""]})
pd.to_datetime(df['day'])
```

### Issue Description

gives
'Pandas version: 2.2.3'
'Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]'

ValueError: time data ""01-Jun-2025"" doesn't match format ""%d-%B-%Y"", at position 1. You might want to try:
    - passing `format` if your strings have a consistent format;
    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;
    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.
File <command-6844361422137531>, line 2
      1 df = pd.DataFrame({'day': [""31-May-2025"",""01-Jun-2025"",""02-Jun-2025""]})
----> 2 pd.to_datetime(df['day'])
File /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1067, in to_datetime(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)
   1065         result = arg.map(cache_array)
   1066     else:
-> 1067         values = convert_listlike(arg._values, format)
   1068         result = arg._constructor(values, index=arg.index, name=arg.name)
   1069 elif isinstance(arg, (ABCDataFrame, abc.MutableMapping)):
File /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:433, in _convert_listlike_datetimes(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)
    431 # `format` could be inferred, or user didn't ask for mixed-format parsing.
    432 if format is not None and format != ""mixed"":
--> 433     return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)
    435 result, tz_parsed = objects_to_datetime64(
    436     arg,
    437     dayfirst=dayfirst,
   (...)
    441     allow_object=True,

### Expected Behavior

it parses happily and correctly with no exception
interestingly it's having the transition end of may. start of June. Starting with 01-Jun-2025 works, ending with 31-May-2025 works,
dateparser.parse is happy
I'm guessing it infers a full month from the May when in fact it is a three character abbreviation. 

### Installed Versions

<details>

running in databricks notebook - checked in a separate version of python locally, with pandas 2.2.1
'Pandas version: 2.2.3'
'Python version: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]' for the notebook.
pd.show_versions() doesn't return anything


locally 
Pandas version: 2.2.1
Python version: 3.12.2 (main, Mar 25 2024, 11:48:28) [Clang 15.0.0 (clang-1500.3.9.4)]

and pd.show_versions() gives.

FileNotFoundError                         Traceback (most recent call last)
File /Users/J.Drummond/Documents/wip/python/truth_soc_[1](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/truth_soc_1.py:1).py:2
      1 # %%
----> [2](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/truth_soc_1.py:2) pd.show_versions()

File ~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:141, in show_versions(as_json)
    [104](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:104) """"""
    [105](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:105) Provide useful information, important for bug reports.
    [106](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:106) 
   (...)
    [138](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:138) ...
    [139](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:139) """"""
    [140](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:140) sys_info = _get_sys_info()
--> [141](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:141) deps = _get_dependency_info()
    [143](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:143) if as_json:
    [144](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:144)     j = {""system"": sys_info, ""dependencies"": deps}

File ~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:98, in _get_dependency_info()
     [96](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:96) result: dict[str, JSONSerializable] = {}
     [97](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:97) for modname in deps:
---> [98](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:98)     mod = import_optional_dependency(modname, errors=""ignore"")
     [99](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:99)     result[modname] = get_version(mod) if mod else None
    [100](https://file+.vscode-resource.vscode-cdn.net/Users/J.Drummond/Documents/wip/python/~/Documents/wip/python/.venv/lib/python3.12/site-packages/pandas/util/_print_versions.py:100) return result
...


</details>
","['Bug', 'Datetime']",,2025-05-03 14:04:02+00:00,2025-05-03 15:12:00+00:00,,0.047199074074074074
61394,DOC: add `api.types.is_dtype_equal` into document,"- [x] closes #60905
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Dtype Conversions']",,2025-05-03 07:20:19+00:00,2025-05-03 20:00:53+00:00,,0.5281712962962963
61393,Subplot title count fix + fix for issue introduced in earlier PR ,"- [x] closes #61019  
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Adds a check for length of subplots as an alternative to the default title check and produces an alternative error message if number of subplots does not match titles produced.

Additionally, includes fix for issues introduced during PR: #61340 and mentioned in #61018 ",['Visualization'],,2025-05-02 22:00:03+00:00,2025-05-07 16:11:19+00:00,,4.757824074074074
61392,DOC: Issue with the general expressiveness of the docs,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

Example: https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html

### Documentation problem

Throughout the docs the explanation of a function is often limited only to a circular sentence that repeats the verb that names the function and nothing else. Eg in the example of `pandas.Series.dt.floor` it basically says ""it does floor"" and the details of the docs are restricted to the individual options and outcomes after that.

### Suggested fix for documentation

In the example of floor it should first say in a richer sentence what floor actually does. It doesn't have to be anything big. I won't write an example of that because the docs didn't tell me what floor does.","['Docs', 'Needs Info']",,2025-05-02 16:28:12+00:00,2025-08-05 17:09:58+00:00,,95.02900462962963
61391,"fix MultiIndex.difference not working with PyArrow timestamps (#61382) ,and some ruff formating fix","## Problem
The `MultiIndex.difference` method fails to remove entries when the index contains PyArrow-backed timestamps (`timestamp[ns][pyarrow]`). This occurs because direct tuple comparisons with PyArrow scalar types are unreliable during membership checks, causing entries to remain unexpectedly.

**Example**:
```python
# PyArrow timestamp index
df = DataFrame(...).astype({""date"": ""timestamp[ns][pyarrow]""}).set_index([""id"", ""date""])
idx_val = df.index[0]
new_index = df.index.difference([idx_val])  # Fails to remove idx_val
```
Solution
Code Conversion: Map other values to integer codes compatible with the original index's levels.

Engine Validation: Use the MultiIndex's internal engine for membership checks, ensuring accurate handling of PyArrow types.

Mask-Based Exclusion: Create a boolean mask to filter out matched entries, then reconstruct the index.

Testing
Added a test in pandas/tests/indexes/multi/test_setops.py that:

Creates a MultiIndex with PyArrow timestamps.

Validates difference correctly removes entries.

Skips the test if PyArrow is not installed.

Use Case Impact
Fixes scenarios where users filter hierarchical datasets with PyArrow timestamps, such as:

```python
# Remove specific timestamps from a time-series index
clean_index = raw_index.difference(unwanted_timestamps)
```
Closes #61382.",[],,2025-05-02 12:10:52+00:00,2025-05-20 16:04:41+00:00,,18.162372685185186
61390,"fix MultiIndex.difference not working with PyArrow timestamps (#61382) ,and some ruff formating fix","## Problem
The `MultiIndex.difference` method fails to remove entries when the index contains PyArrow-backed timestamps (`timestamp[ns][pyarrow]`). This occurs because direct tuple comparisons with PyArrow scalar types are unreliable during membership checks, causing entries to remain unexpectedly.

**Example**:
```python
# PyArrow timestamp index
df = DataFrame(...).astype({""date"": ""timestamp[ns][pyarrow]""}).set_index([""id"", ""date""])
idx_val = df.index[0]
new_index = df.index.difference([idx_val])  # Fails to remove idx_val
```
Solution
Code Conversion: Map other values to integer codes compatible with the original index's levels.

Engine Validation: Use the MultiIndex's internal engine for membership checks, ensuring accurate handling of PyArrow types.

Mask-Based Exclusion: Create a boolean mask to filter out matched entries, then reconstruct the index.

Testing
Added a test in pandas/tests/indexes/multi/test_setops.py that:

Creates a MultiIndex with PyArrow timestamps.

Validates difference correctly removes entries.

Skips the test if PyArrow is not installed.

Use Case Impact
Fixes scenarios where users filter hierarchical datasets with PyArrow timestamps, such as:

```python
# Remove specific timestamps from a time-series index
clean_index = raw_index.difference(unwanted_timestamps)
```
Closes #61382.",[],,2025-05-02 11:30:06+00:00,2025-05-02 12:09:22+00:00,,0.02726851851851852
61389,"BUG: Incorrect Parsing of Timestamps in pd.to_datetime with Series with format=""ISO8601""  and UTC=True","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# Single timestamp
raw = ""2023-10-15T14:30:00""
single = pd.to_datetime(raw, utc=True, format=""ISO8601"")
print(single)
# Output: 2023-10-15 14:30:00+00:00 (correct)

# Series of timestamps
series = pd.Series([0, 0], index=[""2023-10-15T10:30:00-12:00"", raw])
converted = pd.to_datetime(series.index, utc=True, format=""ISO8601"")
print(converted)
# Output: 2023-10-16 02:30:00+00:00 for the second one (incorrect)
# error depends on the previous one timezone
```

### Issue Description

When using pd.to_datetime to parse a Series of timestamps with format=""ISO8601"" and utc=True, the parsing of a timestamp without an explicit timezone offset is incorrect and appears to depend on the timezone offset of the previous timestamp in the Series. This behavior does not occur when parsing a single timestamp.

### Expected Behavior

In this configuration, behavior should not depend on the previous timestamp timezone. Result should be the same as when individually passed.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.0
python-bits           : 64
OS                    : Linux
OS-release            : 5.10.0-34-amd64
Version               : #1 SMP Debian 5.10.234-1 (2025-02-24)
machine               : x86_64
processor             :
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 15.0.2
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.40
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
NameError: name 'version' is not defined

</details>","['Bug', 'Datetime', 'Timezones']","{'login': 'myenugula', 'id': 127900888, 'node_id': 'U_kgDOB5-c2A', 'avatar_url': 'https://avatars.githubusercontent.com/u/127900888?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/myenugula', 'html_url': 'https://github.com/myenugula', 'followers_url': 'https://api.github.com/users/myenugula/followers', 'following_url': 'https://api.github.com/users/myenugula/following{/other_user}', 'gists_url': 'https://api.github.com/users/myenugula/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/myenugula/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/myenugula/subscriptions', 'organizations_url': 'https://api.github.com/users/myenugula/orgs', 'repos_url': 'https://api.github.com/users/myenugula/repos', 'events_url': 'https://api.github.com/users/myenugula/events{/privacy}', 'received_events_url': 'https://api.github.com/users/myenugula/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-05-02 11:24:44+00:00,2025-05-06 18:29:20+00:00,myenugula,4.2948611111111115
61388,"fix MultiIndex.difference not working with PyArrow timestamps (#61382) ,and some formating fix ","## Problem
The `MultiIndex.difference` method fails to remove entries when the index contains PyArrow-backed timestamps (`timestamp[ns][pyarrow]`). This occurs because direct tuple comparisons with PyArrow scalar types are unreliable during membership checks, causing entries to remain unexpectedly.

**Example**:
```python
# PyArrow timestamp index
df = DataFrame(...).astype({""date"": ""timestamp[ns][pyarrow]""}).set_index([""id"", ""date""])
idx_val = df.index[0]
new_index = df.index.difference([idx_val])  # Fails to remove idx_val
```
Solution
Code Conversion: Map other values to integer codes compatible with the original index's levels.

Engine Validation: Use the MultiIndex's internal engine for membership checks, ensuring accurate handling of PyArrow types.

Mask-Based Exclusion: Create a boolean mask to filter out matched entries, then reconstruct the index.

Testing
Added a test in pandas/tests/indexes/multi/test_setops.py that:

Creates a MultiIndex with PyArrow timestamps.

Validates difference correctly removes entries.

Skips the test if PyArrow is not installed.

Use Case Impact
Fixes scenarios where users filter hierarchical datasets with PyArrow timestamps, such as:

```python
# Remove specific timestamps from a time-series index
clean_index = raw_index.difference(unwanted_timestamps)
```
Closes #61382.",[],,2025-05-02 11:21:31+00:00,2025-05-02 11:26:59+00:00,,0.0037962962962962963
61384,BLD: Try using shared memory utilities in Cython to reduce wheel sizes,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Build'],,2025-05-01 00:01:38+00:00,2025-05-16 01:14:44+00:00,,15.05076388888889
61383,ENH: Implement pandas.read_iceberg,"- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['IO Data'],,2025-04-30 21:00:23+00:00,2025-05-14 20:29:30+00:00,,13.978553240740741
61379,DOC: Fix dark mode text visibility in Getting Started accordion (#60024),"- [x] closes [#61377](https://github.com/pandas-dev/pandas/issues/61377) (duplicate of [#60024](https://github.com/pandas-dev/pandas/issues/60024))

### üìÑ **Description**

This pull request fixes the issue described in [#61377](https://github.com/pandas-dev/pandas/issues/61377), where the text in the accordion content of the *Getting Started* tutorial section was not visible in dark mode.

Although #61377 is a duplicate, the underlying problem was originally reported in [#60024](https://github.com/pandas-dev/pandas/issues/60024), and later duplicated in [#60041](https://github.com/pandas-dev/pandas/issues/60041) and [#60921](https://github.com/pandas-dev/pandas/issues/60921). This PR addresses the root cause described in those issues.

### ‚úÖ **Changes Made**

Added CSS variables to ensure that text and background colors are consistent with the active theme:

```css
.tutorial-card .card-header {
  --bs-card-cap-color: var(--pst-color-text-base);
  color: var(--pst-color-text-base);
  cursor: pointer;
  background-color: var(--pst-color-surface);
  border: 1px solid var(--pst-color-border);
}

.tutorial-card .card-body {
  background-color: var(--pst-color-on-background);
  color: var(--pst-color-text-base);
}
```
",['Docs'],,2025-04-29 23:01:49+00:00,2025-04-30 16:21:09+00:00,,0.7217592592592592
61378,DOC: update pandas cheat sheet with a third page (fixes #40680),"- [x] closes #40680
- [x] added 3rd page to the cheat sheet including more details on plotting, frequently used options, input/output formats and more.
- [x] added `.info()`, `.memory_usage()`, and `.dtypes()` to 'Summarize Data' on page 2 and rearranged the page to fill the gap left by the old plotting section.
",['Docs'],,2025-04-29 15:47:54+00:00,2025-05-11 17:29:57+00:00,,12.070868055555556
61377,not able to see the content in the dark mode,"<img width=""1470"" alt=""Image"" src=""https://github.com/user-attachments/assets/1f676b75-6720-4a8a-9bc3-103ebe55e205"" />


##issue in styling of the content line when turning on the dark mode.","['Docs', 'Duplicate Report']","{'login': 'danielpintosalazar', 'id': 90653641, 'node_id': 'MDQ6VXNlcjkwNjUzNjQx', 'avatar_url': 'https://avatars.githubusercontent.com/u/90653641?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/danielpintosalazar', 'html_url': 'https://github.com/danielpintosalazar', 'followers_url': 'https://api.github.com/users/danielpintosalazar/followers', 'following_url': 'https://api.github.com/users/danielpintosalazar/following{/other_user}', 'gists_url': 'https://api.github.com/users/danielpintosalazar/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/danielpintosalazar/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/danielpintosalazar/subscriptions', 'organizations_url': 'https://api.github.com/users/danielpintosalazar/orgs', 'repos_url': 'https://api.github.com/users/danielpintosalazar/repos', 'events_url': 'https://api.github.com/users/danielpintosalazar/events{/privacy}', 'received_events_url': 'https://api.github.com/users/danielpintosalazar/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-04-29 14:24:33+00:00,2025-04-30 16:21:58+00:00,danielpintosalazar,1.081539351851852
61376,BUG: Series.dot for arrow and nullable dtypes returns object-dtyped series,"fixes #61375 by porting DataFrame fix (from #54025 as reported in #53979)

- [x] closes #61375 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Numeric Operations', 'Arrow']",,2025-04-29 14:16:14+00:00,2025-04-29 16:20:40+00:00,,0.08641203703703704
61375,BUG: dot on Arrow Series produces a Numpy object result,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

series_result = pd.Series({""a"": 1.0}, dtype=""Float64"").dot(
    pd.DataFrame({""col1"": {""a"": 2.0}, ""col2"": {""a"": 3.0}}, dtype=""Float64"")
)
series_result.dtype  # is dtype('O')

series_result_2 = pd.Series({""a"": 1.0}, dtype=""float[pyarrow]"").dot(
    pd.DataFrame({""col1"": {""a"": 2.0}, ""col2"": {""a"": 3.0}}, dtype=""float[pyarrow]"")
)
series_result_2.dtype  # same, is dtype('O')

# `DataFrame.dot` was already fixed
df_result = pd.DataFrame({""col1"": {""a"": 2.0}, ""col2"": {""a"": 3.0}}, dtype=""Float64"").T.dot(
    pd.Series({""a"": 1.0}, dtype=""Float64"")
)
df_result.dtype  # is Float64Dtype()
```

### Issue Description

`Series.dot` with Arrow or nullable dtypes returns series result with numpy object dtype. This was reported in #53979 and fixed for DataFrames in #54025.

Possibly side notes: I believe the ""real"" issue here is that the implementation uses `.values` which returns a `dtype=object` array for the DataFrame. This seems directly related to #60038 and at least somewhat related to #60301 (which is also referenced in a comment on the former).

### Expected Behavior

I would expect `Series.dot` to return the ""best"" common datatype for the input datatypes (in the examples, would expect the appropriate float dtype)

```python
import pandas as pd

series_result = pd.Series({""a"": 1.0}, dtype=""Float64"").dot(
    pd.DataFrame({""col1"": {""a"": 2.0}, ""col2"": {""a"": 3.0}}, dtype=""Float64"")
)
series_result.dtype  # would expect Float64Dtype()

series_result_2 = pd.Series({""a"": 1.0}, dtype=""float[pyarrow]"").dot(
    pd.DataFrame({""col1"": {""a"": 2.0}, ""col2"": {""a"": 3.0}}, dtype=""float[pyarrow]"")
)
series_result_2.dtype  # would expect float[pyarrow]
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.12
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 85 Stepping 7, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.2.5
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.1
Cython                : None
sphinx                : 8.2.3
IPython               : 9.2.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.2
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : 0.61.2
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.40
tables                : 3.10.2
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-04-29 14:11:39+00:00,2025-04-29 16:20:41+00:00,,0.08960648148148148
61374,Percentile Scaling Data Transformation,"This pull request adds a new data transformation utility called `percentile_scaling` to the `pandas/io/` module, which scales numerical data to a percentile-based range from 0 to 100. This transformation is useful for standardizing features in data preprocessing workflows, especially for ML pipelines or percentile-based visual analytics.

Implementation Details

- Introduced a new function `percentile_scaling(data: List[float]) -> List[float]` that:
  - Accepts a list or NumPy array of numerical values.
  - Returns values scaled to a [0, 100] percentile scale.
  - Raises appropriate errors for invalid input (e.g., zero variance or empty input).

Tests

- Added unit tests in `pandas/tests/io/test_percentile_scaling.py`:
  - Validates correct scaling behavior.
  - Handles edge cases such as identical values and empty inputs.
  - All tests pass successfully using `unittest`.

Compliance

- [x] Follows Pandas contribution guidelines
- [x] All tests pass successfully
- [x] Function is self-contained and does not introduce dependencies
- [x] Code is PEP8-compliant and cleanly documented

Notes

This contribution is part of a university-level data engineering course project (DATA 226). The goal is to implement practical transformation logic for real-world data pipeline use cases while following standard open-source contribution workflows.


- [x] Tests added and passed
- [x] Code passes style checks and pre-commit hooks
",[],,2025-04-29 11:23:42+00:00,2025-04-29 16:23:41+00:00,,0.20832175925925925
61373,this is testing only,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-29 10:35:03+00:00,2025-04-29 16:21:29+00:00,,0.2405787037037037
61372,Fix pyarrow comparison issue in array.py,"- [x] closes #60937 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-28 21:41:17+00:00,2025-05-19 16:17:13+00:00,,20.774953703703705
61371,CI: Use Cython nightlies for Windows wheel builds again,Validated that the wheel tests should pass now from https://github.com/pandas-dev/pandas/pull/61354,['Build'],,2025-04-28 17:05:20+00:00,2025-04-28 18:17:50+00:00,,0.050347222222222224
61369,Bump pypa/cibuildwheel from 2.23.2 to 2.23.3,"Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 2.23.2 to 2.23.3.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/releases"">pypa/cibuildwheel's releases</a>.</em></p>
<blockquote>
<h2>v2.23.3</h2>
<ul>
<li>üõ† Dependency updates, including Python 3.13.3 (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2371"">#2371</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/blob/main/docs/changelog.md"">pypa/cibuildwheel's changelog</a>.</em></p>
<blockquote>
<h3>v2.23.3</h3>
<p><em>26 April 2025</em></p>
<ul>
<li>üõ† Dependency updates, including Python 3.13.3 (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2371"">#2371</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/faf86a6ed7efa889faf6996aa23820831055001a""><code>faf86a6</code></a> Bump version: v2.23.3</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/4241f37b2c5be7f7ed96214b83f8cfbe1496cc28""><code>4241f37</code></a> [2.x] Update dependencies (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2371"">#2371</a>)</li>
<li>See full diff in <a href=""https://github.com/pypa/cibuildwheel/compare/v2.23.2...v2.23.3"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/cibuildwheel&package-manager=github_actions&previous-version=2.23.2&new-version=2.23.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","['Build', 'CI', 'Dependencies']",,2025-04-28 10:35:52+00:00,2025-04-28 17:41:35+00:00,,0.29563657407407407
61367,DOC: Add missing period in sample docstring,"- Minor documentation fix.
- Adds a missing period at the end of the ""random_state"" description in the `sample` function docstring.
- No functional changes.

- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
",['Docs'],,2025-04-27 20:25:31+00:00,2025-04-28 16:45:43+00:00,,0.8473611111111111
61366,[minor edit] edit definitions of some parameters with correct idiomatic English for better legibility,"<!--
- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
//-->",['Docs'],,2025-04-27 17:32:54+00:00,2025-04-28 16:39:26+00:00,,0.9628703703703704
61364,BUG: groupby.groups with NA categories fails,"- [x] closes #61356 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

There is a slight code duplication here, but we don't need to rely on Cateorical's codes because we can just directly use groupby's. We also can't use `groupby` to implement `Index.groupby` because the former only works in the case where the `values` are exhaustive.","['Bug', 'Groupby', 'Missing-data', 'Categorical']",,2025-04-27 14:19:18+00:00,2025-04-28 16:47:10+00:00,,1.102685185185185
61363,DOC: Added constructor parameters to DateOffset docstring for API consistency #52431," - Added the constructor signature for DateOffset.
 - No functional changes were made, only documentation improvements.
 - Part of the issue #52431 is addressed by this.",[],,2025-04-27 02:11:58+00:00,2025-05-03 13:24:42+00:00,,6.467175925925926
61362,QST: best way to extend/subclass pandas.DataFrame,"### Research

- [x] I have searched the [[pandas] tag](https://stackoverflow.com/questions/tagged/pandas) on StackOverflow for similar questions.

- [x] I have asked my usage related question on [StackOverflow](https://stackoverflow.com).


### Link to question on StackOverflow

https://stackoverflow.com/questions/79594258/best-way-to-extend-subclass-pandas-dataframe

### Question about pandas

I've written a [package](https://www.github.com/rwijtvliet/portfolyo) to work with energy-related timeseries. At its center is a class ([`PfLine`](https://portfolyo.readthedocs.io/en/latest/core/pfline.html)) that is essentially a wrapper around pandas.DataFrame, and it implements various methods and properties that are also available on DataFrames - like `.loc`, `.asfreq()`, `.index`, etc.

I am currently in the middle of a rewrite of this package, and think it would be a good idea to have closer integration with pandas. [This page](https://pandas.pydata.org/docs/development/extending.html) lays out several possibilities, and I am unsure which route to take - and was hoping to find some sparring here.

Let me describe a bit what I'm trying to accomplish with the `PfLine` class:

  * Behaves like a DataFrame, with specific column names allowed and some data conversion (and validation) on initialisation.

  * Is immutable to avoid data from becoming inconsistent.

  * Has additional methods.

The methods could be directly under `PfLine.method()` or under e.g. `df.pfl.method()`.

What is probably important: a way is needed for the user to specify a (still under development) configuration object (`commodity`) when initialising the PfLine. This object contains information used in coercing the data, e.g. what are the correct units and which timezones are allowed for the index.","['Usage Question', 'Closing Candidate']",,2025-04-26 22:17:25+00:00,2025-08-05 03:04:18+00:00,,100.19922453703704
61361,REGR: Fix signature of GroupBy.expanding,"Ref: https://github.com/pandas-dev/pandas/pull/61352#discussion_r2060726723

#61352 replaced `*args` and `**kwargs` in the signature of `GroupBy.expanding`. However I believe further arguments need to be added. We could also revert the PR instead.","['Bug', 'Groupby', 'Regression', 'Blocker', 'Window']",,2025-04-26 17:38:41+00:00,2025-04-27 11:29:29+00:00,,0.7436111111111111
61360,ENH: magic_case(),"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

we basically come up issue about not knowing the case of the column, we can print and view it but to make life little more easier I got magic_case created.

we have to pass the DataFrame and the column name we know (ignoring case) and we can have this assigned to a variable
mc=magic_case(df_2,'jack')
print(mc) # JaCK
and if there are multiple names with difference in case then it throws a value error with list of names
# ValueError: Multiple columns with the same name but different cases found: ['JaCK', 'JACk']


### Feature Description

def magic_case(df, column_name, new_name=None, inplace=False):
    """"""
    Find the exact case-sensitive column name in a DataFrame and optionally rename it.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        The DataFrame to search in
    column_name : str
        The case-insensitive column name to search for
    new_name : str, optional
        If provided, the column will be renamed to this value
    inplace : bool, default False
        If True and new_name is provided, modifies the DataFrame in-place and returns None.
        If False and new_name is provided, returns a copy of the DataFrame with renamed column.
        If new_name is None, this parameter has no effect.
    
    Returns:
    --------
    str or pandas.DataFrame or None
        - If new_name is None: returns the exact case-sensitive column name
        - If new_name is provided and inplace=False: returns the DataFrame with renamed column
        - If new_name is provided and inplace=True: returns None
    
    Raises:
    -------
    ValueError
        If no matching column is found or if multiple matches are found
    """"""
    # Check if the dataframe is empty or has no columns
    if df.empty or len(df.columns) == 0:
        raise ValueError(""DataFrame is empty or has no columns"")
        
    # Strip whitespace from column names for comparison
    clean_columns = {col.lower().strip(): col for col in df.columns}
    
    # Clean and lowercase the search term
    search_term = column_name.lower().strip()
    
    # Check if the lowercase version of the input exists
    if search_term not in clean_columns:
        matches = []
        # Check for partial matches (e.g., ""jack"" might match ""jackson"")
        for col_lower, col_original in clean_columns.items():
            if search_term in col_lower or col_lower in search_term:
                matches.append(col_original)
        
        if matches:
            original_column_name = matches[0]  # Get the first partial match
        else:
            raise ValueError(f""No column matching '{column_name}' was found in the DataFrame"")
    else:
        # Check for multiple exact matches with the same spelling but different cases
        exact_matches = [col for col in df.columns if col.lower().strip() == search_term]
        if len(exact_matches) > 1:
            raise ValueError(f""Multiple columns with the same name but different cases found: {exact_matches}"")
        
        # Get the exact case-sensitive column name
        original_column_name = clean_columns[search_term]
    
    # If new_name is not provided, just return the original column name
    if new_name is None:
        return original_column_name
    
    # If new_name is provided, rename the column
    if inplace:
        df.rename(columns={original_column_name: new_name}, inplace=True)
        return None
    else:
        return df.rename(columns={original_column_name: new_name})

### Alternative Solutions

# nothing

### Additional Context

if you had anything to say - please drop mail to akvamsikrishna@outlook.com with sub: magic_case() üòÖ just to identify easily and prioritize your response over others.","['Enhancement', 'Indexing', 'Closing Candidate']",,2025-04-26 07:05:56+00:00,2025-04-26 18:11:39+00:00,,0.46230324074074075
61359,BUG: Raise ValueError for non-string columns in read_json orient='table' (GH19129),"- Closes #19129
- Adds validation to ensure all column names are strings when using orient='table' in read_json
- Raises a clear ValueError if invalid column names are found
- Adds a new unit test to pandas/tests/io/json/test_json_table_schema.py to cover the invalid input case
- Ran pytest and pre-commit hooks successfully

Looking forward to feedback. Thanks!","['Error Reporting', 'IO JSON', 'Stale']",,2025-04-26 01:10:10+00:00,2025-06-02 16:59:22+00:00,,37.659166666666664
61358,Improve documentation for MonthEnd and YearBegin offsets,"This pull request improves the documentation for two commonly used offset constructors in Pandas: MonthEnd and YearBegin.

Changes include:

Clarified the purpose and behavior of each offset class

Added runnable examples (doctest-compliant) to demonstrate usage

Improved parameter descriptions where necessary

These changes aim to make the documentation more accessible and clear for both new and experienced users of Pandas‚Äô time series functionality.
",[],,2025-04-26 00:37:39+00:00,2025-05-03 13:20:15+00:00,,7.529583333333333
61356,BUG: `DataFrameGroupBy.groups` fails when Categorical indexer contains NaNs and `dropna=False`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
>>> df = DataFrame(
...         {
...             ""cat"": Categorical([""a"", np.nan, ""a""], categories=[""a"", ""b"", ""d""]),
...             ""vals"": [1, 2, 3],
...         }
...     )
>>> g = df.groupby(""cat"", observed=True, dropna=False)
>>> result = g.groups
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/workspaces/pandas/pandas/core/groupby/groupby.py"", line 569, in groups
    return self._grouper.groups
  File ""properties.pyx"", line 36, in pandas._libs.properties.CachedProperty.__get__
  File ""/workspaces/pandas/pandas/core/groupby/ops.py"", line 710, in groups
    return self.groupings[0].groups
  File ""properties.pyx"", line 36, in pandas._libs.properties.CachedProperty.__get__
  File ""/workspaces/pandas/pandas/core/groupby/grouper.py"", line 711, in groups
    return codes, uniques
  File ""/workspaces/pandas/pandas/core/arrays/categorical.py"", line 745, in from_codes
    dtype = CategoricalDtype._from_values_or_dtype(
  File ""/workspaces/pandas/pandas/core/dtypes/dtypes.py"", line 347, in _from_values_or_dtype
    dtype = CategoricalDtype(categories, ordered)
  File ""/workspaces/pandas/pandas/core/dtypes/dtypes.py"", line 230, in __init__
    self._finalize(categories, ordered, fastpath=False)
  File ""/workspaces/pandas/pandas/core/dtypes/dtypes.py"", line 387, in _finalize
    categories = self.validate_categories(categories, fastpath=fastpath)
  File ""/workspaces/pandas/pandas/core/dtypes/dtypes.py"", line 585, in validate_categories
    raise ValueError(""Categorical categories cannot be null"")
ValueError: Categorical categories cannot be null
>>>
```

### Issue Description

When using `df.groupby(cat, dropna=False).groups`, we encounter a `ValueError`. This is counter-intuitive, as grouping operations work without an issue.

```python
>>> df = DataFrame(
...         {
...             ""cat"": Categorical([""a"", np.nan, ""a""], categories=[""a"", ""b"", ""d""]),
...             ""vals"": [1, 2, 3],
...         }
...     )
>>> g = df.groupby(""cat"", observed=True, dropna=False)
>>> g.sum()
     vals
cat      
a       4
NaN     2
>>> g.sum().index
CategoricalIndex(['a', nan], categories=['a', 'b', 'd'], ordered=False, dtype='category', name='cat')
```


### Expected Behavior

`.groups` should return a dictionary which includes the NaN as the last entry.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 41131a14324ababc5c81f194de3d9a239d120f27
python                : 3.10.8
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+2085.g41131a1432
numpy                 : 2.2.5
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 8.35.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2025.3.2
html5lib              : 1.1
hypothesis            : 6.131.8
gcsfs                 : 2025.3.2
jinja2                : 3.1.6
lxml.etree            : 5.4.0
matplotlib            : 3.10.1
numba                 : 0.61.2
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 19.0.1
pyreadstat            : 1.2.8
pytest                : 8.3.5
python-calamine       : None
pytz                  : 2025.2
pyxlsb                : 1.0.10
s3fs                  : 2025.3.2
scipy                 : 1.15.2
sqlalchemy            : 2.0.40
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.3
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Groupby', 'Missing-data', 'Categorical']",,2025-04-25 20:46:45+00:00,2025-04-28 16:47:11+00:00,,2.8336342592592594
61355,"DOC: Removed self-reference to `DataFrame.resample` in the ""See also"" section.","- [ ] ~closes #xxxx (Replace xxxx with the GitHub issue number)~
- [ ] ~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
",[],,2025-04-25 18:51:16+00:00,2025-04-25 18:54:56+00:00,,0.0025462962962962965
61354,Test Cython divmod fix for Windows,"https://github.com/cython/cython/pull/6801 should fix the issues we were seeing in https://github.com/pandas-dev/pandas/pull/61261, but this commit is not apart of the Cython nightly wheels yet.",['Build'],,2025-04-25 16:50:01+00:00,2025-04-25 17:16:32+00:00,,0.018414351851851852
61352,DOC: Updated `groupby.expanding` arguments,"- [ ] ~closes #xxxx (Replace xxxx with the GitHub issue number)~
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
",['Window'],,2025-04-25 00:46:30+00:00,2025-04-25 16:34:50+00:00,,0.6585648148148148
61351,Add warning to `.groupby` when null keys would be dropped due to default `dropna`,"- [X] closes #61339
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

TODO:

- [X] Check performance for `codes` check approaches (`codes.min()` was about 3x faster)
- [ ] Run full test suite to ensure nothing broke
- [ ] Add tests/implementation for `.pivot_table`/`.stack`/etc. (possibly in a follow-up PR?)",['Stale'],,2025-04-24 21:01:55+00:00,2025-05-27 16:18:07+00:00,,32.80291666666667
61350,ENH: th elements from Styler need the row scope,"### Feature Type

- [ ] Adding new functionality to pandas

- [x] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Currently, the pandas [Styler](https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.html) API can be used to create a HTML table from a dataframe. However, the tables it generates are not accessible: it fails [WCAG/H63](https://www.w3.org/WAI/WCAG21/Techniques/html/H63).

### Feature Description

Ensure the output generated by Styler is accessible.

- `th` with class `row_heading` needs the `row` scope

I use the current workaround to add this rule myself:

```
    html_root = lxml.html.fromstring(frame_style.to_html())
    for th in html_root.xpath(""//th[contains(@class, 'row_heading')]""):
        th.set(""scope"", ""row"")
```

### Alternative Solutions

- Make the styler API more flexible for adding attributes. Currently, [set_td_classes](https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_td_classes.html#pandas.io.formats.style.Styler.set_td_classes) and [set_table_styles](https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_styles.html#pandas.io.formats.style.Styler.set_table_styles) aren't flexible enough for this, and [set_table_attributes](https://pandas.pydata.org/docs/reference/api/pandas.io.formats.style.Styler.set_table_attributes.html#pandas.io.formats.style.Styler.set_table_attributes) can't set attributes on `th` elements themselves.


### Additional Context

_No response_","['Enhancement', 'Needs Triage']",,2025-04-24 18:23:37+00:00,2025-04-24 19:03:21+00:00,,0.027592592592592592
61349,TST: Testing for mixed int/str Index,"- [x] closes #54072 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Testing', 'Index']",,2025-04-24 15:48:53+00:00,2025-06-30 18:20:46+00:00,,67.10547453703704
61348,Mixed int string ,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-24 15:25:38+00:00,2025-05-03 13:16:39+00:00,,8.91042824074074
61346,BUG: assignment via loc silently fails with differing dtypes,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
print(pd.__version__)
df = pd.DataFrame({'foo': ['2025-04-23', '2025-04-22']})
df['bar'] = pd.to_datetime(df['foo'], format='%Y-%m-%d')
df.loc[:, 'bar'] = df.loc[:, 'bar'].dt.strftime('%Y%m%d')
print(df)

# Yields
# 2.2.3
#           foo        bar
# 0  2025-04-23 2025-04-23
# 1  2025-04-22 2025-04-22
```

### Issue Description

I expect `bar` to look like 
```
20250423
20250422
```
instead of 
```
2025-04-23
2025-04-22
```


### Expected Behavior

`bar` should look like

```
20250423
20250422
```

### Installed Versions

<details>

```
[ins] In [2]: pd.show_versions()

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.10
python-bits           : 64
OS                    : Linux
OS-release            : 4.18.0-372.32.1.el8_6.x86_64
Version               : #1 SMP Fri Oct 7 12:35:10 EDT 2022
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : None
IPython               : 8.35.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.9.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.2
matplotlib            : 3.10.1
numba                 : 0.61.2
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 15.0.2
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.39
tables                : 3.9.2
tabulate              : 0.9.0
xarray                : 2025.3.1
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
```

</details>
","['Bug', 'Dtype Conversions', 'Closing Candidate']",,2025-04-23 18:48:39+00:00,2025-04-26 12:21:38+00:00,,2.731238425925926
61345,Update groupby().first() documentation to clarify behavior with missing data (#27578),"This PR enhances the docstring for `GroupBy.first()` to clarify:
- It returns the first *non-null* value per column
- It differs from `.nth(0)` and `.head(1)` in how it treats missing values
- Includes comparative examples for better understanding

Fixes part of issue #27578

Ready for review.","['Docs', 'Groupby']",,2025-04-23 18:39:31+00:00,2025-05-19 16:16:47+00:00,,25.900879629629628
61344,BUG: Series of bools with length mismatch does not raise when used with `.iloc`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np

s = pd.Series([1, 2, 3])

mask_series = pd.Series([True, False, True, True])
result = s[mask_series]

print(result)
# Output:
# 0    1
# 2    3
# dtype: int64

mask_array = np.array([True, False, True, True])
print(s[mask_array])
# IndexError: Boolean index has wrong length: 4 instead of 3
```

### Issue Description

When using `.iloc` with a boolean Series mask whose length exceeds the target, pandas does not raise an error. This is inconsistent with numpy bool indexing, which raises an IndexError.



### Expected Behavior

`.iloc` should raise if the boolean Series mask length doesn‚Äôt match the target Series length.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 25e57c34158158de2cd5d2c0843f3e5babbeb3e5
python                : 3.12.9
python-bits           : 64
OS                    : Darwin
OS-release            : 24.0.0
Version               : Darwin Kernel Version 24.0.0: Mon Aug 12 20:49:48 PDT 2024; root:xnu-11215.1.10~2/RELEASE_ARM64_T8103
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+2080.g25e57c3415
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 9.0.2
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2025.3.0
html5lib              : 1.1
hypothesis            : 6.130.4
gcsfs                 : 2025.3.0
jinja2                : 3.1.6
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.6
pymysql               : 1.4.6
pyarrow               : 19.0.1
pyreadstat            : 1.2.8
pytest                : 8.3.5
python-calamine       : None
pytz                  : 2025.2
pyxlsb                : 1.0.10
s3fs                  : 2025.3.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.10
tables                : 3.10.2
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Indexing']",,2025-04-23 18:24:12+00:00,2025-04-24 20:20:13+00:00,,1.0805671296296295
61343,Fix #61072: inconsistent fullmatch results with regex alternation,"in PyArrow strings
Fixes an issue where regex patterns with alternation (|) produce different results between str dtype and string[pyarrow] dtype. When using patterns like ""(as)|(as)"", PyArrow implementation would incorrectly match ""asdf"" while Python's implementation correctly rejects it. The fix adds special handling to ensure alternation patterns are properly parenthesized when using PyArrow-backed strings

- [ ] closes #61072  ","['Bug', 'Strings']",,2025-04-23 11:33:57+00:00,2025-06-30 18:29:34+00:00,,68.28862268518519
61342,BUG: Concatenating data frames with `MultiIndex` with `datetime64[ms]` dtype introduces `NaT` values to the index,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

def resample_each_item(dtype) -> pd.DataFrame:
    df = pd.DataFrame(
        [
            [""A"", ""2023-01-15"", 42],
            [""A"", ""2023-01-17"", 33],
            [""B"", ""2023-02-20"", 78],
            [""B"", ""2023-02-23"", 91],
        ],
        columns=[""item_id"", ""timestamp"", ""target""],
    )
    df[""timestamp""] = pd.to_datetime(df[""timestamp""]).astype(dtype)
    df = df.set_index([""item_id"", ""timestamp""])
    resampled = []
    for item_id in [""A"", ""B""]:
        resampled.append(pd.concat({item_id: df.loc[item_id].resample(""D"", level=""timestamp"").mean()}))
    return pd.concat(resampled)

print(resample_each_item(""datetime64[ns]""))
# For datetime64[ns] all timestamps are valid
#               target
#   timestamp         
# A 2023-01-15    42.0
#   2023-01-16     NaN
#   2023-01-17    33.0
# B 2023-02-20    78.0
#   2023-02-21     NaN
#   2023-02-22     NaN
#   2023-02-23    91.0

print(resample_each_item(""datetime64[ms]""))
# For datetime64[ms] or datetime64[s] dtypes, NaT values are introduced
#               target
#   timestamp         
# A 2023-01-15    42.0
#   NaT            NaN
#   NaT           33.0
# B 2023-02-20    78.0
#   NaT            NaN
#   NaT            NaN
#   NaT           91.0
```

### Issue Description

When concatenating data frames with `MultiIndex`, where one level is of type `datetime64[ms]` or `datetime64[s]`, some timestamps are replaced with `NaT`. If the timestamps are of dtype `datetime64[ns]`, no `NaT` values are introduced.

### Expected Behavior

No `NaT` values are introduced, regardless of whether the timestamp dtype is `datetime64[ms]`, `datetime64[s]` or `datetime64[ns]`.

### Installed Versions

<details>

```
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.9
python-bits           : 64
OS                    : Linux
OS-release            : 6.1.132-147.221.amzn2023.x86_64
Version               : #1 SMP PREEMPT_DYNAMIC Tue Apr  8 13:14:54 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.12.3
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.12.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : 0.61.2
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.40
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
```

</details>
","['Bug', 'Datetime', 'MultiIndex']",,2025-04-23 09:29:06+00:00,2025-04-24 20:18:43+00:00,,1.4511226851851853
61341,"DOC Update link to ""The Grammar of Graphics"" book","Update link to ""The Grammar of Graphics"" book.
https://doi.org/10.1007/0-387-28695-0

Original link does not work:
https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/GOG.html

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-04-23 01:32:17+00:00,2025-04-23 01:47:42+00:00,,0.01070601851851852
61340,BUG: Fixed issue with bar plots not stacking correctly when 'stacked' and 'subplots' are used together,"- [x] closes #61018
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Added check for when stacked and subplots are used in conjunction for bar plots. And logic dictating offsets for individual subplots to account for plots with non-concurrent columns being graphed. 

Currently, does not take into account column order in subplot entry (eg: (A, B) vs (B, A)) when stacking",['Visualization'],,2025-04-23 00:58:23+00:00,2025-04-28 20:10:28+00:00,,5.80005787037037
61338,BUG: Period datatype data gets mangled up in pivoting operation,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df = pd.DataFrame({
    ""id1"": [1, 2], 
    ""id2"": [10, 20], 
    ""id3"": [100, 200], 
    ""period"":[pd.Period(""2021-01""), pd.Period(""2021-03"")]
}).set_index(['id1','id2'])
result = df.unstack().stack(future_stack=True)

#fails - unexpected
assert (result.loc[df.index]==df).all().all()
```

### Issue Description

The data in the ""period"" column gets mangled up, the value associated with the first record shows up twice and the value of the second record disappears. 
The problem appears with both `future_stack=True` and `future_stack=False`.
The problem does not appear when stacking ""period"" series, only when stacking dataframe (so following unstack(), the columns are a mutliindex).

### Expected Behavior

It is expected that `df.unstack().stack()` would return the original records unchanged.
Changing period dtype to 'str' behaves as expected:
```python
import pandas as pd
df = pd.DataFrame({
    ""id1"": [1, 2], 
    ""id2"": [10, 20], 
    ""id3"": [100, 200], 
    ""period"":[pd.Period(""2021-01""), pd.Period(""2021-03"")]
}).set_index(['id1','id2'])

#succeeds - expected
df2 = df.astype({""period"": ""str""})
result = df2.unstack().stack(future_stack=True)
assert (result.loc[df2.index]==df2).all().all()
```


### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.11
python-bits           : 64
OS                    : Linux
OS-release            : 5.10.226-214.880.amzn2.x86_64
Version               : #1 SMP Tue Oct 8 16:18:15 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : en_US.UTF-8
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 9.0.2
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.3.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.39
tables                : None
tabulate              : 0.9.0
xarray                : 2025.1.2
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-04-22 14:49:35+00:00,2025-04-22 16:01:08+00:00,,0.0496875
61336,ENH: IDEA  Introduce axis‚Üí0/axis‚Üí1 arrow aliases to disambiguate direction vs. label operations,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

<ENG>
The `axis` parameter currently serves two distinct purposes:

1. *Along‚Äëaxis* operations that reduce or transform values (e.g. `apply`, `sum`)
2. *Label‚Äëtargeting* operations that modify or drop index / column labels (e.g. `drop`, `rename`)

Because both use the same syntax (`axis=0` or `axis=1`), many users mis‚Äëinterpret which dimension is affected.

<ÌïúÍµ≠Ïñ¥>
ÌòÑÏû¨ axis Îß§Í∞úÎ≥ÄÏàòÎäî ÏÑúÎ°ú Îã§Î•∏ Îëê Í∞ÄÏßÄ Î™©Ï†ÅÏúºÎ°ú ÏÇ¨Ïö©ÎêòÍ≥† ÏûàÏäµÎãàÎã§:
Í∞íÏùÑ Ï∂ïÏÜåÌïòÍ±∞ÎÇò Î≥ÄÌôòÌïòÎäî Ï∂ï Î∞©Ìñ• Ïó∞ÏÇ∞ (Ïòà: apply, sum)
Ïù∏Îç±Ïä§/Ïó¥ Î†àÏù¥Î∏îÏùÑ ÏàòÏ†ïÌïòÍ±∞ÎÇò ÏÇ≠Ï†úÌïòÎäî Î†àÏù¥Î∏î ÎåÄÏÉÅ Ïó∞ÏÇ∞ (Ïòà: drop, rename)
Îëê Í≤ΩÏö∞ Î™®Îëê ÎèôÏùºÌïú Íµ¨Î¨∏(axis=0 ÎòêÎäî axis=1)ÏùÑ ÏÇ¨Ïö©ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê ÎßéÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä Ïñ¥Îñ§ Ï∞®ÏõêÏù¥ ÏòÅÌñ•ÏùÑ Î∞õÎäîÏßÄ ÌòºÎèôÌï©ÎãàÎã§.

### Feature Description

<ENG>
Proposed API
Keep existing syntax and add an **arrow alias** that makes the ‚Äúdirection‚Äù explicit:

| Syntax | Meaning |
|--------|---------|
| `axis=0`¬†*(unchanged)* | target **index labels** (delete / rename) |
| `axis=1`¬†*(unchanged)* | target **column labels** |
| `axis‚Üí0`¬†*(new)* | operate **along index** ‚Äì treat each **column vector** |
| `axis‚Üí1`¬†*(new)* | operate **along columns** ‚Äì treat each **row vector** |

Arrow aliases are optional; existing code keeps working unchanged.

<ÌïúÍµ≠Ïñ¥>

Ï†úÏïàÎêú API
Í∏∞Ï°¥ Íµ¨Î¨∏ÏùÑ Ïú†ÏßÄÌïòÎ©¥ÏÑú ""Î∞©Ìñ•""ÏùÑ Î™ÖÌôïÌûà ÎÇòÌÉÄÎÇ¥Îäî ÌôîÏÇ¥Ìëú Î≥ÑÏπ≠ÏùÑ Ï∂îÍ∞ÄÌï©ÎãàÎã§

| Syntax | Meaning |
|--------|---------|
| `axis=0`¬†*(Î≥ÄÍ≤ΩÏóÜÏùå)* | Ïù∏Îç±Ïä§ Î†àÏù¥Î∏î ÎåÄÏÉÅ (ÏÇ≠Ï†ú / Ïù¥Î¶Ñ Î≥ÄÍ≤Ω) |
| `axis=1`¬†*(Î≥ÄÍ≤ΩÏóÜÏùå)* | Ïó¥ Î†àÏù¥Î∏î ÎåÄÏÉÅ |
| `axis‚Üí0`¬†*(Ïã†Í∑ú)* | Ïù∏Îç±Ïä§ Î∞©Ìñ•ÏúºÎ°ú Ïó∞ÏÇ∞ ‚Äì Í∞Å Ïó¥ Î≤°ÌÑ∞ Ï≤òÎ¶¨ |
| `axis‚Üí1`¬†*(Ïã†Í∑ú)* | Ïó¥ Î∞©Ìñ•ÏúºÎ°ú Ïó∞ÏÇ∞ ‚Äì Í∞Å Ìñâ Î≤°ÌÑ∞ Ï≤òÎ¶¨ |

ÌôîÏÇ¥Ìëú Î≥ÑÏπ≠ÏùÄ ÏÑ†ÌÉù ÏÇ¨Ìï≠Ïù¥Î©∞, Í∏∞Ï°¥ ÏΩîÎìúÎäî Î≥ÄÍ≤Ω ÏóÜÏù¥ Í≥ÑÏÜç ÏûëÎèôÌï©ÎãàÎã§.



### Alternative Solutions

<ENG>

| Alias idea | Interpretation |
|------------|----------------|
| **`axis‚Üí0`** | operate **along index** (column‚Äëwise) |
| **`axis‚Üí1`** | operate **along columns** (row‚Äëwise) |

**Benefits**
* Greatly reduces beginner confusion around `axis`.
* Preserves full NumPy compatibility.
* Requires minimal code changes (add alias mapping in `axis_aliases`).
* 
<ÌïúÍµ≠Ïñ¥>

| Î≥ÑÏπ≠ ÏïÑÏù¥ÎîîÏñ¥ | Ìï¥ÏÑù|
|------------|----------------|
| **`axis‚Üí0`** | Ïù∏Îç±Ïä§ Î∞©Ìñ•ÏúºÎ°ú Ïó∞ÏÇ∞ (Ïó¥ Îã®ÏúÑ) |
| **`axis‚Üí1`** | Ïó¥ Î∞©Ìñ•ÏúºÎ°ú Ïó∞ÏÇ∞ (Ìñâ Îã®ÏúÑ) |

Ïû•Ï†ê
axisÏóê ÎåÄÌïú Ï¥àÎ≥¥ÏûêÏùò ÌòºÎûÄÏùÑ ÌÅ¨Í≤å Ï§ÑÏûÖÎãàÎã§.
NumPy Ìò∏ÌôòÏÑ±ÏùÑ ÏôÑÏ†ÑÌûà Ïú†ÏßÄÌï©ÎãàÎã§.
ÏµúÏÜåÌïúÏùò ÏΩîÎìú Î≥ÄÍ≤ΩÎßå ÌïÑÏöîÌï©ÎãàÎã§ (axis_aliasesÏóê Î≥ÑÏπ≠ Îß§Ìïë Ï∂îÍ∞Ä).

### Additional Context

See repeated questions on Stack¬†Overflow:<br>
<https://stackoverflow.com/q/26716616>.","['Enhancement', 'Needs Discussion', 'Closing Candidate']",,2025-04-22 07:31:10+00:00,2025-04-23 16:19:48+00:00,,1.3671064814814815
61335,ENH/TST: unset_index method #60869,"- [x] closes #60869 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-22 02:34:40+00:00,2025-04-22 15:59:38+00:00,,0.5590046296296296
61334,DOC: Updated `groupby.ewm` arguments,"- [ ] ~closes #xxxx (Replace xxxx with the GitHub issue number)~
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~


","['Groupby', 'Window']",,2025-04-21 23:35:26+00:00,2025-04-22 15:56:52+00:00,,0.6815509259259259
61333,CI: Have dedicated Python 3.13 job instead of using Python dev,"We've been testing Python 3.13 using the `Python dev` job. Since Python 3.13 has been available since last October, we should be able to test this version with a dedicated job with all of our optional dependencies. 

Additionally, this new job caught an unclosed `sqlite3` engine, so modified some `test_sql.py` tests (and removed unnecessary parametrizations)","['CI', 'Python 3.13']",,2025-04-21 21:58:26+00:00,2025-04-30 16:09:41+00:00,,8.7578125
61332,CLN: Use newer numpy random Generator methods in plotting colors,"Noticed in https://github.com/pandas-dev/pandas/pull/61330, replace a numpy legacy random method with a newer random Generator method (in addition to a cleanup)","['Visualization', 'Clean']",,2025-04-21 21:45:31+00:00,2025-04-30 16:08:48+00:00,,8.766168981481481
61331,DEPS: Clean unused dependencies,"* When installing pytables, it appears `blosc2` is generally a dependency now https://github.com/PyTables/PyTables/blob/9afcc380d93192460e7badd1baf568592cadad26/pyproject.toml#L78
* I don't think we use `google-auth` or `gitdb` anywhere now","['Build', 'Dependencies']",,2025-04-21 17:49:35+00:00,2025-05-08 16:24:26+00:00,,16.940868055555555
61330,TYP: Remove unused mypy ignores,Failing on main. Maybe unneeded due to a numpy update.,['Typing'],,2025-04-21 17:15:37+00:00,2025-04-21 20:47:12+00:00,,0.14693287037037037
61329,Remove WillAyd from CODEOWNERS,"This was well intentioned but I do not follow every change to _libs, and this ends up creating more notifications than I follow",['Admin'],,2025-04-21 14:48:02+00:00,2025-04-21 15:45:50+00:00,,0.04013888888888889
61327, ENH/TST: grep-like select columns of a DataFrame by a part of their names (fixes #61319),"- [ ] closes #61319(Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-21 14:13:39+00:00,2025-04-21 14:50:04+00:00,,0.02528935185185185
61326,ENH/TST: grep-like select columns of a DataFrame by a part of their names (fixes #61319) ,"- [ ] closes #61319 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-21 13:26:21+00:00,2025-04-21 13:29:53+00:00,,0.0024537037037037036
61325,add test case for mixed string and int,"- [ ] closes #54072 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-21 13:26:08+00:00,2025-05-09 16:08:27+00:00,,18.112719907407406
61324,ENH/TST: grep-like select columns of a DataFrame by a part of their names (fixes #61319),"- [x] closes #61319(Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-21 13:18:23+00:00,2025-04-21 13:24:23+00:00,,0.004166666666666667
61321,Fix: AttributeError when using .iloc with pyarrow-backed Series in Pandas #61311,"fix : #61311
### Solution:
The problem arises when the code tries to access `.max()` and `.min()` on `ArrowExtensionArray`. To fix this, we can replace `.max()` and `.min()` with `np.max()` and `np.min()`, which can handle these arrays correctly.

Here is the modification to be made:

```python
# check that the key does not exceed the maximum size of the index
if np.max(arr) >= len_axis or np.min(arr) < -len_axis:
    raise IndexError(""positional indexers are out-of-bounds"")
```

---",[],,2025-04-20 17:15:13+00:00,2025-05-09 16:07:23+00:00,,18.95289351851852
61320,PERF: Restore old performances with .isin() on columns typed as np.ui‚Ä¶,"‚Ä¶nt64

- [ ] closes #60098 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Only if dtypes are equal (e.g uint64 vs uint64, uint32 vs uint32...)

%timeit data[""uints""].isin([np.uint64(1), np.uint64(2)]) # 17ms (!)
The last line, with older numpy==1.26.4 (last version <2.0), is even worse: ~200ms.","['Performance', 'Regression', 'isin']",,2025-04-20 14:24:36+00:00,2025-05-19 16:14:47+00:00,,29.076516203703704
61319,ENH: grep-like select columns of a DataFrame by a part of their names,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I wish I could grep-like select columns of a DataFrame by a part of their names, and return a subset of the original DataFrame containing only columns that match the substring.

### Feature Description

```py
from typing import List, Union
import pandas as pd


class ExtendedDF(pd.DataFrame):
    @property
    def _constructor(self):
        return ExtendedDF

    def select_by_substr(self, substr: Union[str, List[str]], *, ignore_case: bool = True) -> Union[pd.DataFrame, 'ExtendedDF']:
        """"""grep-like select columns of a DataFrame by a part of their names.

        Args:
            substr (Union[str, List[str]]): a string or a list of strings to be used as search patterns
            ignore_case (bool): if True (default), ignore search pattern case

        Returns:
            pd.DataFrame: a subset of the original DataFrame containing only columns that match the substring

        Usage:

        Consider two DataFrame objects extracted from two different sources, and thus varying in their column names:

        ```py
        df1 = pd.DataFrame({
            'Distance': [105.0, 0.0, 4.0, 1.0, 1241.0],
            'Distance_percent': [0.2, 0.0, 5.2, 11.1, 92.8],
            'Mixed': [921.0, 0.0, 52.0, 5.0, 0.0],
            'Mixed_percent': [1.9, 0.0, 67.5, 55.6, 0.0],
            'avg_diff': [121146.9, 293246.3, 212169.9, 41299.8, 29438.3],
            'med_diff': [17544.0, 1657.0, 55205.0, 95750.0, 2577.0],
        })
        df2 = pd.DataFrame({
            'distance': [105.0, 0.0, 4.0, 1.0, 1241.0],
            'distance_percent': [0.2, 0.0, 5.2, 11.1, 92.8],
            'mixed': [921.0, 0.0, 52.0, 5.0, 0.0],
            'mixed_percent': [1.9, 0.0, 67.5, 55.6, 0.0],
            'diff_avg': [121146.9, 293246.3, 212169.9, 41299.8, 29438.3],
            'diff_med': [17544.0, 1657.0, 55205.0, 95750.0, 2577.0],
        })
        df1 = ExtendedDF(df1)
        df2 = ExtendedDF(df2)
        ```
        ```
        df1
           Distance  Distance_percent  Mixed  Mixed_percent  avg_diff  med_diff
        0     105.0               0.2  921.0            1.9  121146.9   17544.0
        1       0.0               0.0    0.0            0.0  293246.3    1657.0
        2       4.0               5.2   52.0           67.5  212169.9   55205.0
        3       1.0              11.1    5.0           55.6   41299.8   95750.0
        4    1241.0              92.8    0.0            0.0   29438.3    2577.0

        df2
           distance  distance_percent  mixed  mixed_percent  diff_avg  diff_med
        0     105.0               0.2  921.0            1.9  121146.9   17544.0
        1       0.0               0.0    0.0            0.0  293246.3    1657.0
        2       4.0               5.2   52.0           67.5  212169.9   55205.0
        3       1.0              11.1    5.0           55.6   41299.8   95750.0
        4    1241.0              92.8    0.0            0.0   29438.3    2577.0
        ```

        As an analyst, I need to inspect which column is which between the two datasets:

        (a) either by defining a single string search pattern (`ignore_case=True` by default):

        ```py
        cols_to_select = 'diff'
        print('df1:')
        print(df1.select_by_substr(cols_to_select).T) # transposed for a better legibility
        print()
        print('df2:')
        print(df2.select_by_substr(cols_to_select).T) # transposed for a better legibility
        ```
        ```
        df1:
                         0         1         2        3        4
        avg_diff  121146.9  293246.3  212169.9  41299.8  29438.3
        med_diff   17544.0    1657.0   55205.0  95750.0   2577.0

        df2:
                         0         1         2        3        4
        diff_avg  121146.9  293246.3  212169.9  41299.8  29438.3
        diff_med   17544.0    1657.0   55205.0  95750.0   2577.0
        ```

        (b) or by defining a list of string search patterns (`ignore_case=True` by default):

        ```py
        cols_to_select = ['dist', 'Mix']
        print('df1:')
        print(df1.select_by_substr(cols_to_select).T) # transposed for a better legibility
        print()
        print('df2:')
        print(df2.select_by_substr(cols_to_select).T) # transposed for a better legibility
        ```
        ```
        df1:
                              0    1     2     3       4
        Mixed             921.0  0.0  52.0   5.0     0.0
        Distance          105.0  0.0   4.0   1.0  1241.0
        Mixed_percent       1.9  0.0  67.5  55.6     0.0
        Distance_percent    0.2  0.0   5.2  11.1    92.8

        df2:
                              0    1     2     3       4
        mixed_percent       1.9  0.0  67.5  55.6     0.0
        mixed             921.0  0.0  52.0   5.0     0.0
        distance          105.0  0.0   4.0   1.0  1241.0
        distance_percent    0.2  0.0   5.2  11.1    92.8
        ```

        (c) or, same as (b) but with an explicit `ignore_case=False`:

        ```py
        cols_to_select = ['dist', 'Mix']
        print('df1:')
        print(df1.select_by_substr(cols_to_select, ignore_case=False).T) # transposed for a better legibility
        print()
        print('df2:')
        print(df2.select_by_substr(cols_to_select, ignore_case=False).T) # transposed for a better legibility
        ```
        ```
        df1:
                           0    1     2     3    4
        Mixed_percent    1.9  0.0  67.5  55.6  0.0
        Mixed          921.0  0.0  52.0   5.0  0.0

        df2:
                              0    1    2     3       4
        distance_percent    0.2  0.0  5.2  11.1    92.8
        distance          105.0  0.0  4.0   1.0  1241.0
        ```
        """"""
        substr = [substr] if isinstance(substr, str) else substr
        if ignore_case:
            selected_cols = [col_name for col_name in self.columns for s in substr if s.casefold() in col_name.casefold()]
        else:
            selected_cols = [col_name for col_name in self.columns for s in substr if s in col_name]
        selected_cols = list(set(selected_cols))
        return self[selected_cols]
```

### Alternative Solutions

Idk

### Additional Context

_No response_","['Enhancement', 'Indexing', 'Needs Info']",,2025-04-20 14:10:10+00:00,2025-04-21 15:49:27+00:00,,1.0689467592592592
61318,ENH: inspect duplicate rows for columns that vary,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I wish I had a function that would inspect a DataFrame that has duplicate values and yield, per each group of rows that have a duplicate value, a subset of the input DataFrame featuring only the columns that vary.

### Feature Description

```py
from typing import Union
import pandas as pd


class ExtendedDF(pd.DataFrame):
    @property
    def _constructor(self):
        return ExtendedDF

    def inspect_duplicates(self, key_col: str) -> Union[pd.DataFrame, 'ExtendedDF']:
        """"""Inspects a DataFrame that has duplicate values in the `key_col` column,
        and yields, per each group of rows that have same `key_col` value, a subset
        of the input DataFrame featuring only the columns that vary.

        Args:
            key_col (str): name of the column with duplicate values

        Yields:
            pd.DataFrame: per each group of rows that have same `key_col` value,
            yields a subset of the input DataFrame featuring only the columns that
            vary.

        Examples:

        Consider a dataset containing ramen ratings with duplicates:

        ```py
        df = pd.DataFrame({
            'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
            'style': ['cup', 'pack', 'cup', 'cup', 'pack'],
            'rating': [4, 3.5, 4, 15, 5],
            'col_that_doesnt_change': ['so yummy' for _ in range(5)],
            'another_col_that_doesnt_change': ['mmm love it' for _ in range(5)],
        })
        df = ExtendedDF(df)
        ```
        ```
        df
             brand  style  rating col_that_doesnt_change another_col_that_doesnt_change
        0  Yum Yum    cup     4.0               so yummy                    mmm love it
        1  Yum Yum   pack     3.5               so yummy                    mmm love it
        2  Indomie    cup     4.0               so yummy                    mmm love it
        3  Indomie    cup    15.0               so yummy                    mmm love it
        4  Indomie   pack     5.0               so yummy                    mmm love it
        ```

        Inspect the duplicates using 'brand' column as the key:

        ```py
        print(
            *df.inspect_duplicates('brand')
        )
        ```
        ```
             brand  rating
        2  Indomie     4.0
        3  Indomie    15.0
        4  Indomie     5.0

             brand style  rating
        0  Yum Yum   cup     4.0
        1  Yum Yum  pack     3.5
        ```

        Inspect the duplicates using 'style' column as the key:

        ```py
        print(
            *df.inspect_duplicates('style')
        )
        ```
        ```
          style    brand
        0   cup  Yum Yum
        2   cup  Indomie
        3   cup  Indomie

          style    brand  rating
        1  pack  Yum Yum     3.5
        4  pack  Indomie     5.0
        ```

        Inspect the duplicates using 'rating' column as the key:

        ```py
        print(
            *df.inspect_duplicates('rating')
        )
        ```
        ```
           rating    brand
        0     4.0  Yum Yum
        2     4.0  Indomie
        ```

        You can also concatenate everything that is yielded into a single DataFrame:

        ```py
        print(
            pd.concat([
                *df.inspect_duplicates('brand')
            ])
        )
        ```
        ```
             brand style  rating
        0  Yum Yum   cup     4.0
        1  Yum Yum  pack     3.5
        2  Indomie   NaN     4.0
        3  Indomie   NaN    15.0
        4  Indomie   NaN     5.0
        ```
        """"""
        mark_all_dupl_mask = self.duplicated(key_col, keep=False)
        df_dupl = self.loc[mark_all_dupl_mask]
        for k in set(df_dupl[key_col].values):
            sub_df = self.loc[self[key_col] == k]
            mask_eq = sub_df.iloc[0] != sub_df.iloc[1]
            diff_cols = mask_eq.loc[mask_eq].index.values
            yield sub_df.loc[:, [key_col] + list(diff_cols)]
```

### Alternative Solutions

None

### Additional Context

Authors:

- @miraaitsaada
- @kirisakow","['Enhancement', 'Groupby', 'Closing Candidate']",,2025-04-20 12:11:06+00:00,2025-04-21 15:50:36+00:00,,1.1524305555555556
61315,DOC: Add missing punctuation to merging.rst,"Add missing punctuation to ``merging.rst``.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Reshaping']",,2025-04-20 02:51:59+00:00,2025-04-21 15:46:30+00:00,,1.5378587962962964
61314,[minor edit] fix typo: psudocode -> pseudocode,"this PR fixes this typo spotted here:

https://github.com/pandas-dev/pandas/blob/a811388727bb0640528962191b0f4e50d8235cfd/.github/ISSUE_TEMPLATE/feature_request.yaml#L34

<!--
- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
//-->",['CI'],,2025-04-19 23:28:30+00:00,2025-04-21 15:46:59+00:00,,1.6795023148148147
61313,[ canceled PR ],"this PR fixes this typo spotted here:

https://github.com/pandas-dev/pandas/blob/a811388727bb0640528962191b0f4e50d8235cfd/.github/ISSUE_TEMPLATE/feature_request.yaml?plain=1#L34

<!--
- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
//-->",[],,2025-04-19 23:11:04+00:00,2025-04-19 23:18:47+00:00,,0.005358796296296296
61312,BUG: duplicated() is reporting rows as duplicates when they aren't upon visual inspection.,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
I got the creditcard.csv from Kaggle: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud 

import pandas as pd
import numpy as np

credit_card_df = pd.read_csv('creditcard.csv')

duplicated_df = credit_card_df[credit_card_df.duplicated()]

duplicated_df
```

### Issue Description

If you look at the output of the *duplicated_df* you can see rows 33 and 35 reported as duplicates when they aren't. The values are close but not exact duplicates

### Expected Behavior

Would expect these rows to not be reported as duplicates because the values in the columns that aren't named 'Time' are not identical to each other.

### Installed Versions

![Image](https://github.com/user-attachments/assets/ac5c5337-d62e-41a5-8562-4372d34cb48c)
","['Bug', 'Needs Triage', 'Closing Candidate']",,2025-04-19 20:18:24+00:00,2025-04-19 21:02:03+00:00,,0.0303125
61311,BUG: ``'ArrowExtensionArray' object has no attribute 'max'`` when passing pyarrow-backed series to `.iloc`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
In [1]: import pandas as pd

In [2]: df = pd.DataFrame({""a"": [1, 2], ""c"": [0, 2], ""d"": [""c"", ""a""]})

In [3]: df.iloc[:, df['c']]  # works fine
Out[3]:
   a  d
0  1  c
1  2  a

In [4]: df = pd.DataFrame({""a"": [1, 2], ""c"": [0, 2], ""d"": [""c"", ""a""]}).convert_dtypes(dtype_backend='pyarrow')

In [5]: df.iloc[:, df['c']]  # now, it raises
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Cell In[5], line 1
----> 1 df.iloc[:, df['c']]

File ~/pandas-dev/pandas/core/indexing.py:1189, in _LocationIndexer.__getitem__(self, key)
   1187     if self._is_scalar_access(key):
   1188         return self.obj._get_value(*key, takeable=self._takeable)
-> 1189     return self._getitem_tuple(key)
   1190 else:
   1191     # we by definition only have the 0th axis
   1192     axis = self.axis or 0

File ~/pandas-dev/pandas/core/indexing.py:1692, in _iLocIndexer._getitem_tuple(self, tup)
   1691 def _getitem_tuple(self, tup: tuple):
-> 1692     tup = self._validate_tuple_indexer(tup)
   1693     with suppress(IndexingError):
   1694         return self._getitem_lowerdim(tup)

File ~/pandas-dev/pandas/core/indexing.py:975, in _LocationIndexer._validate_tuple_indexer(self, key)
    973 for i, k in enumerate(key):
    974     try:
--> 975         self._validate_key(k, i)
    976     except ValueError as err:
    977         raise ValueError(
    978             f""Location based indexing can only have [{self._valid_types}] types""
    979         ) from err

File ~/pandas-dev/pandas/core/indexing.py:1613, in _iLocIndexer._validate_key(self, key, axis)
   1610         raise IndexError(f"".iloc requires numeric indexers, got {arr}"")
   1612     # check that the key does not exceed the maximum size of the index
-> 1613     if len(arr) and (arr.max() >= len_axis or arr.min() < -len_axis):
   1614         raise IndexError(""positional indexers are out-of-bounds"")
   1615 else:

AttributeError: 'ArrowExtensionArray' object has no attribute 'max'
```

### Issue Description

`df.iloc[:, df['c']]` works for regular pandas dataframes but raises for pyarrow-backed ones

spotted in [narwhals](https://github.com/narwhals-dev/narwhals)

### Expected Behavior

```
   a  d
0  1  c
1  2  a
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 57fd50221ea3d5de63d909e168f10ad9fc0eee9b
python                : 3.10.12
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+1979.g57fd50221e
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 8.33.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2025.2.0
html5lib              : 1.1
hypothesis            : 6.127.5
gcsfs                 : 2025.2.0
jinja2                : 3.1.5
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 19.0.1
pyreadstat            : 1.2.8
pytest                : 8.3.5
python-calamine       : None
pytz                  : 2025.1
pyxlsb                : 1.0.10
s3fs                  : 2025.2.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.38
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Indexing', 'Arrow']","{'login': 'skonda29', 'id': 60264570, 'node_id': 'MDQ6VXNlcjYwMjY0NTcw', 'avatar_url': 'https://avatars.githubusercontent.com/u/60264570?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/skonda29', 'html_url': 'https://github.com/skonda29', 'followers_url': 'https://api.github.com/users/skonda29/followers', 'following_url': 'https://api.github.com/users/skonda29/following{/other_user}', 'gists_url': 'https://api.github.com/users/skonda29/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/skonda29/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/skonda29/subscriptions', 'organizations_url': 'https://api.github.com/users/skonda29/orgs', 'repos_url': 'https://api.github.com/users/skonda29/repos', 'events_url': 'https://api.github.com/users/skonda29/events{/privacy}', 'received_events_url': 'https://api.github.com/users/skonda29/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-04-19 19:08:44+00:00,2025-08-05 17:21:49+00:00,skonda29,107.92575231481482
61310,BUG: no last function in window rolling,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
s = pd.Series(range(5))
s.rolling(3).last()
```

### Issue Description

The reproducible example is right from the [docs](https://pandas.pydata.org/docs/dev/reference/api/pandas.core.window.rolling.Rolling.last.html).
Same goes for agg invocations.

<ins>Typical error messages:</ins>
  * AttributeError: 'last' is not a valid function for 'Rolling' object
  * AttributeError: 'Rolling' object has no attribute 'last'

### Expected Behavior

Last if available.

### Installed Versions

commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.3
python-bits           : 64
OS                    : Linux
OS-release            : 6.14.2-arch1-1
Version               : #1 SMP PREEMPT_DYNAMIC Thu, 10 Apr 2025 18:43:59 +0000
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.1.3
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 9.1.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : 1.1
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : 5.3.2
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None
","['Bug', 'Needs Info', 'Window', 'Closing Candidate']",,2025-04-19 10:00:37+00:00,2025-04-21 02:52:26+00:00,,1.702650462962963
61309,"BUG: to_latex, when escaped=True, doesn't escape columns name","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

df = pd.DataFrame(data=[{""hello"":""world""}])
df.columns.name = ""hello_world""
df.to_latex(""table.tex"",escape=True)
```

### Issue Description

Contents of df.columns.name aren't escaped.

### Expected Behavior

df.columns.name should be escaped.

### Installed Versions

INSTALLED VERSIONS
------------------
commit           : 0f437949513225922d851e9581723d82120684a6
python           : 3.8.10.final.0
python-bits      : 64
OS               : Linux
OS-release       : 5.15.167.4-microsoft-standard-WSL2
Version          : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine          : x86_64
processor        : x86_64
byteorder        : little
LC_ALL           : None
LANG             : C.UTF-8
LOCALE           : en_US.UTF-8

pandas           : 2.0.3
numpy            : 1.24.4
pytz             : 2025.2
dateutil         : 2.9.0.post0
setuptools       : 44.0.0
pip              : 20.0.2
Cython           : 3.0.12
pytest           : None
hypothesis       : None
sphinx           : None
blosc            : None
feather          : None
xlsxwriter       : None
lxml.etree       : None
html5lib         : None
pymysql          : None
psycopg2         : None
jinja2           : 3.1.6
IPython          : 8.12.3
pandas_datareader: None
bs4              : None
bottleneck       : None
brotli           : None
fastparquet      : None
fsspec           : None
gcsfs            : None
matplotlib       : 3.7.5
numba            : None
numexpr          : 2.8.6
odfpy            : None
openpyxl         : None
pandas_gbq       : None
pyarrow          : None
pyreadstat       : None
pyxlsb           : None
s3fs             : None
scipy            : None
snappy           : None
sqlalchemy       : None
tables           : 3.8.0
tabulate         : None
xarray           : None
xlrd             : None
zstandard        : None
tzdata           : 2025.2
qtpy             : None
pyqt5            : None
","['Bug', 'Duplicate Report', 'Styler']",,2025-04-19 09:43:14+00:00,2025-04-19 12:37:13+00:00,,0.12082175925925925
61308,ENH: Add tzdata to hard dependencies,"- [x] closes #61273
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
",['Error Reporting'],,2025-04-19 09:10:48+00:00,2025-04-22 16:04:22+00:00,,3.287199074074074
61307,EHN: `df.to_latex(escape=True)` also escape index names,"- [ ] closes #57362 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Stage 3. Part of an multi-stages effort: https://github.com/pandas-dev/pandas/pull/57880#issuecomment-2003636401
Part 2 has a issue at https://github.com/pandas-dev/pandas/issues/59324
But in the process of implementing, I realized the current implementation of `df.to_latex(escape)` does not go through `styler.to_latex` but to call `styler.format_index`. This implementation follows the same flow. So maybe part 2 is not really relevant.
","['Bug', 'IO LaTeX', 'Styler']",,2025-04-19 08:50:21+00:00,2025-04-28 16:58:41+00:00,,9.33912037037037
61305,50000,,[],,2025-04-18 00:56:25+00:00,2025-04-18 16:10:01+00:00,,0.6344444444444445
61304,ENH: Add Optional Schema Definitions to Enable IDE Autocompletion,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Pandas is widely used in data-heavy workflows, and in many cases, the structure of a DataFrame is known in advance ‚Äî especially when loading from sources like CSVs, databases, or APIs.

However, pandas DataFrames are fully dynamic, so IDEs and static type checkers cannot infer the structure. This limits productivity, especially in large codebases, because Column names don‚Äôt autocomplete

We‚Äôre not asking for runtime schema enforcement or data validation ‚Äî we‚Äôre already familiar with Pandera and similar tools. What‚Äôs missing is a mechanism for IDEs and static tools (like Pylance and MyPy) to recognize DataFrame schemas for better code intelligence.


### Feature Description

Introduce an optional way to define column names and types for a DataFrame that tools like VS Code + Pylance can use for autocompletion and type hints.

Example syntax (suggested API):

```python
import pandas as pd
from pandas.typing import Schema  # hypothetical

class OrderSchema(Schema):
    OrderID: int
    CustomerName: str
    OrderDate: str
    Product: str
    Quantity: int
    Price: float
    Country: str

df: pd.DataFrame[OrderSchema] = pd.read_csv(""orders.csv"")

# IDE should support:
df.Country           # autocomplete & type: str
```

This would behave similarly to how TypedDict or Pydantic models enable structure-aware development, but focused on DataFrame-level constructs.

It does not need to affect runtime at all ‚Äî just serve as a static hint for tooling. 


### Alternative Solutions

No

### Additional Context

_No response_","['Enhancement', 'Needs Triage']",,2025-04-17 20:23:14+00:00,2025-04-17 20:56:31+00:00,,0.023113425925925926
61302,Fix #59772: tz_aware NaT raises exception on to_numpy,"Fix error when converting tz-aware Series with NaT to NumPy array

- [x] closes #59772 
- [x] [Tests added and passed] if fixing a bug or adding a new feature
- [ ] All [code checks passed]
- [ ] Added [type annotations] to new arguments/methods/functions.
- [x] Added an entry in the latest doc/source/whatsnew/vX.X.X.rst file if fixing a bug or adding a new feature.

Previously,  converting a Series of timezone-aware pd.NaT to a NumPy array using
.to_numpy(""datetime64[ns]"") would raise an exception.
It would happen because it could not be converted to datetime64 as a tz-aware value.
This is now fixed by removing the timezone localization from NaT values before the conversion.
",[],,2025-04-17 14:46:13+00:00,2025-05-09 16:06:15+00:00,,22.055578703703702
61301,DOC: Fix documentation for DataFrameGroupBy.filter and SeriesGroupBy.filter,"- [x] closes #61300
- [ ] ~~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- [ ] ~~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~
",[],,2025-04-17 01:57:12+00:00,2025-04-17 04:32:42+00:00,,0.10798611111111112
61300,DOC: DataFrameGroupBy.filter documentation is misleading,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html and https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.SeriesGroupBy.filter.html

### Documentation problem

Both `DataFrameGroupBy.filter` and `SeriesGroupBy.filter` state that they ""filter *elements* from groups"".

This is not true, these methods filter whole groups. If you attempt to filter individual elements within a group by returning a series of boolean you get an error:
```
df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
                          'foo', 'bar'],
                   'B' : [1, 2, 3, 4, 5, 6],
                  'C' : [2.0, 5., 8., 1., 2., 9.]})
df.groupby(""A"").filter(lambda x: x['B'] > 1).sum()
```
```
TypeError: filter function returned a Series, but expected a scalar bool
```

### Suggested fix for documentation

Suggested documentation:
```
Filter groups that don‚Äôt satisfy a criterion.

Groups are filtered if they do not satisfy the boolean criterion specified by func.
```","['Docs', 'Needs Triage']",,2025-04-17 01:35:00+00:00,2025-04-17 04:34:38+00:00,,0.12474537037037037
61299,DOC: copyedit _base.py,"No need to restate the library name

- ~~[ ] closes #xxxx (Replace xxxx with the GitHub issue number)~~
- ~~[ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~~
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- ~~[ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- ~~[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~",['Docs'],,2025-04-16 16:37:48+00:00,2025-04-16 20:41:28+00:00,,0.16921296296296295
61298,"I would like to join the pandas community, but the Slack link is broken and I cannot join.","I would like to join the pandas community on Slack, so I would appreciate if you could provide me with a new invitation link.",[],,2025-04-16 05:05:35+00:00,2025-04-17 16:11:22+00:00,,1.462349537037037
61297,BUG: Raise clear error when assign is used with non-string column keys,"### What does this PR do?

Fixes confusing behavior when `.assign()` is used with non-string keys like tuples. Python raises a generic `TypeError: keywords must be strings`, which confuses users.

This PR adds a more helpful message:
> assign() only supports string column names. Use df[('C', 'one')] = ... to assign non-string column names like tuples.

### Why?

This improves the developer experience and avoids unnecessary debugging time.

### How was this fixed?

- Added `__kwargs_dict__` as a keyword-only argument for testing with tuple keys
- Added validation in `assign()` for string-only keys
- Updated existing test for compatibility
- Added new test: `test_assign_with_tuple_column_key_raises_typeerror`

### Test added

 `test_assign_with_tuple_column_key_raises_typeerror`
",[],,2025-04-16 03:02:15+00:00,2025-04-16 16:08:03+00:00,,0.5456944444444445
61296,BUG: Underscores aren't escaped in LaTeX outputs,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

df = pd.DataFrame([{""header_1"": 1, ""header_2"": 2}, {""header_1"": 3, ""header_2"": 4}])
print(df.to_latex(index=False))
```

### Issue Description

Underlines in strings ( _ ) should be escaped in LaTeX outputs given than underscores in LaTeX represent subscripts.

### Expected Behavior

The expected output of the provided code example _should_ be:

```latex
\begin{tabular}{rr}
\toprule
header\_1 & header\_2 \\
\midrule
1 & 2 \\
3 & 4 \\
\bottomrule
\end{tabular}
```

But instead is:

```latex
\begin{tabular}{rr}
\toprule
header_1 & header_2 \\
\midrule
1 & 2 \\
3 & 4 \\
\bottomrule
\end{tabular}
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.7
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : 9.1.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.4
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.12.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-04-15 23:52:45+00:00,2025-04-15 23:55:10+00:00,,0.0016782407407407408
61295,BUG: df.assign no longer works with multilevel columns,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np

# Creating a DataFrame with multilevel columns
arrays = [['A', 'A', 'B', 'B'], ['one', 'two', 'one', 'two']]
tuples = list(zip(*arrays))
index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])
df = pd.DataFrame(np.random.randn(3, 4), columns=index)

# Try to create a new column using ""assign""
df = df.assign(**{('C', 'one'): [1, 2, 3]})
```

### Issue Description

The final line reports the error: TypeError: keywords must be strings

### Expected Behavior

It should create a new column (""C"", 'one') with 1,2,3 in it.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.3
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 154 Stepping 4, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en
LOCALE                : English_Australia.1252

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : 7.3.7
IPython               : 8.30.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : None
numexpr               : 2.10.1
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : 1.2.7
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : 3.1.1
zstandard             : None
tzdata                : 2023.3
qtpy                  : 2.4.1
pyqt5                 : None

</details>
",['Bug'],,2025-04-15 22:38:25+00:00,2025-04-16 13:40:29+00:00,,0.6264351851851852
61293,BUG: pivot_table with overlapping values,"- [x] closes #57876
- [x] closes #61292
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Reshaping']",,2025-04-15 17:56:43+00:00,2025-04-23 21:47:17+00:00,,8.160115740740741
61292,BUG: `values` argument ignored when also supplied to `index`/`columns` in `pivot_table`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd
from pandas import Index, MultiIndex
import pandas.testing as tm


def test_pivot_table_values_in_columns():
    """"""``values`` arg is shared between ``values`` and ``columns``.""""""
    data = [
        [""A"", 1, 50, -1],
        [""B"", 1, 100, -2],
        [""A"", 2, 100, -2],
        [""B"", 2, 200, -4],
    ]
    df = pd.DataFrame(data=data, columns=[""index"", ""col"", ""value"", ""extra""])
    result = df.pivot_table(values=""value"", index=""index"", columns=[""col"", ""value""])
    nan = np.nan
    e_data = [
        [50.0, nan, 100.0, nan],
        [nan, 100.0, nan, 200.0],
    ]
    e_index = Index(data=[""A"", ""B""], name=""index"")
    e_cols = MultiIndex.from_arrays(
        arrays=[[1, 1, 2, 2], [50, 100, 100, 200]], names=[""col"", ""value""]
    )
    expected = pd.DataFrame(data=e_data, index=e_index, columns=e_cols)
    tm.assert_frame_equal(left=result, right=expected)


def test_pivot_table_values_in_index():
    """"""``values`` arg is shared between ``values`` and ``index``.""""""
    data = [
        [""A"", 1, 50, -1],
        [""B"", 1, 100, -2],
        [""A"", 2, 100, -2],
        [""B"", 2, 200, -4],
    ]
    df = pd.DataFrame(data=data, columns=[""index"", ""col"", ""value"", ""extra""])
    result = df.pivot_table(values=""value"", index=[""index"", ""value""], columns=""col"")
    nan = np.nan
    e_data = [
        [50.0, nan],
        [nan, 100.0],
        [100.0, nan],
        [nan, 200.0],
    ]
    e_index = MultiIndex.from_arrays(
        arrays=[[""A"", ""A"", ""B"", ""B""], [50, 100, 100, 200]], names=[""index"", ""value""]
    )
    e_cols = Index(data=[1, 2], name=""col"")
    expected = pd.DataFrame(data=e_data, index=e_index, columns=e_cols)
    tm.assert_frame_equal(left=result, right=expected)


test_pivot_table_values_in_columns()  # Fails.
test_pivot_table_values_in_index()  # Fails.
```

### Issue Description

When the column supplied to `values` in [`pandas.DataFrame.pivot_table`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html) is also supplied to `index` or `columns`, the resulting `DataFrame` does not contain the aggregations of the `values` argument. If any extra column(s) are present, those columns are aggregated instead of those supplied to `values`. This is similar to issue #57876, but the additional columns result in a non-empty `DataFrame`.

### Expected Behavior

I would expect the two tests above to pass, i.e., the `values` arg is aggregated instead of the non-supplied ""extra"" column.

```python
# Expected output of ``test_pivot_table_values_in_columns``:
col       1             2       
value   50     100    100    200
index                           
A      50.0    NaN  100.0    NaN
B       NaN  100.0    NaN  200.0
```

```python
# Expected output of ``test_pivot_table_values_in_index``:
col              1      2
index value              
A     50      50.0    NaN
      100      NaN  100.0
B     100    100.0    NaN
      200      NaN  200.0
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.3
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.22631
machine               : AMD64
processor             : AMD64 Family 25 Model 116 Stepping 1, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 9.1.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Reshaping']",,2025-04-15 16:18:14+00:00,2025-04-23 21:47:19+00:00,,8.228530092592592
61289,WEB: Update benchmarks page,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Benchmark', 'Web']",,2025-04-14 13:10:24+00:00,2025-04-19 11:47:47+00:00,,4.942627314814815
61288,BUG: Fix #46726; wrong result with varying window size min/max rolling calc.,"- [x] closes #46726 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) 
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Speed improved by ~10% as measured by ASV.
- [x] added an entry in the latest `doc/source/whatsnew/v3.0.0.rst`.

### Summary:

-	Fixes a 3-year-old bug with incorrect min/max rolling calculation for custom window sizes. Adds an error check for invalid inputs.
-	Speed improvement of ~10% by not using additional queue for handling NaNs.
-	For complex cases, incurs additional multiplicative log(k) complexity (where k is max window size), but this cost is only incurred in cases that produced invalid result before. For example, for constant window size this cost is not incurred.

### Changed behavior:
Has additional validity check, which will raise ValueError if the function detects a condition it cannot work with, namely improper ordering of start/end bounds. The existing method would happily consume such input and would produce a wrong result. There is a new unit test to check for the raised ValueError.

### Note on invalid inputs:

It is possible to make the method work for an arbitrary stream of start/end window bounds, but it will require sorting. It is very unlikely that such work is worth the effort, and it is estimated to have extremely low need, if any. Let someone create an enhancement request first. 
If sorting is to be implemented: it can be done with only incurring performance hit in the case of unsorted input: copy and sort the start/end arrays, producing a permutation, run the main method on the copy, and then extract the result back using the permutation. To detect if the start/end array pair is properly sorted will only take O(N). (Soring is N*log(N), does not have to be stable, but the input array is extremely likely to be ‚Äúalmost‚Äù sorted, and you have to pick your poison of a sorting method that works well with nearly sorted array, or use efficient soring methods, most of which do not offer additional speed on nearly sorted arrays.) Working such intermediate step (without copying and pasting) into 3 different implementations will require some less than straightforward work in the ‚Äúapply‚Äù family of methods used by other rolling functions, and therefore will bear risk. If this is decided to be done, it is recommended to have an additional parameter to optionally skip the ‚Äúsorted‚Äù check. (The user may already know that the arrays are properly sorted).

### How to Debug numba
You can temporarily change 2 lines of code in order to Python-debug numba implementation with VS Code or another Python debugger:
- Comment out the `numba.jit` decorator on the function(`sliding_min_max()` in `min_max_.py`). 
- Do the same with the `column_looper()` function defined inside the `generate_apply_looper()` function in **executor.py**.
- Your breakpoint inside the function will now hit!

### Misc Notes

The speed improvement of ~10% was confirmed in two ways:
-	As measured by pandas‚Äô supplied asv benchmark suite (0.80-0.91 coefficient (depending on particular test) on my hardware).
-	With a custom load test over a 2MM-long rolling window on a 300MM-long data set. (See the supplied [bench.py.txt](https://github.com/user-attachments/files/19735182/bench.py.txt).) A single run of the test takes approx. 6-8 seconds and consumes ~15GB of RAM on a 32-GB RAM PC.

","['Bug', 'Window']",,2025-04-14 12:15:42+00:00,2025-04-25 20:28:19+00:00,,11.342094907407407
61287,PERF: Restore old performances with .isin() on columns typed as np.ui‚Ä¶,"‚Ä¶nt64

- [ ] closes #60098 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-14 10:07:07+00:00,2025-04-14 18:44:21+00:00,,0.3591898148148148
61286,ENH: Update DataFrame.to_stata to handle pd.NA and None values in strL columns,"- [x] closes #23633  (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['IO Stata'],,2025-04-14 09:08:20+00:00,2025-04-22 16:02:29+00:00,,8.287604166666666
61285,DOC: Improve clarity and beginner-friendly tone in table tutorial,"This PR makes small improvements to the 01_table_oriented.rst tutorial in the getting_started/intro_tutorials section. The changes include:

Simplified explanations for importing pandas and creating DataFrames.

Improved grammar and sentence clarity.

Reworded the Series and describe() method descriptions to be more beginner-friendly.

These edits aim to enhance readability and help first-time users better understand pandas concepts.
",[],,2025-04-14 07:04:32+00:00,2025-04-14 16:53:24+00:00,,0.4089351851851852
61284,Doc-groupby-ewm,"- [x] closes #61268 (Adding documentation for `groupby.ewm()`)
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.",[],,2025-04-14 06:53:34+00:00,2025-04-14 16:54:59+00:00,,0.417650462962963
61283,DOC: Add documentation for `groupby.ewm()`,"- [x] closes #61268
- [ ] ~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
","['Docs', 'Window']",,2025-04-14 05:24:05+00:00,2025-04-14 20:05:35+00:00,,0.6121527777777778
61280,DOC: to_json for stream object,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html

### Documentation problem

Currently the docs for `to_json`method only mentions about file-like object, yet we can pass buffer which are more like stream object. This was raised on the stubs repo (https://github.com/pandas-dev/pandas-stubs/issues/1179).
Should the docs reflect the ability of not just file-like but also stream-like? It seems to be supported at run time for sure.

Thanks!

### Suggested fix for documentation

Add mention of stream-like object for the `path_or_buf` argument.","['Docs', 'IO JSON', 'Closing Candidate']",,2025-04-12 16:35:16+00:00,2025-04-14 14:03:02+00:00,,1.8942824074074074
61279,WEB: Add pandas cookbook 3 to home page,"#61271 was hard reverted, as it contained a 1.4 Mb image which we didn't want in our git history.

Same PR here, but with the image now using 9Kb.

@WillAyd, if you check in detail, you and Matt look a bit like cartoons, hahaha. This is because I'm just using 24 colors in the image, as this makes the file size much smaller than using 256. I don't think anyone will notice, and even when paying attention to me it looks kind of cool, more than anything bad. But I'm surely happy to improve the quality of the image and have an image some Kb bigger if you prefer. Just let me know.",['Web'],,2025-04-12 16:17:16+00:00,2025-04-12 18:51:17+00:00,,0.10695601851851852
61278,"WEB: Removed Coiled as a sponsor, and update past sponsors list","- [X] xref #61277

Removing only Coiled for now (NumFOCUS pending discussion)

In #61121 I forgot to move removed sponsors to the past sponsors list. Doing it here.",['Web'],,2025-04-12 15:00:33+00:00,2025-04-13 15:37:19+00:00,,1.0255324074074075
61277,WEB: Remove NumFOCUS and Coiled as sponsors,"pandas is it's not really well funded these days, and we've been updating the sponsors list recently to be more accurate, and I'd like to still remove NumFOCUS and Coiled from the list. Of course I do appreciate the support that both NumFOCUS and Coiled provided and still provide to pandas, but I think having them as sponsors is at this point misleading and create the false impression that pandas is better funded than it is.

For NumFOCUS, we pay them 15% of the pandas income for financial support mostly.  We get few other things like legal support or small development grants. But I wouldn't list them as ""pandas has the support of NumFOCUS"" in periods of very low funding like now, as we probably supported NumFOCUS more than NumFOCUS supported us. For reference OpenCollective US would charge as 10%, and OpenCollective EU 8%.

For Coiled, I saw Patrick made two commits in the last 7 months, and if I'm not wrong he's not very active in PR review or other maintenance tasks recently. Truly thankful to them as Patrick could make lots of quality work for pandas sponsored by them in the past, but as of today, having them as a sponsor it's again misleading visitors of our website into thinking pandas is in a healthy financial state as it was a couple of years ago, when in practice it's not.

I hope having a more accurate list can help find new sponsors, help when we ask new grants, and maybe even help bring awareness of our current sponsors how key is their support at this point.

@pandas-dev/pandas-core @phofl please let me know if any objection, otherwise I'll move forward with this in the next few days.",['Web'],,2025-04-12 13:03:38+00:00,2025-04-13 15:39:45+00:00,,1.1084143518518519
61276,BUG:FutureWarning for palette parameter without hue in faceted distributions,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Sample data
tips = sns.load_dataset(""tips"")

# Faceted distribution plot
sns.displot(data=tips, x=""total_bill"", palette=""viridis"")
plt.show()
```

### Issue Description

When using faceted distributions with Seaborn and passing the `palette` parameter without assigning `hue`, a FutureWarning is raised. The warning suggests assigning `hue` and setting `legend=False` to avoid deprecation in future versions (v0.14.0). This behavior needs clarification or adjustment in Pandas' integration with Seaborn plotting functions.
observed behavior:
FutureWarning: Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.


### Expected Behavior

The warning should either be suppressed or handled gracefully within Pandas' plotting functions when interfacing with Seaborn.


### Installed Versions

<details>

/usr/local/lib/python3.11/dist-packages/_distutils_hack/__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.11.12.final.0
python-bits           : 64
OS                    : Linux
OS-release            : 6.1.85+
Version               : #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : en_US.UTF-8
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.2
numpy                 : 2.0.2
pytz                  : 2025.2
dateutil              : 2.8.2
setuptools            : 75.2.0
pip                   : 24.1.2
Cython                : 3.0.12
pytest                : 8.3.5
hypothesis            : None
sphinx                : 8.2.3
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : 5.3.1
html5lib              : 1.1
pymysql               : None
psycopg2              : 2.9.10
jinja2                : 3.1.6
IPython               : 7.34.0
pandas_datareader     : 0.10.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.2
gcsfs                 : 2025.3.2
matplotlib            : 3.10.0
numba                 : 0.60.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : 0.28.0
pyarrow               : 18.1.0
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : 2.0.40
tables                : 3.10.2
tabulate              : 0.9.0
xarray                : 2025.1.2
xlrd                  : 2.0.1
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>

![Image](https://github.com/user-attachments/assets/35b68104-544b-44ac-bbf4-b8e98d8b2753)
","['Bug', 'Visualization']",,2025-04-12 12:05:08+00:00,2025-04-26 12:04:01+00:00,,13.999224537037037
61274,DOC: Add documentation for `groupby.expanding()`,"- [x] closes #61254 
- [ ] ~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
","['Docs', 'Groupby', 'Window']",,2025-04-12 00:15:43+00:00,2025-04-14 22:41:29+00:00,,2.9345601851851852
61273,ENH: Add `tzdata` to the `_hard_dependencies`,"### Feature Type

- [ ] Adding new functionality to pandas

- [x] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

In https://github.com/pandas-dev/pandas/pull/61084#pullrequestreview-2669422152,  suggesting that `tzdata` should be added to the `_hard_dependencies` list.

### Feature Description

Extend current `_hard_dependencies` from `(""numpy"", ""dateutil"")` to `(""numpy"", ""dateutil"", ""tzdata"")`. 

### Alternative Solutions

No

### Additional Context

_No response_","['Enhancement', 'Dependencies']","{'login': 'chilin0525', 'id': 41913261, 'node_id': 'MDQ6VXNlcjQxOTEzMjYx', 'avatar_url': 'https://avatars.githubusercontent.com/u/41913261?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/chilin0525', 'html_url': 'https://github.com/chilin0525', 'followers_url': 'https://api.github.com/users/chilin0525/followers', 'following_url': 'https://api.github.com/users/chilin0525/following{/other_user}', 'gists_url': 'https://api.github.com/users/chilin0525/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/chilin0525/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/chilin0525/subscriptions', 'organizations_url': 'https://api.github.com/users/chilin0525/orgs', 'repos_url': 'https://api.github.com/users/chilin0525/repos', 'events_url': 'https://api.github.com/users/chilin0525/events{/privacy}', 'received_events_url': 'https://api.github.com/users/chilin0525/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-04-11 15:43:38+00:00,2025-04-22 16:04:23+00:00,chilin0525,11.014409722222222
61272,"BUILD: Error installing pandas 2.2.3 on AIX 7.3 system (error: conflicting types for lockf64, lseek64, ftruncate64..)","### Installation check

- [x] I have read the [installation guide](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-pandas).


### Platform

AIX-3-CENSORED-powerpc-64bit

### Installation Method

pip install

### pandas Version

2.2.3

### Python Version

3.11

### Installation Logs

```
pip3.11 install --no-build-isolation pandas -vvv
```
<details>
  Running command Preparing metadata (pyproject.toml)
  + meson setup /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/.mesonpy-j4blhphr -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=/tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/.mesonpy-j4blhphr/meson-python-native-file.ini
  The Meson build system
  Version: 1.6.1
  Source dir: /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d
  Build dir: /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/.mesonpy-j4blhphr
  Build type: native build
  Project name: pandas
  Project version: 2.2.3
  C compiler for the host machine: gcc (gcc 10.3.0 ""gcc (GCC) 10.3.0"")
  C linker for the host machine: gcc ld.aix 7.3.2
  C++ compiler for the host machine: c++ (gcc 10.3.0 ""c++ (GCC) 10.3.0"")
  C++ linker for the host machine: c++ ld.aix 7.3.2
  Cython compiler for the host machine: cython (cython 3.0.8)
  Host machine cpu family: ppc
  Host machine cpu: powerpc
  Program python found: YES (/opt/freeware/bin/python3.11)
  Found pkg-config: YES (/opt/freeware/bin/pkg-config) 0.29.2
  Run-time dependency python found: YES 3.11
  Build targets in project: 53

  pandas 2.2.3

    User defined options
      Native files: /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/.mesonpy-j4blhphr/meson-python-native-file.ini
      b_ndebug    : if-release
      b_vscrt     : md
      buildtype   : release
      vsenv       : true

  Found ninja-1.12.1 at /opt/freeware/bin/ninja

  Visual Studio environment is needed to run Ninja. It is recommended to use Meson wrapper:
  /opt/freeware/bin/meson compile -C .
  + /opt/freeware/bin/ninja
  [1/151] Generating pandas/_libs/algos_take_helper_pxi with a custom command
  [2/151] Generating pandas/_libs/algos_common_helper_pxi with a custom command
  [3/151] Generating pandas/_libs/khash_primitive_helper_pxi with a custom command
  [4/151] Generating pandas/_libs/hashtable_class_helper_pxi with a custom command
  [5/151] Generating pandas/_libs/hashtable_func_helper_pxi with a custom command
  [6/151] Generating pandas/_libs/index_class_helper_pxi with a custom command
  [7/151] Generating pandas/_libs/intervaltree_helper_pxi with a custom command
  [8/151] Generating pandas/_libs/sparse_op_helper_pxi with a custom command
  [9/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/base.pyx
  [10/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/dtypes.pyx
  [11/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/np_datetime.pyx
  [12/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/ccalendar.pyx
  [13/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/nattype.pyx
  warning: /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/nattype.pyx:79:0: Global name __nat_unpickle matched from within class scope in contradiction to to Python 'class private name' rules. This may change in a future release.
  warning: /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/nattype.pyx:79:0: Global name __nat_unpickle matched from within class scope in contradiction to to Python 'class private name' rules. This may change in a future release.
  [14/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/conversion.pyx
  [15/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/parsing.pyx
  [16/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/fields.pyx
  [17/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/offsets.pyx
  [18/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/period.pyx
  [19/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/strptime.pyx
  [20/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/vectorized.pyx
  [21/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/timezones.pyx
  [22/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/arrays.pyx
  [23/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/tzconversion.pyx
  [24/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/timedeltas.pyx
  [25/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslibs/timestamps.pyx
  [26/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/indexing.pyx
  [27/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/hashing.pyx
  [28/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/internals.pyx
  [29/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/missing.pyx
  [30/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/ops_dispatch.pyx
  [31/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/index.pyx
  [32/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/interval.pyx
  [33/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/parsers.pyx
  [34/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/lib.pyx
  [35/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/ops.pyx
  [36/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/properties.pyx
  [37/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/join.pyx
  [38/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/byteswap.pyx
  [39/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/algos.pyx
  [40/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/hashtable.pyx
  [41/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/sas.pyx
  [42/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/testing.pyx
  [43/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/groupby.pyx
  [44/151] Compiling C object pandas/_libs/tslibs/base.cpython-311.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o
  [45/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/window/indexers.pyx
  [46/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/reshape.pyx
  [47/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/tslib.pyx
  [48/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/window/aggregations.pyx
  [49/151] Compiling C object pandas/_libs/tslibs/ccalendar.cpython-311.so.p/meson-generated_pandas__libs_tslibs_ccalendar.pyx.c.o
  [50/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/sparse.pyx
  [51/151] Compiling Cython source /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d/pandas/_libs/writers.pyx
  [52/151] Compiling C object pandas/_libs/tslibs/parsing.cpython-311.so.p/.._src_parser_tokenizer.c.o
  [53/151] Compiling C object pandas/_libs/tslibs/np_datetime.cpython-311.so.p/meson-generated_pandas__libs_tslibs_np_datetime.pyx.c.o
  [54/151] Compiling C object pandas/_libs/tslibs/dtypes.cpython-311.so.p/meson-generated_pandas__libs_tslibs_dtypes.pyx.c.o
  [55/151] Compiling C object pandas/_libs/tslibs/nattype.cpython-311.so.p/meson-generated_pandas__libs_tslibs_nattype.pyx.c.o
  [56/151] Compiling C object pandas/_libs/tslibs/conversion.cpython-311.so.p/meson-generated_pandas__libs_tslibs_conversion.pyx.c.o
  pandas/_libs/tslibs/conversion.cpython-311.so.p/pandas/_libs/tslibs/conversion.pyx.c: In function '__pyx_pf_6pandas_5_libs_6tslibs_10conversion_cast_from_unit_vectorized.constprop':
  pandas/_libs/tslibs/conversion.cpython-311.so.p/pandas/_libs/tslibs/conversion.pyx.c:3064:79: warning: '__pyx_v_i' may be used uninitialized in this function [-Wmaybe-uninitialized]
   3064 |     __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
        |                                                                               ^~
   3065 |     (is_list ? (PyErr_SetString(PyExc_IndexError, ""list index out of range""), (PyObject*)NULL) :\
        |
  pandas/_libs/tslibs/conversion.cpython-311.so.p/pandas/_libs/tslibs/conversion.pyx.c:23754:14: note: '__pyx_v_i' was declared here
  23754 |   Py_ssize_t __pyx_v_i;
        |              ^~~~~~~~~
  [57/151] Compiling C object pandas/_libs/tslibs/fields.cpython-311.so.p/meson-generated_pandas__libs_tslibs_fields.pyx.c.o
  [58/151] Compiling C object pandas/_libs/tslibs/timezones.cpython-311.so.p/meson-generated_pandas__libs_tslibs_timezones.pyx.c.o
   [59/151] Compiling C object pandas/_libs/tslibs/strptime.cpython-311.so.p/meson-generated_pandas__libs_tslibs_strptime.pyx.c.o
  [60/151] Compiling C object pandas/_libs/tslibs/vectorized.cpython-311.so.p/meson-generated_pandas__libs_tslibs_vectorized.pyx.c.o
  [61/151] Compiling C object pandas/_libs/tslibs/period.cpython-311.so.p/meson-generated_pandas__libs_tslibs_period.pyx.c.o
  [62/151] Compiling C object pandas/_libs/arrays.cpython-311.so.p/meson-generated_pandas__libs_arrays.pyx.c.o
  [63/151] Compiling C object pandas/_libs/tslibs/tzconversion.cpython-311.so.p/meson-generated_pandas__libs_tslibs_tzconversion.pyx.c.o
  [64/151] Compiling C object pandas/_libs/tslibs/parsing.cpython-311.so.p/meson-generated_pandas__libs_tslibs_parsing.pyx.c.o
  [65/151] Compiling C object pandas/_libs/indexing.cpython-311.so.p/meson-generated_pandas__libs_indexing.pyx.c.o
  [66/151] Compiling C object pandas/_libs/tslibs/timestamps.cpython-311.so.p/meson-generated_pandas__libs_tslibs_timestamps.pyx.c.o
  [67/151] Compiling C object pandas/_libs/tslibs/timedeltas.cpython-311.so.p/meson-generated_pandas__libs_tslibs_timedeltas.pyx.c.o
  [68/151] Compiling C object pandas/_libs/hashing.cpython-311.so.p/meson-generated_pandas__libs_hashing.pyx.c.o
  [69/151] Compiling C object pandas/_libs/lib.cpython-311.so.p/src_parser_tokenizer.c.o
  [70/151] Compiling C object pandas/_libs/internals.cpython-311.so.p/meson-generated_pandas__libs_internals.pyx.c.o
  [71/151] Compiling C object pandas/_libs/pandas_datetime.cpython-311.so.p/src_vendored_numpy_datetime_np_datetime.c.o
  [72/151] Compiling C object pandas/_libs/pandas_datetime.cpython-311.so.p/src_vendored_numpy_datetime_np_datetime_strings.c.o
  [73/151] Compiling C object pandas/_libs/pandas_datetime.cpython-311.so.p/src_datetime_date_conversions.c.o
  [74/151] Compiling C object pandas/_libs/pandas_datetime.cpython-311.so.p/src_datetime_pd_datetime.c.o
  [75/151] Compiling C object pandas/_libs/pandas_parser.cpython-311.so.p/src_parser_tokenizer.c.o
  [76/151] Compiling C object pandas/_libs/pandas_parser.cpython-311.so.p/src_parser_io.c.o
  [77/151] Compiling C object pandas/_libs/pandas_parser.cpython-311.so.p/src_parser_pd_parser.c.o
  [78/151] Compiling C object pandas/_libs/missing.cpython-311.so.p/meson-generated_pandas__libs_missing.pyx.c.o
  [79/151] Compiling C object pandas/_libs/parsers.cpython-311.so.p/src_parser_tokenizer.c.o
  [80/151] Compiling C object pandas/_libs/parsers.cpython-311.so.p/src_parser_io.c.o
  [81/151] Compiling C object pandas/_libs/json.cpython-311.so.p/src_vendored_ujson_python_ujson.c.o
  [82/151] Compiling C object pandas/_libs/tslibs/offsets.cpython-311.so.p/meson-generated_pandas__libs_tslibs_offsets.pyx.c.o
  [83/151] Compiling C object pandas/_libs/json.cpython-311.so.p/src_vendored_ujson_python_JSONtoObj.c.o
  FAILED: pandas/_libs/json.cpython-311.so.p/src_vendored_ujson_python_JSONtoObj.c.o
  gcc -Ipandas/_libs/json.cpython-311.so.p -Ipandas/_libs -I../pandas/_libs -I../../../../home/USERNAME/.local/lib/python3.11/site-packages/numpy/core/include -I../pandas/_libs/include -I/opt/freeware/include/python3.11 -fvisibility=hidden -fdiagnostics-color=always -DNDEBUG -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -Wextra -std=c11 -O3 -DNPY_NO_DEPRECATED_API=0 -DNPY_TARGET_VERSION=NPY_1_21_API_VERSION -fPIC -MD -MQ pandas/_libs/json.cpython-311.so.p/src_vendored_ujson_python_JSONtoObj.c.o -MF pandas/_libs/json.cpython-311.so.p/src_vendored_ujson_python_JSONtoObj.c.o.d -o pandas/_libs/json.cpython-311.so.p/src_vendored_ujson_python_JSONtoObj.c.o -c ../pandas/_libs/src/vendored/ujson/python/JSONtoObj.c
  In file included from /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/string.h:52,
                   from ../pandas/_libs/include/pandas/portable.h:12,
                   from ../pandas/_libs/include/pandas/vendored/ujson/lib/ultrajson.h:55,
                   from ../pandas/_libs/src/vendored/ujson/python/JSONtoObj.c:41:
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:207:16: error: conflicting types for 'lseek64'
    207 | extern off64_t _NOTHROW(lseek64, (int, off64_t, int));
        |                ^~~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:205:23: note: previous declaration of 'lseek64' was here
    205 | extern off_t _NOTHROW(lseek, (int, off_t, int));
        |                       ^~~~~
  In file included from /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:864,
                   from /opt/freeware/include/python3.11/Python.h:29,
                   from ../pandas/_libs/src/vendored/ujson/python/JSONtoObj.c:43:
  /usr/include/sys/lockf.h:64:13: error: conflicting types for 'lockf64'
     64 |  extern int lockf64 (int, int, off64_t);
        |             ^~~~~~~
  /usr/include/sys/lockf.h:62:13: note: previous declaration of 'lockf64' was here
     62 |  extern int lockf (int, int, off_t);
        |             ^~~~~
  In file included from /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/string.h:52,
                   from ../pandas/_libs/include/pandas/portable.h:12,
                   from ../pandas/_libs/include/pandas/vendored/ujson/lib/ultrajson.h:55,
                   from ../pandas/_libs/src/vendored/ujson/python/JSONtoObj.c:41:
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:937:14: error: conflicting types for 'ftruncate64'
    937 |  extern int  _NOTHROW(ftruncate64, (int, off64_t));
        |              ^~~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:935:23: note: previous declaration of 'ftruncate64' was here
    935 |  extern int  _NOTHROW(ftruncate, (int, off_t));
        |                       ^~~~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:994:14: error: conflicting types for 'truncate64'
    994 |  extern int  _NOTHROW(truncate64, (const char *, off64_t));
        |              ^~~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:992:23: note: previous declaration of 'truncate64' was here
    992 |  extern int  _NOTHROW(truncate, (const char *, off_t));
        |                       ^~~~~~~~
  In file included from /opt/freeware/include/python3.11/Python.h:29,
                   from ../pandas/_libs/src/vendored/ujson/python/JSONtoObj.c:43:
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1013:18: error: conflicting types for 'pread64'
   1013 |  extern ssize_t  pread64(int, void *, size_t, off64_t);
        |                  ^~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1010:18: note: previous declaration of 'pread64' was here
   1010 |  extern ssize_t  pread(int, void *, size_t, off_t);
        |                  ^~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1014:18: error: conflicting types for 'pwrite64'
   1014 |  extern ssize_t  pwrite64(int, const void *, size_t, off64_t);
        |                  ^~~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1011:18: note: previous declaration of 'pwrite64' was here
   1011 |  extern ssize_t  pwrite(int, const void *, size_t, off_t);
        |                  ^~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1110:17: error: conflicting types for 'fclear64'
   1110 |  extern off64_t fclear64(int, off64_t);
        |                 ^~~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1107:15: note: previous declaration of 'fclear64' was here
   1107 |  extern off_t fclear(int, off_t);
        |               ^~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1111:13: error: conflicting types for 'fsync_range64'
   1111 |  extern int fsync_range64(int, int, off64_t, off64_t);
        |             ^~~~~~~~~~~~~
  /opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10/include-fixed/unistd.h:1108:13: note: previous declaration of 'fsync_range64' was here
   1108 |  extern int fsync_range(int, int, off_t, off_t);
        |             ^~~~~~~~~~~
  [84/151] Compiling C object pandas/_libs/json.cpython-311.so.p/src_vendored_ujson_python_objToJSON.c.o
  [85/151] Compiling C object pandas/_libs/index.cpython-311.so.p/meson-generated_pandas__libs_index.pyx.c.o
  [86/151] Compiling C object pandas/_libs/parsers.cpython-311.so.p/meson-generated_pandas__libs_parsers.pyx.c.o
  [87/151] Compiling C object pandas/_libs/lib.cpython-311.so.p/meson-generated_pandas__libs_lib.pyx.c.o
  pandas/_libs/lib.cpython-311.so.p/pandas/_libs/lib.pyx.c:91529:12: warning: '__pyx_memview_set_object' defined but not used [-Wunused-function]
  91529 | static int __pyx_memview_set_object(const char *itemp, PyObject *obj) {
        |            ^~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/lib.cpython-311.so.p/pandas/_libs/lib.pyx.c:91524:20: warning: '__pyx_memview_get_object' defined but not used [-Wunused-function]
  91524 |   static PyObject *__pyx_memview_get_object(const char *itemp) {
        |                    ^~~~~~~~~~~~~~~~~~~~~~~~
  [88/151] Compiling C object pandas/_libs/interval.cpython-311.so.p/meson-generated_pandas__libs_interval.pyx.c.o
  [89/151] Compiling C object pandas/_libs/join.cpython-311.so.p/meson-generated_pandas__libs_join.pyx.c.o
  [90/151] Compiling C object pandas/_libs/algos.cpython-311.so.p/meson-generated_pandas__libs_algos.pyx.c.o
  [91/151] Compiling C object pandas/_libs/groupby.cpython-311.so.p/meson-generated_pandas__libs_groupby.pyx.c.o
  [92/151] Compiling C object pandas/_libs/hashtable.cpython-311.so.p/meson-generated_pandas__libs_hashtable.pyx.c.o
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_complex128':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:134615:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  134615 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_complex64':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:136475:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  136475 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_float64':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:138335:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  138335 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_float32':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:140195:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  140195 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_uint64':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:142055:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  142055 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_uint32':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:143915:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  143915 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_uint16':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:145775:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  145775 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_uint8':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:147635:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  147635 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_object':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:149433:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  149433 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_16; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_int64':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:151193:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  151193 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_int32':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:153053:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  153053 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_int16':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:154913:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  154913 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_f_6pandas_5_libs_9hashtable_value_count_int8':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:156773:33: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'khuint_t' {aka 'unsigned int'} [-Wsign-compare]
  156773 |   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_15; __pyx_t_1+=1) {
         |                                 ^
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_4__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:147685:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  147685 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_UInt8Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:147216:26: note: '__pyx_v_val' was declared here
  147216 |   __pyx_t_5numpy_uint8_t __pyx_v_val;
         |                          ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_0__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:156823:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  156823 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_Int8Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:156354:25: note: '__pyx_v_val' was declared here
  156354 |   __pyx_t_5numpy_int8_t __pyx_v_val;
         |                         ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_6__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:143965:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  143965 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_UInt32Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:143496:27: note: '__pyx_v_val' was declared here
  143496 |   __pyx_t_5numpy_uint32_t __pyx_v_val;
         |                           ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_1__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:154963:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  154963 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_Int16Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:154494:26: note: '__pyx_v_val' was declared here
  154494 |   __pyx_t_5numpy_int16_t __pyx_v_val;
         |                          ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_5__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:145825:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  145825 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_UInt16Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:145356:27: note: '__pyx_v_val' was declared here
  145356 |   __pyx_t_5numpy_uint16_t __pyx_v_val;
         |                           ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_8__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:140245:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  140245 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_Float32Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:139776:28: note: '__pyx_v_val' was declared here
  139776 |   __pyx_t_5numpy_float32_t __pyx_v_val;
         |                            ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_7__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:142105:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  142105 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_UInt64Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:141636:27: note: '__pyx_v_val' was declared here
  141636 |   __pyx_t_5numpy_uint64_t __pyx_v_val;
         |                           ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_9__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:138385:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  138385 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_Float64Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:137916:28: note: '__pyx_v_val' was declared here
  137916 |   __pyx_t_5numpy_float64_t __pyx_v_val;
         |                            ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_2__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:153103:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  153103 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_Int32Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:152634:26: note: '__pyx_v_val' was declared here
  152634 |   __pyx_t_5numpy_int32_t __pyx_v_val;
         |                          ^~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c: In function '__pyx_fuse_3__pyx_f_6pandas_5_libs_9hashtable_value_count.constprop':
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:151243:6: warning: '__pyx_v_val' may be used uninitialized in this function [-Wmaybe-uninitialized]
  151243 |     ((struct __pyx_vtabstruct_6pandas_5_libs_9hashtable_Int64Vector *)__pyx_v_result_keys->__pyx_vtab)->append(__pyx_v_result_keys, __pyx_v_val);
         |     ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  pandas/_libs/hashtable.cpython-311.so.p/pandas/_libs/hashtable.pyx.c:150774:26: note: '__pyx_v_val' was declared here
  150774 |   __pyx_t_5numpy_int64_t __pyx_v_val;
         |                          ^~~~~~~~~~~
  ninja: build stopped: subcommand failed.
  error: subprocess-exited-with-error

  Preparing metadata (pyproject.toml) did not run successfully.
  exit code: 1

  See above for output.

  note: This error originates from a subprocess, and is likely not a problem with pip.
  full command: /opt/freeware/bin/python3.11 /opt/freeware/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py prepare_metadata_for_build_wheel /tmp/tmpwrjwf5p1
  cwd: /tmp/pip-install-m6bze4df/pandas_9acde4f69c3542ff9312ac4b80e89b4d
  Preparing metadata (pyproject.toml) ... error
error: metadata-generation-failed

Encountered error while generating package metadata.

See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
Exception information:
Traceback (most recent call last):
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/operations/build/metadata.py"", line 35, in generate_metadata
    distinfo_dir = backend.prepare_metadata_for_build_wheel(metadata_dir)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/utils/misc.py"", line 772, in prepare_metadata_for_build_wheel
    return super().prepare_metadata_for_build_wheel(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_impl.py"", line 186, in prepare_metadata_for_build_wheel
    return self._call_hook('prepare_metadata_for_build_wheel', {
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_impl.py"", line 311, in _call_hook
    self._subprocess_runner(
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 252, in runner
    call_subprocess(
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess
    raise error
pip._internal.exceptions.InstallationSubprocessError: Preparing metadata (pyproject.toml) exited with 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 180, in exc_logging_wrapper
    status = run_func(*args)
             ^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 245, in wrapper
    return func(self, options, args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 377, in run
    requirement_set = resolver.resolve(
                      ^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 95, in resolve
    result = self._result = resolver.resolve(
                            ^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 546, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 397, in resolve
    self._add_to_criteria(self.state.criteria, r, parent=None)
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py"", line 173, in _add_to_criteria
    if not criterion.candidates:
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py"", line 156, in __bool__
    return bool(self._sequence)
           ^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 155, in __bool__
    return any(self)
           ^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 143, in <genexpr>
    return (c for c in iterator if id(c) not in self._incompatible_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py"", line 47, in _iter_built
    candidate = func()
                ^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py"", line 211, in _make_candidate_from_link
    self._link_candidate_cache[link] = LinkCandidate(
                                       ^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 293, in __init__
    super().__init__(
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 156, in __init__
    self.dist = self._prepare()
                ^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 225, in _prepare
    dist = self._prepare_distribution()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py"", line 304, in _prepare_distribution
    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 525, in prepare_linked_requirement
    return self._prepare_linked_requirement(req, parallel_builds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 640, in _prepare_linked_requirement
    dist = _get_prepared_distribution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 71, in _get_prepared_distribution
    abstract_dist.prepare_distribution_metadata(
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 67, in prepare_distribution_metadata
    self.req.prepare_metadata()
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 577, in prepare_metadata
    self.metadata_directory = generate_metadata(
                              ^^^^^^^^^^^^^^^^^^
  File ""/opt/freeware/lib/python3.11/site-packages/pip/_internal/operations/build/metadata.py"", line 37, in generate_metadata
    raise MetadataGenerationFailed(package_details=details) from error
pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed
</details>
",['Build'],,2025-04-11 14:00:12+00:00,2025-04-17 08:40:30+00:00,,5.777986111111111
61271,Add Pandas Cookbook to Book Recommendations,The link here is a special link used to track sales of the Pandas Cookbook through the pandas website. NumFOCUS and Packt (the publisher) have agreed that the latter will donate part of the proceeds through this link directly back to NumFOCUS,['Docs'],,2025-04-11 13:16:27+00:00,2025-04-11 15:48:57+00:00,,0.10590277777777778
61270,BUG: Unexpected behavior change in DataFrame.min(axis=1) with numpy.array elements in pandas 2.2 vs pandas 1.1,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np

df = pd.DataFrame(
    {
        ""A"": [
            np.array([1]),
            np.array([2]),
            np.array([3]),
            np.array([4]),
            np.array([5]),
        ],
        ""B"": [10, 20, 30, 40, 50],
    }
)

df = df[[""A"", ""B""]].min(axis=1)
print(df)
```

### Issue Description

The behavior of DataFrame.min(axis=1) when a column contains numpy.array elements has changed between pandas 2.2 and pandas 1.1. I did not find any mention of this change in the changelog, and it is unclear whether this is a regression or an intentional change.

### Expected Behavior

Output on pandas 1.1
```
0    1
1    2
2    3
3    4
4    5
dtype: float64
```

Output on pandas 2.2
```
0    [1]
1    [2]
2    [3]
3    [4]
4    [5]
dtype: object
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.4
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:16 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Nested Data']",,2025-04-11 10:55:24+00:00,2025-04-13 16:25:38+00:00,,2.2293287037037035
61269,BUG: pandas change in style overrides defaults format for other columns,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
 
pd.set_option('display.float_format', '{:.2f}'.format)
 
pd.DataFrame(15.22345676543234567,columns=[1,2,3,4,5,6],index=['A','Z','R','T'])#.style.format({1:'{:.2%}'})
 
pd.DataFrame(15.22345676543234567,columns=[1,2,3,4,5,6],index=['A','Z','R','T']).style.format({1:'{:.2%}'})
```

### Issue Description

After setting float default number of decimal place to display to 2, the first exemple works, only showing 2 decimals for all column. However when adding a custom style to only the first columns all other columns are formatted with the default 6 decimals places. This is quite counterproductive as it means if we want to set some format we need to define all format. It would be nice to be able to change only a few formats while the unchanged are set to default.

### Expected Behavior


When specifying a format for a given columns, pandas should style use user specified default value for other columns.

### Installed Versions


INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.0
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.22621
machine               : AMD64
processor             : Intel64 Family 6 Model 142 Stepping 12, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : fr_FR.cp1252
 
pandas                : 2.2.3
numpy                 : 2.2.1
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : 8.31.0
adbc-driver-postgresql: None
...
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None
 
","['Styler', 'Closing Candidate']",,2025-04-11 08:11:14+00:00,2025-04-13 20:21:25+00:00,,2.5070717592592593
61268,DOC: Add documentation for `groupby.ewm()`,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/reference/groupby.html

### Documentation problem

There is no reference for `DataFrameGroupBy.ewm()`, even though it exists in API, and Docstring can be greatly improved.

Similar to: #61254 

E.g. consider working example:

```
>>> import pandas as pd
>>> pd.__version__
'2.2.3'
>>> data = {""Class"": [""A"", ""A"", ""A"", ""B"", ""B"", ""B""],""Value"": [10, 20, 30, 40, 50, 60],}
>>> df = pd.DataFrame(data)
>>> df
  Class  Value
0     A     10
1     A     20
2     A     30
3     B     40
4     B     50
5     B     60
>>> ewm_mean = (df.groupby(""Class"").ewm(span=2).mean().reset_index(drop=True))
>>> ewm_mean
   Value
0  10.000000
1  17.500000
2  26.153846
3  40.000000
4  47.500000
5  56.153846
```



### Suggested fix for documentation

Include reference of DataFrameGroupBy.ewm and SeriesGroupBy.ewm, like for [DataFrameGroupBy.rolling](https://pandas.pydata.org/docs/dev/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html#pandas.core.groupby.DataFrameGroupBy.rolling)
and [SeriesGroupBy.rolling](https://pandas.pydata.org/docs/dev/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html#pandas.core.groupby.SeriesGroupBy.rolling)

Improve `groupby.ewm()` function Docstring","['Docs', 'Needs Triage']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-04-11 06:42:06+00:00,2025-04-14 20:05:36+00:00,arthurlw,3.557986111111111
61267,BUG: Inconsistent date resolution,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import datetime
import pandas as pd
pd.__version__  # ‚Äò2.2.2‚Äô

d = datetime.datetime(2025, 4, 10)

pd.Series([d]).dtype  # dtype('<M8[ns]')

pd.DataFrame([{'date': d}])['date'].dtype  # dtype('<M8[ns]')

df = pd.DataFrame([{'x': 0}])
df['date'] = d  # <‚Äî broadcast scalar
df['date'].dtype  # dtype('<M8[us]')  <‚Äî different date resolution!
```

### Issue Description

Date resolution differs between Series/DataFrame construction versus assignment via a scalar broadcast. 

### Expected Behavior

I‚Äôd expect the same date resolution across the examples I provided. 

### Installed Versions

<details>

commit        : d9cdd2ee5a58015e
python         : 3.11.9.final.0
python-bits : 64
OS                : Windows
OS-release  : 10
Version        : AMD64
processor    : Intel64 Family 6 Model 85 Stepping 7, GenuineIntel
byteorder     : little

pandas         : 2.2.2
numpy          : 1.26.4
Cython         : 3.0.10

</details>
","['Bug', 'Datetime']",,2025-04-10 22:29:16+00:00,2025-04-13 12:31:31+00:00,,2.5848958333333334
61266,Backport PR #61265: TYP: Add ignores for numpy 2.2 updates,xref https://github.com/pandas-dev/pandas/pull/61265,"['Code Style', 'Typing']",,2025-04-10 20:22:58+00:00,2025-04-11 01:14:48+00:00,,0.20266203703703703
61265,TYP: Add ignores for numpy 2.2 updates,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Code Style', 'Typing']",,2025-04-10 17:36:13+00:00,2025-04-10 20:17:42+00:00,,0.1121412037037037
61264,API: Rename `arg` to `func` in `Series.map`,"- [X] closes #61260
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

CC: @rhshadrach ","['Apply', 'API - Consistency']",,2025-04-10 12:30:14+00:00,2025-04-14 13:14:29+00:00,,4.030729166666666
61263,BUG: Impossible creation of array with dtype=string,"closes #61155

- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).

Hello @rhshadrach ,

I‚Äôve created a fix that raises a ValueError when trying to create a StringArray from a list of lists with inconsistent lengths or non-character elements. This aligns the behavior for both consistent and inconsistent input formats and also tested.

I've would like to hear opinion to raise an error when a list of lists is passed for `dtype=StringDtype`, to avoid ambiguous behavior. If preferred, we could instead join the inner lists into strings automatically ‚Äî happy to adjust based on guidance.
Example case :  `pd.array([[""t"", ""e"", ""s"", ""t""], [""w"", ""o"", ""r"", ""d""]], dtype=""string"") `
`output : <StringArray>
['test', 'word']
Length: 2, dtype: string`

Thanks","['Bug', 'Strings']",,2025-04-09 19:22:02+00:00,2025-05-15 16:13:21+00:00,,35.868969907407404
61262,DEBUG: Cython failures,Trying to get a Cython reproducer for https://github.com/pandas-dev/pandas/pull/61249,['Build'],,2025-04-09 19:15:21+00:00,2025-04-09 21:27:45+00:00,,0.09194444444444444
61261,CI: Pin Cython to a specific commit Window PY3.13t builds,Manual backport of https://github.com/pandas-dev/pandas/pull/61249,['CI'],,2025-04-09 18:21:08+00:00,2025-04-09 19:48:24+00:00,,0.06060185185185185
61260,API: Rename arg to func in Series.map for consistency,"The API of methods taking udf follow certain patterns that make them consistent and easier to learn and use. There are some small differences, which have been listed in #40112 and #61128.

This issue is to rename the `arg` parameter of `Series.map` to `func`, which is the name consistently used in almost all methods. In the case of `Series.map`, the argument is slightly different than others, given that `arg` or `func` can also be a `dict` or a `Series`, which will make `map` replace values from these mappings, instead of executing an elementwise udf.

This issue is for the renaming of the parameter, making the parameter consistent with other methods such as `DataFrame.apply` can be considered in another issue. But there are some cases to consider, given that the behavior of `map` is slightly different when providing a mapping, than when providing a function that maps. In particular, `map` will use `NaN` when the mapping returns `None`, but it will use `None` when the function returns `None`. Also, if we stop supporting dictionaries, users in general should just replace their code from `Series.map(my_dict)` to `Series.map(my_dict.get)`. But there are some special cases, for example when the dictionary is a `defaultdict`, `.get` will return `None`, while the current `map` implementation with a `defaultdict` will consider the default value.","['API Design', 'Apply', 'API - Consistency']",,2025-04-09 17:47:36+00:00,2025-04-14 13:14:30+00:00,,4.810347222222222
61259,Add to_snake_case and to_camel_case for index label conversion using ‚Ä¶,"**Add `to_snake_case` and `to_camel_case` methods for Index label conversion**

This PR adds two new string transformation methods to the `pandas.Index` class:

### üöÄ New methods
- `to_snake_case()`: Converts string index labels to `snake_case` using `inflection.underscore`
- `to_camel_case()`: Converts string index labels to `camelCase` using `inflection.camelize`

Both methods:
- Leave non-string values (e.g. integers, `None`) unchanged
- Are chainable and return a new `Index` instance

### üß™ Tests
Added unit tests for both methods in `test_base.py`:
- Covers strings with mixed case and spaces
- Verifies behavior with mixed-type labels

### üìå Example
```python
import pandas as pd

df = pd.DataFrame({""first name"": [1], ""another_column"": [1]})
df.columns = df.columns.to_camel_case()
print(df.columns)
# Index(['firstName', 'anotherColumn'], dtype='object')

df.columns = df.columns.to_snake_case()
print(df.columns)
# Index(['first_name', 'another_column'], dtype='object')
```

",[],,2025-04-09 04:31:33+00:00,2025-04-09 16:44:42+00:00,,0.5091319444444444
61258,DOC: Update the last ArcticDB link in ecosystem.md,"Update the last ArcticDB link in ecosystem.md.

Correct link:
https://docs.arcticdb.io/latest/api/processing/#arcticdb.QueryBuilder

The old link does not work:
https://docs.arcticdb.io/latest/api/query_builder/

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-04-09 01:24:17+00:00,2025-04-09 16:45:48+00:00,,0.6399421296296296
61257,Changed term non-null to NA,"- [ ] closes #60802

Changed the term non-null to NA, to reflect pandas' docs standard
",['Docs'],,2025-04-08 19:51:26+00:00,2025-04-10 16:04:03+00:00,,1.8420949074074073
61255,DOC: Add real-world aggregation example to GroupBy user guide,This PR adds a real-world example using sales data to the GroupBy Aggregation section in the user guide (groupby.rst). This enhances understanding for new users by supplementing the existing animals DataFrame example with a business-style case.,[],,2025-04-08 15:48:24+00:00,2025-04-08 16:44:39+00:00,,0.0390625
61254,DOC: Add documentation for groupby.expanding(),"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

""https://pandas.pydata.org/docs/dev/reference/groupby.html""

### Documentation problem

There is no reference for `DataFrameGroupBy.expanding()`, even though it exists in API

E.g. consider working example:
```
>>> import pandas as pd
>>> pd.__version__
'2.2.3'
>>> data = {""Class"": [""A"", ""A"", ""A"", ""B"", ""B"", ""B""],""Value"": [10, 20, 30, 40, 50, 60],}
>>> df = pd.DataFrame(data)
>>> df
  Class  Value
0     A     10
1     A     20
2     A     30
3     B     40
4     B     50
5     B     60
>>> expanding_mean = df.groupby(""Class"").expanding().mean().reset_index(drop=True)
>>> expanding_mean
   Value
0   10.0
1   15.0
2   20.0
3   40.0
4   45.0
5   50.0
```
It's undocumented behaviour

### Suggested fix for documentation

Include reference of `DataFrameGroupBy.expanding` and `SeriesGroupBy.expanding`, like for [DataFrameGroupBy.rolling](https://pandas.pydata.org/docs/dev/reference/api/pandas.core.groupby.DataFrameGroupBy.rolling.html#pandas.core.groupby.DataFrameGroupBy.rolling)
and  [SeriesGroupBy.rolling](https://pandas.pydata.org/docs/dev/reference/api/pandas.core.groupby.SeriesGroupBy.rolling.html#pandas.core.groupby.SeriesGroupBy.rolling)","['Docs', 'Groupby', 'Window']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-04-08 12:36:06+00:00,2025-04-14 22:41:30+00:00,arthurlw,6.420416666666667
61253,BUG: Selecting the wrong first column,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
TTP_CWE_mappingDF = pd.read_csv('./658.csv', sep=',')

columns_list = TTP_CWE_mappingDF.columns.tolist()  # Returns column names as a list
print(columns_list)
print(""\n"")


TEST = TTP_CWE_mappingDF.iloc[:, [0]]



columns_list2 = TEST.columns.tolist()  # Returns column names as a list
print(columns_list2)

print(TEST)

# first_column = TTP_CWE_mappingDF.iloc[:, 0]  # All rows (:) + first column (0)
# print(first_column)
```

### Issue Description

Hi,

When downloading the MITRE CAPEC cwe .csv I tried to import it on Python to play with it a bit.
Surprisingly, when selecting the first column, the data is from the second column, and this applies to the whole dataframe; all columns are off by one. The key is correct, but the data is for the next key.


This is rather problematic, as you can imagine.

I added the .csv file I am using as well.

[658.csv](https://github.com/user-attachments/files/19648994/658.csv)

### Expected Behavior

this is the result i get:

[""'ID"", 'Name', 'Abstraction', 'Status', 'Description', 'Alternate Terms', 'Likelihood Of Attack', 'Typical Severity', 'Related Attack Patterns', 'Execution Flow', 'Prerequisites', 'Skills Required', 'Resources Required', 'Indicators', 'Consequences', 'Mitigations', 'Example Instances', 'Related Weaknesses', 'Taxonomy Mappings', 'Notes']


[""'ID""]
                                                   'ID
1    Accessing Functionality Not Properly Constrain...
11                  Cause Web Server Misclassification
112                                        Brute Force
114                               Authentication Abuse
115                              Authentication Bypass
..                                                 ...
698                        Install Malicious Extension
70       Try Common or Default Usernames and Passwords
700                          Network Boundary Bridging
94                      Adversary in the Middle (AiTM)
98                                            Phishing

[177 rows x 1 columns]



the expected result should be:

[""'ID"", 'Name', 'Abstraction', 'Status', 'Description', 'Alternate Terms', 'Likelihood Of Attack', 'Typical Severity', 'Related Attack Patterns', 'Execution Flow', 'Prerequisites', 'Skills Required', 'Resources Required', 'Indicators', 'Consequences', 'Mitigations', 'Example Instances', 'Related Weaknesses', 'Taxonomy Mappings', 'Notes']


[""'ID""]
'ID
1    
11                  
112             
114                        
115        
..          
698     
70      
700       
94        
98     

[177 rows x 1 columns]

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.7
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.11-arm64
Version               : #1 SMP Kali 6.8.11-1kali2 (2024-05-30)
machine               : aarch64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 24.1.1
Cython                : None
sphinx                : None
IPython               : 9.0.2
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'IO CSV']",,2025-04-08 12:32:18+00:00,2025-04-08 21:07:37+00:00,,0.3578587962962963
61252,BUG: AttributeError: 'SparseArray' object has no attribute 'round',"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df = pd.DataFrame([1.1,2.5,3,4.7], dtype = pd.SparseDtype())

hasattr(df, 'round')
# True

df.round()
# AttributeError: 'SparseArray' object has no attribute 'round'
```

### Issue Description

the sparsed `df` do has `round` method, but can not execute it

### Expected Behavior

`df` can execute `round` method

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.2
python-bits           : 64
OS                    : Linux
OS-release            : 3.10.0-1160.102.1.0.1.an7.x86_64
Version               : #1 SMP Sun Oct 29 06:40:18 CST 2023
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : en_US.utf8
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Sparse']",,2025-04-08 10:10:36+00:00,2025-04-08 21:14:41+00:00,,0.4611689814814815
61251,PERF: future_stack is too slow,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this issue exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this issue exists on the main branch of pandas.


### Reproducible Example

The future_stack is very slow compared to the previous implementation:

```python
import pandas as pd, numpy as np

df = pd.DataFrame(np.random.randn(5000, 5000))

%%time
df.stack(dropna=False)
# CPU times: user 49.4 ms, sys: 49.7 ms, total: 99.1 ms
# Wall time: 96 ms

%%time
df.stack(future_stack=True)
# CPU times: user 1.96 s, sys: 122 ms, total: 2.08 s
# Wall time: 2.08 s
```


### Installed Versions

<details>


INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.16
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.0-122-generic
Version               : #132-Ubuntu SMP Thu Aug 29 13:45:52 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0
pip                   : 24.0
Cython                : 3.0.7
sphinx                : 7.3.7
IPython               : 8.25.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.6.0
html5lib              : None
hypothesis            : 6.129.3
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.9.2
numba                 : 0.60.0
numexpr               : 2.10.0
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : 1.4.6
pyarrow               : 16.1.0
pyreadstat            : None
pytest                : 8.2.2
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.0
sqlalchemy            : 2.0.31
tables                : 3.9.2
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.22.0
tzdata                : 2024.1
qtpy                  : 2.4.1
pyqt5                 : None
</details>


### Prior Performance

_No response_","['Performance', 'Needs Triage']",,2025-04-08 08:39:36+00:00,2025-04-08 16:18:07+00:00,,0.31841435185185185
61250,BUG: Raise error if not busdaycalendar,"Closes #60647. Raises TypeError if anything other than `None` or `np.busdaycalendar` is passed to `calendar`. Also added test for this exception as well as a note in whatsnew

- [x] closes #60647 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-04-08 01:34:52+00:00,2025-05-19 16:16:29+00:00,,41.612233796296294
61249,BLD: Try installing older Cython for windows free threading build,"- [ ] closes #61242 (Replace xxxx with the GitHub issue number)

",['Build'],,2025-04-07 21:57:16+00:00,2025-04-09 17:56:30+00:00,,1.832800925925926
61248,CI Use released numpy for Windows wheels testing,Following #61249 this also used released numpy for testing on Windows free-threaded wheels.,['Build'],,2025-04-07 20:07:10+00:00,2025-04-10 16:46:26+00:00,,2.8606018518518517
61246,STY: Bump pre-commit checks,Supersedes https://github.com/pandas-dev/pandas/pull/61243,['Code Style'],,2025-04-07 17:46:30+00:00,2025-04-07 21:21:32+00:00,,0.1493287037037037
61244,BUG: Handle overlapping line and scatter on the same plot,"- [x] closes #61005
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Running the code from the issue above now shows a correct plot.
```python
import datetime
import matplotlib.pyplot as plt
import pandas as pd

datetime_list = [datetime.datetime(year=2025, month=1, day=1, hour=n) for n in range(23)]
y = [n for n in range(23)]
df = pd.DataFrame(columns=['datetime', 'y'])
for i, n in enumerate(datetime_list):
    df.loc[len(df)] = [n, y[i]]
fig, ax = plt.subplots(2, sharex=True)
df.plot.scatter(x='datetime', y='y', ax=ax[0])
df.plot(x='datetime', y='y', ax=ax[1])
```
![image](https://github.com/user-attachments/assets/bd2501ab-4b9c-4507-bb72-2686c27f2455)

",['Visualization'],,2025-04-07 16:50:39+00:00,2025-04-09 16:28:51+00:00,,1.9848611111111112
61243,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.9 ‚Üí v0.11.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.9...v0.11.4)
- [github.com/pre-commit/mirrors-clang-format: v19.1.7 ‚Üí v20.1.0](https://github.com/pre-commit/mirrors-clang-format/compare/v19.1.7...v20.1.0)
- [github.com/trim21/pre-commit-mirror-meson: v1.7.0 ‚Üí v1.7.2](https://github.com/trim21/pre-commit-mirror-meson/compare/v1.7.0...v1.7.2)
<!--pre-commit.ci end-->",[],,2025-04-07 16:29:50+00:00,2025-04-07 17:46:45+00:00,,0.05341435185185185
61242,No Windows free-threaded wheel available in scientific-python-nightly-wheels,"In scikit-learn we noticed there are no Windows free-threaded development wheel in [scientific-python-nightly-wheels](https://anaconda.org/scientific-python-nightly-wheels/pandas/files).

The reason seems to be that your Wheels builder has failed consistently for more than a week, see [build logs](https://github.com/pandas-dev/pandas/actions/workflows/wheels.yml?query=event%3Aschedule).

The failures only happen for Windows free-threaded i.e. `cp313t-win_amd64`. I had a quick look at one of the log there are almost 300 failures and plenty of them seem to be related to indexes with timestamps ...

One thing I did notice is that you are still using numpy development wheel for Windows free-threaded and I think using a released numpy may be good enough since numpy 2.2.4 (and probably a few earlier versions as well) has a free-threaded wheel for Windows, see [PyPI numpy info](https://pypi.org/project/numpy/#files).",[],,2025-04-07 15:06:16+00:00,2025-04-09 17:56:31+00:00,,2.1182291666666666
61241,DOC Update the awkward-pandas GitHub link,"In ecosystems.md, the awkward-pandas link should be:  
https://github.com/scikit-hep/awkward

The old link does not work:
https://awkward-pandas.readthedocs.io/

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-04-06 23:18:27+00:00,2025-04-07 16:35:30+00:00,,0.7201736111111111
61240,BLD/CI: Try to fix the Windows Python 3.13t wheel build,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Build', 'Windows', 'Python 3.13']",,2025-04-06 15:27:16+00:00,2025-04-10 12:26:52+00:00,,3.874722222222222
61239,made changes,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-06 12:42:28+00:00,2025-04-06 12:42:37+00:00,,0.00010416666666666667
61238,"DOC: Added docstrings to min, max, and reso","Closes #59458

Added docstrings to `min`, `max`, and `resolution` for class `Timestamp`. Used same approach as seen in PR #61119

- [x] closes #59458 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-04-06 11:42:54+00:00,2025-04-07 16:57:53+00:00,,1.218738425925926
61237,ENH: Add dropna parameter to Series.unique() (fixes #61209),"- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

### Changes:
- Added `dropna` parameter to `Series.unique()` (default=True)
- Ensured backward compatibility
- Added comprehensive test coverage

### Notes:
- Changes split into logical commits:
  1. Core functionality (ENH)
  2. Test coverage (TST)",[],,2025-04-06 11:00:59+00:00,2025-05-15 16:10:28+00:00,,39.21491898148148
61236,BUG: Pyarrow timestamp support for map() function,"- [x] closes #61231  (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Stale', 'Arrow']",,2025-04-06 06:10:47+00:00,2025-05-21 16:13:33+00:00,,45.41858796296296
61235,ENH: Add dropna parameter to Series.unique() (fixes #61209),"- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-04-05 20:30:17+00:00,2025-05-15 16:10:56+00:00,,39.819895833333334
61234,BUG: Fix DatetimeIndex timezone preservation when joining indexes with same timezone but different units,"- [x] closes #60080
- [x] [Tests added and passed]
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations]
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Dtype Conversions', 'Timezones']",,2025-04-05 17:08:57+00:00,2025-05-30 18:21:53+00:00,,55.05064814814815
61233,BUG:  Fix scatter plot colors in groupby context to match line plot behavior (#59846),"- [x] closes #59846
- [x] [Tests added and passed]
- [x] All [code checks passed]
- [x] Added [type annotations]
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Groupby', 'Visualization', 'Stale']",,2025-04-05 16:16:14+00:00,2025-07-28 17:19:06+00:00,,114.04365740740741
61232,ENH: The method of obtaining a certain cell or slice of the dataframe is confusing and unclear,"### Feature Type

- [ ] Adding new functionality to pandas

- [x] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

The method of obtaining a certain cell or slice of the dataframe is confusing and unclear, such as using `loc`, `iloc`, `at`, `iat`, and the operator `[]`, etc. For example, `df.loc[row_label, col_label]` and `df.iloc[row_index, col_index]`. If `loc` is a property, it is better to be a variable but now it is a verb or something rather than a df buffer. The user wants to take the cell value, so the behavior of `loc` is like a member function and the `()` operator should be used to pass parameters. However, you are using the operator `[]`, but the object of the operator `[]` is usually an instance, which is a confusing place.

And when taking two columns or slices at the same time, for example, taking one column and one row, the expression `value = df.loc[1, 'B']`, where the operator `[]` represents the horizontal and vertical coordinate information, and taking two columns and one row, `row_data = df.loc['row_label', ['col1', 'col2']]`, where the second operator `[]` has both vertical coordinate information but behaves like a `list` or `tuple` instead of the former, this is another confusing aspect.

In mathematics, the coordinate values such as (3, 4) represent the horizontal and vertical coordinates respectively, as well as the `()` operator. I hope that the operation rules you define should conform to common customs or competition analysis or benchmarking such as numpy. thank you.

### Feature Description

n/a

### Alternative Solutions

n/a

### Additional Context

_No response_","['Enhancement', 'Needs Triage', 'Closing Candidate']",,2025-04-04 16:27:25+00:00,2025-08-05 16:30:20+00:00,,123.00202546296296
61229,BUG: Fix #61222: Keep index name when resampling with pyarrow dtype,"- [x] closes #61222
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Resample', 'Arrow']",,2025-04-03 21:39:09+00:00,2025-04-07 16:55:09+00:00,,3.8027777777777776
61228,Fix false friends in implicit string concatenation in tests,"[In a PR](https://github.com/nvim-treesitter/nvim-treesitter/pull/7788) about how to syntax-highlight Python docstrings, @rmuir and I discovered that instead of implicit concatenation of strings a string plus a docstring have been written.

Since this is a subtle one, I want to briefly show the differences:
 
The false friend of implicit string concatenation
```python
# var == ""foo""

var = ""foo""  # <-- no implicit string concatenation
""bar""        # <-- docstring, legal for the bytecode compiler, against PEP 257
```

can be fixed for example with surrounding brackets:
```python
# var == ""foobar""

var = (
    ""foo""    # <-- gets implicitly concatenated
    ""bar""
)
```

I felt free to fix the ones I found right away such that the tests pass.

I searched with [`ripgrep`](https://github.com/BurntSushi/ripgrep) like so:

```sh
# in path/to/cloned/pandas
rg -A 1 -B 2 -U ' = f?""[^""]*""\s+f?""[^""]+""\s*' pandas/
```

I am pretty confident, but not entirely sure, to have catched all cases. :thinking: ",['Testing'],,2025-04-03 18:52:35+00:00,2025-04-03 21:53:11+00:00,,0.12541666666666668
61227,DOC Removed excessive Plotly links in ecosystem.md,"Removed excessive Plotly links in `ecosystem.md`.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-04-03 18:20:10+00:00,2025-04-03 18:41:21+00:00,,0.014710648148148148
61226, BUG: Fix #61221: Exception with unstack(sort=False) and NA in index. ,"- [ ‚úîÔ∏è ] closes #61221  
- [‚úîÔ∏è ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [‚úîÔ∏è ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [‚úîÔ∏è ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ‚úîÔ∏è] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-04-03 16:05:18+00:00,2025-07-28 17:18:14+00:00,,116.05064814814814
61225,BUG: Fix #57608: queries on categorical string columns in HDFStore.select() return unexpected results.,"In function __init__() of class Selection (pandas/core/io/pytables.py), the method self.terms.evaluate() was not returning the correct value for the where condition. The issue stemmed from the function convert_value() of class BinOp (pandas/core/computation/pytables.py), where the function searchedsorted() did not return the correct index when matching the where condition in the metadata (categories table). Replacing searchsorted() with np.where() resolves this issue.

- [x] closes #57608
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['IO HDF5'],,2025-04-03 14:15:29+00:00,2025-05-20 15:57:34+00:00,,47.0708912037037
61224,ENH: Implement loading and dumping to and from YAML,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Hi,

I am nowadays mostly working with YAML and moved away from JSON, given that it has proven far superior in terms of userfriendlines (e.g. readability). However I am missing a quick way to load and dump data from yaml to pandas.

### Feature Description

```python
df = pd.from_yaml('/path/to/my/yaml/file.yml')
df.to_yaml('/path/to/my/yaml/file.yml')
```

### Alternative Solutions

I can write my wrapper to do all the dirty work myself for now.

### Additional Context

_No response_","['Enhancement', 'Needs Triage']",,2025-04-03 11:30:41+00:00,2025-04-03 15:12:31+00:00,,0.15405092592592592
61222,"BUG: Index name lost when using ""resample"" with pyarrow dtypes","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# Create a df with DatetimeIndex called ""timestamp"" and native pandas dtype
native_df = pd.DataFrame(
    {'value': [23.5, 24.1, 22.8, 25.3, 23.9]},
    index=pd.date_range(start='2025-01-01 00:00:00', end='2025-01-01 04:00:00', freq='h'),
)
native_df.index.name = ""timestamp""

# Create a similar df with pyarrow dtypes
pyarrow_df = native_df.copy()
pyarrow_df.index = pyarrow_df.index.astype('timestamp[ns][pyarrow]')
pyarrow_df[""value""] = pyarrow_df[""value""].astype('float64[pyarrow]')

native_df.resample(""2h"").mean().reset_index()[""timestamp""] # OK
pyarrow_df.resample(""2h"").mean().reset_index()[""timestamp""] # KeyError: 'timestamp'
```

### Issue Description

The `resample` forget the name of the index when using `pyarrow` dtypes. 

By the way, I notice that `DatetimeIndex` are converted to `Index` when using `pyarrow` dtypes. Maybe it is related?

See concrete example in screenshot
![Image](https://github.com/user-attachments/assets/a9b1b5f7-907d-4910-abb4-5be186bcb2d9)



### Expected Behavior

The `resample` methods is expected to behave in the same way for `pyarrow` and `native` dtypes.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
python                : 3.12.8
python-bits           : 64
OS                    : Linux
OS-release            : 5.10.234-225.910.amzn2.x86_64
Version               : #1 SMP Fri Feb 14 16:52:40 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : C.UTF-8
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.2
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.3.2
scipy                 : 1.15.2
sqlalchemy            : 2.0.38
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Resample', 'Arrow']",,2025-04-03 10:37:17+00:00,2025-04-07 16:55:10+00:00,,4.262418981481481
61220,ENH: Create infrastructure for translations,"Hi all,

This PR is a proposal for adding the translations infrastructure to the pandas web page. 

Following the discussion in #56301, we (a group of folks working on the Scientific Python grant) have been working to set up infrastructure and translate the contents of the pandas web site. As of this moment, we have 100% translations for the pandas website into Spanish and Brazilian Portuguese, with other languages available for translation (depending on volunteer translators).

What this PR **does**:

* Reorganizes web site sources file structure for multilanguage support, with a new ""pt"" folder which, in the future, can hold Brazilian Portuguese translations pulled in from Crowdin.
* Adds a language switcher to the top of the page
* Adds language option to web pages command line builder

What this PR **does not** do:

* Add actual translations for the full contents of the website. This needs to be done in a follow-up.

This PR is a draft, as we are looking for feedback on the approach and appetite for this change. We would love to have more languages added, and we firmly believe having the translations infrastructure may help recruit new translators which will then see their work published on the actual website. We can also work on adding a ""Translations team"" to the pandas website if desired, with data pulled in automatically from Crowdin. 

To build, this will require the following command:

```
python pandas_web.py pandas/content --target-path build --languages en pt
```

If you want to check out other related work, please take a look at https://github.com/scipy/scipy.org/pull/617

Some of this is still work in progress, and @goanpeca is working on automations to make synchronizing and updating the translations easier- he can also help answer questions on the overall integration with Crowdin.

Any feedback is appreciated, and we are happy to answer questions and discuss more if needed.

Cheers!

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Web'],,2025-04-02 19:19:57+00:00,2025-05-12 07:46:13+00:00,,39.518240740740744
61219,Fix #58421: Index[timestamp[pyarrow]].union with itself return object type,"- [X] closes #58421
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

### Fix Summary:
Previously, the `_make_concat_multiindex` method could silently downgrade extension dtypes (e.g., to object) when creating levels. This PR ensures that the `_concat_indexes` helper uses the correct dtype-aware construction (`array(..., dtype=...)`) to preserve the original dtype of the first index.

### Test added:
Added a test in `pandas/tests/frame/methods/test_concat_arrow_index.py` that covers the preservation of extension dtypes when using `pd.concat` with `keys=` that triggers MultiIndex creation.

The test creates two DataFrames with `timestamp[pyarrow]` indices, then concatenates them with `pd.concat(..., keys=...)` and asserts that:
- The resulting index is a `MultiIndex`
- The second level (`levels[1]`) retains the `ArrowDtype('timestamp[us][pyarrow]')` instead of being downgraded to `object`.

This ensures the dtype preservation fix is validated and regressed against.
",[],,2025-04-02 18:45:22+00:00,2025-05-15 16:11:15+00:00,,42.892974537037034
61218,QST: Should the absence of tzdata package affect the performance in any way ?,"### Research

- [x] I have searched the [[pandas] tag](https://stackoverflow.com/questions/tagged/pandas) on StackOverflow for similar questions.

- [x] I have asked my usage related question on [StackOverflow](https://stackoverflow.com).


### Link to question on StackOverflow

https://stackoverflow.com/search?page=3&tab=Relevance&pagesize=30&q=pandas%20AND%20tzdata%20&searchOn=3

### Question about pandas

We are on pandas 1.5.3.   We are investigating some performance bottlenecks.  At this point, we are not sure where the problem lies.  However, we have a consistent pattern of observations.

We noticed that when `tzdata==2025.2` was uninstalled, there was a severe degradation in performance (> 10x).

Upon further investigations and eliminations, we arrived at the following matrix:

## Good perf-1
```
pandas==2.2.3
tzdata==2025.2
```

## Good perf-2
```
pandas==1.5.3
tzdata==2025.2
```

## Bad perf
No `tzdata`
```
pandas==1.5.3
```

Any suggestions ?




Is there any logic in any part of Pandas that relies on `tzdata`  ?

Thanks,
Sau



","['Usage Question', 'Needs Info']",,2025-04-02 15:53:10+00:00,2025-08-05 17:04:53+00:00,,125.04980324074074
61217,BUG: unstack incorrectly reshuffles data when sort=False,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
a = pd.Series([f'a{i}' for i in range(10)])
b = pd.Series([f'b{i}' for i in range(10)])

ser = pd.concat({'a': a, 'b': b})  # multi-indexed series e.g. ('a', 0) = 'a0'
df = ser.unstack(0, sort=False)  # dataframe with integer index and columns=['a','b'], some a values end up in b column and vice-versa
```

### Issue Description

When unstacking a multi-indexed series (or dataframe), passing sort=False fails to preserve the original mapping of multi-index keys to values. In other words, the resulting ""a"" column has a mix of ""a"" and ""b""-prefixed values.

### Expected Behavior

I would expect sort=False to prevent a sort of the newly produced column names but preserve the mapping of multi-index keys to values based on the following from the documentation: ""sort: Sort the level(s) in the resulting MultiIndex columns.""

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.9
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : AMD64 Family 25 Model 97 Stepping 2, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']","{'login': 'gsmll', 'id': 76072280, 'node_id': 'MDQ6VXNlcjc2MDcyMjgw', 'avatar_url': 'https://avatars.githubusercontent.com/u/76072280?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/gsmll', 'html_url': 'https://github.com/gsmll', 'followers_url': 'https://api.github.com/users/gsmll/followers', 'following_url': 'https://api.github.com/users/gsmll/following{/other_user}', 'gists_url': 'https://api.github.com/users/gsmll/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/gsmll/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/gsmll/subscriptions', 'organizations_url': 'https://api.github.com/users/gsmll/orgs', 'repos_url': 'https://api.github.com/users/gsmll/repos', 'events_url': 'https://api.github.com/users/gsmll/events{/privacy}', 'received_events_url': 'https://api.github.com/users/gsmll/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-04-02 14:12:08+00:00,2025-04-03 02:51:31+00:00,gsmll,0.527349537037037
61216,BUG: OverflowError when fillna on DataFrame with a pd.Timestamp (#61208) ,"- Now correctly raises OutOfBoundsDatetime
- Added test_fillna_out_of_bounds_datetime()

- [x] closes #61208
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions. (does not apply)
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


### Fix for `fillna` with Out-of-Bounds Datetime Values

**Issue**: Using `fillna` on a `datetime64[ns]` column with an out-of-bounds timestamp (e.g., `'0001-01-01'`) raised an `AssertionError` instead of the expected `OutOfBoundsDatetime`.

**Fix**: Modified the `where` method in `pandas/core/internals/blocks.py` to catch and re-raise `OutOfBoundsDatetime` directly, preventing the `AssertionError`.


**Fix (`inplace=True`)**: Modified the `putmask` method in `pandas/core/internals/blocks.py` to catch and re-raise `OutOfBoundsDatetime` directly, preventing the `AssertionError`.


**Test Added**:
- Created `test_fillna_out_of_bounds_datetime` in `pandas/tests/frame/methods/test_fillna.py`.
- The test:
  - Sets up a DataFrame with a `datetime64[ns]` column containing `NaT`.
  - Attempts to fill `NaT` with `'0001-01-01'`.
  - Expects `OutOfBoundsDatetime`.
","['Bug', 'Missing-data', 'Error Reporting', 'Timestamp']",,2025-04-02 10:16:22+00:00,2025-04-14 16:58:58+00:00,,12.279583333333333
61215,DOC: Fix ES01 for pandas.api.extensions.ExtensionDtype,"fixes

```
pandas.api.extensions.ExtensionDtype ES01",['Docs'],,2025-04-02 06:23:50+00:00,2025-04-02 16:12:35+00:00,,0.4088541666666667
61214,Restrict clipping of DataFrame.corr only when cov=False," Closes #61154 `DataFrame.corr` was clipped between `-1` and `1` to handle numerical precision errors. However, this was done regardless of whether `cov` equals `True` or `False`, and should instead only be done when `cov=False`.

- [x] closes #61154 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['cov/corr'],,2025-04-02 02:37:04+00:00,2025-04-03 21:55:24+00:00,,1.8043981481481481
61213,BUG: DataFrame.corr clips values when cov=True,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

In [50]: x = pd.DataFrame({""A"": [1, 2, None, 4], ""B"": [2, 4, None, 9]})

In [51]: x.cov()
Out[51]:
     A    B
A  1.0  1.0
B  1.0  1.0

In [52]: x.dropna().cov()
Out[52]:
          A     B
A  2.333333   5.5
B  5.500000  13.0
```

### Issue Description

Stemming from #61154. `DataFrame.corr` was clipped between `-1` and `1` to handle numerical precision errors. However, this was done regardless of whether `cov` equals `True` or `False`, and should instead only be done when `cov=False`.

### Expected Behavior

import pandas as pd

In [50]: x = pd.DataFrame({""A"": [1, 2, None, 4], ""B"": [2, 4, None, 9]})

In [51]: x.cov()
Out[51]:
     A    B
A  1.0  1.0
B  1.0  1.0

In [52]: x.dropna().cov()
Out[52]:
     A    B
A  1.0  1.0
B  1.0  1.0

### Installed Versions

<details>

commit                : cdc9e952f139746c2e6816997d82b389f605ec58
python                : 3.10.16
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:22 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6041
machine               : x86_64
processor             : i386
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+2006.gcdc9e952f1
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 8.34.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2025.3.0
html5lib              : 1.1
hypothesis            : 6.130.4
gcsfs                 : 2025.3.0
jinja2                : 3.1.6
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.9
pymysql               : 1.4.6
pyarrow               : 19.0.1
pyreadstat            : 1.2.8
pytest                : 8.3.5
python-calamine       : None
pytz                  : 2025.2
pyxlsb                : 1.0.10
s3fs                  : 2025.3.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.40
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Needs Triage']",,2025-04-02 02:20:50+00:00,2025-04-02 02:38:39+00:00,,0.012372685185185184
61212,BUG: OverflowError when fillna on DataFrame with a pd.Timestamp (#61208),"- [x] closes #61208
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions. (Does not apply)
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

### Fix for `fillna` with Out-of-Bounds Datetime Values

**Issue**: Using `fillna` on a `datetime64[ns]` column with an out-of-bounds timestamp (e.g., `'0001-01-01'`) raised an `AssertionError` instead of the expected `OutOfBoundsDatetime`.

**Fix**: Modified the `putmask` method in `pandas/core/internals/blocks.py` to catch and re-raise `OutOfBoundsDatetime` directly, preventing the `AssertionError`.

**Test Added**:
- Created `test_fillna_out_of_bounds_datetime` in `pandas/tests/frame/methods/test_fillna.py`.
- The test:
  - Sets up a DataFrame with a `datetime64[ns]` column containing `NaT`.
  - Attempts to fill `NaT` with `'0001-01-01'`.
  - Expects `OutOfBoundsDatetime`.",[],,2025-04-02 00:08:59+00:00,2025-04-02 09:07:19+00:00,,0.3738425925925926
61211,BUG: Preserve extension dtypes in MultiIndex during concat (#58421),"- [X] closes #58421
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

### Fix Summary:
Previously, the `_make_concat_multiindex` method could silently downgrade extension dtypes (e.g., to object) when creating levels. This PR ensures that the `_concat_indexes` helper uses the correct dtype-aware construction (`array(..., dtype=...)`) to preserve the original dtype of the first index.

### Test added:
Added a test in `pandas/tests/frame/methods/test_concat_arrow_index.py` that covers the preservation of extension dtypes when using `pd.concat` with `keys=` that triggers MultiIndex creation.

The test creates two DataFrames with `timestamp[pyarrow]` indices, then concatenates them with `pd.concat(..., keys=...)` and asserts that:
- The resulting index is a `MultiIndex`
- The second level (`levels[1]`) retains the `ArrowDtype('timestamp[us][pyarrow]')` instead of being downgraded to `object`.

This ensures the dtype preservation fix is validated and regressed against.",[],,2025-04-01 23:19:47+00:00,2025-04-02 18:26:52+00:00,,0.7965856481481481
61208,BUG: OverflowError when fillna on DataFrame with a pd.Timestamp,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

df = pd.DataFrame({
'datetime' : pd.date_range('1/1/2011', periods=3, freq='h'),
'value' : [1,2,3]
})

df.iloc[0,0] = None
df.fillna(pd.Timestamp('0001-01-01'), inplace=True)
```

### Issue Description

Issue is similar to [this closed issue without a reproducible example](https://github.com/pandas-dev/pandas/issues/56502 ).

A DataFrame that has a column with datetime64[ns] with NaT gets an error if trying to fill null values with a pd.Timestamp that lies outside the range of the given precision.

### Expected Behavior

The null values in the DataFrame should be replaced with the provided TimeStamp or an error should be provided to the user that the Timestamps have incompatible precisions and ranges.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------------
commit : 0691c5cf90477d3503834d983f69350f250a6ff7
python : 3.10.8
python-bits : 64
OS : Windows
OS-release : 10
Version : 10.0.17763
machine : AMD64
processor : Intel64 Family 6 Model 143 Stepping 8, GenuineIntel
byteorder : little
LC_ALL : None
LANG : None
LOCALE : German_Switzerland.1252

pandas : 2.2.3
numpy : 2.2.4
pytz : 2025.2
dateutil : 2.9.0.post()
pip : 25.0.1
Cython : None
sphinx : None
IPython : None
adbc-driver-postgresql: None
adbc-driver-sqlite : None
bs4 : None
blosc : None
bottleneck : None
dataframe-api-compat : None
fastparquet : None
fsspec : None
html5lib : None
hypothesis : None
gcsfs : None
jinja2 : None
lxml.etree : None
matplotlib : None
numba : None
numexpr : None
odfpy : None
openpyxl : None
pandas_gbq : None
psycopg2 : None
pymysql : None
pyarrow : None
pyreadstat : None
pytest : None
python-calamine : None
pyxlsb : None
s3fs : None
scipy : None
sqlalchemy : None
tables : None
tabulate : None
xarray : None
xlrd : None
xlsxwriter : None
zstandard : None
tzdata : 2025.2
qtpy : None
pyqt5 : None
</details>
","['Bug', 'Error Reporting', 'Timestamp']","{'login': 'PedroM4rques', 'id': 155019955, 'node_id': 'U_kgDOCT1qsw', 'avatar_url': 'https://avatars.githubusercontent.com/u/155019955?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/PedroM4rques', 'html_url': 'https://github.com/PedroM4rques', 'followers_url': 'https://api.github.com/users/PedroM4rques/followers', 'following_url': 'https://api.github.com/users/PedroM4rques/following{/other_user}', 'gists_url': 'https://api.github.com/users/PedroM4rques/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/PedroM4rques/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/PedroM4rques/subscriptions', 'organizations_url': 'https://api.github.com/users/PedroM4rques/orgs', 'repos_url': 'https://api.github.com/users/PedroM4rques/repos', 'events_url': 'https://api.github.com/users/PedroM4rques/events{/privacy}', 'received_events_url': 'https://api.github.com/users/PedroM4rques/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-31 15:19:29+00:00,2025-04-14 16:59:00+00:00,PedroM4rques,14.069108796296296
61207,Fix #60494: query doesn't work on DataFrame integer column names,"- [x] closes #60494
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
Some io code checks failed but they were already failing before the bugfix.
Function _get_cleaned_column_resolvers ignores integer column names, so when it is called on eval function, it returns empty columns which it shouldn't since there is an integer column. Converting the integer columns to strings before calling the _get_cleaned_column_resolvers on eval fucntion fixes this.",['expressions'],,2025-03-31 08:36:24+00:00,2025-04-01 16:50:16+00:00,,1.342962962962963
61206,BUG: round on object columns no longer raises a TypeError,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df=pd.DataFrame(data=['foo'],columns=['bar'])
df.loc[0,'bar']=0.2
df['bar'].round()

Out[4]: 
0    0.2
```

### Issue Description

pd.Series.round() appears to have changed behaviour in 2.2.3 compared to 2.1.4.
In previous versions, attempting to round a column with ""object"" dtype would raise a TypeError. In 2.2.3, round now silently returns the same column, without applying any rounding.

I'm not sure if there is some underlying change that causes this behaviour, but together with the removal of downcasting from a variety of methods (ffill, replace, fillna,...) this change in behaviour seems dangerous without any warnings.

### Expected Behavior

import pandas as pd
df=pd.DataFrame(data=['foo'],columns=['bar'])
df.loc[0,'bar']=0.2
df['bar'].round()

TypeError: loop of ufunc does not support argument 0 of type float which has no callable rint method

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.9.18
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 142 Stepping 12, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United Kingdom.1252
pandas                : 2.2.3
numpy                 : 1.26.3
pytz                  : 2023.3.post1
dateutil              : 2.8.2
pip                   : 23.3.1
Cython                : None
sphinx                : None
IPython               : 8.15.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.2
blosc                 : None
bottleneck            : 1.3.6
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.2
lxml.etree            : 4.9.3
matplotlib            : 3.8.0
numba                 : 0.60.0
numexpr               : 2.8.7
odfpy                 : None
openpyxl              : 3.1.0
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 7.4.0
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.11.4
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : 2023.12.0
xlrd                  : 2.0.1
xlsxwriter            : 3.1.1
zstandard             : 0.19.0
tzdata                : 2023.3
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Regression', 'Error Reporting', 'Numeric Operations']","{'login': 'KevsterAmp', 'id': 109636487, 'node_id': 'U_kgDOBojrhw', 'avatar_url': 'https://avatars.githubusercontent.com/u/109636487?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/KevsterAmp', 'html_url': 'https://github.com/KevsterAmp', 'followers_url': 'https://api.github.com/users/KevsterAmp/followers', 'following_url': 'https://api.github.com/users/KevsterAmp/following{/other_user}', 'gists_url': 'https://api.github.com/users/KevsterAmp/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/KevsterAmp/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/KevsterAmp/subscriptions', 'organizations_url': 'https://api.github.com/users/KevsterAmp/orgs', 'repos_url': 'https://api.github.com/users/KevsterAmp/repos', 'events_url': 'https://api.github.com/users/KevsterAmp/events{/privacy}', 'received_events_url': 'https://api.github.com/users/KevsterAmp/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-31 08:18:12+00:00,2025-05-21 00:33:34+00:00,KevsterAmp,50.677337962962966
61205,Bump pypa/cibuildwheel from 2.23.1 to 2.23.2,"Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 2.23.1 to 2.23.2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/releases"">pypa/cibuildwheel's releases</a>.</em></p>
<blockquote>
<h2>v2.23.2</h2>
<ul>
<li>üêõ Workaround an issue with pyodide builds when running cibuildwheel with a Python that was installed via UV (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2328"">#2328</a> via <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2331"">#2331</a>)</li>
<li>üõ† Dependency updates, including a manylinux update that fixes an <a href=""https://redirect.github.com/pypa/manylinux/issues/1760"">'undefined symbol' error</a> in gcc-toolset (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2334"">#2334</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/blob/main/docs/changelog.md"">pypa/cibuildwheel's changelog</a>.</em></p>
<blockquote>
<h3>v2.23.2</h3>
<p><em>24 March 2025</em></p>
<ul>
<li>üêõ Workaround an issue with pyodide builds when running cibuildwheel with a Python that was installed via UV (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2328"">#2328</a> via <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2331"">#2331</a>)</li>
<li>üõ† Dependency updates, including a manylinux update that fixes an <a href=""https://redirect.github.com/pypa/manylinux/issues/1760"">'undefined symbol' error</a> in gcc-toolset (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2334"">#2334</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/d04cacbc9866d432033b1d09142936e6a0e2121a""><code>d04cacb</code></a> Bump version: v2.23.2</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/5f4e019684661085adb6558969c7fd389a532174""><code>5f4e019</code></a> [2.x] Update dependencies (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2334"">#2334</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/2efa648f38e83a421aae82bc80002f8cabf92be7""><code>2efa648</code></a> fix: always resolve --python argument (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2328"">#2328</a>) (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2331"">#2331</a>)</li>
<li>See full diff in <a href=""https://github.com/pypa/cibuildwheel/compare/v2.23.1...v2.23.2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/cibuildwheel&package-manager=github_actions&previous-version=2.23.1&new-version=2.23.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","['Build', 'CI', 'Dependencies']",,2025-03-31 08:13:04+00:00,2025-03-31 17:22:55+00:00,,0.3818402777777778
61203,BUG: fix to_json on period,"- [x] closes #55490 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-03-30 17:35:03+00:00,2025-07-28 17:18:48+00:00,,119.98871527777777
61202,DOC: Simplify pandas theme footer by removing social buttons and stre‚Ä¶,"I'll help you complete the pull request form with the appropriate information. Here's what you should fill in:

Title:
```
DOC: Simplify pandas theme footer
```

Description:
```markdown
This PR simplifies the pandas theme footer by:
- Removing social media buttons (which are already present in the navigation bar)
- Streamlining the copyright text to be more concise
- Adding proper CSS styling for better visual appearance

The changes make the footer cleaner and more focused while maintaining essential information. The social media links remain accessible through the navigation bar.

- [x] closes #51536
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
```

Notes about the checkboxes:
1. ‚úÖ `closes #51536` - Checked because this PR addresses issue #51536
2. ‚úÖ `All code checks passed` - Checked because the changes are purely documentation/CSS and don't require tests
3. ‚ùå `Added type annotations` - Unchecked because we only modified HTML and CSS files
4. ‚ùå `Added an entry in whatsnew` - Unchecked because this is a documentation-only change

The changes look good in the diff view:
1. Removed the social media buttons from the footer
2. Simplified the copyright text
3. Added proper CSS styling for the footer

The PR follows pandas' contribution guidelines by:
- Using the correct prefix (DOC:)
- Keeping changes focused and minimal
- Including proper CSS styling
- Maintaining accessibility
- Following the existing code style

Would you like me to help you with anything else regarding the pull request?
","['Docs', 'Web']",,2025-03-30 05:21:34+00:00,2025-03-30 22:03:33+00:00,,0.6958217592592593
61201,Fix missing blank line in DataFrame.round docstring (PEP 257 style),"This PR fixes a minor style issue in the docstring of `DataFrame.round()`.

### What Changed:
- Adds a missing blank line before the closing triple quotes (`""""""`)
- Ensures compliance with PEP 257 and pandas' internal docstring style guidelines
- Helps maintain clean parsing for automated doc tools and improves readability

This is a **non-functional, formatting-only change** intended to improve internal consistency across the API documentation.

---

### ‚úÖ Checklist

- [ ] closes #xxxx (No issue to close ‚Äî docstring formatting only)
- [ ] Tests added and passed (Not applicable)
- [x] All code checks passed (pre-commit and linting compliant)
- [ ] Added type annotations (Not applicable)
- [ ] Added an entry in `doc/source/whatsnew/` (Not applicable for style-only fix)

Author: Michael Alexander Montoya (@cureprotocols)
",['Docs'],,2025-03-30 03:48:16+00:00,2025-03-30 17:11:29+00:00,,0.5577893518518519
61200,BUG: date comparison fails when series is all pd.NaT values,"- [x] closes #61188 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Datetime', 'Missing-data']",,2025-03-30 00:45:01+00:00,2025-04-15 12:42:00+00:00,,16.497905092592593
61199,BUG: Fix Series comparison fails when index dtypes differ (object vs string) (#61099),"- [x] closes #61099
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.",[],,2025-03-29 23:50:02+00:00,2025-04-01 23:28:12+00:00,,2.984837962962963
61198,BUG: Fix AttributeError in pd.eval for method calls on binary operations,"- [x] closes #61175 
- [x] [Tests added and passed] if fixing a bug or adding a new feature.
- [x] All [code checks passed]
- [x] Added [type annotations] to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.","['Bug', 'expressions']",,2025-03-29 18:36:26+00:00,2025-03-31 16:52:36+00:00,,1.9278935185185184
61197,ENH: Add a new parameter to pandas.read_csv #61172,"- [x] closes #61172
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

### Notes:
I tried to fix this issue by adding a new parameter named `return_empty` for `pandas.read_csv` which is by default _**False**_ and will return an empty DataFrame if set to _**True**_.

I am not familiar with Tests and didn't test it but should not break anythings.",[],,2025-03-29 16:29:35+00:00,2025-03-29 18:34:44+00:00,,0.08690972222222222
61196,BUG: `to_datetime()` warns unnecessarily that format cannot be inferred,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
pd.to_datetime(['2020-01-01T20:20:20', '2020-01-01T20:21:20'])
```

### Issue Description

This produces the following warning even though the format is inferable:

```
UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
```

Digging deeper, this warning occurs only when the year = concatenated hour and minute in the first element of the list, e.g. year = 2020, hour = 20, minute = 20.

### Expected Behavior

`to_datetime()` should behave just as it does when this unique condition does not hold.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.9
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:24 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6030
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.1.3
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : 7.3.7
IPython               : 8.30.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.12.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : 0.61.0
numexpr               : 2.10.1
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : 2024.12.0
scipy                 : 1.15.1
sqlalchemy            : 2.0.37
tables                : 3.10.2
tabulate              : 0.9.0
xarray                : 2024.11.0
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2023.3
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Bug', 'Datetime', 'Warnings']",,2025-03-28 21:49:48+00:00,2025-03-29 12:30:42+00:00,,0.6117361111111111
61195,DOC: User Guide Page on user-defined functions,"- [x] closes #61126 
- [ ] ~[Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~
- [ ] ~All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).~
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~
","['Docs', 'Apply']",,2025-03-28 19:15:48+00:00,2025-05-18 19:31:46+00:00,,51.01108796296296
61193,BUG: Fix pyarrow categoricals not working for pivot and multiindex,"- [X] closes #53051
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

<details>
<summary>Disclaimer</summary>
THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

</details>
","['Reshaping', 'Arrow']",,2025-03-28 09:10:56+00:00,2025-04-14 17:00:04+00:00,,17.32578703703704
61192,Feature/guepard pandas,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-28 02:43:32+00:00,2025-03-28 02:44:07+00:00,,0.0004050925925925926
61190,Update guidance on CFLAGS,"I recently discovered that setting the flags like this also interferes with Meson's ability to look up a caching tool like ccache or sccache. Rather than appending to these, I think its best to just unset them entirely while developing",['Docs'],,2025-03-27 18:25:45+00:00,2025-03-28 20:12:26+00:00,,1.0740856481481482
61189,BUG: \0 null bytes in `str` not preserved in `pandas.CategoricalIndex` or `pandas.MultiIndex`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
from sys import version_info as py_version_info
from pandas import __version__ as pd_version

assert py_version_info[:3] == (3, 13, 2)
assert pd_version == '2.2.3' or pd_version == '3.0.0.dev0+2028.gb64f438cc8'

from pandas import CategoricalIndex, MultiIndex

entities = [b'abc', b'abc\0']

# CORRECT
cat = CategoricalIndex(entities)
assert cat.tolist() == entities
assert len({*cat.tolist()}) == len({*entities})

# CORRECT
idx = MultiIndex.from_product([entities])
assert idx.get_level_values(0).tolist() == entities
assert len({*idx.get_level_values(0).tolist()}) == len({*entities})

entities = ['abc', 'abc\0']

# INCORRECT
cat = CategoricalIndex(entities)
assert cat.tolist() != entities
assert len({*cat.tolist()}) < len({*entities})

# INCORRECT
idx = MultiIndex.from_product([entities])
assert idx.get_level_values(0).tolist() != entities
assert len({*idx.get_level_values(0).tolist()}) < len({*entities})

entities = ['abc', 'abc\0def']

# INCORRECT
cat = CategoricalIndex(entities)
assert cat.tolist() != entities
assert len({*cat.tolist()}) < len({*entities})

# INCORRECT
idx = MultiIndex.from_product([entities])
assert idx.get_level_values(0).tolist() != entities
assert len({*idx.get_level_values(0).tolist()}) < len({*entities})
```

### Issue Description

When constructing a `pandas.CategoricalIndex` or `pandas.MultiIndex` from Python `str` values, any code points following a '\0' are discarded. This does not occur with `bytes` inputs.

### Expected Behavior

The null bytes should be preserved exactly.

### Installed Versions

<details>
>>> from pandas import show_versions
>>> show_versions() # trimmed

INSTALLED VERSIONS
------------------
commit                : b64f438cc8079d441331396fbac1e2dc61b26af9
python                : 3.13.2
python-bits           : 64
OS                    : Linux
OS-release            : 6.12.20-1-lts
Version               : #1 SMP PREEMPT_DYNAMIC Sun, 23 Mar 2025 08:02:10 +0000
machine               : x86_64
processor             :
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+2028.gb64f438cc8
numpy                 : 2.3.0.dev0+git20250325.2a6f4f0
dateutil              : 2.9.0.post0
pip                   : 24.3.1
tzdata                : 2025.2
</details>","['Bug', 'Algos', 'Strings']",,2025-03-27 15:38:25+00:00,2025-03-28 20:44:37+00:00,,1.2126388888888888
61188,BUG: date comparison fails when series is all pd.NaT values,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
from datetime import datetime

s = pd.Series([pd.NaT, ""1/1/2020 10:00:00""])
s = pd.to_datetime(s)
print(s.dt.date.le(datetime.now().date()))
# 0    False
# 1     True
# dtype: bool

s = pd.Series([pd.NaT, pd.NaT])
s = pd.to_datetime(s)
print(s.dt.date.le(datetime.now().date()))
# TypeError: Invalid comparison between dtype=datetime64[ns] and date
```

### Issue Description

When comparing a `datetime[ns]` or similar series, where all the values turn out to be `pd.NaT` values, the comparison just breaks. This is problematic, as the input series cannot necessarily be controlled beforehand, and if there's any actual non-NaT value, the comparison works. The Series `dtype` values are the same in both cases, which would make me expect that the rest of the behaviour is the same too.

### Expected Behavior

In the above code, I would expect it to return:

```python
0    False
1    False
dtype: bool
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.16
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:16 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_GB.UTF-8
LOCALE                : en_GB.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.2
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : 8.34.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.0
html5lib              : None
hypothesis            : 6.130.4
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : 0.28.0
psycopg2              : None
pymysql               : None
pyarrow               : 15.0.2
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.3.0
scipy                 : None
sqlalchemy            : 2.0.39
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Datetime', 'good first issue']","{'login': 'MayurKishorKumar', 'id': 46263936, 'node_id': 'MDQ6VXNlcjQ2MjYzOTM2', 'avatar_url': 'https://avatars.githubusercontent.com/u/46263936?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/MayurKishorKumar', 'html_url': 'https://github.com/MayurKishorKumar', 'followers_url': 'https://api.github.com/users/MayurKishorKumar/followers', 'following_url': 'https://api.github.com/users/MayurKishorKumar/following{/other_user}', 'gists_url': 'https://api.github.com/users/MayurKishorKumar/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/MayurKishorKumar/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/MayurKishorKumar/subscriptions', 'organizations_url': 'https://api.github.com/users/MayurKishorKumar/orgs', 'repos_url': 'https://api.github.com/users/MayurKishorKumar/repos', 'events_url': 'https://api.github.com/users/MayurKishorKumar/events{/privacy}', 'received_events_url': 'https://api.github.com/users/MayurKishorKumar/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-27 09:24:05+00:00,2025-04-15 12:42:01+00:00,MayurKishorKumar,19.137453703703702
61187,"BUG: DataFrame.min raises TypeError when column contains mixed types (e.g., np.nan and datetime)","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np
import datetime

data = {
    ""dates"": [
        np.nan,
        np.nan,
        datetime.datetime(2025, 1, 3),
        datetime.datetime(2025, 1, 4),
    ],
}

df = pd.DataFrame(data)

df.min(axis=0)
```

### Issue Description

When calling DataFrame.min(axis=0) on a DataFrame with columns containing mixed types (np.nan and datetime), a TypeError is raised due to the comparison of float (from np.nan) and datetime.date. The default behavior of min should skip np.nan values when skipna=True (default), but this does not happen.
```Traceback (most recent call last):

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\test.py"", line 29, in <module>

    df.min(axis=0)

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\frame.py"", line 11643, in min

    result = super().min(axis, skipna, numeric_only, **kwargs)

             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\generic.py"", line 12388, in min

    return self._stat_function(

           ^^^^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\generic.py"", line 12377, in _stat_function

    return self._reduce(

           ^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\frame.py"", line 11562, in _reduce

    res = df._mgr.reduce(blk_func)

          ^^^^^^^^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\internals\managers.py"", line 1500, in reduce

    nbs = blk.reduce(func)

          ^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\internals\blocks.py"", line 404, in reduce

    result = func(self.values)

             ^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\frame.py"", line 11481, in blk_func

    return op(values, axis=axis, skipna=skipna, **kwds)

           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\nanops.py"", line 147, in f

    result = alt(values, axis=axis, skipna=skipna, **kwds)

             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\nanops.py"", line 404, in new_func

    result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)

             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\pandas\core\nanops.py"", line 1098, in reduction

    result = getattr(values, meth)(axis)

             ^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File ""C:\Users\45217950\Downloads\GitHub\irr-cloud\.venv\Lib\site-packages\numpy\_core\_methods.py"", line 48, in _amin

    return umr_minimum(a, axis, None, out, keepdims, initial, where)

           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

TypeError: '<=' not supported between instances of 'float' and 'datetime.date'
```

### Expected Behavior

The min function should skip np.nan values when skipna=True (default) and return the minimum datetime value:
```
dates   2025-01-03
dtype: datetime64[ns]
```

### Installed Versions

<details>

INSTALLED VERSIONS

------------------

commit                : 0691c5cf90477d3503834d983f69350f250a6ff7

python                : 3.12.7

python-bits           : 64

OS                    : Windows

OS-release            : 10

Version               : 10.0.19045

machine               : AMD64

processor             : Intel64 Family 6 Model 85 Stepping 7, GenuineIntel

byteorder             : little

LC_ALL                : None

LANG                  : en_US.UTF-8

LOCALE                : English_United States.1252

 

pandas                : 2.2.3

numpy                 : 2.2.3

pytz                  : 2025.1

dateutil              : 2.9.0

pip                   : 24.2

Cython                : None

sphinx                : None

IPython               : None

adbc-driver-postgresql: None

adbc-driver-sqlite    : None

bs4                   : None

blosc                 : None

bottleneck            : None

dataframe-api-compat  : None

fastparquet           : None

fsspec                : None

html5lib              : None

hypothesis            : None

gcsfs                 : None

jinja2                : None

lxml.etree            : None

matplotlib            : None

numba                 : None

numexpr               : None

odfpy                 : None

openpyxl              : 3.1.5

pandas_gbq            : 0.28.0

psycopg2              : None

pymysql               : None

pyarrow               : 19.0.1

pyreadstat            : None

pytest                : None

python-calamine       : None

pyxlsb                : None

s3fs                  : None

scipy                 : 1.15.2

sqlalchemy            : None

tables                : None

tabulate              : None

xarray                : None

xlrd                  : None

xlsxwriter            : 3.2.2

zstandard             : None

tzdata                : 2025.1

qtpy                  : None

pyqt5                 : None

</details>
","['Bug', 'Missing-data', 'Needs Info', 'Reduction Operations']",,2025-03-27 03:16:47+00:00,2025-03-31 02:16:58+00:00,,3.958460648148148
61186,BUG: engine calamine lost 0 when read_excel from vlookup cell,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
df = pd.read_excel(r'C:\Users\ryjfgjl\Desktop\Ê±ΩËΩ¶ËÆ°Êèê1-2ÊúàÊòéÁªÜ(1).xlsx', sheet_name=3, na_filter=False, engine='calamine', dtype=object)
print(df)
```

### Issue Description

Excel data
![Image](https://github.com/user-attachments/assets/faac4ada-81cc-4318-b86b-ae6402677412)

df:
![Image](https://github.com/user-attachments/assets/9014cb58-0c15-4f53-af80-7a4a1888f774)

### Expected Behavior

change engine to openpyxl is correct

![Image](https://github.com/user-attachments/assets/665555b9-4f5f-417d-83c8-2c2fb0ccfcb6)

### Installed Versions

<details>

2.2.3

</details>
","['Bug', 'IO Excel', 'Closing Candidate', 'Upstream issue']","{'login': 'chilin0525', 'id': 41913261, 'node_id': 'MDQ6VXNlcjQxOTEzMjYx', 'avatar_url': 'https://avatars.githubusercontent.com/u/41913261?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/chilin0525', 'html_url': 'https://github.com/chilin0525', 'followers_url': 'https://api.github.com/users/chilin0525/followers', 'following_url': 'https://api.github.com/users/chilin0525/following{/other_user}', 'gists_url': 'https://api.github.com/users/chilin0525/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/chilin0525/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/chilin0525/subscriptions', 'organizations_url': 'https://api.github.com/users/chilin0525/orgs', 'repos_url': 'https://api.github.com/users/chilin0525/repos', 'events_url': 'https://api.github.com/users/chilin0525/events{/privacy}', 'received_events_url': 'https://api.github.com/users/chilin0525/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-27 01:57:03+00:00,2025-06-19 20:51:54+00:00,chilin0525,84.78809027777778
61185,ENH: Reimplement DataFrame.lookup,"- [x] closes #40140
- [x] [Tests added and passed]
- [x] All [code checks passed]
- [x] Added [type annotations]
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Optimization notes:
Most important change is removal of:
`if not self._is_mixed_type or n > thresh`

The old implementation slowed down when `n < thresh`, with or without mixed types. Cases `n < thresh` now 10x faster.

Logic can be followed via python operator precedence:

https://docs.python.org/3/reference/expressions.html#operator-precedence

Test notes:
I am unfamiliar with pytest and did not add paramterization","['Enhancement', 'Indexing', 'Stale']",,2025-03-26 21:13:46+00:00,2025-06-02 17:00:28+00:00,,67.82409722222222
61184,DOC: Add details of dropna in DataFrame.pivot_table,"- [x] closes #61113 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Missing-data', 'Reshaping']",,2025-03-26 16:55:56+00:00,2025-04-02 21:28:16+00:00,,7.189120370370371
61183,REGR: Interpolate with method=index,"- [x] closes #61122 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Partial revert of #56515. Regression is only on main; hasn't been released yet so no whatsnew.","['Bug', 'Missing-data', 'Regression']",,2025-03-26 16:40:24+00:00,2025-03-29 18:01:32+00:00,,3.0563425925925927
61182,BUG: Negation of `.str.isnumeric()` changes `dtype` when `pd.NA` is present,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

s = pd.Series(["""", ""0"", ""123"", "" 123"", pd.NA])
print(s.str.isnumeric())
print(~s.str.isnumeric())

t = pd.Series(["""", ""0"", ""123"", "" 123""])
print(t.str.isnumeric())
print(~t.str.isnumeric())
```

### Issue Description

When `pd.NA` is present in a `Series` object, negating the `.str.isnumeric()` method changes `bool` values to `int` values.


### Expected Behavior

Negation should adhere to the [Kleene logic](https://pandas.pydata.org/docs/user_guide/boolean.html) implemented elsewhere in `pandas`.


### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.16
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-1021-azure
Version               : #25-Ubuntu SMP Wed Jan 15 20:45:09 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : 8.34.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.1
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.39
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Missing-data', 'Strings', 'Needs Discussion', 'Closing Candidate']",,2025-03-26 16:35:55+00:00,2025-04-04 09:59:28+00:00,,8.7246875
61181,update offsets.pyx to fix #60647,"- [x ] closes #60647 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-26 11:51:20+00:00,2025-04-28 18:23:34+00:00,,33.27238425925926
61179,BUG: replace with np.nan unexpectedly converts pd.Timestamp to pd.NaT,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import numpy as np

data = {
    ""date"": [
        pd.Timestamp(""2025-01-01""),
        pd.Timestamp(""2025-01-02""),
        pd.Timestamp(""2025-01-03""),
    ],
}

df = pd.DataFrame(data)

df.replace([pd.Timestamp(""2025-01-01""), pd.Timestamp(""2025-01-02"")], np.nan)
```

### Issue Description

When using `DataFrame.replace()` to replace specific `pd.Timestamp` values with np.nan, the resulting values become `pd.NaT` instead of `np.nan`. This behavior differs from `pandas 1.1.5`, where the replaced values were `np.nan` as expected.

Output
``` 
        date
0        NaT
1        NaT
2 2025-01-03
```

### Expected Behavior

```
        date
0        NaN
1        NaN
2 2025-01-03
```


### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.5
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:16 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.0.0
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 23.2.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Missing-data', 'Timestamp']",,2025-03-26 07:57:42+00:00,2025-03-26 19:26:41+00:00,,0.47846064814814815
61178,pandas edit,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Please approve
",[],,2025-03-25 16:58:08+00:00,2025-03-25 17:00:40+00:00,,0.0017592592592592592
61176,BUG: DataFrame.resample is changing thBUG: DataFrame.resample is changing the index type to MultiIndex when the dataframe is empty (pandas-dev#61174) * BUG: DataFramee index type to MultiIndex when the dataframe is empty (pandas-dev#61174) * BUG: DataFrame    solved,"- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-25 10:55:53+00:00,2025-03-25 15:40:36+00:00,,0.1977199074074074
61175,BUG: AttributeError on method call after binary operation in eval expression,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

x = pd.Series([1,2,3,5])
y = pd.Series([2,3,4])

pd.eval(""(x + y).dropna()"")
# raises AttributeError: 'BinOp' object has no attribute 'value'

# Note that something like pd.eval(""(x.dropna() + y)"") works!
```

### Issue Description

Also effects other Series methods called on the result of a binary operation, which work well if applied to one operand.

See also https://github.com/pandas-dev/pandas/issues/24670

### Expected Behavior

Should return a Series of sums with nan values removed. Generally I would expect that it should be possible to apply a Series method to the result of a binary operation as part of an eval expression.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.2
python-bits           : 64
OS                    : Linux
OS-release            : 6.13.7-arch1-1
Version               : #1 SMP PREEMPT_DYNAMIC Thu, 13 Mar 2025 18:12:00 +0000
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : de_DE.UTF-8
LOCALE                : de_DE.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.3
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 9.0.1
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : None
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.38
tables                : 3.10.2
tabulate              : None
xarray                : 2025.1.2
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'expressions']","{'login': 'ycdjun', 'id': 47006276, 'node_id': 'MDQ6VXNlcjQ3MDA2Mjc2', 'avatar_url': 'https://avatars.githubusercontent.com/u/47006276?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ycdjun', 'html_url': 'https://github.com/ycdjun', 'followers_url': 'https://api.github.com/users/ycdjun/followers', 'following_url': 'https://api.github.com/users/ycdjun/following{/other_user}', 'gists_url': 'https://api.github.com/users/ycdjun/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ycdjun/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ycdjun/subscriptions', 'organizations_url': 'https://api.github.com/users/ycdjun/orgs', 'repos_url': 'https://api.github.com/users/ycdjun/repos', 'events_url': 'https://api.github.com/users/ycdjun/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ycdjun/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-25 10:14:20+00:00,2025-03-31 16:52:37+00:00,ycdjun,6.276585648148148
61174,BUG: DataFrame.resample is changing the index type to MultiIndex when the dataframe is empty,"BUG: DataFrame.resample is changing the index type to MultiIndex when the dataframe is empty

very easy bug to reproduce. the bug has been opened for 1 year.

```
# repro
import pandas as pd

df = pd.DataFrame(columns = [""a"", ""b""], index = pd.DatetimeIndex([]))
sampled = df.resample(""8h"").apply(pd.Series.mean)

print(df.index)
print(sampled.index)
```

output on pandas 1
```
DatetimeIndex([], dtype='datetime64[ns]', freq=None)
DatetimeIndex([], dtype='datetime64[ns]', freq='8H')
```

output on pandas 2 and main branch
```
DatetimeIndex([], dtype='datetime64[ns]', freq=None)
MultiIndex([], )
```


- [X] closes #55572 (Replace xxxx with the GitHub issue number)
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['MultiIndex', 'Resample']",,2025-03-24 16:18:53+00:00,2025-03-24 19:13:30+00:00,,0.12126157407407408
61173,BUG: Handle overlapping line and bar on the same plot,"- [x] closes #61161
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This code
```python
import pandas as pd
import matplotlib.pyplot as plt

index = pd.period_range('2023', periods=3, freq='Y')
df = pd.DataFrame({
    'col1': [10, 20, 30],
    'col2': [40, 25, 10]
}, index=index)

fig, ax = plt.subplots()
df['col1'].plot(kind='bar', ax=ax)
ax2 = ax.twinx()
df['col2'].plot(kind='line', ax=ax2, color = 'r')
plt.show()
```
from the linked issue gives this plot:
![image](https://github.com/user-attachments/assets/9732188c-5478-4e93-ae3c-ae18e77776f3)

And swapping the lines (line before bar)
```python
df['col2'].plot(kind='line', ax=ax2, color = 'r')
df['col1'].plot(kind='bar', ax=ax)
```
gives
![image](https://github.com/user-attachments/assets/35815445-dd3d-4a95-8c27-5a4dd07810be)

I believe the difference of results stems from the fact that the figure is always cropped to match the x-range of the last plot. We can certainly adjust the PR to make the first figure behave like the second one if desired.

Please provide feedback on the overall approach. Once confirmed, I'll expand and cover with tests.
","['Bug', 'Visualization']",,2025-03-24 09:22:19+00:00,2025-04-18 16:12:46+00:00,,25.28503472222222
61171,DataFrame.dtypes.to_json OverflowError: Maximum recursion level reached,"- [x] closes #61170  (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'IO JSON', 'Stale']",,2025-03-23 20:16:22+00:00,2025-05-21 16:14:31+00:00,,58.83204861111111
61169,ENH: add destructor to HDFStore,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

When using pd.HDFStore methods directly the store often stays open. Especially in interactive context. That can cause some permission errors:

```
In [1]: pd.Series([1,2,3]).to_hdf('foo.h5', 'x')

In [2]: pd.Series([1,2,3]).to_hdf('foo.h5', 'y')

In [3]: pd.HDFStore('foo.h5', 'r').keys()
Out[3]: ['/x', '/y']

In [4]: pd.Series([1,2,3]).to_hdf('foo.h5', 'z')
ValueError: The file 'foo.h5' is already opened, but in read-only mode.  Please close it before reopening in append mode.

In [5]: os.rename('foo.h5', 'bar.h5')
On Windows:
PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'foo.h5' -> 'bar.h5' 
```

### Feature Description

Adding destructor solves this

```
pd.io.pytables.HDFStore.__del__ = lambda self: self.close()
```

### Alternative Solutions

.

### Additional Context

_No response_","['Enhancement', 'Needs Triage']",,2025-03-23 17:23:42+00:00,2025-03-24 16:35:22+00:00,,0.9664351851851852
61168,ENH: Accept no fields for groupby by,"- [ ] closes #61160 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-23 13:21:20+00:00,2025-04-14 17:03:57+00:00,,22.154594907407407
61167,DOC: Add punctuation to basics.rst in User Guide,"Add punctuation to `basics.rst` in User Guide.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-22 21:44:07+00:00,2025-03-24 16:37:08+00:00,,1.7868171296296296
61165,BUG: `datetime64[s]` fails round trip using `.to_parquet` and `read_parquet`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

c = pd.Series([""2024-01-01"", ""2025-01-01"", ""2026-01-01""], dtype=""datetime64[s]"")
df0 = c.to_frame()

print(df0.dtypes)
df0.to_parquet(""test.parquet"")

df1 = pd.read_parquet(""test.parquet"")
print(df1.dtypes)
```

### Issue Description

The `dtype` changes from `datetime64[s]` to `datetime64[ms]`.

### Expected Behavior

I would expect the `dtype` to remain unchanged.

### Installed Versions

<details>
INSTALLED VERSIONS

------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.16
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-1021-azure
Version               : #25-Ubuntu SMP Wed Jan 15 20:45:09 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : 8.34.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : 5.3.1
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.39
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5          
</details>
","['Bug', 'Datetime', 'IO Parquet']",,2025-03-21 23:39:25+00:00,2025-03-22 11:19:36+00:00,,0.4862384259259259
61163,"WEB: Remove self (Marco Gorelli) from ""active maintainers"" list","This is a bit overdue, but I haven't been active (barring minor PRs) for some time. This isn't anything personal against anyone, nor against pandas, I'm just recognising that my involvement has waned, and that unfortunately I don't have capacity for pandas maintenance

Thanks everyone for having involved me, I really appreciate it. A highlight for me was meeting many of you in Basel, and on the technical side a personal highlight was working on PDEP-4 and PDEP-6

There are some changes I've made which affect 3.0, and I'm happy to be pinged and to take responsibility for them, but I can do so even just as contributor, no need for me to be in the ""active maintainers"" list for that

All the best ü§ó ",['Web'],,2025-03-21 20:24:14+00:00,2025-03-25 16:57:23+00:00,,3.8563541666666667
61162,ENH: Support `Series[bool]` as indexer for `iloc.__getitem__`  ,"- [x] closes #60994 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Enhancement', 'Indexing']",,2025-03-21 19:44:44+00:00,2025-04-09 16:27:05+00:00,,18.862743055555555
61161,BUG: fails to plot 2 plots with secondary y axis when index type is PeriodIndex and plot kinds are different,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import matplotlib.pyplot as plt

print(pd.__version__)

index = pd.period_range('2023', periods=3, freq='Y')
df = pd.DataFrame({
    'col1': [10, 20, 30],
    'col2': [40, 25, 10]
}, index=index)

# Workaround !!!!
# df.index = df.index.astype(str)

print(type(df.index))

fig, ax = plt.subplots()

df['col1'].plot(kind='bar', ax=ax)

ax2 = ax.twinx()

df['col2'].plot(kind='line', ax=ax2, color = 'r')

plt.show()
```

### Issue Description

I seem to have found the following bug:

It is not possible to plot 2 plots with different Y axis when the following 2 conditions are met:

* plot kinds are different (e.g. 'bar' and 'line')
* index type is **PeriodIndex**


![Image](https://github.com/user-attachments/assets/84241d4d-14db-4928-aeb3-eb7f5d77ee0c)

The easy workaround is to convert index to string:

<img width=""442"" alt=""Image"" src=""https://github.com/user-attachments/assets/2bd9f427-7887-47e3-a6d4-17322e9c64e2"" />


If the parameter 'kind' of both axis is identical, then it works as well without workound

![Image](https://github.com/user-attachments/assets/f972ef18-4749-4838-bed9-b59e84ab2b72)


### Expected Behavior

Both plots shall be possible to be seen

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.7
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.22631
machine               : AMD64
processor             : Intel64 Family 6 Model 170 Stepping 4, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_Netherlands.1252

pandas                : 2.2.3
numpy                 : 2.2.1
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : 8.31.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.10.0
html5lib              : 1.1
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.3
python-calamine       : None
pyxlsb                : 1.0.10
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Visualization']","{'login': 'MartinBraquet', 'id': 25173236, 'node_id': 'MDQ6VXNlcjI1MTczMjM2', 'avatar_url': 'https://avatars.githubusercontent.com/u/25173236?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/MartinBraquet', 'html_url': 'https://github.com/MartinBraquet', 'followers_url': 'https://api.github.com/users/MartinBraquet/followers', 'following_url': 'https://api.github.com/users/MartinBraquet/following{/other_user}', 'gists_url': 'https://api.github.com/users/MartinBraquet/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/MartinBraquet/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/MartinBraquet/subscriptions', 'organizations_url': 'https://api.github.com/users/MartinBraquet/orgs', 'repos_url': 'https://api.github.com/users/MartinBraquet/repos', 'events_url': 'https://api.github.com/users/MartinBraquet/events{/privacy}', 'received_events_url': 'https://api.github.com/users/MartinBraquet/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-21 19:34:07+00:00,2025-04-18 16:12:48+00:00,MartinBraquet,27.86019675925926
61159,BUG: Faulty DatetimeIndex union,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
def test_pandas_datetime_index_union(self):
    """"""
    Demonstrates a suspected bug in pandas 2.2.3, where unions of DatetimeIndexes (and therefore pd.concats of dataframes with DatetimeIndexes)
    are returning unexpected values.

    My actual usecase (concatenating two dataframes with these DatetimeIndexes, from which I extracted these date ranges) works in
    pandas 1.5.3, but not 2.2.3.

    Interestingly, this passes in both versions if you change the dtype to datetime64[ns].

    """"""

    dti1 = DatetimeIndex(
        ['2021-10-05 17:30:00', 
         '2021-10-05 18:00:00', 
         '2021-10-05 18:30:00', 
         '2021-10-05 19:00:00', 
         '2021-10-05 19:30:00'],
        dtype='datetime64[us]', name='DATETIME', freq='30min'
    )
    dti2 = DatetimeIndex(
        ['2021-10-05 17:30:00', 
         '2021-10-05 18:00:00',  
         '2021-10-05 18:30:00', 
         '2021-10-05 19:00:00', 
         '2021-10-05 19:30:00', 
         '2021-10-05 20:00:00'], # <-- Extra datetime
        dtype='datetime64[us]', name='DATETIME', freq='30min'
    )

    union = set(dti1.union(dti2))
    expected = set(dti1) | set(dti2)
    print(f""{union=}"")
    print(f""{expected=}"")

    assert len(union) == len(expected), ""Should have all the rows from the concatenated dataframes""


def test_range_index_equality(self):
    """""" This (presumably) faulty equality check appears to be the root cause of the datetimeindex union bug above
    Note that the two stop values are different, so the RangeIndexes should not be equal.
    Interestingly, this fails in both pandas 1.5.3 and 2.2.3.
    """"""
    a = RangeIndex(start=1633455000000000, stop=1635262200000000, step=1800000000000)
    b = RangeIndex(start=1633455000000000, stop=1635264000000000, step=1800000000000)
    assert not a.equals(b)
```

### Issue Description

These tests above (details in the function doc) demonstrate the issue and what I think is the root cause.
Basically we get back what appears to be an incorrect result when taking the union of two DatetimeIndexes with different ranges.  

I traced this as far as the RangeIndex equality check in the second test, which appears to be faulty, returning True for two different `stop` values. 



### Expected Behavior

Out from first test should be (as in pandas 1.5.3):
```
union={Timestamp('2021-10-05 18:30:00'), Timestamp('2021-10-05 19:00:00'), Timestamp('2021-10-05 17:30:00'), Timestamp('2021-10-05 20:00:00'), Timestamp('2021-10-05 19:30:00'), Timestamp('2021-10-05 18:00:00')}

expected={Timestamp('2021-10-05 18:30:00'), Timestamp('2021-10-05 19:00:00'), Timestamp('2021-10-05 17:30:00'), Timestamp('2021-10-05 20:00:00'), Timestamp('2021-10-05 19:30:00'), Timestamp('2021-10-05 18:00:00')}
``` 

But the actual output in pandas 2.2.3 is (incorrectly):
```
union={Timestamp('2021-10-05 17:30:00'), Timestamp('2021-10-26 13:30:00')}

expected={Timestamp('2021-10-05 19:30:00'), Timestamp('2021-10-05 20:00:00'), Timestamp('2021-10-05 17:30:00'), Timestamp('2021-10-05 19:00:00'), Timestamp('2021-10-05 18:00:00'), Timestamp('2021-10-05 18:30:00')}

```


### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.6
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_Australia.1252
pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : 4.5.0
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.3.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.6
lxml.etree            : None
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.3.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.39
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'setops', 'Non-Nano']",,2025-03-21 05:11:25+00:00,2025-03-22 11:36:51+00:00,,1.267662037037037
61158,Fix bug in `Series.describe` where the median is included any time the `percentiles` argument is not None,"- [x] closes #60550 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This PR aims at fixing the bug mentioned in the issue referenced above. Multiple PRs (#61024, #61023 , #60986 , #60557) have already attempted to resolve it, yet all of them got closed or stale for more than 2 weeks. So I allowed myself to apply here all the comments in the issue and previous PRs.

One last thing left hanging pertains to backward incompatibility. The only case in which the result will change is when `percentiles` is a list that does not contain 0.5. Before the PR, it adds 0.5 to the result; after the PR, it does not include it. 
If we add a warning message in such case, it would be considered as:
* useful for the people who read the median even though they didn't include it in the list of percentiles
* spamming / undesirable for the rest

So, what is pandas' policy regarding warning messages and its potentially large number of false alerts?
",['Series'],,2025-03-21 03:03:30+00:00,2025-03-21 21:13:04+00:00,,0.7566435185185185
61157,Preserve Complex Data Types for to_csv,"This Pull Request solves the issue outlined in:
https://github.com/pandas-dev/pandas/issues/60895

Complex data types like numpy arrays can now be stored in csv format and later recovered. 
A new parameter, preserve_complex, is introduces, and when it is set to true in your to_csv function call, the complex data types will be preserved and can be recovered from the csv.

The way this works is by serializing Numpy arrays into JSON format for preserve_complex=True. To get them from the csv, we can set the same parameter in read_csv, and the original Numpy array will be returned.

Please refer to tests in scripts/tests/test_csv.py to see how this is used.

Please refer to the original issue for more information on the problem definition.

","['Enhancement', 'IO CSV', 'Complex', 'Needs Discussion']",,2025-03-20 20:41:52+00:00,2025-05-09 16:05:49+00:00,,49.80829861111111
61155,BUG: Impossible creation of array with dtype=string,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

pd.array([list('test')], dtype='string')
# ValueError: Buffer has wrong number of dimensions (expected 1, got 2)

pd.array([list('test'), list('word')], dtype='string')
# ValueError: Buffer has wrong number of dimensions (expected 1, got 2)

pd.array([list('test'), list('words')], dtype='string')
# <StringArray>
# [""['t', 'e', 's', 't']"", ""['w', 'o', 'r', 'd', 's']""]
# Length: 2, dtype: string

pd.array([list('test')])
# <NumpyExtensionArray>
# [['t', 'e', 's', 't']]
# Length: 1, dtype: object
```

### Issue Description

I'm trying to transform a list of list of strings into a `StringArray`, but the `pd.array` method with `dtype='string'` doesn't work when the second last level list contains lists of same length, raising an exception (see example). If the lists have different lengths, then the output doesn't raise an error and is correct.

In an older version of pandas (1.5.3), it produced a list of same length, but containing repeated casts of string arrays
```
<StringArray>
[
[""['t' 'e' 's' 't']"", ""['t' 'e' 's' 't']"", ""['t' 'e' 's' 't']"",
 ""['t' 'e' 's' 't']""]
]
Shape: (1, 4), dtype: string
```

### Expected Behavior

Same as pd.array([list('test')]) but with `StringArray` type.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.12.3.final.0
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.22631
machine               : AMD64
processor             : Intel64 Family 6 Model 154 Stepping 3, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en
LOCALE                : English_Europe.1252

pandas                : 2.2.2
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
setuptools            : 75.1.0
pip                   : 24.2
Cython                : None
pytest                : 7.4.4
hypothesis            : None
sphinx                : 7.3.7
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : 5.2.1
html5lib              : None
pymysql               : None
psycopg2              : None
jinja2                : 3.1.4
IPython               : 8.27.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
bottleneck            : 1.3.7
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.6.1
gcsfs                 : None
matplotlib            : 3.9.2
numba                 : 0.60.0
numexpr               : 2.8.7
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
pyarrow               : 16.1.0
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : 2024.6.1
scipy                 : 1.13.1
sqlalchemy            : 2.0.34
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2023.6.0
xlrd                  : None
zstandard             : 0.23.0
tzdata                : 2023.3
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Bug', 'Strings']","{'login': 'Manju080', 'id': 84699147, 'node_id': 'MDQ6VXNlcjg0Njk5MTQ3', 'avatar_url': 'https://avatars.githubusercontent.com/u/84699147?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Manju080', 'html_url': 'https://github.com/Manju080', 'followers_url': 'https://api.github.com/users/Manju080/followers', 'following_url': 'https://api.github.com/users/Manju080/following{/other_user}', 'gists_url': 'https://api.github.com/users/Manju080/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Manju080/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Manju080/subscriptions', 'organizations_url': 'https://api.github.com/users/Manju080/orgs', 'repos_url': 'https://api.github.com/users/Manju080/repos', 'events_url': 'https://api.github.com/users/Manju080/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Manju080/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-20 14:25:51+00:00,2025-05-15 16:13:22+00:00,Manju080,56.07466435185185
61154,BUG: Clip corr edge cases between -1.0 and 1.0,"Closes #61120 

Clips correlation coefficient in `DataFrame.corr()` between `-1.0` and `1.0`

Adds `test_corr_within_bounds` to ensure coefficient within bounds

- [x] closes #61120 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['cov/corr'],,2025-03-20 13:15:41+00:00,2025-03-25 17:11:39+00:00,,5.163865740740741
61153,BUG: import pandas 2.2.3 on WSL 2.4.12.0 raises broken support for `numpy.longdouble` dtype warning,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
# on WSL2, ubuntu 24
import pandas

#raises
#/home/pepmts/git_projects/mts-python-monorepo/projects/mml-python-toolkit/venv/lib/python3.11/#site-packages/numpy/_core/getlimits.py:551: UserWarning: Signature #b'\x00\xd0\xcc\xcc\xcc\xcc\xcc\xcc\xfb\xbf\x00\x00\x00\x00\x00\x00' for <class #'numpy.longdouble'> does not match any known type: falling back to type probe function.
#This warnings indicates broken support for the dtype!
#  machar = _get_machar(dtype)
```

### Issue Description

Whenever I import pandas on WSL I get this broken dtype warning
```python
>>> import pandas
/home/pepmts/git_projects/mts-python-monorepo/projects/mml-python-toolkit/venv/lib/python3.11/site-packages/numpy/_core/getlimits.py:551: UserWarning: Signature b'\x00\xd0\xcc\xcc\xcc\xcc\xcc\xcc\xfb\xbf\x00\x00\x00\x00\x00\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.
This warnings indicates broken support for the dtype!
  machar = _get_machar(dtype)
```

### Expected Behavior

no warning

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.5
python-bits           : 64
OS                    : Linux
OS-release            : 4.4.0-26100-Microsoft
Version               : #1882-Microsoft Fri Jan 01 08:00:00 PST 2016
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.4
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : 8.18.1
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : 5.3.0
matplotlib            : 3.9.4
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.2
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.13.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Build', 'Upstream issue']",,2025-03-20 10:12:53+00:00,2025-03-26 13:44:36+00:00,,6.147025462962963
61152,ENH: Adds `dict` & `**dict` support for `pd.set_option` [#61093],"- [x] closes #61093
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.


@rhshadrach & @yasirroni I have Two Approaches one adds support for `pd.set_option(options)` and other adds support for both `pd.set_option(options) & pd.set_option(**options)`
",[],,2025-03-20 07:07:50+00:00,2025-04-14 17:08:58+00:00,,25.417453703703703
61151,ENH: Added dict support for `pd.set_option`,"- [x] closes #61093
- [x] Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Enhancement', 'API Design']",,2025-03-20 05:38:08+00:00,2025-05-29 18:44:31+00:00,,70.54609953703704
61150,DOC: Add missing period,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-20 05:27:12+00:00,2025-03-20 16:22:34+00:00,,0.45511574074074074
61149,BUG: Added deprecation warning to Timestamp constructor,"Part of #11953

Added deprecation warning to Timestamp constructor when `ts_input = """"`. 

This addition was motivated by this comment: https://github.com/pandas-dev/pandas/issues/11953#issuecomment-1210981966

- [ ] closes #11953 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Missing-data', 'Deprecate', 'Stale', 'Timestamp']",,2025-03-20 01:42:57+00:00,2025-06-30 18:26:54+00:00,,102.6971875
61148,String dtype: more informative repr (keeping brief __str__),"Attempt to address https://github.com/pandas-dev/pandas/issues/59342

With the current version of the PR, the reprs for the different dtype variants are:

```python
# default NaN variants
<StringDtype(na_value=nan)>
<StringDtype(storage='python', na_value=nan)>
# nullable NA variants
<StringDtype(na_value=<NA>)>
<StringDtype(storage='python', na_value=<NA>)>
```

Some questions to decide on:

- Do we use surrounding `<...>` or not? (we are somewhat inconsistent internally for similar reprs; e.g. the Index repr does not use it, the ExtensionArray repr does)
  - Including the `<..>` makes it clearer that it is not necessarily exactly executable code, I think 
- Do we keep the current `__str__` as is (i.e. just `""str""` or `""string""`), or do we include the storage for the `""string""` case (to preserve the current repr behaviour). i.e. make it to have the options `""str""`, `""string[pyarrow]""` or `""string[python]""`.
  - Essentially, this comes down to changing the `dtype.name` attribute or not (which right now is defined to be ""str"" or ""string"")
  - As comparison, for DatetimeTZDtype we do include the [] parametrization in `.name` (e.g. ""datetime64[s, UTC]""), while for CategoricalDtype we do not (there it is just ""category"")
  - If we don't use it in the name/str, we actually never show `""string[python]""`, while we still allow that as string alias for `dtype` arguments (e.g. in constructors or in `astype()`)
- Currently I just use their own repr for `pd.NA` and `np.nan`, which means they are displayed as `<NA>` and `nan`
  - But we could also make it to look like `pd.NA` and `np.nan`. This makes it a more ""executable"" repr, which could be nice, but on the other hand I also don't want to encourage that too much.","['Output-Formatting', 'Strings']",,2025-03-19 18:35:07+00:00,2025-05-10 14:29:47+00:00,,51.82962962962963
61147,Implemented Reviewer Feedback :Followed Dev Docs and Added Test for from_records,"### Changes Made:
- Followed the guidelines from the Pandas contribution documents to implement the requested changes.
- Added tests for from_records based on the current tests and test structure.

These changes align with the contributions guide as per the Pandas development documentation. Please review and let me know if further adjustments are needed.",[],,2025-03-19 17:14:47+00:00,2025-03-24 16:39:12+00:00,,4.975289351851852
61146,Fix #61123 with simple doc change,"- [X] closes #61123 
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-19 17:02:58+00:00,2025-03-19 20:37:22+00:00,,0.14888888888888888
61143,BUG: Preserve column names in DataFrame.from_records when nrows=0,"### Description
Updates pandas/core/frame.py to preserve column names in empty DataFrames when nrows == 0. Changed from return Cls() to return Cls(columns=columns).

Closes #61140

### Changes Made
- Modified if nrows == 0 in core/frame.py.
- Added test in tests/frame/test_constructors.py.

### Testing
- Added test case for empty DataFrame column retention.
- Verified locally with pytest.
","['Bug', 'IO Data', 'Stale']",,2025-03-18 15:25:23+00:00,2025-05-21 16:14:57+00:00,,64.0344212962963
61142,BUG: Collision between equivalent frequencies 'QS-‚Ä¶,"‚Ä¶FEB' and 'QS-NOV'

- [x] closes #61086 (Replace 61086 with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Datetime', 'Frequency', 'Stale']",,2025-03-18 13:54:49+00:00,2025-05-21 16:15:38+00:00,,64.09778935185186
61141,"BUG: astype transforms NA to ""NA""","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas

a = pandas.Series([pandas.NA], dtype = ""str"")

# This is tight
print(type(a[0]))
<class 'pandas._libs.missing.NAType'>

print(type(a.astype(""str"")[0]))
<class 'str'>
```

### Issue Description

When we work with missing data, and we do transformation from NA to ""str"", is does not keep the NA value, instead returns the string ""NA"".

### Expected Behavior

Return NA instead of ""NA""

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.9
python-bits           : 64
OS                    : Linux
OS-release            : 6.12.16-gentoo-x86_64
Version               : #1 SMP PREEMPT_DYNAMIC Tue Feb 25 08:36:23 -03 2025
machine               : x86_64
processor             : AMD Ryzen 7 5800H with Radeon Graphics
byteorder             : little
LC_ALL                : None
LANG                  : es_CL.utf8
LOCALE                : es_CL.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.3
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Missing-data', 'Strings']",,2025-03-17 20:26:18+00:00,2025-03-19 12:34:58+00:00,,1.6726851851851852
61139,DOC: Clarification on Python 3.13 support,"### Pandas version checks

The issue doesn't still exist on the latest versions of the docs on main since 
https://pandas.pydata.org/docs/dev/getting_started/install.html#python-version-support
refers to https://scientific-python.org/specs/spec-0000/ which says Python 3.13 is supported. So the question is about the released version 2.2.3

### Location of the documentation

https://pandas.pydata.org/docs/getting_started/install.html#python-version-support

### Documentation problem


In [this issue](https://github.com/python/cpython/issues/131354) @StanFromIreland pointed out that Pandas docs say:

> #### Python version support
>
> Officially Python 3.9, 3.10, 3.11 and 3.12.

I see that there are Python 3.13 wheels, that it is tested in CI, and `pyproject.toml` includes the `Programming Language :: Python :: 3.13` classifier. Is it an accidental omission that Python 3.13 isn't included in the officially supported list? If it _isn't_ officially supported, it would be good to call this out more obviously.


### Suggested fix for documentation

Perhaps the new text in the dev docs should be backported?","['Docs', 'Closing Candidate']",,2025-03-17 14:27:48+00:00,2025-03-19 13:59:25+00:00,,1.9802893518518518
61138,"API (string dtype): implement hierarchy (NA > NaN, pyarrow > python) for consistent comparisons between different string dtypes","Closes https://github.com/pandas-dev/pandas/issues/60639


This does not yet handle the case of comparison to object dtype.


- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Numeric Operations', 'Strings', 'API - Consistency']",,2025-03-17 10:08:28+00:00,2025-05-19 15:51:39+00:00,,63.23832175925926
61137,Bump pypa/cibuildwheel from 2.23.0 to 2.23.1,"Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 2.23.0 to 2.23.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/releases"">pypa/cibuildwheel's releases</a>.</em></p>
<blockquote>
<h2>v2.23.1</h2>
<ul>
<li>‚ö†Ô∏è Added warnings when the shorthand values <code>manylinux1</code>, <code>manylinux2010</code>, <code>manylinux_2_24</code>, and <code>musllinux_1_1</code> are used to specify the images in linux builds. The shorthand to these (unmaintainted) images will be removed in v3.0. If you want to keep using these images, explicitly opt-in using the full image URL, which can be found in <a href=""https://github.com/pypa/cibuildwheel/blob/v2.23.1/cibuildwheel/resources/pinned_docker_images.cfg"">this file</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2312"">#2312</a>)</li>
<li>üõ† Dependency updates, including a manylinux update which fixes an <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2303"">issue with rustup</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2315"">#2315</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/cibuildwheel/blob/v2.23.1/docs/changelog.md"">pypa/cibuildwheel's changelog</a>.</em></p>
<blockquote>
<h3>v2.23.1</h3>
<p><em>15 March 2025</em></p>
<ul>
<li>‚ö†Ô∏è Added warnings when the shorthand values <code>manylinux1</code>, <code>manylinux2010</code>, <code>manylinux_2_24</code>, and <code>musllinux_1_1</code> are used to specify the images in linux builds. The shorthand to these (unmaintainted) images will be removed in v3.0. If you want to keep using these images, explicitly opt-in using the full image URL, which can be found in <a href=""https://github.com/pypa/cibuildwheel/blob/v2.23.1/cibuildwheel/resources/pinned_docker_images.cfg"">this file</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2312"">#2312</a>)</li>
<li>üõ† Dependency updates, including a manylinux update which fixes an <a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2303"">issue with rustup</a>. (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2315"">#2315</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/42728e866bbc80d544a70825bd9990b9a26f1a50""><code>42728e8</code></a> Bump version: v2.23.1</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/6e1527b153c481c51f987a5e3a1bed216b16a260""><code>6e1527b</code></a> Fix unit test when other warnings are present</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/c25fe603855d4d4dbbb013375765345f346aece0""><code>c25fe60</code></a> fix: image deprecation warning (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2314"">#2314</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/a880bf5105e70f0add65d840db82a7cc6c1555e4""><code>a880bf5</code></a> fix: warn on deprecated images being set (<a href=""https://redirect.github.com/pypa/cibuildwheel/issues/2312"">#2312</a>)</li>
<li><a href=""https://github.com/pypa/cibuildwheel/commit/c087d85b69012f624e0321468b40345d921c72e5""><code>c087d85</code></a> Update dependencies</li>
<li>See full diff in <a href=""https://github.com/pypa/cibuildwheel/compare/v2.23.0...v2.23.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pypa/cibuildwheel&package-manager=github_actions&previous-version=2.23.0&new-version=2.23.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>","['Build', 'CI', 'Dependencies']",,2025-03-17 09:01:30+00:00,2025-03-17 16:59:34+00:00,,0.33199074074074075
61136,Issue Title Here,Description of the issue goes here.,[],,2025-03-17 07:55:45+00:00,2025-03-17 07:56:55+00:00,,0.0008101851851851852
61135,Issue Title Here,Description of the issue goes here.,[],,2025-03-17 07:41:22+00:00,2025-03-17 07:42:01+00:00,,0.00045138888888888887
61134,DOC: Added docstring to Timestamp.tzinfo,"Follow up on #59458

Added docstring to `Timestamp.tzinfo`. Emphasized that `Timestamp.tz` is preferred due to its Pandas-specific functionality. Sections added are as follows:
- Summary
- Extended Summary
- See Also
- Examples

Removed `Timestamp.tzinfo` from code_checks.sh

- [ ] closes #59458 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-16 14:03:43+00:00,2025-03-17 17:20:05+00:00,,1.1363657407407408
61133,ENH: Adding some common functionalities,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Some feature suggestions.

1) Pandas Plotting: Method chaining in plotting would make it really powerful.
sample:- https://github.com/maddytae/pytae/blob/master/src/plotter.ipynb
2) Select: Native R like select function in pandas would make method chaining much more easier.
sample:-https://github.com/maddytae/pytae/blob/master/src/select.ipynb
3) qry:- A dict based filtering criteria.
sample:- https://github.com/maddytae/pytae/blob/master/src/qry.ipynb
4) reshaping: More intuitive reshaping.
sample:- https://github.com/maddytae/pytae/blob/master/src/shape.ipynb
5) aggregation: easy aggregation.
sample:- https://github.com/maddytae/pytae/blob/master/src/agg_df.ipynb
6) Other utilities: Some minor useful functions.
sample:- https://github.com/maddytae/pytae/blob/master/src/other_utilities.ipynb




### Feature Description

Sample implementation:-
1) https://github.com/maddytae/pytae/blob/master/src/pytae/plotting.py
2) https://github.com/maddytae/pytae/blob/master/src/pytae/select.py
3) https://github.com/maddytae/pytae/blob/master/src/pytae/qry.py
4) https://github.com/maddytae/pytae/blob/master/src/pytae/shape.py
5) https://github.com/maddytae/pytae/blob/master/src/agg_df.ipynb
6) https://github.com/maddytae/pytae/blob/master/src/pytae/other_utilities.py

### Alternative Solutions

https://pypi.org/project/pytae/

### Additional Context

Apologies for not following conventions. I am still learning and have little experiencing contributing to open source. I have also leveraged llms for some of the codes but again I am hopeful the ideas I have share others will find some of it useful.","['Enhancement', 'Needs Triage']",,2025-03-16 13:12:18+00:00,2025-03-17 16:27:14+00:00,,1.1353703703703704
61132,BUG: .mode(dropna=False) doesn't work with nullable integers,"Issue #58926
Edited `pandas.core.algorithms.mode` function so that mode(dropna=False) works with nullable integers.
PR of others before: https://github.com/pandas-dev/pandas/pull/58931

- [x] closes #58926 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['NA - MaskedArrays'],,2025-03-16 10:09:09+00:00,2025-03-17 16:33:40+00:00,,1.267025462962963
61131,BUG: Fix inconsistency of converting empty categorical with dtype_backend='pyarrow',"Follows up #59935

- [x] closes #59934 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Dtype Conversions', 'Categorical']",,2025-03-15 21:42:49+00:00,2025-03-17 19:44:21+00:00,,1.9177314814814814
61130,DOC: Add skrub to ecosystem.md,"Skrub is starting to be very mature and very useful.

It provides simple solutions to problems that users really struggle with (I say this based on stackoverflow questions).
It is coded by people who understand very well machine learning in Python (including myself), with the highest quality standards.

I think that directly more users to it will help people, hence I am proposing to add it to this page",['Web'],,2025-03-15 09:27:30+00:00,2025-03-16 06:01:56+00:00,,0.8572453703703704
61129,fix for 61123 read_excel nrows param reads extra rows,"**Issue**: [GH-61123](#)  
When reading Excel files with `pd.read_excel` and specifying `nrows=4`, the behavior differs depending on whether there‚Äôs a blank row between tables. For a file with two tables (each with a header and 3 data rows), `nrows=4` should yield a DataFrame with one header and 3 data rows (shape `(3, n)`). However:
- In `test1.xlsx` (with a blank row), it correctly reads the first table (header + 3 rows).
- In `test2.xlsx` (no blank row), it incorrectly includes the second table‚Äôs header as a data row, resulting in a shape of `(4, n)`.

This inconsistency occurs because `read_excel` doesn‚Äôt properly respect table boundaries when tables are adjacent, despite the `nrows` limit.

**Fix**:  
- Modified `pandas/io/excel/_base.py` and related reader modules (`_openpyxl.py`, `_pyxlsb.py`, `_xlrd.py`) to ensure `nrows` limits reading to the specified number of rows, excluding subsequent table headers even when tables are adjacent.
- Added a new test `test_excel_read_tables_with_and_without_blank_row` in `pandas/tests/io/excel/test_readers.py` to verify that `nrows=4` consistently returns a DataFrame with shape `(3, 2)` (header + 3 data rows) for both cases.

**Changes**:
- Updated Excel reader logic to stop at `nrows` without parsing beyond table boundaries.
- Ensured consistent behavior across `openpyxl`, `pyxlsb`, and `xlrd` engines.
- Squashed commits into a single commit for clarity.

**Verification**:
- Tested with `test1.xlsx` (blank row) and `test2.xlsx` (no blank row).
- Confirmed both now yield a DataFrame with shape `(3, 2)` and only the first table‚Äôs data.

**Steps to Test**:
1. Run `pytest pandas/tests/io/excel/test_readers.py::TestReaders::test_excel_read_tables_with_and_without_blank_row`.
2. Verify `df1.shape == (3, 2)` and `df2.shape == (3, 2)` match the expected output.

**Related Files**:
- `pandas/io/excel/_base.py`
- `pandas/io/excel/_openpyxl.py`
- `pandas/io/excel/_pyxlsb.py`
- `pandas/io/excel/_xlrd.py`
- `pandas/tests/io/excel/test_readers.py`

Closes #61123",[],,2025-03-15 05:32:09+00:00,2025-03-17 20:13:36+00:00,,2.6121180555555554
61127,fix for 61123 read_excel-nrows-param-reads-extra-rows,"**Issue**: [GH-61123](#)  
When reading Excel files with `pd.read_excel` and specifying `nrows=4`, the behavior differs depending on whether there‚Äôs a blank row between tables. For a file with two tables (each with a header and 3 data rows), `nrows=4` should yield a DataFrame with one header and 3 data rows (shape `(3, n)`). However:
- In `test1.xlsx` (with a blank row), it correctly reads the first table (header + 3 rows).
- In `test2.xlsx` (no blank row), it incorrectly includes the second table‚Äôs header as a data row, resulting in a shape of `(4, n)`.

This inconsistency occurs because `read_excel` doesn‚Äôt properly respect table boundaries when tables are adjacent, despite the `nrows` limit.

**Fix**:  
- Modified `pandas/io/excel/_base.py` and related reader modules (`_openpyxl.py`, `_pyxlsb.py`, `_xlrd.py`) to ensure `nrows` limits reading to the specified number of rows, excluding subsequent table headers even when tables are adjacent.
- Added a new test `test_excel_read_tables_with_and_without_blank_row` in `pandas/tests/io/excel/test_readers.py` to verify that `nrows=4` consistently returns a DataFrame with shape `(3, 2)` (header + 3 data rows) for both cases.

**Changes**:
- Updated Excel reader logic to stop at `nrows` without parsing beyond table boundaries.
- Ensured consistent behavior across `openpyxl`, `pyxlsb`, and `xlrd` engines.
- Squashed commits into a single commit for clarity.

**Verification**:
- Tested with `test1.xlsx` (blank row) and `test2.xlsx` (no blank row).
- Confirmed both now yield a DataFrame with shape `(3, 2)` and only the first table‚Äôs data.

**Steps to Test**:
1. Run `pytest pandas/tests/io/excel/test_readers.py::TestReaders::test_excel_read_tables_with_and_without_blank_row`.
2. Verify `df1.shape == (3, 2)` and `df2.shape == (3, 2)` match the expected output.

**Related Files**:
- `pandas/io/excel/_base.py`
- `pandas/io/excel/_openpyxl.py`
- `pandas/io/excel/_pyxlsb.py`
- `pandas/io/excel/_xlrd.py`
- `pandas/tests/io/excel/test_readers.py`

Closes #61123",[],,2025-03-15 05:07:16+00:00,2025-03-15 05:19:33+00:00,,0.008530092592592593
61126,DOC: Write user guide page on apply/map/transform methods,"There is some information in our documentation regarding how to use user defined functions in pandas. The API pages of the used methods, and these sections:

- https://pandas.pydata.org/docs/user_guide/groupby.html#aggregation-with-user-defined-functions
- https://pandas.pydata.org/docs/user_guide/gotchas.html#gotchas-udf-mutation

My understanding is that we've been mostly discouraging the use of functions like apply, or at least the community has with many posts and comments regarding `apply` is slow, which seem fair. With the work going on supporting JIT compilers on these functions (see https://github.com/pandas-dev/pandas/pull/54666 and https://github.com/pandas-dev/pandas/pull/61032) this can hopefully change, and allow in some cases for clearer code while not compromising speed.

I think it may be difficult to communicate all the information related to udf in the existing sections on group by and FAQ pages and in the API docs. A dedicated page in the users guide that guides users on when to use udf, a general idea of the API, the differences between the different methods, the options available... seems a better idea.

Also, the APIs of the different methods are quite inconsistent, and in some cases cumbersome. I think writing this page will be a good exercise to identify cases when explaining the functionality to the users is complex and not intuitive, and see if we can address them.","['Docs', 'Apply']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-15 04:03:22+00:00,2025-05-18 19:31:47+00:00,arthurlw,64.6447337962963
61124,ENH: fillna enhancement with method='nearest',"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

This should be a simple follow-up to https://github.com/pandas-dev/pandas/issues/9471, enabling support for alignment with method='nearest'.

Since fillna internally uses interpolate, which already supports method='nearest', this might work right away, though it will require extensive testing.

### Feature Description

The new feature could be implemented by extending the current alignment functionality in Pandas to support `method='nearest'`. This would allow the user to align two Series or DataFrames by their indices, using the nearest available value when exact matches are not found. Here's a basic idea of how it could be implemented in pseudocode:

```python
def align_nearest(df1, df2):
    # Use a nearest neighbor search to align the indices
    df1_nearest = df1.reindex(df2.index, method='nearest')
    return df1_nearest
```

This functionality could be added as a method to the existing `pandas.DataFrame` and `pandas.Series` objects, integrating smoothly into the current API.


### Alternative Solutions

  An alternative solution would be to use the existing `interpolate` function with `method='nearest'`, which can be applied to the DataFrame or Series before performing the alignment. Additionally, third-party libraries like `fuzzywuzzy` or `scipy.spatial` could be used for more complex nearest matching.

```python
import pandas as pd
from fuzzywuzzy import process

# Example using fuzzywuzzy to find nearest match
df1 = pd.DataFrame([...])
df2 = pd.DataFrame([...])
df1['nearest'] = df1['index_column'].apply(lambda x: process.extractOne(x, df2['index_column'])[0])
```

However, native support within Pandas would likely be more efficient and user-friendly.


### Additional Context

 ","['Enhancement', 'Missing-data', 'Needs Info']",,2025-03-15 01:03:57+00:00,2025-08-05 17:08:20+00:00,,143.66971064814814
61123,DOC: `read_excel` `nrows` parameter reads extra rows when tables are adjacent (no blank row),"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# Two tables, each header row + 3 data rows
file1 = ""test1.xlsx"" # blank row between the tables
file2 = ""test2.xlsx"" # no blank row between the tables
df1 = pd.read_excel(file1, header=0, nrows=4)
df2 = pd.read_excel(file2, header=0, nrows=4)

print(df1)
print(df2)
assert df1.shape == df2.shape

# df2 includes the header row of the following table
```

### Issue Description

Consider two Excel files with nearly identical data: two tables, each with a header row and 3 data rows. The only difference is that the first has a blank row between the tables and the second does not.

It seems that the blank line makes a difference, even when `nrows` is specified. I expect `nrows=4` to always parse 4 rows, yielding a data frame with a header and 3 data rows. Yet without a blank line, `read_excel` also includes the next row, which is the header for the next table.

[test1.xlsx](https://github.com/user-attachments/files/19254818/test1.xlsx)
[test2.xlsx](https://github.com/user-attachments/files/19254817/test2.xlsx)

### Expected Behavior

I expect `nrows=4` to always parse 4 rows regardless of context: a header and 3 data rows.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.0rc1
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.12.3
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.3
lxml.etree            : None
matplotlib            : 3.8.4
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.2
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.2.0
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : None
tzdata                : 2024.1
qtpy                  : None
pyqt5                 : None

</details>
","['Docs', 'IO Excel', 'good first issue']",,2025-03-14 21:30:43+00:00,2025-03-19 20:37:24+00:00,,4.962974537037037
61122,BUG: ``Series.interpolate`` regression in latest Pandas 3.0.0 nightly (method 'linear' behaves like 'index'),"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [ ] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd

s = pd.Series([1.0, np.nan, 3.0], index=[1, 3, 4])
s.interpolate(method='linear')
s.interpolate(method='index')
```

### Issue Description

The interpolation method 'linear' behaves like the method 'index' with current Pandas 3.0.0 nightly. This is a regression from 2.2.3.

According to the documentation (stable and dev):

> Interpolation technique to use. One of:
>
>  - ‚Äòlinear‚Äô: Ignore the index and treat the values as equally spaced. This is the only method supported on MultiIndexes.
> [...]
>  - ‚Äòindex‚Äô: The interpolation uses the numerical values of the DataFrame‚Äôs index to linearly calculate missing values.

In the example above, the index is not linearly spaced. But both interpolation methods return the output that is expected for the 'index' method when using the latest Pandas 3.0.0 nightly.

```
>>> s.interpolate(method='linear')
1    1.000000
3    2.333333
4    3.000000
dtype: float64
>>> s.interpolate(method='index')
1    1.000000
3    2.333333
4    3.000000
dtype: float64
```

### Expected Behavior

The output should be different and ``'linear'`` should ignore the non-linearly spaced index. The expected output should be the same as with Pandas 2.2.3:

```
>>> s.interpolate(method='linear')
1    1.0
3    2.0
4    3.0
dtype: float64
>>> s.interpolate(method='index')
1    1.000000
3    2.333333
4    3.000000
dtype: float64
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : ddd0aa8dc73481017330892dfd0ea95c0dfaa1d3
python                : 3.12.1
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19044
machine               : AMD64
processor             : AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United Kingdom.1252

pandas                : 3.0.0.dev0+2010.gddd0aa8dc7
numpy                 : 2.3.0.dev0+git20250311.a651643
dateutil              : 2.9.0.post0
pip                   : 23.2.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pytz                  : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Missing-data', 'Regression', 'Blocker']","{'login': 'rhshadrach', 'id': 45562402, 'node_id': 'MDQ6VXNlcjQ1NTYyNDAy', 'avatar_url': 'https://avatars.githubusercontent.com/u/45562402?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/rhshadrach', 'html_url': 'https://github.com/rhshadrach', 'followers_url': 'https://api.github.com/users/rhshadrach/followers', 'following_url': 'https://api.github.com/users/rhshadrach/following{/other_user}', 'gists_url': 'https://api.github.com/users/rhshadrach/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/rhshadrach/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/rhshadrach/subscriptions', 'organizations_url': 'https://api.github.com/users/rhshadrach/orgs', 'repos_url': 'https://api.github.com/users/rhshadrach/repos', 'events_url': 'https://api.github.com/users/rhshadrach/events{/privacy}', 'received_events_url': 'https://api.github.com/users/rhshadrach/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-14 16:52:42+00:00,2025-03-29 18:01:33+00:00,rhshadrach,15.0478125
61121,WEB: Update sponsors and fix logos style,"Updating the list of sponsors, @jreback @jorisvandenbossche @jbrockmendel please let me know if I'm mistaken.

Also, fixing the style of the logos, which had the centering wrong, and a border was introduced by mistake:

![Screenshot at 2025-03-14 23-15-34](https://github.com/user-attachments/assets/fe67b218-b68d-4def-ae85-038dddc70a1e)
",['Web'],,2025-03-14 16:20:33+00:00,2025-03-24 16:04:13+00:00,,9.988657407407407
61120,BUG: .corr() values significantly higher than 1,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
data = pd.DataFrame(dict(
    x=[0, 1],
    y=[1.35951, 1.3595100000000007]
))
data.corr().max().max()
```

### Issue Description

The example above results in `1.1547005383792517`.

This is similar to https://github.com/pandas-dev/pandas/issues/35135 which was closed as ""_not an issue with pandas, but just numerical computations_"" but differently to that issue which showed minuscule differences (practically negligible), I am presenting an example where the Pearson correlation is over 15% above the maximum of 1.

I was able to reproduce this on multiple machines.

I think this might warrant a mention in the documentation.

### Expected Behavior

These two are perfectly correlated, so we would expect `1`. `1` is the result for both:
- `(data + 0.0000000000000002).corr().max().max()`
- `(data - 0.0000000000000002).corr().max().max()`

Interestingly, using `corrwith` or R leads to a different result which under-estimates the correlation (but at least is not out of range, and the relative error is smaller!):
- `data[['x']].corrwith(data['y'])` returns `0.948683`
- `cor` in R also returns 0.9486833
```
cor(c(0, 1), c(1.35951, 1.3595100000000007))
[1] 0.9486833
```


### Installed Versions

<details>

```
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.4
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-55-generic
Version               : #57-Ubuntu SMP PREEMPT_DYNAMIC Wed Feb 12 23:42:21 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_GB.UTF-8
LOCALE                : en_GB.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.3
pytz                  : 2023.3.post1
dateutil              : 2.8.2
pip                   : 23.1.2
Cython                : None
sphinx                : None
IPython               : 9.0.0.dev
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.3
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 15.0.0
pyreadstat            : None
pytest                : 7.4.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2023.4
qtpy                  : None
pyqt5                 : None
```

</details>
","['Bug', 'cov/corr']","{'login': 'j-hendricks', 'id': 105813545, 'node_id': 'U_kgDOBk6WKQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/105813545?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/j-hendricks', 'html_url': 'https://github.com/j-hendricks', 'followers_url': 'https://api.github.com/users/j-hendricks/followers', 'following_url': 'https://api.github.com/users/j-hendricks/following{/other_user}', 'gists_url': 'https://api.github.com/users/j-hendricks/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/j-hendricks/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/j-hendricks/subscriptions', 'organizations_url': 'https://api.github.com/users/j-hendricks/orgs', 'repos_url': 'https://api.github.com/users/j-hendricks/repos', 'events_url': 'https://api.github.com/users/j-hendricks/events{/privacy}', 'received_events_url': 'https://api.github.com/users/j-hendricks/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-14 13:05:53+00:00,2025-03-25 17:11:41+00:00,j-hendricks,11.170694444444445
61119,DOC: Added docstrings to min/max/reso for Timedelta,"Issue: #59698

Added docstrings to `pandas.Timedelta.min`,  `pandas.Timedelta.max`, and `pandas.Timedelta.resolution`

- [ ] closes #59698 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-14 11:53:14+00:00,2025-03-17 16:54:39+00:00,,3.2093171296296297
61118,"BUG/TST/DEPR: Ensure dtype=""category"" always implies ordered=False & add tests","- [ ] closes #61074  
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Issue: Previously, if a Series had ordered=True, using astype(""category"") would incorrectly preserve the ordering. This was inconsistent and against expectations.

Fix:
1. Now, dtype=""category"" always implies ordered=False.
2. If ordered=True before conversion, a deprecation warning is raised to inform users.
3. Tests have been updated to verify this new behavior.
",[],,2025-03-13 23:32:42+00:00,2025-04-14 17:10:05+00:00,,31.734293981481482
61117,DOC: Added docs to min/max/resolution for Timedelta,"- [ ] closes #59698 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-13 23:20:38+00:00,2025-03-14 11:34:42+00:00,,0.5097685185185186
61116,Bug: Save original index and remap after function completes,"- [x] closes #55767
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Note: I'm new to this project, so this is my first PR.

Saves the index for SeriesNLargest at algorithm start and resets it before returning. This fixes performance issues when the index has many duplicate values.

### Results:
- The original statistics can be viewed in the original ticket, but slow_df was several ms. Note that the results in the ticket were not from my development machine and specific timings differ.
```
In [4]: import pandas as pd
   ...: import numpy as np
   ...: 
   ...: N = 1500
   ...: N_HALF = 750
   ...: 
   ...: slow_df = pd.DataFrame({'a':  np.random.rand(N)}, index=np.concatenate([[1] * N_HALF, np.arange(N_HALF)]))
   ...: print(""slow_df"")
   ...: %timeit slow_df['a'].nlargest()
   ...: 
   ...: fast_df = pd.DataFrame({'a': np.random.rand(N)})
   ...: print(""fast_df"")
   ...: %timeit fast_df['a'].nlargest()

slow_df
427 Œºs ¬± 11.4 Œºs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
fast_df
420 Œºs ¬± 5.4 Œºs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)

```

### Tests
The existing tests should cover this unless we want to add specific tests via the `asv_bench`.

### Addendum
I also modified the call to sort to use `sort(kind=""stable"")` to get consistent ordering which is what is currently happening in the equivalent Frame method (it was using `kind=mergesort` which is equivalent to `kind=stable`, but kept for portability). I can remove this -- it may be better in another PR.
https://numpy.org/doc/stable/reference/generated/numpy.sort.html#numpy.sort","['Performance', 'Filters']",,2025-03-13 20:23:53+00:00,2025-04-15 00:59:23+00:00,,32.191319444444446
61115,BUG: Raise TypeError when subracting DateTimeArray and other date types,"- [ ] closes #59571
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-13 05:16:08+00:00,2025-03-13 10:49:52+00:00,,0.23175925925925925
61114,BUG: Fix bug in reindexing of period columns after unstack,"- [ ] closes #60980
- [ ] closes #60273
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

When indexing a `Period` block, the `BaseBlockManager.reindex_indexer` method thinks `Period` blocks can't store 2D values and always returns the first element. This is because it uses a hardcoded list of types (which is missing `PeriodDtype`) that are known to allow 2D values. The fix is to use the `is_1d_only_ea_dtype` utility function which internally uses the `_supports_2d` flag of the dtype.

The bug only happens when indexing a 2D period block, which may be created after operations like transpose, pivot, unstack etc.","['Indexing', 'Period']",,2025-03-13 00:02:18+00:00,2025-03-17 16:55:31+00:00,,4.703622685185185
61113,BUG: `pivot_table` drops rows and columns despite values being non-`NaN`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd
import pandas._testing as tm


def test_pivot_table_index_and_column_with_nan() -> None:
    """"""Index and columns should exist if any non-null values.

    Input data
    ----------
        row  col  val
    0  NaN  0.0    0
    1  0.0  1.0    1
    2  1.0  2.0    2
    3  2.0  3.0    3
    4  3.0  NaN    4

    Expected output
    ---------------
    col  0.0  1.0  2.0  3.0  NaN
    row                         
    NaN  0.0  NaN  NaN  NaN  NaN
    0.0  NaN  1.0  NaN  NaN  NaN
    1.0  NaN  NaN  2.0  NaN  NaN
    2.0  NaN  NaN  NaN  3.0  NaN
    3.0  NaN  NaN  NaN  NaN  4.0
    """"""
    data = {
        ""row"": [None, *range(4)],
        ""col"": [*range(4), None],
        ""val"": range(5)
    }
    df = pd.DataFrame(data)
    actual = df.pivot_table(values=""val"", index=""row"", columns=""col"")
    e_index = [None, *range(4)]
    e_columns = [*range(4), None]
    e_data = np.zeros(shape=(5, 5))
    e_data.fill(np.NaN)
    np.fill_diagonal(a=e_data, val=range(5))
    expected = pd.DataFrame(
        data=e_data,
        index=pd.Index(data=e_index, name=""row""),
        columns=pd.Index(data=e_columns, name=""col"")
    )
    tm.assert_frame_equal(left=actual, right=expected)  # fails
```

### Issue Description

Rows and columns are unexpectedly dropped while creating a pivot table with a single `NaN` index label and a single `NaN` column label and _no_ `NaN` values in the input data.

# Input data
```text
   row  col  val
0  NaN  0.0    0
1  0.0  1.0    1
2  1.0  2.0    2
3  2.0  3.0    3
4  3.0  NaN    4
```

# Actual output
```text
col  1.0  2.0  3.0
row               
0.0  1.0  NaN  NaN
1.0  NaN  2.0  NaN
2.0  NaN  NaN  3.0
```

### Expected Behavior

The docs for `dropna` state:
> Do not include columns whose entries are all NaN. If True, rows with a NaN value in any column will be omitted before computing margins.

Given that `dropna=True` by default, I'd expect all columns and rows to be present as each has _at least one_ non-`NaN` value.

# Expected output
```text
col  0.0  1.0  2.0  3.0  NaN
row                         
NaN  0.0  NaN  NaN  NaN  NaN
0.0  NaN  1.0  NaN  NaN  NaN
1.0  NaN  NaN  2.0  NaN  NaN
2.0  NaN  NaN  NaN  3.0  NaN
3.0  NaN  NaN  NaN  NaN  4.0
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 3c93d06d641621ff62453c9c7748eeec3d6d8a97
python                : 3.13.2
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.22631
machine               : AMD64
processor             : AMD64 Family 25 Model 116 Stepping 1, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252
pandas                : 3.0.0.dev0+2007.g3c93d06d64
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 9.0.2
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2025.3.0
html5lib              : 1.1
hypothesis            : 6.129.0
gcsfs                 : 2025.3.0
jinja2                : 3.1.6
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 19.0.1
pyreadstat            : 1.2.8
pytest                : 8.3.5
python-calamine       : None
pytz                  : 2025.1
pyxlsb                : 1.0.10
s3fs                  : 2025.3.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.39
tables                : 3.10.2
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Docs', 'Missing-data', 'Reshaping']",,2025-03-12 23:41:34+00:00,2025-04-02 21:28:17+00:00,,20.90744212962963
61112,TST: Add test for retaining dtype of datetime columns in DataFrame.to_hdf,"- [x] closes #60353 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Testing'],,2025-03-12 13:24:56+00:00,2025-03-12 23:50:30+00:00,,0.4344212962962963
61111,DOC: Update infer_dtype docstring,"- [x] closes #61081

",['Docs'],,2025-03-12 08:59:46+00:00,2025-03-13 15:38:16+00:00,,1.276736111111111
61110,ENH: Automate reading of data in chunks,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I have a file with 20Gb of data that I need to process. When I use a pandas dataframe, the full 20Gb need to be loaded. That will make the computer slow or even crash. Can this process be made more efficient by _automatically_ (very very important that the user does not have to do anything here) loads a chunk, processes it, writes it, loads the second chunk, etc. 

This is stuff is possible, it is done by [ROOT](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) for instance.

### Feature Description

This would just work with the normal dataframes, there could be an option like

```python
pd.chunk_size = 100
```
which would process 100Mb at a time. So that no more than 100 Mb would be in memory.

### Alternative Solutions

Alternatively we can

```python
import ROOT

rdf = ROOT.RDataFrame('tree', 'path_to_file.root')
```

### Additional Context

_No response_","['Enhancement', 'Needs Info', 'Closing Candidate']",,2025-03-12 06:58:57+00:00,2025-08-05 16:30:42+00:00,,146.3970486111111
61109,ENH: Passing a single value to .describe(percentiles = [0.25]) returns 25th- and 50th-percentile,Just created the PR still have to work on the code.,[],,2025-03-12 03:12:00+00:00,2025-03-24 16:43:08+00:00,,12.563287037037037
61108,DOC: Updated link for OVH server benchmark visualization,"- [x] closes #60915 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-12 02:43:52+00:00,2025-04-13 17:58:40+00:00,,32.63527777777778
61107,Backport PR #61085 on branch 2.3.x (DEPS: Update NumpyExtensionArray repr for NEP51),Backport PR #61085: DEPS: Update NumpyExtensionArray repr for NEP51,"['Output-Formatting', 'ExtensionArray']",,2025-03-12 01:27:52+00:00,2025-03-12 16:51:22+00:00,,0.6413194444444444
61106,DOC: fix docstring validation errors for pandas.util.hash_pandas_object and pandas.Timestamp.resolution,"follow up on issue #59458 and #27977

for pandas.util.hash_pandas_object:
- Add parameter description to obj parameter
- Correct the Returns section
	- Change the type line to correctly callout 'Series' type
	- Update return description to describe the type contained in the Series
- Add See Also section
- Removed from code_checks.sh

for pandas.Timestamp.resolution
- Removed from code_checks.sh (I don't believe more work is needed because resolution is no longer a function, see #29910 ",['Stale'],,2025-03-11 22:50:04+00:00,2025-04-11 00:18:07+00:00,,30.061145833333335
61105,BUG: DataFrame.explode doesn't work for pyarrow.large_list type,"- [ ] closes #61091 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
",['Arrow'],,2025-03-11 20:38:06+00:00,2025-03-11 22:20:33+00:00,,0.07114583333333334
61104,DOC: iss-59698-pandas-Timedelta-to_numpy-PR01 ,"Updated dtypes and copy
",['Stale'],,2025-03-11 19:13:57+00:00,2025-04-11 00:17:41+00:00,,30.210925925925928
61103,Enh arrow json extension,"- [x] closes #60958 
- [x] [Tests added and passed]
- [x] All [code checks passed]
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Arrow'],,2025-03-11 18:23:19+00:00,2025-03-12 23:51:30+00:00,,1.2279050925925925
61102,Backport PR #61098: CI/TST: Address TestArrowArray::test_reduce_series_numeric supporting skew,,"['Testing', 'Arrow']",,2025-03-11 17:18:19+00:00,2025-03-13 15:45:05+00:00,,1.9352546296296296
61101,BUG: Passing original properties of `DataFrame` and `Series` subclasses to their constructors,"- [x] closes #34177 BUG: Subclassed DataFrame doesn't persist \_metadata properties across binary operations
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
No new arguments, methods nor functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

While implementing a subclass of `Dataframe`, I found that in some operations, objects that subclass's `DataFrame` and `Series` forget their original properties.

```python
import pandas as pd

class SubclassedSeries(pd.Series):
    _metadata = ['original_property']
    def __init__(self, data=None, original_property=None, *args, **kwargs):
        super().__init__(data, *args, **kwargs)
        self.original_property = original_property
    @property
    def _constructor(self):
        return SubclassedSeries
    @property
    def _constructor_expanddim(self):
        return SubclassedDataFrame


class SubclassedDataFrame(pd.DataFrame):
    _metadata = ['original_property']
    def __init__(self, data=None, original_property=None, *args, **kwargs):
        super().__init__(data, *args, **kwargs)
        self.original_property = original_property
    @property
    def _constructor(self):
        return SubclassedDataFrame
    @property
    def _constructor_sliced(self):
        return SubclassedSeries

## __init__
df = SubclassedDataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'], 'value': [1, 2, 3, 5]}, original_property='original_property')
print(f'__init__: {df.original_property}')

## Select
select_df = df[df['value'] == '1']
print(f'Select: {df.original_property}')

## loc
loc_df = df.loc[df['lkey'] == 'foo']
print(f'loc: {loc_df.original_property}')

## Concat
df = pd.concat([df, df])
print(f'Concat: {df.original_property}')

## Merge
df1 = SubclassedDataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],
                   'value': [1, 2, 3, 5]}, original_property='original_property')
df2 = SubclassedDataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],
                   'value': [5, 6, 7, 8]}, original_property='original_property')
merged_df = df1.merge(df2, left_on='lkey', right_on='rkey')
print(f'Merge: {merged_df.original_property}')

## Series
series = df['value']
print(f'Series: {series.original_property}')

## Sum
sum_df = df1 + df2
print(f'Sum: {sum_df.original_property}')

(df * 2).added_property
```
This functionality is critical for my project so I decided to fix it. I had the following considerations:

- `__init__` parameters in both parent classes weren't modified.
- `_name` stays in `Series._metadata` and their children because [@540db96b](https://github.com/pandas-dev/pandas/commit/540db96b8179c2ed83e427b9d501b04d68ee1804). It is removed right before the calling the constructor and added again in `__init__` of parent class.
- I added a unit test covering the cases mentioned above. I mentioned #34177 but I think #32860, #35415, #32638, #19850 and #8572 are related.
- Each `DataFrame` child must come with their respective `Series` child (and vice versa). Both children must contain and handle the same `_metadata` parameters.
- The constructors' parameters of both children must begin with `data=None`. The example with `(self, data=None, **_metadata, *args, **kwargs)` was the cleanest I was able to think without having to clean `*args` and `**kwargs` (like the old unit test in pandas/tests/frame/test_subclass.py:MySubclassWithMetadata). Not enforcing `data` as the first parameter and having to clean up `*args` and `**kwargs` felt as wrong as adding `*args` and `**kwargs` to `__init__` in both parents.

My environment consist on SUSE 15.6 and Python 3.11.11

Edit: Removed WIP comments about tests and code checks.",['Stale'],,2025-03-11 15:26:39+00:00,2025-07-28 17:16:57+00:00,,139.07659722222223
61100,DOC: Add GL08 for pandas.Timestamp.tzinfo,"- [x] xref [DOC: Enforce Numpy Docstring Validation for pandas.Timestamp #58550](https://github.com/pandas-dev/pandas/issues/58505)

fixes
```
pandas.Timestamp.tzinfo
```
",['Docs'],,2025-03-11 02:03:59+00:00,2025-03-17 16:57:40+00:00,,6.620613425925926
61099,BUG: Can only compare identically-labeled Series objects (string vs. object),"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
s1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])
s2 = pd.Series([4, 5, 6], index=['a', 'b', 'c'])
s2.index = s2.index.astype('string')

s1 < s2  # fails

s1, s2 = s1.align(s2)
s1 < s2  # also fails

s1 = s1.reindex(s2.index)
s1 < s2  # succeeds
```

### Issue Description

When a series (or dataframe) with otherwise identical indices are compared, but the indexes are *technically* dtype(object) and dtype(string), element-wise comparison fails. In the debugger, it looks like the ExtensionArray StringArray.equals is False when comparing to a python list of strings, causing Series._indexed_same to return False.

### Expected Behavior

Ideally the string and object dtype would be comparable. This in-between state for Pandas dtypes has been quite awkward, with some libraries porting over to numpy-nullable / pyarrow dtype backends, but the Pandas library defaults not using them yet. 

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Strings', 'Index']","{'login': 'sanggon6107', 'id': 68040183, 'node_id': 'MDQ6VXNlcjY4MDQwMTgz', 'avatar_url': 'https://avatars.githubusercontent.com/u/68040183?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/sanggon6107', 'html_url': 'https://github.com/sanggon6107', 'followers_url': 'https://api.github.com/users/sanggon6107/followers', 'following_url': 'https://api.github.com/users/sanggon6107/following{/other_user}', 'gists_url': 'https://api.github.com/users/sanggon6107/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/sanggon6107/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/sanggon6107/subscriptions', 'organizations_url': 'https://api.github.com/users/sanggon6107/orgs', 'repos_url': 'https://api.github.com/users/sanggon6107/repos', 'events_url': 'https://api.github.com/users/sanggon6107/events{/privacy}', 'received_events_url': 'https://api.github.com/users/sanggon6107/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-10 20:18:17+00:00,2025-07-10 20:58:45+00:00,sanggon6107,122.02810185185186
61098,CI/TST: Address TestArrowArray::test_reduce_series_numeric supporting skew,xref https://github.com/apache/arrow/pull/45677,"['Testing', 'Arrow']",,2025-03-10 17:59:07+00:00,2025-03-11 04:32:47+00:00,,0.44004629629629627
61097,"DOC: Remove outdated comment, use DateOffset instead of BaseOffset in docs","- closes #60886 
- `PeriodDtype.from_date_offset` was removed in #46338
- some drive-by walruses",['Docs'],,2025-03-10 15:56:46+00:00,2025-03-24 16:41:45+00:00,,14.031238425925926
61096,"DOCS: remove outdated `PeriodDtype.from_date_offset` comment, use `DateOffset` instead of `BaseOffset` in docstrings","- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

- closes #60886 
- `PeriodDtype.from_date_offset` was removed in #46338
- some drive-by walruses",[],,2025-03-10 15:51:46+00:00,2025-03-10 15:56:05+00:00,,0.0029976851851851853
61095,BLD: add option to specify numpy header location,"In some cases the numpy module might not be usable during build-time, especially when cross-compiling. (E.g. when compiling for arm32 on a x86-64 machine, the arm32 module is not usable at build time).

This makes meson fail, as it isn't able to figure out the location of numpy headers.

To allow an alternative way to find these headers, introduce a meson build option, where the location of the numpy headers can be specified.

In case numpy module cannot be loaded for some reason to query the include folder location, fall back to the value of this meson option.

- [x] closes #55305 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Build'],,2025-03-10 13:17:09+00:00,2025-03-18 19:03:23+00:00,,8.240439814814815
61093,ENH: Support dict to `pd.set_option` for cleaner code,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I wish that I could use dict for `pd.set_option`, just like other packages typically accept dict when there are lots of option. Current pandas style follow what old programming language do, such as MATLAB.

### Feature Description

```python
import pandas as pd

options = {
    'display.precision': 2,
    'display.max_columns': 100,
    'styler.format.precision': 2,
}

# like this
pd.set_option(**options)

# or like this:
pd.set_option(options)
```

### Alternative Solutions

Current implementations is:

```python
pd.set_option('display.precision', 2)
pd.set_option('display.max_columns', 100)
pd.set_option('styler.format.precision', 2)

# or

options = {
    'display.precision': 2,
    'display.max_columns': 100,
    'styler.format.precision': 2,
}

for key, value in options.items():
    pd.set_option(key, value)
```

### Additional Context

Because if I write it like this:

```python
pd.set_option(
    'display.precision', 2,
    'display.max_columns', 100,
    'styler.format.precision', 2,
)
```

An auto formatter like `ruff` will make it into:

```python
pd.set_option(
    'display.precision',
    2,
    'display.max_columns',
    100,
    'styler.format.precision',
    2,
)
```","['Enhancement', 'API Design']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-10 03:44:46+00:00,2025-05-29 18:44:32+00:00,arthurlw,80.62483796296296
61092,Updated infer_dtype docstring,"- [x] closes #61081 
",[],,2025-03-10 00:24:18+00:00,2025-03-12 09:59:03+00:00,,2.3991319444444446
61091,BUG: DataFrame.explode doesn't explode when using pyarrow large list type,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
In [4]: pd.DataFrame({'a': [[1, 2], [3, 4]]}, dtype=pd.ArrowDtype(pa.list_(pa.int64()))).explode('a')
Out[4]:
   a
0  1
0  2
1  3
1  4

In [5]: pd.DataFrame({'a': [[1, 2], [3, 4]]}, dtype=pd.ArrowDtype(pa.large_list(pa.int64()))).explode('a')
Out[5]:
       a
0  [1 2]
1  [3 4]
```

### Issue Description

For `list_`, it explodes correctly, but for `large_list`, it's a no-op

### Expected Behavior

```
   a
0  1
0  2
1  3
1  4
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 57fd50221ea3d5de63d909e168f10ad9fc0eee9b
python                : 3.10.12
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+1979.g57fd50221e
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 8.33.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2025.2.0
html5lib              : 1.1
hypothesis            : 6.127.5
gcsfs                 : 2025.2.0
jinja2                : 3.1.5
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 19.0.1
pyreadstat            : 1.2.8
pytest                : 8.3.5
python-calamine       : None
pytz                  : 2025.1
pyxlsb                : 1.0.10
s3fs                  : 2025.2.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.38
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Reshaping', 'Arrow']","{'login': 'snitish', 'id': 7503884, 'node_id': 'MDQ6VXNlcjc1MDM4ODQ=', 'avatar_url': 'https://avatars.githubusercontent.com/u/7503884?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/snitish', 'html_url': 'https://github.com/snitish', 'followers_url': 'https://api.github.com/users/snitish/followers', 'following_url': 'https://api.github.com/users/snitish/following{/other_user}', 'gists_url': 'https://api.github.com/users/snitish/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/snitish/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/snitish/subscriptions', 'organizations_url': 'https://api.github.com/users/snitish/orgs', 'repos_url': 'https://api.github.com/users/snitish/repos', 'events_url': 'https://api.github.com/users/snitish/events{/privacy}', 'received_events_url': 'https://api.github.com/users/snitish/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-09 15:33:23+00:00,2025-03-11 22:20:34+00:00,snitish,2.2827662037037038
61090,Boolean indexing inconsistency,"- [x] closes #60994
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-09 03:53:01+00:00,2025-03-10 21:27:05+00:00,,1.7319907407407407
61089,Update hist.py,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-09 00:23:17+00:00,2025-03-24 16:41:01+00:00,,15.67898148148148
61088,Update boxplot.py,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-03-08 23:28:43+00:00,2025-03-09 00:07:03+00:00,,0.02662037037037037
61087,ENH: Add Rolling.nunique(),"- [ ] closes #26958 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

Hash-map (C++ `unordered_map` via Cython) based implementation of `Rolling.nunique()` with `O(N)` average time complexity.","['Enhancement', 'Window']",,2025-03-08 22:15:38+00:00,2025-03-10 17:11:09+00:00,,1.7885532407407407
61085,DEPS: Update NumpyExtensionArray repr for NEP51,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Continuation of #54268
","['Output-Formatting', 'ExtensionArray']",,2025-03-08 20:56:31+00:00,2025-03-12 01:27:23+00:00,,3.188101851851852
61084,BUG: Improve ImportError message to suggest importing dependencies directly for full error details,"- [x] closes #61030 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Build', 'Error Reporting']",,2025-03-08 17:45:09+00:00,2025-04-14 16:39:18+00:00,,36.95427083333333
61083,Bug: Fix for overflow at edge cases in `normalize()` by raising exception,"- [x] closes #60583 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-03-08 08:04:46+00:00,2025-05-19 16:18:05+00:00,,72.34258101851852
61082,DOC: Add doc for half year offsets,Adding doc for newly added HalfYear date offset (added as part of #60946),['Docs'],,2025-03-08 04:58:39+00:00,2025-03-10 17:32:55+00:00,,2.5237962962962963
61081,BUG: pd.api.types.infer_dtype on scalar input,"### Context
I was trying to identify data types in columns with mixed data types:
```python
df.map(pd.api.types.infer_dtype)
```


### Pandas version checks

- [x] I have checked that this issue has not already been reported.
- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.
- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

pd.api.types.infer_dtype(1)
pd.api.types.infer_dtype(1.0)
pd.api.types.infer_dtype(True)
```

### Issue Description

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[8], line 1
----> 1 pd.api.types.infer_dtype(1)

File lib.pyx:1605, in pandas._libs.lib.infer_dtype()

TypeError: 'int' object is not iterable
```

### Expected Behavior

According to the documentation, pd.api.types.infer_dtype() should accept scalar input.

### Installed Versions

<details>

```
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.5
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 154 Stepping 4, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.1.0
pytz                  : 2024.1
dateutil              : 2.9.0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.9.2
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : 2.0.37
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2024.1
qtpy                  : None
pyqt5                 : None
```

</details>
","['Bug', 'Docs']","{'login': 'gm-oo9', 'id': 146922228, 'node_id': 'U_kgDOCMHa9A', 'avatar_url': 'https://avatars.githubusercontent.com/u/146922228?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/gm-oo9', 'html_url': 'https://github.com/gm-oo9', 'followers_url': 'https://api.github.com/users/gm-oo9/followers', 'following_url': 'https://api.github.com/users/gm-oo9/following{/other_user}', 'gists_url': 'https://api.github.com/users/gm-oo9/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/gm-oo9/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/gm-oo9/subscriptions', 'organizations_url': 'https://api.github.com/users/gm-oo9/orgs', 'repos_url': 'https://api.github.com/users/gm-oo9/repos', 'events_url': 'https://api.github.com/users/gm-oo9/events{/privacy}', 'received_events_url': 'https://api.github.com/users/gm-oo9/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-07 18:50:10+00:00,2025-03-13 15:38:18+00:00,gm-oo9,5.8667592592592595
61080,BUG: Fix OverflowError in lib.maybe_indices_to_slice(),"This fixes this error when slicing massive dataframes:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py"", line 4093, in __getitem__
    return self._getitem_bool_array(key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py"", line 4155, in _getitem_bool_array
    return self._take_with_is_copy(indexer, axis=0)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py"", line 4153, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py"", line 4133, in take
    new_data = self._mgr.take(
               ^^^^^^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py"", line 893, in take
    new_labels = self.axes[axis].take(indexer)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/datetimelike.py"", line 839, in take
    maybe_slice = lib.maybe_indices_to_slice(indices, len(self))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""lib.pyx"", line 522, in pandas._libs.lib.maybe_indices_to_slice
OverflowError: value too large to convert to int

- [x] closes #59531
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature (test not added because it requires a large amount of memory to reproduce this problem)
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions (left the existing type-hint as-is because it seems `int` is correct from a Python perspective)
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Internals'],,2025-03-07 17:44:38+00:00,2025-03-07 23:30:55+00:00,,0.24047453703703703
61078,Doc for backend-specific arguments for df.plot(),"Updated DataFrame.plot documentation and visualization guide for back end-specific arguments.

- [x] closes #61020 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Stale']",,2025-03-07 15:04:30+00:00,2025-04-07 16:35:54+00:00,,31.063472222222224
61077,BUG: PeriodIndex.to_datetime inconsistent with its docstring,"- [x] closes #59371
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-03-07 14:55:38+00:00,2025-04-07 17:04:09+00:00,,31.089247685185185
61076,PERF: why nlargest is so slower?,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this issue exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this issue exists on the main branch of pandas.


### Reproducible Example

nlargest is so slow, I think this is question, maybe we should do someting to improve it.

Here, is my code, you can see nlargest use many time more than it should use.

![Image](https://github.com/user-attachments/assets/cac98d73-b0ed-4e6d-8a1d-51798c1ad96d)


### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>


### Prior Performance

_No response_","['Performance', 'Needs Info']",,2025-03-07 14:31:23+00:00,2025-08-05 17:07:45+00:00,,151.10858796296296
61073,BUG: Addressing #61072,"Trying to address #61072 since I created the issue. I've never contributed to pandas, but I have tried to follow what is in the guide.",[],,2025-03-07 00:25:43+00:00,2025-03-24 16:44:53+00:00,,17.67997685185185
61071,BUG: Potentially incorrect result of `df.rolling(window=...).mean()`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd

if __name__ == '__main__':    
    values = [
        -3.333333e-01,
        0.,
        1.000000e+15,
        -4.874588e+14,
        6.103516e-05,
        0.,
        1.100000e+00,
        0.,
        0.,
        -8.581237e+14,
        0.,
        1.000000e+15,
        0.,
        0.,
        0.,
        0.,
        0.,
        -5.96e-03,
        0.,
        0.,
    ]

    s = pd.Series(values, dtype=np.float64)
    window = 8

    ground_truth = np.sum(values[-window:]) / window
    rolling_mean_1 = s.rolling(window=window).mean()
    rolling_mean_2 = s.iloc[1:].rolling(window=window).mean()

    # >>> ground_truth
    # np.float64(-0.000745)

    # >>> rolling_mean_1.iloc[-1]
    # np.float64(-0.01637)
    
    # >>> rolling_mean_2.iloc[-1]
    # np.float64(-0.000745)

    # The first number is ~22 times greater than both the last one and the ground_truth value, which is significant.
    # >>> rolling_mean_1.iloc[-1] / rolling_mean_2.iloc[-1]
    # np.float64(21.973154362416107)
    # >>> rolling_mean_1.iloc[-1] / ground_truth
    # np.float64(21.973154362416107)
    
    assert np.allclose(rolling_mean_2.iloc[-1], ground_truth)  # passes
    assert np.allclose(rolling_mean_1.iloc[-1], ground_truth, rtol=0, atol=1e-2)  # fails
```

### Issue Description

While using pandas' `.rolling(window=...).mean()`, there is an unexpected discrepancy when comparing two different ways of computing the rolling mean:

1. `rolling_mean_1 = s.rolling(window=window).mean()`
2. `rolling_mean_2 = s.iloc[1:].rolling(window=window).mean()`

The discrepancy is significant, as `rolling_mean_1.iloc[-1]` is approximately `22` times greater than `rolling_mean_2.iloc[-1]`, even though the values required to compute the result for the last row are the same in both cases. Additionally, the reference value `ground_truth` is almost identical to `rolling_mean_2.iloc[-1]`. 

Likely, it's related to **rounding errors**, but I don't understand how they could cause such a large discrepancy in this case, given that the absolute values of the original data are not that large (<= `1e15`)

### Expected Behavior

`assert np.allclose(rolling_mean_1.iloc[-1], ground_truth)`  should pass

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.8
python-bits           : 64
OS                    : Darwin
OS-release            : 23.4.0
Version               : Darwin Kernel Version 23.4.0: Wed Feb 21 21:44:54 PST 2024; root:xnu-10063.101.15~2/RELEASE_ARM64_T6031
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : en_US.UTF-8
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8
pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : None
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : 6.125.2
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Window', 'Closing Candidate']",,2025-03-06 20:12:51+00:00,2025-03-07 09:23:57+00:00,,0.549375
61070,DOC: Outdated example of DataFrame.mean,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.mean.html#pandas.DataFrame.mean

### Documentation problem

The second example specifies no axis and shows the mean for each column. According to the documentation above, the behavior when the axis is not specified should be to aggregate the mean over both axis since version 2.0.0

I didn't check if the same mistake is present in other aggregation functions.

### Suggested fix for documentation

Replace `df.mean()` with `df.mean(axis=0)` on the example.","['Docs', 'Needs Triage']",,2025-03-06 19:36:06+00:00,2025-03-06 19:39:50+00:00,,0.0025925925925925925
61069,DOC: Update warning in `Index.values` docstring to clarify index modification which causes segmentation fault,"Index Modification issues (#60954)

- [x] Added [docstring](pandas/core/indexes/base.py) under existing function.

This PR updates the docstring for Index.values to clearly warn users that modifying it directly is not supported and may lead to memory corruption or segmentation faults. It also recommends safe alternatives, such as using `Index.array` or `Index.to_numpy(copy=True)`.

As per @mroeschke s note, in Pandas 3.0 this operation will raise an error under Copy-on-Write mode, making it clear that modifying is disallowed.

closes https://github.com/pandas-dev/pandas/issues/60954",['Docs'],,2025-03-06 18:35:17+00:00,2025-03-11 16:49:34+00:00,,4.926585648148148
61068,BUG:  Sorting fails in specific cases with pandas==2.1.1,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# Example data
data = {'A': [3, 1, 2], 'B': ['x', 'y', 'z']}
df = pd.DataFrame(data)

# Sorting operation
sorted_df = df.sort_values(by='A')
print(sorted_df)
```

### Issue Description

I‚Äôve encountered an issue where sorting operations fail under specific conditions when using pandas==2.1.1. This behavior does not occur in pandas==1.5.3, which suggests it might be a regression or a bug introduced in newer versions.

### Expected Behavior


Additional Context:

This issue does not occur in pandas==1.5.3.
I‚Äôve tested this in multiple environments and confirmed the behavior.
If more details are needed, I can provide additional examples or data.
Tips for Submitting an Issue:

Be Clear and Concise: Clearly describe the problem and steps to reproduce it.
Provide Code and Data: Include a minimal reproducible example to help developers debug the issue.
Check for Duplicates: Before submitting, search the [Pandas Issues](https://github.com/pandas-dev/pandas/issues) to ensure it hasn‚Äôt already been reported.
Be Polite and Professional: Open-source maintainers appreciate respectful and constructive feedback.

### Installed Versions

Environment:

Python version: [e.g., 3.9.12]
Pandas version: 2.1.1
Operating System: [ Windows 10]
","['Bug', 'Needs Info', 'Sorting']",,2025-03-06 05:56:49+00:00,2025-03-27 01:22:18+00:00,,20.809363425925927
61067,DOC: Fix typo in Timestamp.isoformat,"repeated word

- ~~[ ] closes #xxxx (Replace xxxx with the GitHub issue number)~~
- ~~[ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~~
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- ~~[ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- ~~[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~
",['Docs'],,2025-03-06 01:26:18+00:00,2025-03-06 16:18:44+00:00,,0.6197453703703704
61066,DOC: Fix syntax highlighting in overview,"Remove bogus syntax highlighting on LICENSE in overview.rst

- ~~[ ] closes #xxxx (Replace xxxx with the GitHub issue number)~~
- ~~[ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~~
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- ~~[ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- ~~[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~",['Docs'],,2025-03-06 01:22:35+00:00,2025-03-06 16:19:17+00:00,,0.6227083333333333
61065,DOC: Add inference type information to Dataframe Apply,"- [#61057] (Replace xxxx with the GitHub issue number)
-~~[ ] [Tests added and passed] if fixing a bug or adding a new feature~~
- [ ] All [code checks passed]
-~~[ ] Added [type annotations] to new arguments/methods/functions.~~
-~~[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~
",['Docs'],,2025-03-06 01:05:49+00:00,2025-03-06 16:20:40+00:00,,0.6353125
61064,DOC: Add inference type information to Dataframe Apply,"- [#61057 ] (Replace xxxx with the GitHub issue number)
- ~~[ ] [Tests added and passed] if fixing a bug or adding a new feature~~
- [ ] All [code checks passed].
- ~~[ ] Added [type annotations] to new arguments/methods/functions.~~
- ~~[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~
",[],,2025-03-06 00:39:25+00:00,2025-03-06 00:52:58+00:00,,0.009409722222222222
61063,DOC: Add link description,"- ~~[ ] closes #xxxx (Replace xxxx with the GitHub issue number)~~
- ~~[ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature~~
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- ~~[ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- ~~[ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~",['Docs'],,2025-03-05 23:30:33+00:00,2025-03-06 16:21:41+00:00,,0.7021759259259259
61062,BUG: Fix na_position type in IndexEngine,"- [x] closes #58924 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature  
  (I modified an existing test to cover the problematic case)
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).  
  (Stubs check fails locally for seemingly unrelated reasons. Passed on GH Actions.)
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.  
  (**Not applicable**)
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Index'],,2025-03-05 21:23:12+00:00,2025-03-07 00:57:57+00:00,,1.1491319444444446
61059,DOC: Correct a typo in ecosystem.md,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-05 10:15:53+00:00,2025-03-05 18:15:20+00:00,,0.33295138888888887
61058,"DOC: Pivot() example call incorrectly used and would give ""error: duplicate index""","### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

doc/source/user_guide/reshaping.rst



### Documentation problem

the table given as an example for pivot() is wrong and cant be used. it would return ""error duplicate index"" as there are duplicate values in the column given for ""index"" parameter.

<img width=""772"" alt=""Image"" src=""https://github.com/user-attachments/assets/d7198715-b74e-4c35-88f8-5a01ee8eefe4"" />



### Suggested fix for documentation

The ""foo"" column must contain unique values ","['Reshaping', 'Error Reporting', 'Needs Info']",,2025-03-05 04:39:53+00:00,2025-08-05 17:06:52+00:00,,153.51873842592593
61056,ENH: json_normalize accepts JSON with str and bytes input,"- [x] closes #61006
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
",[],,2025-03-04 22:52:21+00:00,2025-03-05 18:56:44+00:00,,0.8363773148148148
61055,BUG:  invalid result of reindex on columns after unstack with Period data #60980,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

series1 = pd.DataFrame(
   [(0, ""s2"", pd.Period(2022)), (0, ""s1"", pd.Period(2021))],
   columns=[""A"", ""B"", ""C""]
).set_index([""A"", ""B""])[""C""]

series2 = series1.astype(str)

print(series1.unstack(""B"").reindex([""s2""], axis=1))
print(series2.unstack(""B"").reindex([""s2""], axis=1))
```

### Issue Description

The example code prints

B  s2
A      
0  2021

B  s2
A‚ÄÉ‚ÄÉ
0  2022

### Expected Behavior

Expect the result for both pd.Period and str data to be 2022:

B  s2
A‚ÄÉ‚ÄÉ
0  2022

B  s2
A‚ÄÉ‚ÄÉ
0  2022

(actually observed with older Pandas 2.0.3)

### Installed Versions

<details>

INSTALLED VERSIONS
commit : https://github.com/pandas-dev/pandas/commit/0691c5cf90477d3503834d983f69350f250a6ff7
python : 3.11.10
python-bits : 64
OS : Linux
OS-release : 6.2.16
Version : https://github.com/pandas-dev/pandas/issues/1-NixOS SMP PREEMPT_DYNAMIC Tue Jan 1 00:00:00 UTC 1980
machine : x86_64
processor :
byteorder : little
LC_ALL : None
LANG : en_US.UTF-8
LOCALE : en_US.UTF-8
pandas : 2.2.3
numpy : 2.2.3
pytz : 2025.1
dateutil : 2.9.0.post0
pip : 24.0
Cython : None
sphinx : None
IPython : None
adbc-driver-postgresql: None
adbc-driver-sqlite : None
bs4 : None
blosc : None
bottleneck : None
dataframe-api-compat : None
fastparquet : None
fsspec : None
html5lib : None
hypothesis : None
gcsfs : None
jinja2 : None
lxml.etree : None
matplotlib : None
numba : None
numexpr : None
odfpy : None
openpyxl : None
pandas_gbq : None
psycopg2 : None
pymysql : None
pyarrow : None
pyreadstat : None
pytest : None
python-calamine : None
pyxlsb : None
s3fs : None
scipy : None
sqlalchemy : None
tables : None
tabulate : None
xarray : None
xlrd : None
xlsxwriter : None
zstandard : None
tzdata : 2025.1
qtpy : None
pyqt5 : None

</details>
","['Bug', 'Reshaping']",,2025-03-04 18:11:53+00:00,2025-03-05 00:13:34+00:00,,0.2511689814814815
61054,BUG: Fix return type of loc/iloc,"- [X] closes #60600 
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

## Description of Linked Issue
`loc/iloc` inconsistently returns dtype. For example,

```python
>>> import pandas as pd
>>> df = pd.DataFrame([['a', 1., 2.], ['b', 3., 4.]])

>>> df.loc[0, [1, 2]]
1    1.0
2    2.0
Name: 0, dtype: object

>>> df[[1, 2]].loc[0]
1    1.0
2    2.0
Name: 0, dtype: float64

>>> df.loc[[0, 1], 1]
0    1.0
1    3.0
Name: 1, dtype: float64
```

This behaviour seems to happen following the below sequence:
1. For axis=0, `BlockManager.fast_xs()` returns a cross-section of `df`, determining the `dtype` as `object`, since `df.loc[0,:]` is supposed to include `'a'`.
2. For axis=1, `NDFrame._reindex_with_indexers()` returns the result, not additionally inferring the dtype of the result.

## Proposed Solution

Based on the above examples, we can conclude that this issue only apprears where `axis[0]=int` amd `axis[1]=list/slice` - `loc[int/slice]`.
Therefore, I'd like to propose to add the below codes to additionally infer the dtype after the column selection.

```python
    @final
    def _getitem_lowerdim(self, tup: tuple):

...

                # This is an elided recursive call to iloc/loc
                out = getattr(section, self.name)[new_key]
                # Re-interpret dtype of out.values for loc/iloc[int, list/slice].
                # GH60600
                if (
                    i == 0
                    and isinstance(key, int)
                    and isinstance(new_key, (list, slice))
                ):
                    out = out.infer_objects()
                return out
```

Thanks!","['Bug', 'Indexing', 'Dtype Conversions']",,2025-03-04 14:52:06+00:00,2025-06-30 18:25:43+00:00,,118.1483449074074
61053,DOC Fix Styler.to_latex to be in Writer column,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

I saw that this field for the latex writer was actually in the read column.  This moves this to the right column.  Here's a link to the current doc page: https://pandas.pydata.org/docs/user_guide/io.html
",['Docs'],,2025-03-04 12:19:51+00:00,2025-03-04 18:03:15+00:00,,0.23847222222222222
61052,BUG: sometimes when using ~ and & operators for indexing it evaluated incorrectly,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

Edit [rhshadrach]: The code below does _not_ reproduce the issue.

```python
# No idea how to exactly reproduce it, but it occurs sometimes. Logic is this:
import pandas as pd
bool_df = pd.DataFrame([
    {""first"": True, ""second"": False, ""third"": True},
    {""first"": True, ""second"": True, ""third"": True},
    {""first"": True, ""second"": False, ""third"": True},
    {""first"": True, ""second"": True, ""third"": True},
    {""first"": True, ""second"": True, ""third"": True},
    {""first"": True, ""second"": False, ""third"": True},
    {""first"": True, ""second"": True, ""third"": True},
    {""first"": False, ""second"": False, ""third"": True},
    {""first"": True, ""second"": True, ""third"": True},
    {""first"": True, ""second"": False, ""third"": True},
])
bool_df = bool_df[bool_df[""third""]][[""first"", ""second""]]
# In some cases, this line prints the length of the DataFrame (10)
print(len(bool_df[(~bool_df[""first""]) & (~bool_df[""second""])])) # Sometimes prints 10

# This line prints the expected output (1)
print(len(bool_df[(bool_df[""first""] == False) & (bool_df[""second""] == False)])) # Prints 1

# Using De Morgan's law also returned with the expected output
print(len(bool_df[~((bool_df[""first""]) | (bool_df[""second""]))])) # Prints: 1
```

### Issue Description

We don't know when and why this occurs. We werre looking for any rational explanation for hours. Anyone else experienced similar? How could this be possible?
(Environment: MacBook Pro 2023, Sequoia 15.3)

### Expected Behavior

print(len(bool_df[(~bool_df[""first""]) & (~bool_df[""second""])])) # Print 1

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.1
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:23 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6031
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : None.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.3
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : 9.0.1
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.38
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Numeric Operations', 'Needs Info']",,2025-03-04 12:14:16+00:00,2025-03-07 23:49:47+00:00,,3.482997685185185
61051,"Renamed ""normalise"" to ""normalize""","- [x] closes #61047 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
",['Code Style'],,2025-03-04 08:43:25+00:00,2025-03-04 18:04:13+00:00,,0.3894444444444444
61050,Adjust Docker File Key Value Format,"- [x] closes #61036
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.",[],,2025-03-04 08:41:29+00:00,2025-03-05 18:47:19+00:00,,1.4207175925925926
61049,BUG: Ghost Column Generation Bug in .loc[] with Series Column Selector (Pandas 2.2.2),"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
print(pd.__version__)  # 2.2.2

data = {'CustomerID': [101, 102, 103, 104, 105],
        'Name': ['John', 'Alice', 'Bob', 'David', 'Mike'],
        'CreditScore': [650, 720, 710, 600, 750],
        'LoanAmount': [40000, 70000, 80000, 30000, 120000],
        'AccountType': ['Savings', 'Current', 'Current', 'Savings', 'Current']}

df = pd.DataFrame(data)

# This line generates unexpected columns without warning
df.loc[(df['AccountType'] == ""Current"") & (df['CreditScore'] > 700), df['LoanAmount']] = 90000

print(df)
```

### Issue Description

I found a hidden bug inside .loc[] method that silently generates new columns when the second parameter is a Series column selector.

### Expected Behavior

Only LoanAmount column should be updated.

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.12.7.final.0
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_India.1252

pandas                : 2.2.2
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
setuptools            : 75.1.0
pip                   : 24.2
Cython                : None
pytest                : 7.4.4
hypothesis            : None
sphinx                : 7.3.7
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : 5.2.1
html5lib              : None
pymysql               : 1.4.6
psycopg2              : None
jinja2                : 3.1.4
IPython               : 8.27.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
bottleneck            : 1.3.7
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.6.1
gcsfs                 : None
matplotlib            : 3.9.2
numba                 : 0.60.0
numexpr               : 2.8.7
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
pyarrow               : 16.1.0
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : 2024.6.1
scipy                 : 1.13.1
sqlalchemy            : 2.0.34
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2023.6.0
xlrd                  : None
zstandard             : 0.23.0
tzdata                : 2023.3
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Bug', 'Indexing']",,2025-03-04 07:06:45+00:00,2025-03-04 23:52:31+00:00,,0.6984490740740741
61048,"Renamed ""normalise"" to ""normalize""","- [x] closes #61047 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
",[],,2025-03-04 06:06:57+00:00,2025-03-04 08:37:18+00:00,,0.10440972222222222
61047,"Correction: Standardize spelling of ""normalize"" in codebase","Some functions in `_normalize.py` use British spelling (""normalise"") and some use American spelling (""normalize""). To maintain consistency with standard American spelling used in Pandas, ""normalise"" should be replaced with ""normalize"".

<img width=""683"" alt=""Image"" src=""https://github.com/user-attachments/assets/eac39be2-ef14-4a11-9b10-ac9ebfd74b8f"" />",[],,2025-03-04 05:45:56+00:00,2025-03-04 18:04:14+00:00,,0.5127083333333333
61046,perf: improve membership check performance in column filtering,"- [x] closes #61045 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Performance', 'IO CSV']",,2025-03-04 01:52:00+00:00,2025-04-26 18:10:39+00:00,,53.67961805555556
61045,PERF: Optimize membership check in column filtering for better performance,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this issue exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this issue exists on the main branch of pandas.


### Reproducible Example

### Description  
Currently, the `columns` variable is a list of hashable elements returned by `_filter_usecols`. In the dictionary comprehension at [`pandas/pandas/io/parsers/c_parser_wrapper.py#L262`](https://github.com/pandas-dev/pandas/blob/main/pandas/io/parsers/c_parser_wrapper.py#L262):  

```python
col_dict = {k: v for k, v in col_dict.items() if k in columns}
```
### Proposed Improvement
Convert columns to a set before performing the membership check, reducing lookup time to O(1):

```python
columns_set = set(columns)  # Convert once
col_dict = {k: v for k, v in col_dict.items() if k in columns_set}
```

This avoids repeated list traversal and improves performance when filtering columns.

Expected Benefits
- Faster execution when columns contains many elements.
- Improved efficiency in scenarios with frequent membership checks.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.8
python-bits           : 64
OS                    : Linux
OS-release            : 6.5.0-1025-azure
Version               : #26~22.04.1-Ubuntu SMP Thu Jul 11 22:33:04 UTC 2024
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 8.33.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : 1.4.2
dataframe-api-compat  : None
fastparquet           : 2024.11.0
fsspec                : 2025.2.0
html5lib              : 1.1
hypothesis            : 6.127.5
gcsfs                 : 2025.2.0
jinja2                : 3.1.5
lxml.etree            : 5.3.1
matplotlib            : 3.10.1
numba                 : 0.61.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 19.0.1
pyreadstat            : 1.2.8
pytest                : 8.3.5
python-calamine       : None
pyxlsb                : 1.0.10
s3fs                  : 2025.2.0
scipy                 : 1.15.2
sqlalchemy            : 2.0.38
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>


### Prior Performance

_No response_","['Performance', 'IO CSV']",,2025-03-04 01:51:13+00:00,2025-04-26 18:10:40+00:00,,53.68017361111111
61044,Backport PR #61042: CI/TST: Fix xfail in test_columns_dtypes_not_invalid for pyarrow nightly,,"['Testing', 'CI']",,2025-03-03 23:08:05+00:00,2025-03-04 02:56:39+00:00,,0.15872685185185184
61043,BUG: `.str.replace()` with capture groups does not play nice with string methods,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

Code
```python
import pandas as pd
c = pd.Series(""THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG"")
x, y, z = ""\\b(FOX|THE)\\b"", ""_ABC_"", ""\\1_ABC_""
print(c.str.replace(x, y.lower(), regex=True))
print(c.str.replace(x, z.lower(), regex=True))
```

Output
```
0    _abc_ QUICK BROWN _abc_ JUMPS OVER _abc_ LAZY DOG
dtype: object
0    THE_abc_ QUICK BROWN FOX_abc_ JUMPS OVER THE_a...
dtype: object
```


### Issue Description

The `.lower()` string method inconsistently modifies the `repl` argument when the latter includes a regex capture group.


### Expected Behavior

I would expect `.lower()` to modify all characters in `repl`, including those in the capture group (or a warning stating otherwise).


### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.16
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:16 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : 8.33.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.1
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>","['Bug', 'Strings']",,2025-03-03 22:00:55+00:00,2025-03-03 22:56:12+00:00,,0.038391203703703705
61042,CI/TST: Fix xfail in test_columns_dtypes_not_invalid for pyarrow nightly,e.g. https://github.com/pandas-dev/pandas/actions/runs/13639721895/job/38126633833,"['Testing', 'CI']",,2025-03-03 21:34:28+00:00,2025-03-03 22:56:22+00:00,,0.056875
61041,BUG: Recognize chained fsspec URLs,"- [ ] closes #48978
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

The new `(::[A-Za-z0-9+\-+.]+)*` part of the regex will allow for optional `::<alphanumeric+-.>`-like strings  before the `://` section of the URL, which will enable it to recognize chained fsspec URLs.",['IO Network'],,2025-03-03 20:50:16+00:00,2025-03-05 22:12:10+00:00,,2.056875
61040,Adjust Docker File Key Value Format,"- [x] closes #61036
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
",[],,2025-03-03 18:57:10+00:00,2025-03-04 05:47:10+00:00,,0.4513888888888889
61039,CI: Bump GHA uses versions,,['CI'],,2025-03-03 18:33:23+00:00,2025-03-03 20:22:45+00:00,,0.07594907407407407
61038,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.9.4 ‚Üí v0.9.9](https://github.com/astral-sh/ruff-pre-commit/compare/v0.9.4...v0.9.9)
- [github.com/PyCQA/isort: 6.0.0 ‚Üí 6.0.1](https://github.com/PyCQA/isort/compare/6.0.0...6.0.1)
<!--pre-commit.ci end-->",['Code Style'],,2025-03-03 16:30:46+00:00,2025-03-03 18:12:44+00:00,,0.07081018518518518
61036,Correction: Adjust Dockerfile key value format,"Suggest to add ""="" for assigning variable in Dockerfile.




![Image](https://github.com/user-attachments/assets/ea01d02e-26da-4dfb-be04-13fa457b35f0)","['Build', 'Clean']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-03 14:09:36+00:00,2025-03-05 18:47:20+00:00,arthurlw,2.1928703703703705
61035,BUG: fix DataFrame.__setitem__ throwing a ValueError when setting a column with a 2D object array,"- [x] closes #61026
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-03-03 07:25:34+00:00,2025-04-04 17:08:59+00:00,,32.405150462962965
61034,DOC: Correct typos in Working with text data,"Correct typos in Working with text data.
https://pandas.pydata.org/docs/dev/user_guide/text.html

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-03-03 04:30:19+00:00,2025-03-03 18:13:26+00:00,,0.5716087962962964
61032,ENH: Allow JIT compilation with an internal API,"- [X] closes #60668, supersedes #60622

I've been exploring what @MarcoGorelli proposed in https://github.com/pandas-dev/pandas/pull/60622#pullrequestreview-2584711239 regarding allowing JIT compilers to implement their own apply engine. I think it is a much better approach than the current implementation. I've been testing different APIs, both the user facing one, and the internal (what Numba and Bodo have to implement that we will call), and this PR is what I think makes more sense...

The approach here is to use a `jit` parameter for any function that could make sense to JIT in pandas (`DataFrame.apply`, `Series.map`, `SeriesGroupBy.transform`...) that delegates to the JIT compiler (Numba or Bodo) 100% of the logic. So far I just implement `DataFrame.apply` for simplicity, but happy to add the rest once there is agreement.

Final user API would look like next examples:

```python
df.apply(lambda x: x.A + x.B, axis=1, jit=bodo.njit)
df.apply(lambda x: x.A + x.B, axis=1, jit=bodo.jit(parallel=True))
```

Which I think it's very simple and intuitive, and at the same time it makes users import `numba` and `bodo` themselves, creating the right impression that they are using those libraries to JIT compile, and it's not something provided by pandas. Also, it makes users install the library themselves, which I think makes things easier (any installation or importing error is not reported to pandas, no need for a soft dependency, no need to even add them to our CI if we don't want).

I think this approach is very convenient for us, as maintaining the code in pandas is trivial. Which I think it should address the concerns @jbrockmendel expressed, and I think many of us share. It should also be very convenient for Numba and Bodo, which should be able to fix any issue much faster, as well as performance improvements, and support for new use cases . Numba and Bodo can probably release faster than us, so any needed work in the JIT functionality shouldn't consume pandas resources, make Numba and Bodo life easier, and end up in the users faster.

The exact internal API (the `__pandas_udf__` function in this PR) can probably be improved. To make it looks simple and reasonable, but happy to know other points of view.

As said in the code, the `bodo_patched.py` file is only in the PR so there is more context on the API that we will call. But the code will be properly implemented in Numba and Bodo, and removed from this PR before it's merged.

@ehsantn @scott-routledge2 @pandas-dev/pandas-core ","['Enhancement', 'Apply']",,2025-03-02 17:28:30+00:00,2025-03-14 15:03:10+00:00,,11.899074074074074
61030,BUG: Dependency check custom error loses information,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
# in an environment where numpy fails to be imported because for example libstdc++.so.6 doesn't exist
import pandas
```

### Issue Description

I was importing pandas in an environment where `libstdc++.so.6` could not be found, which causes numpy to fail to load its C++ extensions.

The error I got was the following:
```
Traceback (most recent call last):
  File ""/home/nora/projects/rplcs-events-tournament-1/report_generator.py"", line 2, in <module>
    import pandas as pd
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/pandas/__init__.py"", line 19, in <module>
    raise ImportError(
ImportError: Unable to import required dependencies:
numpy: Error importing numpy: you should not try to import numpy from
        its source directory; please exit the numpy source tree, and relaunch
        your python interpreter from there.
```

This does not contain any information about the missing shared library. If I patch out this custom throw https://github.com/pandas-dev/pandas/blob/57fd50221ea3d5de63d909e168f10ad9fc0eee9b/pandas/__init__.py#L13 here and replace it with just `raise _e` I get the full error, which mentioned missing `libstdc++.so.6` which was very useful to debug the issue (hidden in a details tag as it's big):

<details><summary>The full error</summary>
<p>

```
Traceback (most recent call last):
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/numpy/_core/__init__.py"", line 23, in <module>
    from . import multiarray
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/numpy/_core/multiarray.py"", line 10, in <module>
    from . import overrides
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/numpy/_core/overrides.py"", line 7, in <module>
    from numpy._core._multiarray_umath import (
ImportError: libstdc++.so.6: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/numpy/__init__.py"", line 114, in <module>
    from numpy.__config__ import show_config
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/numpy/__config__.py"", line 4, in <module>
    from numpy._core._multiarray_umath import (
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/numpy/_core/__init__.py"", line 49, in <module>
    raise ImportError(msg)
ImportError: 

IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!

Importing the numpy C-extensions failed. This error can happen for
many reasons, often due to issues with your setup or how NumPy was
installed.

We have compiled some common reasons and troubleshooting tips at:

    https://numpy.org/devdocs/user/troubleshooting-importerror.html

Please note and check the following:

  * The Python version is: Python3.12 from ""/home/nora/projects/rplcs-events-tournament-1/.venv/bin/python3""
  * The NumPy version is: ""2.2.3""

and make sure that they are the versions you expect.
Please carefully study the documentation linked above for further help.

Original error was: libstdc++.so.6: cannot open shared object file: No such file or directory


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/nora/projects/rplcs-events-tournament-1/report_generator.py"", line 2, in <module>
    import pandas as pd
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/pandas/__init__.py"", line 16, in <module>
    raise _e
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/pandas/__init__.py"", line 14, in <module>
    __import__(_dependency)
  File ""/home/nora/projects/rplcs-events-tournament-1/.venv/lib/python3.12/site-packages/numpy/__init__.py"", line 119, in <module>
    raise ImportError(msg) from e
ImportError: Error importing numpy: you should not try to import numpy from
        its source directory; please exit the numpy source tree, and relaunch
        your python interpreter from there.
```

</p>
</details> 

### Expected Behavior

Pandas printing the *full* error, including nested exceptions.

### Installed Versions

<details>

It can't run it because my environment is broken, but I can see the relevant code on master. Pandas version is 2.2.3

</details>
","['Bug', 'Error Reporting']","{'login': 'chilin0525', 'id': 41913261, 'node_id': 'MDQ6VXNlcjQxOTEzMjYx', 'avatar_url': 'https://avatars.githubusercontent.com/u/41913261?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/chilin0525', 'html_url': 'https://github.com/chilin0525', 'followers_url': 'https://api.github.com/users/chilin0525/followers', 'following_url': 'https://api.github.com/users/chilin0525/following{/other_user}', 'gists_url': 'https://api.github.com/users/chilin0525/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/chilin0525/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/chilin0525/subscriptions', 'organizations_url': 'https://api.github.com/users/chilin0525/orgs', 'repos_url': 'https://api.github.com/users/chilin0525/repos', 'events_url': 'https://api.github.com/users/chilin0525/events{/privacy}', 'received_events_url': 'https://api.github.com/users/chilin0525/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-02 10:07:09+00:00,2025-04-14 16:39:19+00:00,chilin0525,43.272337962962965
61029,BUG: Printing float16 with NumPy>=2.0 gives overflow warning,"    print(pd.Series([1.0], dtype=""float16""))
    # RuntimeWarning: overflow encountered in cast np.array([1.0], dtype=""float16"") > 1e6
    # 0    1.0
    # dtype: float16

This occurs here:

https://github.com/pandas-dev/pandas/blob/bc34e2497f1471409f144fde89330a71bb8ba892/pandas/io/formats/format.py#L1446

Perhaps we just set `has_large_values` to be false for float16?","['Bug', 'Output-Formatting', 'Warnings']","{'login': 'Pedro-Santos04', 'id': 134413112, 'node_id': 'U_kgDOCAL7OA', 'avatar_url': 'https://avatars.githubusercontent.com/u/134413112?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Pedro-Santos04', 'html_url': 'https://github.com/Pedro-Santos04', 'followers_url': 'https://api.github.com/users/Pedro-Santos04/followers', 'following_url': 'https://api.github.com/users/Pedro-Santos04/following{/other_user}', 'gists_url': 'https://api.github.com/users/Pedro-Santos04/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Pedro-Santos04/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Pedro-Santos04/subscriptions', 'organizations_url': 'https://api.github.com/users/Pedro-Santos04/orgs', 'repos_url': 'https://api.github.com/users/Pedro-Santos04/repos', 'events_url': 'https://api.github.com/users/Pedro-Santos04/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Pedro-Santos04/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-03-01 22:07:17+00:00,2025-03-07 23:43:08+00:00,Pedro-Santos04,6.0665625
61028,Bump to `pypa/cibuildwheel@v2.23.0`; build WASM wheels against Pyodide 0.27,"- [x] follow-up of https://github.com/pandas-dev/pandas/pull/60756#issuecomment-2607902892
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This bumps to https://github.com/pypa/cibuildwheel/releases/tag/v2.23.0 that was released a while ago. The notable highlights are that the project now _officially_ supports and tests the `ubuntu-22.04-arm` images, and bumps to Pyodide 0.27, matching the version used in the nightly wheels.

Other ancillary items from the release notes: PyPy 3.11 is now supported, but PyPy has been marked with a TODO and is not addressed here. ",['CI'],,2025-03-01 13:53:00+00:00,2025-03-01 18:08:29+00:00,,0.17741898148148147
61027,Added documentation with current and future project plans,Added documentation with current and future project plans.,[],,2025-03-01 13:00:32+00:00,2025-03-01 13:01:03+00:00,,0.0003587962962962963
61024,Fixed describe.py,"
![Screenshot 2025-03-01 123317](https://github.com/user-attachments/assets/06e6801b-da32-4642-a408-57db38a57049)
Issue-60550-Fixed

Removed the condition that included 50th percentile. i.e. 

if 0.5 not in percentiles :
      percentiles.append(0.5)

Added the condition, that 50th percentile should only be appended if the list 'percentiles' is empty.   
",['Enhancement'],,2025-03-01 07:07:02+00:00,2025-03-09 01:26:41+00:00,,7.763645833333333
61023,Issue 60550 fix,"# Fix-#60550

#Removed this condition as a fix for issue #60550 :
![image](https://github.com/user-attachments/assets/70db04c3-7065-479e-bbc4-fe4c8800305c)

#Added this condition
 if percentiles == []:
        percentiles.append(0.5) # By default, if percentiles is empty then appending 50th percentile. 

![image](https://github.com/user-attachments/assets/5f2f122a-a536-4498-8d23-5527fdab824b)
",[],,2025-03-01 05:33:18+00:00,2025-03-01 06:58:23+00:00,,0.05908564814814815
61022,BUG: Fix bug in to_datetime that occasionally throws FloatingPointErr‚Ä¶,"‚Ä¶or when called on a float array with missing values

- [ ] closes #58419
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

The cause of the error is a numpy array created via np.empty(). Sometimes it contains garbage values which subsequently get passed to `np.round` causing errors.","['Datetime', 'Missing-data']",,2025-03-01 03:21:19+00:00,2025-03-02 00:31:06+00:00,,0.8817939814814815
61021,TST: Add test for groupby with datetime and NaT values,"- [x] closes #35202
- [x] [Tests added and passed]
- [x] All [code checks passed]
- [ ] Added [type annotations]
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Testing'],,2025-02-28 20:50:09+00:00,2025-02-28 21:50:49+00:00,,0.04212962962962963
61019,BUG: df.plot() multi-column subplots & title interaction,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import matplotlib.pyplot as plt
import pandas as pd

df = pd.DataFrame([(30, 10, 10), (20, 20, 20), (10, 30, 30)], columns=list('ABC'))
df.plot(subplots= [('A','B')],kind=""bar"", stacked=True, title=[""A&B"",""C"", ""Needs another title despite no title here, removing this will error""])

print(df)
# print(pd.show_versions())
plt.show()
```

### Issue Description

df.plot() has a hard coded check to make sure there are the same number of titles when using with the ""subplots"" parameter, however subplots allows for multiple columns to be represented on one plot, so there are scenarios where the number of plots is less than the check for the number of titles

### Expected Behavior

You shouldn't need to purposefully make empty titles up to the number of columns, the check should be run on the number of subplots

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.0
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.22631
machine               : AMD64
processor             : AMD64 Family 25 Model 33 Stepping 2, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 1.24.2
pytz                  : 2025.1
dateutil              : 2.8.2
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : 8.12.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.2
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.9
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Visualization']","{'login': 'eicchen', 'id': 63069720, 'node_id': 'MDQ6VXNlcjYzMDY5NzIw', 'avatar_url': 'https://avatars.githubusercontent.com/u/63069720?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/eicchen', 'html_url': 'https://github.com/eicchen', 'followers_url': 'https://api.github.com/users/eicchen/followers', 'following_url': 'https://api.github.com/users/eicchen/following{/other_user}', 'gists_url': 'https://api.github.com/users/eicchen/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/eicchen/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/eicchen/subscriptions', 'organizations_url': 'https://api.github.com/users/eicchen/orgs', 'repos_url': 'https://api.github.com/users/eicchen/repos', 'events_url': 'https://api.github.com/users/eicchen/events{/privacy}', 'received_events_url': 'https://api.github.com/users/eicchen/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-28 05:50:48+00:00,2025-05-07 16:11:20+00:00,eicchen,68.43092592592592
61018,"BUG: df.plot() ""Subplots"" changes behavior of how values are stacked using the ""Stacked"" property","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

df = pd.DataFrame([(30, 10, 10), (20, 20, 20), (10, 30, 30)], columns=list('ABC'))
df.plot(kind=""bar"", stacked=True)
df.plot(subplots= [('A','B')],kind=""bar"", stacked=True)
plt.show()
print(df)
```

### Issue Description

Using both the ""stacked"" and ""subplots"" option when drawing a bar graph changes how the bar graph is stacked.

Illustrated with image below where instead of numberically stacking the values for A and B it just physically overlays them. My guess is it doesn't properly use the ""bottom"" attribute when drawing B. 

![Image](https://github.com/user-attachments/assets/30d4655d-1a88-4321-be17-6ea88bbf2646)

### Expected Behavior

The behavior of the subplot version should be inline with when the option is not used. So the total of the values should equal to A+B for each element

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.0
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.22631
machine               : AMD64
processor             : AMD64 Family 25 Model 33 Stepping 2, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 1.24.2
pytz                  : 2025.1
dateutil              : 2.8.2
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : 8.12.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.2
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.9
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Visualization']","{'login': 'eicchen', 'id': 63069720, 'node_id': 'MDQ6VXNlcjYzMDY5NzIw', 'avatar_url': 'https://avatars.githubusercontent.com/u/63069720?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/eicchen', 'html_url': 'https://github.com/eicchen', 'followers_url': 'https://api.github.com/users/eicchen/followers', 'following_url': 'https://api.github.com/users/eicchen/following{/other_user}', 'gists_url': 'https://api.github.com/users/eicchen/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/eicchen/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/eicchen/subscriptions', 'organizations_url': 'https://api.github.com/users/eicchen/orgs', 'repos_url': 'https://api.github.com/users/eicchen/repos', 'events_url': 'https://api.github.com/users/eicchen/events{/privacy}', 'received_events_url': 'https://api.github.com/users/eicchen/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-28 05:41:34+00:00,2025-04-28 20:10:29+00:00,eicchen,59.60341435185185
61017,BUG: Fix MultiIndex alignment issue in Dataframe-Series binary operat‚Ä¶,"‚Ä¶ion in case of different levels

- [ ] closes #61009
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

In case of arithmetic operations between a `DataFrame` with MultiIndex columns and a `Series`, if the two multiindexes don't have the same levels, the output values are all `nan` (see example in the original issue).
A similar issue for `DataFrame`-`DataFrame` arithmetic operations was fixed in #60538. This PR addresses the bug in the `DataFrame`-`Series` case with `axis=1` (i.e. aligning DataFrame columns with Series MultiIndex).

The fix itself is simple - we just use
```
right = other._reindex_indexer(join_index, ridx)
```
instead of 
```
right = other.reindex(join_index, level=level)
```
because `Series.reindex` needs the new MultiIndex to have identical levels to the current index. Instead, we simply use the `ridx` object that we already have from a previous `Index.join` call, which does handle partially overlapping levels well.","['Bug', 'MultiIndex']",,2025-02-28 04:45:01+00:00,2025-02-28 18:27:00+00:00,,0.5708217592592593
61016,BUG: Cannot cast float to int using map function,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df=pd.DataFrame({'VAR_NAME': {65: 'FIN4_0020', 66: 'FIN1_0021', 67: 'FIN3_0021', 68: 'FIN4_0021', 69: 'FIN1_0022', 70: 'FIN3_0022', 71: 'FIN4_0022', 72: 'FIN1_0023', 73: 'FIN3_0023', 74: 'FIN4_0023', 75: 'FIN1_0024'}, 'LYM1': {65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1}, 'LYM2': {65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1}, 'LYM3': {65: 1.0, 66: 1.0, 67: 1.0, 68: 1.0, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 1.0, 74: 1.0, 75: 1.0}, 'LYM4': {65: 2, 66: 1, 67: 'T', 68: 2, 69: 1, 70: 'T', 71: 2, 72: 1, 73: 'T', 74: 2, 75: 1}})
```

### Issue Description

I can't explain the difference between the 2 ways of casting int using the map function. I just changed the order of using map function in code below and the result is different. The problem occurs when I read directly from the file as in the example below..

### Expected Behavior

```python
>>> df = pd.read_excel(excel_file, sheet_name=sheet_name)
>>> print(df[['VAR_NAME','LYM1','LYM2','LYM3','LYM4']].map(lambda x: int(x) if isinstance(x,float) else x,na_action='ignore').query('VAR_NAME==""FIN3_0022""'))
>>> print(df.query('VAR_NAME==""FIN3_0022""')[['VAR_NAME','LYM1','LYM2','LYM3','LYM4']].map(lambda x: int(x) if isinstance(x,float) else x,na_action='ignore'))

     VAR_NAME  LYM1 LYM2  LYM3 LYM4
70  FIN3_0022     1    1   1.0    T
     VAR_NAME  LYM1  LYM2  LYM3 LYM4
70  FIN3_0022     1     1     1    T


>>> df=pd.DataFrame({'VAR_NAME': {65: 'FIN4_0020', 66: 'FIN1_0021', 67: 'FIN3_0021', 68: 'FIN4_0021', 69: 'FIN1_0022', 70: 'FIN3_0022', 71: 'FIN4_0022', 72: 'FIN1_0023', 73: 'FIN3_0023', 74: 'FIN4_0023', 75: 'FIN1_0024'}, 'LYM1': {65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1}, 'LYM2': {65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1}, 'LYM3': {65: 1.0, 66: 1.0, 67: 1.0, 68: 1.0, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 1.0, 74: 1.0, 75: 1.0}, 'LYM4': {65: 2, 66: 1, 67: 'T', 68: 2, 69: 1, 70: 'T', 71: 2, 72: 1, 73: 'T', 74: 2, 75: 1}})
>>> df
     VAR_NAME  LYM1  LYM2  LYM3 LYM4
65  FIN4_0020     1     1   1.0    2
66  FIN1_0021     1     1   1.0    1
67  FIN3_0021     1     1   1.0    T
68  FIN4_0021     1     1   1.0    2
69  FIN1_0022     1     1   1.0    1
70  FIN3_0022     1     1   1.0    T
71  FIN4_0022     1     1   1.0    2
72  FIN1_0023     1     1   1.0    1
73  FIN3_0023     1     1   1.0    T
74  FIN4_0023     1     1   1.0    2
75  FIN1_0024     1     1   1.0    1
>>> print(df[['VAR_NAME','LYM1','LYM2','LYM3','LYM4']].map(lambda x: int(x) if isinstance(x,float) else x,na_action='ignore').query('VAR_NAME==""FIN3_0022""'))
     VAR_NAME  LYM1  LYM2  LYM3 LYM4
70  FIN3_0022     1     1     1    T
>>> print(df.query('VAR_NAME==""FIN3_0022""')[['VAR_NAME','LYM1','LYM2','LYM3','LYM4']].map(lambda x: int(x) if isinstance(x,float) else x,na_action='ignore'))
     VAR_NAME  LYM1  LYM2  LYM3 LYM4
70  FIN3_0022     1     1     1    T
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.11
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.26100
machine               : AMD64
processor             : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 24.0
Cython                : None
sphinx                : None
IPython               : 8.24.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : 5.2.2
matplotlib            : 3.9.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.4
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.11.4
sqlalchemy            : 2.0.38
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : None
tzdata                : 2024.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Dtype Conversions', 'Apply']","{'login': 'preet545', 'id': 146775121, 'node_id': 'U_kgDOCL-cUQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/146775121?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/preet545', 'html_url': 'https://github.com/preet545', 'followers_url': 'https://api.github.com/users/preet545/followers', 'following_url': 'https://api.github.com/users/preet545/following{/other_user}', 'gists_url': 'https://api.github.com/users/preet545/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/preet545/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/preet545/subscriptions', 'organizations_url': 'https://api.github.com/users/preet545/orgs', 'repos_url': 'https://api.github.com/users/preet545/repos', 'events_url': 'https://api.github.com/users/preet545/events{/privacy}', 'received_events_url': 'https://api.github.com/users/preet545/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-27 10:54:58+00:00,2025-03-03 23:13:09+00:00,preet545,4.512627314814814
61015,Update describe.py,"Updated the code to exclude 0.5 percentile

Excluded the 0.5 percentile from the code where a value is passed.

Added a test case to validate if 0.5 percentile is excluded or not
",[],,2025-02-27 05:40:16+00:00,2025-02-27 16:19:28+00:00,,0.4438888888888889
61014,PERF: use `blk.dtype` in `where()` & `_setitem_frame()`,"- [ ] closes #61010 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

this pr is a one-line change to the code here:
https://github.com/pandas-dev/pandas/blob/d1ec1a4c9b58a9ebff482af2b918094e39d87893/pandas/core/generic.py#L9735-L9737


### Performance comparison:

#### test script:
```python
import numpy as np
import pandas as pd
import timeit

for width in [10, 1000, 1000_00, 1000_0000]:
    df = pd.DataFrame(np.random.randn(1, width))
    mask = df > 0.5
    tm = timeit.timeit(""df.where(mask)"", number=10, globals=globals())
    print(width, tm)
```

#### for _dt in cond.dtypes:

10 0.002963045029900968
1000 0.006705133942887187
100000 0.40306550299283117
10000000 46.55275956704281
![image](https://github.com/user-attachments/assets/2f028c89-b868-45f2-9f01-dc0bcd9ba446)

#### for _dt in cond.dtypes.unique():

10 0.0028260269900783896
1000 0.002695770002901554
100000 0.042065858957357705
10000000 6.068146598991007
![image](https://github.com/user-attachments/assets/ade4f6a5-cc1a-47e4-8633-73c90522e64b)

#### for _dt in [blk.dtype for blk in cond._mgr.blocks]:

10 0.0009857049444690347
1000 0.0011893719201907516
100000 0.003112988080829382
10000000 0.13763279700651765
![image](https://github.com/user-attachments/assets/086371f8-a0f4-4d09-8130-d10ce0697565)
",['Performance'],,2025-02-27 02:35:03+00:00,2025-02-28 18:22:59+00:00,,1.658287037037037
61013,DOC: Update DataFrame.drop() docstring ,"Updated to reflect existing behavior of allowing any iterable

- [x] closes #59890 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-26 20:23:33+00:00,2025-02-26 21:09:26+00:00,,0.03186342592592593
61012,"removed ""if we"" typo in is_dtype() doc","- [x] closes #61011
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
",['Docs'],,2025-02-26 17:53:54+00:00,2025-02-26 19:15:13+00:00,,0.056469907407407406
61011,DOC: fix docstring typo,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://github.com/pandas-dev/pandas/blob/main/pandas/core/dtypes/dtypes.py

### Documentation problem

There seem to be two extra words in the _**is_dtype**_ method docstring, both in the _**PeriodDtype**_ and _**IntervalDtype**_ classes: 
```
@classmethod
    def is_dtype(cls, dtype: object) -> bool:
        """"""
        Return a boolean if we if the passed type is an actual dtype that we
        can match (via string or type)
        """"""
```

### Suggested fix for documentation

Remove the words **'if we'** in both places. ",['Docs'],"{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-26 15:33:08+00:00,2025-02-26 19:15:14+00:00,arthurlw,0.1542361111111111
61010,PERF: bottleneck in `where()`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this issue exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this issue exists on the main branch of pandas.


### Reproducible Example

```python
import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.randn(1, 1_000_000))

mask = df > 0.5
```
```python
%%timeit
_ = df.where(mask)
# 693 ms ¬± 3.49 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)
```
perf result taken from pyinstrument:

![Image](https://github.com/user-attachments/assets/77f7afb1-b3a6-413a-ab8e-439730b644a7)

This issue seems to be related to this:
https://github.com/pandas-dev/pandas/blob/d1ec1a4c9b58a9ebff482af2b918094e39d87893/pandas/core/generic.py#L9735-L9737

When dataframe is large, this overhead of `is_bool_dtype` accumulates. Would it be better to use `cond.dtypes.unique()` instead?

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.14
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.0-122-generic
Version               : #132-Ubuntu SMP Thu Aug 29 13:45:52 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0
pip                   : 24.0
Cython                : 3.0.7
sphinx                : 7.3.7
IPython               : 8.25.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.6.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.9.2
numba                 : 0.60.0
numexpr               : 2.10.0
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : 1.4.6
pyarrow               : 16.1.0
pyreadstat            : None
pytest                : 8.2.2
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.0
sqlalchemy            : 2.0.31
tables                : 3.9.2
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.22.0
tzdata                : 2024.1
qtpy                  : 2.4.1
pyqt5                 : None

</details>


### Prior Performance

_No response_","['Performance', 'Needs Triage']",,2025-02-26 09:47:27+00:00,2025-02-28 18:23:01+00:00,,2.3580324074074075
61009,BUG: `.mul` on multi index columns doesnt work.,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
data = pd.DataFrame(
    {
        ""state"": ([""vic"", ""nsw"", ""tas""] * 3 + ['vic'])*2,
        ""colour"": ['red'] * 10 + ['blue'] * 10,
        ""month"": ['mar', 'sep'] * 10,
        ""year"": [2020, 2020, 2020, 2021, 2021, 2021, 2022, 2022, 2022, 2023] * 2,
        ""value"": range(20),
    }
).set_index(['state','colour','year', 'month']).unstack(['state','year','month'])['value']
data.pipe(print)
""""""
state    vic  nsw  tas  vic  nsw  tas  vic  nsw  tas  vic
year    2020 2020 2020 2021 2021 2021 2022 2022 2022 2023
month    mar  sep  mar  sep  mar  sep  mar  sep  mar  sep
colour                                                   
blue      10   11   12   13   14   15   16   17   18   19
red        0    1    2    3    4    5    6    7    8    9
""""""

scaler = pd.DataFrame(
    [
        {""year"": 2020, ""month"": ""mar"", ""scale"": 0.5},
        {""year"": 2020, ""month"": ""sep"", ""scale"": 0.5},
        {""year"": 2021, ""month"": ""mar"", ""scale"": 0.5},
        {""year"": 2021, ""month"": ""sep"", ""scale"": 0.5},
        {""year"": 2022, ""month"": ""mar"", ""scale"": 0.5},
        {""year"": 2022, ""month"": ""sep"", ""scale"": 0.5},
        {""year"": 2023, ""month"": ""mar"", ""scale"": 0.5},
        {""year"": 2023, ""month"": ""sep"", ""scale"": 0.5},
    ]
).set_index(['year','month'])['scale']
scaler.pipe(print)
""""""
year  month
2020  mar      0.5
      sep      0.5
2021  mar      0.5
      sep      0.5
2022  mar      0.5
      sep      0.5
2023  mar      0.5
      sep      0.5
Name: scale, dtype: float64
""""""

mul_on_cols = data.mul(scaler, axis = 1)
mul_on_cols.pipe(print)
""""""
state   vic  tas  nsw       vic  tas  vic  tas  nsw  NaN  vic
year   2020 2020 2020 2021 2021 2021 2022 2022 2022 2023 2023
month   mar  mar  sep  mar  sep  sep  mar  mar  sep  mar  sep
colour                                                       
blue    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN
red     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN
""""""

mul_on_index = data.T.mul(scaler, axis = 0).T
mul_on_index.pipe(print)
""""""
state   vic  tas  nsw       vic  tas  vic  tas  nsw  NaN  vic
year   2020 2020 2020 2021 2021 2021 2022 2022 2022 2023 2023
month   mar  mar  sep  mar  sep  sep  mar  mar  sep  mar  sep
colour                                                       
blue    5.0  6.0  5.5  7.0  6.5  7.5  8.0  9.0  8.5  NaN  9.5
red     0.0  1.0  0.5  2.0  1.5  2.5  3.0  4.0  3.5  NaN  4.5
""""""
```

### Issue Description

using `.mul` on multi index columns fails, but on multi index rows, works as expected. View screenshots and code example. 

### Expected Behavior

Refer to screenshots and example

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.16
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.0
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.17.2
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : None
gcsfs                 : 2025.2.0
jinja2                : 3.1.5
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : 0.61.0
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : None
pyarrow               : 17.0.0
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : 1.0.10
s3fs                  : None
scipy                 : 1.15.2
sqlalchemy            : 2.0.38
tables                : None
tabulate              : 0.9.0
xarray                : 2025.1.2
xlrd                  : 2.0.1
xlsxwriter            : 3.2.2
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']","{'login': 'snitish', 'id': 7503884, 'node_id': 'MDQ6VXNlcjc1MDM4ODQ=', 'avatar_url': 'https://avatars.githubusercontent.com/u/7503884?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/snitish', 'html_url': 'https://github.com/snitish', 'followers_url': 'https://api.github.com/users/snitish/followers', 'following_url': 'https://api.github.com/users/snitish/following{/other_user}', 'gists_url': 'https://api.github.com/users/snitish/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/snitish/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/snitish/subscriptions', 'organizations_url': 'https://api.github.com/users/snitish/orgs', 'repos_url': 'https://api.github.com/users/snitish/repos', 'events_url': 'https://api.github.com/users/snitish/events{/privacy}', 'received_events_url': 'https://api.github.com/users/snitish/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-26 01:07:36+00:00,2025-02-28 18:27:02+00:00,snitish,2.7218287037037037
61008,docs: include option 'delete_rows' into `DataFrame.to_sql`,"- [x] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Hello folks, I missed to add the documentation in this place so it is a patch to the original [PR](https://github.com/pandas-dev/pandas/pull/60376).

https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.DataFrame.to_sql.html#
There's no mention to `delete_rows` ‚òùÔ∏è .

Please let me know if there's any other place :)

cc @WillAyd , @mroeschke ","['Docs', 'IO SQL']",,2025-02-25 21:48:04+00:00,2025-02-26 00:53:21+00:00,,0.12866898148148148
61007,TST: parametrize test_common,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Testing', 'Clean']",,2025-02-25 21:30:37+00:00,2025-02-25 22:39:43+00:00,,0.04798611111111111
61006,ENH: json_normalize should work with JSON,"### Feature Type

- [x] Adding new functionality to pandas

- [x] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I wish `pd.json_normalize` accepted JSON (as str or bytes), and not just `dict`.

Or, as a joke, there could be a `pd.dict_normalize` that only accepts JSON ;)

### Feature Description

Given a Series with JSON as str or bytes:
```
>>> df[""data""]
0                  {""value"":0.0}
1          {""value"":0.005787037}
2         {""value"":0.0115740741}
3         {""value"":0.0173611111}
```

It should be possible to parse the JSON with `pd.json_normalize`, e.g.

```
>>> pd.json_normalize(df[""data""])
            value
0        0.000000
1        0.005787
2        0.011574
3        0.017361
```

Pandas already has good JSON integration, so don't see why it can't be done.

### Alternative Solutions

From what I understand, right now it must be first parsed with some other library, e.g. with `apply`, before using `pd.json_normalize`.

```
>>> import json
>>> pd.json_normalize(df[""data""].apply(json.loads))
            value
0        0.000000
1        0.005787
2        0.011574
3        0.017361
```

### Additional Context

With better JSON/JSONB support in databases like postgres and sqlite, encountering this sort of data is becoming more common, and the intermediate `apply` step is a performance and usability issue:
```
>>> import json
>>> df = pd.read_sql(sql=query, con=conn)
>>> pd.json_normalize(df[""data""].apply(json.loads))
            value
0        0.000000
1        0.005787
2        0.011574
3        0.017361
```","['Enhancement', 'Needs Triage']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-25 16:09:43+00:00,2025-03-05 19:00:08+00:00,arthurlw,8.118344907407407
61005,BUG: scatter and line matplotlib plots not compatible for sharex=True datetime plots,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
datetime_list = [datetime.datetime(year = 2025, month = 1, day = 1, hour = n) for n in range(23)]
y = [n for n in range(23)]

df = pd.DataFrame(columns = ['datetime','y'])
for i, n in enumerate(datetime_list):
    df.loc[len(df)] = [n,y[i]]

#Plotting with pandas - first subplot shows up as blank
fig, ax = plt.subplots(2, sharex=True)
df.plot.scatter(x = 'datetime', y = 'y', ax = ax[0])
df.plot(x = 'datetime', y = 'y', ax = ax[1])

#Plotting with matplotlib - this works
fig, ax = plt.subplots(2, sharex=True)
ax[0].scatter(df['datetime'],df['y'])
ax[1].plot(df['datetime'],df['y'])
```

### Issue Description

When I am trying to plot a line plot and scatter plot using df.plot and df.plot.scatter, the scatter plot shows up as blank when I select sharex=True when making the figure and axes.

```python
#Plotting with pandas - first subplot shows up as blank
fig, ax = plt.subplots(2, sharex=True)
df.plot.scatter(x = 'datetime', y = 'y', ax = ax[0])
df.plot(x = 'datetime', y = 'y', ax = ax[1])
```

![Image](https://github.com/user-attachments/assets/df1b5ee5-dcec-44dd-911e-bcfcee2500db)

However, if I plot using the standard matplotlib way of plotting (ax.scatter and ax.plot), both subplots show up correctly when I set sharex=True for the figure.

```python
#Plotting with matplotlib - this works
fig, ax = plt.subplots(2, sharex=True)
ax[0].scatter(df['datetime'],df['y'])
ax[1].plot(df['datetime'],df['y'])
```

![Image](https://github.com/user-attachments/assets/fb9a7ae4-2c51-4058-9a30-52919958cdbc)

### Expected Behavior

I would expect for the both subplots to show up, not blank. The behavior should be more similar to the traditional way of plotting with matplotlib.

### Installed Versions

<details>


INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.1
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Visualization']","{'login': 'Nivya-21', 'id': 65037575, 'node_id': 'MDQ6VXNlcjY1MDM3NTc1', 'avatar_url': 'https://avatars.githubusercontent.com/u/65037575?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Nivya-21', 'html_url': 'https://github.com/Nivya-21', 'followers_url': 'https://api.github.com/users/Nivya-21/followers', 'following_url': 'https://api.github.com/users/Nivya-21/following{/other_user}', 'gists_url': 'https://api.github.com/users/Nivya-21/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Nivya-21/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Nivya-21/subscriptions', 'organizations_url': 'https://api.github.com/users/Nivya-21/orgs', 'repos_url': 'https://api.github.com/users/Nivya-21/repos', 'events_url': 'https://api.github.com/users/Nivya-21/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Nivya-21/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-25 16:06:08+00:00,2025-04-09 16:28:52+00:00,Nivya-21,43.015787037037036
61004,DOC: Fix missing a closing bracket in contributing codebase,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-25 15:23:49+00:00,2025-02-25 17:51:53+00:00,,0.10282407407407407
61003,DOC: Updates to documentation,Updated the doc to make iloc assignment visible on webpage.,['Docs'],,2025-02-25 13:44:49+00:00,2025-02-26 00:51:28+00:00,,0.46295138888888887
61002,DOC: fix ES01 for pandas.DataFrame.astype,"fixes

```
pandas.DataFrame.astype ES01
```",['Docs'],,2025-02-25 04:29:12+00:00,2025-02-25 17:44:28+00:00,,0.5522685185185185
61001,Backport PR #61000 on branch 2.3.x (TST: Change sqlite test query string values to single quotes),Backport PR #61000: TST: Change sqlite test query string values to single quotes,"['Testing', 'IO SQL']",,2025-02-24 21:40:02+00:00,2025-02-24 23:21:05+00:00,,0.07017361111111112
61000,TST: Change sqlite test query string values to single quotes,"xref https://github.com/pandas-dev/pandas/actions/runs/13505086719/job/37732738398

Might be a new failure interaction with `sqlite3` and sqlite 3.49 being released recently https://www.sqlite.org/changes.html, but if this query is backward compatible we might as well use this form.

closes https://github.com/pandas-dev/pandas/issues/60989","['Testing', 'IO SQL']",,2025-02-24 20:44:36+00:00,2025-02-24 21:39:27+00:00,,0.03809027777777778
60997,BUG: fix read_json ignoring the dtype with the pyarrow engine,"- Added code to check if dtypes have been passed in, if they are, read the JSON with the schema built from those dtypes
- Split read JSON function up for the respective engines

- [X] closes #59516  (Replace xxxx with the GitHub issue number)
- [X] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [X] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['IO JSON', 'Arrow']",,2025-02-24 12:17:40+00:00,2025-03-19 18:12:52+00:00,,23.246666666666666
60995,WEB: Fix donation page,"Closes #60360 
",['Web'],,2025-02-24 05:30:01+00:00,2025-02-24 07:42:06+00:00,,0.09172453703703703
60994,BUG: `iloc` with `Series` as indexer fails for `__getitem__` but works with `__setitem__`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
# __getitem__
>>> a = pd.Series([0, 1, 2])
>>> a.iloc[pd.Series([True, False, False])]
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In[8], line 1
----> 1 a.iloc[pd.Series([True, False, False])]

File ~/.local/share/hatch/env/virtual/lontras/VBVTu9RT/lontras/lib/python3.11/site-packages/pandas/core/indexing.py:1191, in _LocationIndexer.__getitem__(self, key)
   1189 maybe_callable = com.apply_if_callable(key, self.obj)
   1190 maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)
-> 1191 return self._getitem_axis(maybe_callable, axis=axis)

File ~/.local/share/hatch/env/virtual/lontras/VBVTu9RT/lontras/lib/python3.11/site-packages/pandas/core/indexing.py:1738, in _iLocIndexer._getitem_axis(self, key, axis)
   1735     key = np.asarray(key)
   1737 if com.is_bool_indexer(key):
-> 1738     self._validate_key(key, axis)
   1739     return self._getbool_axis(key, axis=axis)
   1741 # a list of integers

File ~/.local/share/hatch/env/virtual/lontras/VBVTu9RT/lontras/lib/python3.11/site-packages/pandas/core/indexing.py:1578, in _iLocIndexer._validate_key(self, key, axis)
   1576 if hasattr(key, ""index"") and isinstance(key.index, Index):
   1577     if key.index.inferred_type == ""integer"":
-> 1578         raise NotImplementedError(
   1579             ""iLocation based boolean ""
   1580             ""indexing on an integer type ""
   1581             ""is not available""
   1582         )
   1583     raise ValueError(
   1584         ""iLocation based boolean indexing cannot use ""
   1585         ""an indexable as a mask""
   1586     )
   1587 return

NotImplementedError: iLocation based boolean indexing on an integer type is not available

# __setitem__
>>> a.iloc[pd.Series([True, False, False])] = 10; a
0    10
1     1
2     2
dtype: int64
```

### Issue Description

Behavior of `loc` with a `Series` as argument shows inconsistent behavior for `__getitem__` and `__setitem__`

### Expected Behavior

Either both `__getitem__` and `__setitem__` should work or both should fail

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.10
python-bits           : 64
OS                    : Linux
OS-release            : 6.12.10-arch1-1
Version               : #1 SMP PREEMPT_DYNAMIC Sat, 18 Jan 2025 02:26:57 +0000
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : 8.1.3
IPython               : 8.31.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Indexing']","{'login': 'arthurlw', 'id': 126365160, 'node_id': 'U_kgDOB4gt6A', 'avatar_url': 'https://avatars.githubusercontent.com/u/126365160?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/arthurlw', 'html_url': 'https://github.com/arthurlw', 'followers_url': 'https://api.github.com/users/arthurlw/followers', 'following_url': 'https://api.github.com/users/arthurlw/following{/other_user}', 'gists_url': 'https://api.github.com/users/arthurlw/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/arthurlw/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/arthurlw/subscriptions', 'organizations_url': 'https://api.github.com/users/arthurlw/orgs', 'repos_url': 'https://api.github.com/users/arthurlw/repos', 'events_url': 'https://api.github.com/users/arthurlw/events{/privacy}', 'received_events_url': 'https://api.github.com/users/arthurlw/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-23 16:29:36+00:00,2025-04-09 16:27:06+00:00,arthurlw,44.998263888888886
60993,ENH(string dtype): fallback for HDF5 with UTF-8 surrogates,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

One oddity I encountered here: only the index is currently encoded / decoded on write / read operations respectively. Columns on the other hand are written and read as strings. I haven't looked into why this is, and if we can avoid encode/decode for index.

It seemed best to only fallback when `errors=""surrogatepass""`, though that use is a bit odd since there is no actual decode occurring. If there are other approaches (perhaps always falling back?), I'm certainly open to them.

Another option here is to fallback to `object` instead of `StringDtype(storage=""python"")`, but it seems with `infer_string=True` the latter is more appropriate.","['IO HDF5', 'Strings']",,2025-02-23 15:04:04+00:00,2025-04-16 14:25:08+00:00,,51.97296296296296
60992,BUG: fix PeriodIndex.difference producing incorrect results,"- [x] closes #58971 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-02-23 14:15:17+00:00,2025-04-04 17:08:46+00:00,,40.12047453703704
60991,Update test_describe.py,"Added test case

Modified the .describe() method to avoid adding the 50th percentile by default when a custom percentiles list is provided.
Added a test case to verify the behavior when a single percentile is passed.",[],,2025-02-23 13:15:15+00:00,2025-02-25 02:18:46+00:00,,1.5441087962962963
60990,DOC: Updated set_index doc with a warning,"- [x] closes #60973 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
",['Docs'],,2025-02-23 10:21:48+00:00,2025-03-05 00:39:08+00:00,,9.59537037037037
60989,BUG: `Urgent` - All PR's are getting deployment errors in git pipeline,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
na
```

### Issue Description

FAILED pandas/tests/io/test_sql.py::test_xsqlite_execute_fail - pandas.errors.DatabaseError: Execution failed on sql 'INSERT INTO test VALUES(""foo"", ""bar"", 1.234)': no such column: ""foo"" - should this be a string literal in single-quotes?
FAILED pandas/tests/io/test_sql.py::test_xsqlite_execute_closed_connection - pandas.errors.DatabaseError: Execution failed on sql 'INSERT INTO test VALUES(""foo"", ""bar"", 1.234)': no such column: ""foo"" - should this be a string literal in single-quotes?
= 2 failed, 3760 passed, 372 skipped, 232245 deselected, 376 xfailed, 1 xpassed, 81 warnings in 1182.58s (0:19:42) =
/home/runner/micromamba/envs/test/lib/python3.12/site-packages/s3fs/core.py:569: DeprecationWarning: There is no current event loop
  loop = asyncio.get_event_loop()
Error: Process completed with exit code 1.
Run actions/upload-artifact@v4
With the provided path, there will be 1 file uploaded
Artifact name is valid!
Root directory input is valid!
Beginning upload of artifact content to blob storage
Uploaded bytes 39831
Finished uploading artifact content to blob storage!
SHA256 hash of uploaded artifact zip is f1126cc96347284a152f921e8e59bcadd2762e4d3872d66fe1d9881a9775948f
Finalizing artifact upload
Artifact Test results.zip successfully finalized. Artifact ID 2636217021
Artifact Test results has been successfully uploaded! Final size is 39831 bytes. Artifact ID is 2636217021
Artifact download URL: https://github.com/pandas-dev/pandas/actions/runs/13478588009/artifacts/2636217021
Run codecov/codecov-action@v4
eventName: pull_request
baseRef: pandas-dev:main | headRef: Anurag-Varma:bug#60723
==> Fork detected, tokenless uploading used
==> linux OS detected
https://cli.codecov.io/latest/linux/codecov.SHA256SUM
gpg: directory '/home/runner/.gnupg' created
gpg: keybox '/home/runner/.gnupg/pubring.kbx' created
gpg: /home/runner/.gnupg/trustdb.gpg: trustdb created
gpg: key 806BB28AED779869: public key ""Codecov Uploader (Codecov Uploader Verification Key) <security@codecov.io>"" imported
gpg: Total number processed: 1
gpg:               imported: 1
gpg: Signature made Fri Feb 21 21:18:38 2025 UTC
gpg:                using RSA key 27034E7FDB850E0BBC2C62FF806BB28AED779869
gpg: Good signature from ""Codecov Uploader (Codecov Uploader Verification Key) <security@codecov.io>"" [unknown]
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the owner.
Primary key fingerprint: 2703 4E7F DB85 0E0B BC2C  62FF 806B B28A ED77 9869
==> Uploader SHASUM verified (ec031bdc38a2ca279ea1f56650b63aa6ce1365e7ee9da33b[413](https://github.com/pandas-dev/pandas/actions/runs/13477733861/job/37658956940#step:9:417)e6f175a94fe2b  codecov)
==> Running version latest
Could not pull latest version information: SyntaxError: Unexpected token '<', ""<!DOCTYPE ""... is not valid JSON
==> Running git config --global --add safe.directory /home/runner/work/pandas/pandas
/usr/bin/git config --global --add safe.directory /home/runner/work/pandas/pandas
==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-commit'
/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-commit --git-service github -B Anurag-Varma:bug#60723 -C 42c51ec8e4efc3c8a221625c92b22e2730b5fe7e
info - 2025-02-23 02:40:28,834 -- ci service found: github-actions
info - 2025-02-23 02:40:28,861 -- Creating a commit for an unprotected branch: Anurag-Varma:bug#60723
info - 2025-02-23 02:40:29,365 -- Process Commit creating complete
==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-report'
/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-report --git-service github -C 42c51ec8e4efc3c8a221625c92b22e2730b5fe7e
info - 2025-02-23 02:40:30,161 -- ci service found: github-actions
info - 2025-02-23 02:40:30,587 -- Process Report creating complete
info - 2025-02-23 02:40:30,588 -- Finished creating report successfully --- {""response"": ""{\""status\"":\""queued\""}\n""}
==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov do-upload'
/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov do-upload -F unittests --git-service github -n codecov-pandas -C 42c51ec8e4efc3c8a221625c92b22e2730b5fe7e
info - 2025-02-23 02:40:31,391 -- ci service found: github-actions
warning - 2025-02-23 02:40:31,[418](https://github.com/pandas-dev/pandas/actions/runs/13477733861/job/37658956940#step:9:422) -- xcrun is not installed or can't be found.
warning - 2025-02-23 02:40:31,450 -- No gcov data found.
warning - 2025-02-23 02:40:31,450 -- coverage.py is not installed or can't be found.
info - 2025-02-23 02:40:31,498 -- Found 1 coverage files to report
info - 2025-02-23 02:40:31,498 -- > /home/runner/work/pandas/pandas/coverage.xml
info - 2025-02-23 02:40:32,005 -- Your upload is now processing. When finished, results will be available at: https://app.codecov.io/github/pandas-dev/pandas/commit/42c51ec8e4efc3c8a221625c92b22e2730b5fe7e
info - 2025-02-23 02:40:32,331 -- Process Upload complete

### Expected Behavior

na

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Needs Triage']",,2025-02-23 03:31:35+00:00,2025-02-24 21:39:28+00:00,,1.755474537037037
60988,BUG: The Series `.map()` function frequently fails when using dictionaries with tuple keys in various cases.,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.



### Issue Description

The Series `.map()` function frequently fails when using dictionaries with tuple keys which is given as parameter to the map function. See the below examples:

Ex 1:
```Python
import pandas as pd

df = pd.DataFrame({""a"": [(1,1), (2,2), (3,4), (5,6)]})  
label_mappings = {(1,): ""A"", (2,2): ""B"", (3,4): ""A"", (5,6): ""B""}  
df[""mapped_labels""] = df[""a""].map(label_mappings)  

print(df)
# Output:
#        a        mapped_labels
# 0  (1, 1)             A
# 1  (2, 2)             B
# 2  (3, 4)             A
# 3  (5, 6)             B

# Expected Ouput:
#        a        mapped_labels
# 0  (1, 1)           NaN
# 1  (2, 2)             B
# 2  (3, 4)             A
# 3  (5, 6)             B
```



Ex 2:
```Python
import pandas as pd

df = pd.DataFrame({""a"": [(1,1), (2,2), (3,4), (5,6)]})  
label_mappings = {(2,): ""A"", (2,2): ""B"", (3,4): ""A"", (5,6): ""B""}  
df[""mapped_labels""] = df[""a""].map(label_mappings)  

print(df)
# Output:
# Produces error: pandas.errors.InvalidIndexError: Reindexing only valid with uniquely valued Index objects

# Expected Ouput:
#        a        mapped_labels
# 0  (1, 1)           NaN
# 1  (2, 2)             B
# 2  (3, 4)             A
# 3  (5, 6)             B
```


EX 3:
```Python
import pandas as pd

df = pd.DataFrame({""a"": [(1,), (2,2), (3,4), (5,6)]})  
label_mappings = {(1,None): ""A"", (2,2): ""B"", (3,4): ""A"", (5,6): ""B""}  
df[""mapped_labels""] = df[""a""].map(label_mappings)  

print(df)

# Output:
# Produces error: AssertionError: Length of new_levels (2) must be <= self.nlevels (1)

# Expected Ouput:
#        a        mapped_labels
# 0  (1, )               NaN
# 1  (2, 2)             B
# 2  (3, 4)             A
# 3  (5, 6)             B
```



EX 4:
```Python
import pandas as pd

df = pd.DataFrame({""a"": [(1,), (2,2), (3,4), (5,6)]})  
label_mappings = {(1,1): ""A"", (2,2): ""B"", (3,4): ""A"", (5,6): ""B""}   
df[""mapped_labels""] = df[""a""].map(label_mappings)  

print(df)

# Output:
# Produces error: AssertionError: Length of new_levels (2) must be <= self.nlevels (1)

# Expected Ouput:
#        a        mapped_labels
# 0  (1, )               NaN
# 1  (2, 2)             B
# 2  (3, 4)             A
# 3  (5, 6)             B
```


EX 5:
```Python
import pandas as pd

df = pd.DataFrame({""a"": [(1,1), (1,2), (3,4), (5,6)]})  
label_mappings = {(1,): ""A"", (2,2): ""B"", (3,4): ""A"", (5,6): ""B""}   
df[""mapped_labels""] = df[""a""].map(label_mappings)  

print(df)

# Output:
#        a        mapped_labels
# 0  (1, 1)             A
# 1  (1, 2)             A
# 2  (3, 4)             A
# 3  (5, 6)             B

# Expected Ouput:
#        a        mapped_labels
# 0  (1, 1)             NaN
# 1  (1, 2)             NaN
# 2  (3, 4)             A
# 3  (5, 6)             B
```

### Expected Behavior

Gave the actual outputs and expected outputs.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 6bcd30397d67c3887288c7a82c2c235ce8bc3c7f
python                : 3.10.14
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.26120
machine               : AMD64
processor             : AMD64 Family 23 Model 96 Stepping 1, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 3.0.0.dev0+1944.g6bcd30397d.dirty
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 24.0
Cython                : 3.0.10
sphinx                : 7.3.7
IPython               : 8.18.1
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
fastparquet           : None
fsspec                : 2024.6.1
html5lib              : 1.1
hypothesis            : 6.105.0
gcsfs                 : 2024.6.1
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : None
numba                 : 0.61.0
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : None
pymysql               : 1.4.6
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pytz                  : 2025.1
pyxlsb                : 1.0.10
s3fs                  : 2024.6.1
scipy                 : 1.15.2
sqlalchemy            : 2.0.31
tables                : None
tabulate              : 0.9.0
xarray                : 2024.6.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'IO Data']","{'login': 'Anurag-Varma', 'id': 62068859, 'node_id': 'MDQ6VXNlcjYyMDY4ODU5', 'avatar_url': 'https://avatars.githubusercontent.com/u/62068859?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Anurag-Varma', 'html_url': 'https://github.com/Anurag-Varma', 'followers_url': 'https://api.github.com/users/Anurag-Varma/followers', 'following_url': 'https://api.github.com/users/Anurag-Varma/following{/other_user}', 'gists_url': 'https://api.github.com/users/Anurag-Varma/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Anurag-Varma/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Anurag-Varma/subscriptions', 'organizations_url': 'https://api.github.com/users/Anurag-Varma/orgs', 'repos_url': 'https://api.github.com/users/Anurag-Varma/repos', 'events_url': 'https://api.github.com/users/Anurag-Varma/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Anurag-Varma/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-22 22:56:33+00:00,2025-03-07 23:51:47+00:00,Anurag-Varma,13.03835648148148
60987,MNT: Bump dev pin on NumPy,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Dependencies'],,2025-02-22 21:22:35+00:00,2025-04-03 15:30:25+00:00,,39.755439814814814
60986,Update describe.py,"This PR fixes an issue where passing a single value to .describe(percentiles=[...]) would incorrectly include the 50th percentile (median) in the output. The fix ensures that only the explicitly requested percentiles are returned.

Changes:
Modified the .describe() method to avoid adding the 50th percentile by default when a custom percentiles list is provided.

Closes: #60550",['Enhancement'],,2025-02-22 17:14:56+00:00,2025-03-24 16:46:26+00:00,,29.980208333333334
60985,BUG(string dtype): groupby/resampler.min/max returns float on all NA strings,"- [x] closes #60810 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Built on top of #60936","['Bug', 'Groupby', 'Missing-data', 'Strings', 'Reduction Operations']",,2025-02-22 15:30:08+00:00,2025-04-19 15:22:37+00:00,,55.99478009259259
60984,Backport PR #60938: ENH(string dtype): Implement cumsum for Python-backed strings,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Strings'],,2025-02-22 13:28:24+00:00,2025-02-22 18:51:17+00:00,,0.22422453703703704
60983,BUG: Fix concat DataFrame and Series with ignore_index=True,"- [x] closes #60723 
- [x] closes #56257 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'Reshaping']",,2025-02-22 06:57:33+00:00,2025-03-07 01:04:18+00:00,,12.7546875
60982,DOC: Add missing punctuation to pandas documentation,"Add missing punctuation to pandas documentation:

1. `doc/source/user_guide/text.rst`
2. `doc/source/reference/arrays.rst`

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-22 04:44:32+00:00,2025-02-24 18:25:34+00:00,,2.570162037037037
60980,BUG: invalid result of reindex on columns after unstack with Period data,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

series1 = pd.DataFrame(
   [(0, ""s2"", pd.Period(2022)), (0, ""s1"", pd.Period(2021))],
   columns=[""A"", ""B"", ""C""]
).set_index([""A"", ""B""])[""C""]

series2 = series1.astype(str)

print(series1.unstack(""B"").reindex([""s2""], axis=1))
print(series2.unstack(""B"").reindex([""s2""], axis=1))
```

### Issue Description

The example code prints
```
B  s2
A      
0  2021

B  s2
A‚ÄÉ‚ÄÉ
0  2022
```

The result with `pd.Period` data is the incorrect 2021, but with `str` data it's the correct 2022.

This only occurs with certain index values. When replacing ""s1"" with ""s3"", the effect disappears and the result is 2022 in both cases.



### Expected Behavior

Expect the result for both `pd.Period` and `str` data to be 2022:
```
B  s2
A‚ÄÉ‚ÄÉ
0  2022

B  s2
A‚ÄÉ‚ÄÉ
0  2022
```

(actually observed with older Pandas 2.0.3)


### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.10
python-bits           : 64
OS                    : Linux
OS-release            : 6.2.16
Version               : #1-NixOS SMP PREEMPT_DYNAMIC Tue Jan  1 00:00:00 UTC 1980
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8
pandas                : 2.2.3
numpy                 : 2.2.3
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 24.0
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Reshaping']","{'login': 'pedromfdiogo', 'id': 146959142, 'node_id': 'U_kgDOCMJrJg', 'avatar_url': 'https://avatars.githubusercontent.com/u/146959142?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/pedromfdiogo', 'html_url': 'https://github.com/pedromfdiogo', 'followers_url': 'https://api.github.com/users/pedromfdiogo/followers', 'following_url': 'https://api.github.com/users/pedromfdiogo/following{/other_user}', 'gists_url': 'https://api.github.com/users/pedromfdiogo/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/pedromfdiogo/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/pedromfdiogo/subscriptions', 'organizations_url': 'https://api.github.com/users/pedromfdiogo/orgs', 'repos_url': 'https://api.github.com/users/pedromfdiogo/repos', 'events_url': 'https://api.github.com/users/pedromfdiogo/events{/privacy}', 'received_events_url': 'https://api.github.com/users/pedromfdiogo/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-21 18:07:08+00:00,2025-03-17 16:55:32+00:00,pedromfdiogo,23.950277777777778
60979,DOC: Add missing attributes to Styler class,"- [x] closes #60815
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Validated changes using `python scripts/validate_docstrings.py pandas.io.formats.style.Styler`

### Tasks performed

- Added documentation for `index` and `columns` under `Attributes` in `pandas.io.formats.style.Styler` as [discussed](https://github.com/pandas-dev/pandas/issues/60815#issuecomment-2665924948).

### Additional Comments

- First PR on this project, your feedback is highly valuable to me, looking forward to contributing more and more in the coming days!
",['Docs'],,2025-02-21 17:05:11+00:00,2025-02-21 18:06:52+00:00,,0.04283564814814815
60978,BUG: Unexpected datetime dtype change on assignments,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

ts = pd.Timestamp.today()
df = pd.DataFrame({""A"": [ts]})
print(df.dtypes)

# B now has datetime64[us] dtype
df[""B""] = ts
print(df.dtypes)

# A remains datetime64[ns] dtype
df.loc[:, ""A""] = pd.Timestamp.today()
print(df.dtypes)

# A now changes to datetime64[us] dtype
df[""A""] = ts
print(df.dtypes)

# B remains datetime64[us] dtype
df.loc[:, ""B""] = ts
print(df.dtypes)
```

### Issue Description

Dataframe (and series) creation with a pd.Timestamp results in a dtype of `datetime64[ns]`.
However when I assign the same timestamp to a new column the dtype changes to `datetime64[us]`.
Assigning a different way maintains the original dtype.

### Expected Behavior

I would expect both assignments to maintain the same dtype of  `datetime64[ns]`.

### Installed Versions

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.0
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : Intel64 Family 6 Model 158 Stepping 13, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United Kingdom.1252
pandas                : 2.2.3
numpy                 : 1.26.0
pytz                  : 2023.3.post1
dateutil              : 2.8.2
pip                   : 22.3
Cython                : None
sphinx                : None
IPython               : 8.16.1
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.2
blosc                 : None
bottleneck            : 1.3.7
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.8.0
numba                 : 0.60.0
numexpr               : 2.8.7
odfpy                 : None
openpyxl              : 3.1.4
pandas_gbq            : None
psycopg2              : 2.9.9
pymysql               : None
pyarrow               : 11.0.0
pyreadstat            : None
pytest                : 7.4.3
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.11.3
sqlalchemy            : 2.0.0
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : None
tzdata                : 2023.3
qtpy                  : None
pyqt5                 : None","['Bug', 'Needs Triage']",,2025-02-21 12:52:59+00:00,2025-02-21 18:02:40+00:00,,0.21505787037037036
60977,DEPS: Revert SQLAlchemy minimum version back to 1.4.36,"- [ ] closes #57049
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v2.3.0.rst` file if fixing a bug or adding a new feature.
","['IO SQL', 'Dependencies', 'Stale']",,2025-02-21 07:41:05+00:00,2025-06-09 02:27:39+00:00,,107.78233796296297
60976,DOC: Clarify the magnitude for truncation,"Original statement: When values differ with magnitude :math:`1/np.finfo(np.double).eps` this results in truncation.

Added clarification: `1/np.finfo(np.double).eps` is approximately `4.5 x 10^{15}`.

https://pandas.pydata.org/docs/dev/user_guide/window.html

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-21 04:20:06+00:00,2025-02-21 18:05:02+00:00,,0.5728703703703704
60975,GH60942 Update docs and overload for Series.rename,"- [x] closes #60942 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Typing', 'Series']",,2025-02-21 00:41:18+00:00,2025-02-22 01:12:30+00:00,,1.0216666666666667
60974,BUG: fix error message for multiindex.fillna,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

It's very surprising to me that there's 3 different tests which explicitly check this error message, yet the discrepancy was never noticed (unless I'm missing something here, which is definitely a possibility)","['Error Reporting', 'MultiIndex']",,2025-02-20 12:06:06+00:00,2025-02-20 17:18:47+00:00,,0.2171412037037037
60973,DOC: No warning in set_index() that previous index column is removed.,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html

### Documentation problem

set_index(), when applied to a DataFrame which already has a data column (non-default) assigned as index, will delete this data column from the DataFrame when assigning another data column to be the index.

While I find this behaviour inappropriate, I understand that reset_index() should be used before set_index(), in which case the original index column may be preserved.

The problem is that the documentation for set_index() does not mention this at all, so the user is left to discover the problem and then the way to avoid it.

### Suggested fix for documentation

Add a comment in the set_index documentation to clarify that setting a data column as index, when there is already a different data column serving as index, will delete that data column, unless reset_index is performed first.","['Docs', 'Indexing', 'Needs Discussion']","{'login': 'SaraInCode', 'id': 42293506, 'node_id': 'MDQ6VXNlcjQyMjkzNTA2', 'avatar_url': 'https://avatars.githubusercontent.com/u/42293506?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/SaraInCode', 'html_url': 'https://github.com/SaraInCode', 'followers_url': 'https://api.github.com/users/SaraInCode/followers', 'following_url': 'https://api.github.com/users/SaraInCode/following{/other_user}', 'gists_url': 'https://api.github.com/users/SaraInCode/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/SaraInCode/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/SaraInCode/subscriptions', 'organizations_url': 'https://api.github.com/users/SaraInCode/orgs', 'repos_url': 'https://api.github.com/users/SaraInCode/repos', 'events_url': 'https://api.github.com/users/SaraInCode/events{/privacy}', 'received_events_url': 'https://api.github.com/users/SaraInCode/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-20 10:41:16+00:00,2025-03-05 00:39:09+00:00,SaraInCode,12.581863425925926
60972,ENH: Support for Python 3.13.2 free-threading version,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

Firstly, use `python3.13t -m pip install pandas` to build and install `pandas` on VS 16.11.43 and MSVC 19.29.30158.  
Then try to import it:

```python
E:\Git-repositories\project179>python3.13t
Python 3.13.2 experimental free-threading build (tags/v3.13.2:4f8bb39, Feb  4 2025, 15:33:40) [MSC v.1942 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import pandas as pd
<Segmentation fault caused there>
```

### Issue Description

The line `import pandas` failed in Python 3.13 free-threading version on x64 Windows.  
As I tried to execute it, a segmentation fault caused because I've seen `werfault.exe` appeared in the task manager.  

### Expected Behavior

The line `import pandas` successfully be executed.  

### Installed Versions

<details>
pandas 2.2.3
(Note: cannot call pd.show_versions() as I couldn't import pandas at the first step)
</details>

Additionally, this is the output during compiling pandas that contains the MSVC version:
```
 + meson setup C:\Users\admin\AppData\Local\Temp\pip-install-yk54bvta\pandas_93cffcf8ab364c6d8ccc39766c5b148a C:\Users\admin\AppData\Local\Temp\pip-install-yk54bvta\pandas_93cffcf8ab364c6d8ccc39766c5b148a\.mesonpy-6btzqpgz\build -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=C:\Users\admin\AppData\Local\Temp\pip-install-yk54bvta\pandas_93cffcf8ab364c6d8ccc39766c5b148a\.mesonpy-6btzqpgz\build\meson-python-native-file.ini
      The Meson build system
      Version: 1.2.1
      Source dir: C:\Users\admin\AppData\Local\Temp\pip-install-yk54bvta\pandas_93cffcf8ab364c6d8ccc39766c5b148a
      Build dir: C:\Users\admin\AppData\Local\Temp\pip-install-yk54bvta\pandas_93cffcf8ab364c6d8ccc39766c5b148a\.mesonpy-6btzqpgz\build
      Build type: native build
      Project name: pandas
      Project version: 2.2.3
      Activating VS 16.11.43
      C compiler for the host machine: cl (msvc 19.29.30158 ""Áî®‰∫é x64 ÁöÑ Microsoft (R) C/C++ ‰ºòÂåñÁºñËØëÂô® 19.29.30158 Áâà"")
      C linker for the host machine: link link 14.29.30158.0
      C++ compiler for the host machine: cl (msvc 19.29.30158 ""Áî®‰∫é x64 ÁöÑ Microsoft (R) C/C++ ‰ºòÂåñÁºñËØëÂô® 19.29.30158 Áâà"")
      C++ linker for the host machine: link link 14.29.30158.0
      Cython compiler for the host machine: cython (cython 3.0.12)
      Host machine cpu family: x86_64
      Host machine cpu: x86_64
      Program python found: YES (D:\Python\Python313\python3.13t.exe)
      Run-time dependency python found: YES 3.13
      Build targets in project: 53

      pandas 2.2.3

        User defined options
          Native files: C:\Users\admin\AppData\Local\Temp\pip-install-yk54bvta\pandas_93cffcf8ab364c6d8ccc39766c5b148a\.mesonpy-6btzqpgz\build\meson-python-native-file.ini
          buildtype   : release
          vsenv       : True
          b_ndebug    : if-release
          b_vscrt     : md

      Found ninja.EXE-1.11.1.git.kitware.jobserver-1 at C:\Users\admin\AppData\Local\Temp\pip-build-env-3jrexmoi\normal\Scripts\ninja.EXE

      Visual Studio environment is needed to run Ninja. It is recommended to use Meson wrapper:
      C:\Users\admin\AppData\Local\Temp\pip-build-env-3jrexmoi\overlay\Scripts\meson compile -C .
      + meson compile
      [1/151] Generating pandas/_libs/algos_common_helper_pxi with a custom command
      [2/151] Generating pandas/_libs/khash_primitive_helper_pxi with a custom command
      [3/151] Generating pandas/_libs/hashtable_class_helper_pxi with a custom command
      [4/151] Generating pandas/_libs/algos_take_helper_pxi with a custom command
      [5/151] Generating pandas/_libs/hashtable_func_helper_pxi with a custom command
      [6/151] Generating pandas/_libs/intervaltree_helper_pxi with a custom command
      [7/151] Generating pandas/_libs/index_class_helper_pxi with a custom command
      [8/151] Generating pandas/_libs/sparse_op_helper_pxi with a custom command
      [9/151] Generating pandas/__init__.py with a custom command
      [10/151] Compiling C object pandas/_libs/tslibs/parsing.cp313t-win_amd64.pyd.p/.._src_parser_tokenizer.c.obj
      ..\..\pandas\_libs\include\pandas/vendored/klib/khash.h(729): warning C4090: ‚ÄúÂáΩÊï∞‚Äù: ‰∏çÂêåÁöÑ‚Äúconst‚ÄùÈôêÂÆöÁ¨¶
      [11/151] Compiling Cython source C:/Users/admin/AppData/Local/Temp/pip-install-yk54bvta/pandas_93cffcf8ab364c6d8ccc39766c5b148a/pandas/_libs/tslibs/base.pyx
      [12/151] Compiling C object pandas/_libs/tslibs/base.cp313t-win_amd64.pyd.p/meson-generated_pandas__libs_tslibs_base.pyx.c.obj
```
","['Enhancement', 'Build']","{'login': 'rhshadrach', 'id': 45562402, 'node_id': 'MDQ6VXNlcjQ1NTYyNDAy', 'avatar_url': 'https://avatars.githubusercontent.com/u/45562402?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/rhshadrach', 'html_url': 'https://github.com/rhshadrach', 'followers_url': 'https://api.github.com/users/rhshadrach/followers', 'following_url': 'https://api.github.com/users/rhshadrach/following{/other_user}', 'gists_url': 'https://api.github.com/users/rhshadrach/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/rhshadrach/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/rhshadrach/subscriptions', 'organizations_url': 'https://api.github.com/users/rhshadrach/orgs', 'repos_url': 'https://api.github.com/users/rhshadrach/repos', 'events_url': 'https://api.github.com/users/rhshadrach/events{/privacy}', 'received_events_url': 'https://api.github.com/users/rhshadrach/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-20 08:44:21+00:00,2025-06-04 18:16:56+00:00,rhshadrach,104.39762731481481
60971,WEB: Partial update of workgroups,"Making a first update for the new teams structure. I think some more will be needed, including the steering committee one, but for now updating just this, as it's useful for the OVH discussions.
","['Admin', 'Web']",,2025-02-20 03:30:05+00:00,2025-02-20 17:11:07+00:00,,0.570162037037037
60970,DOC: Correct a typo in merging.rst,"Correct a typo in merging.rst.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-20 02:23:03+00:00,2025-02-20 02:35:24+00:00,,0.008576388888888889
60969,Feature auto infer orient as table or split in read_json,"- [x] closes #52713
- [x] [Tests added and passed]
- [x] All [code checks passed]
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

### Example:

This example demonstrates how to use the updated functionality of `read_json` to correctly handle the new `orient='table'` format.

#### Saving DataFrame to JSON with orient='table':

```python
import pandas as pd

# Create a sample DataFrame
df = pd.DataFrame({""A"": [1, 2, 3]})

df.to_json('test.json', indent=1, orient='table')
read = pd.read_json('test.json')
print(read)

   A
0  1
1  2
2  3
```

#### Saving DataFrame to JSON with orient='split':

```python
df = pd.DataFrame({""A"": [1, 2, 3]})

df.to_json('test.json', indent=1, orient='split')
read = pd.read_json('test.json')
print(read)

   A
0  1
1  2
2  3
```",['IO JSON'],,2025-02-20 00:00:13+00:00,2025-02-25 19:44:04+00:00,,5.822118055555555
60968,Backport PR #60940: ENH: Add dtype argument to str.decode,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Enhancement', 'Strings']",,2025-02-19 22:32:33+00:00,2025-02-20 17:32:04+00:00,,0.7913310185185185
60967,Backport PR #60943: BUG(string dtype): Resolve pytables xfail when reading with condition,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['IO HDF5', 'Strings']",,2025-02-19 22:10:38+00:00,2025-02-20 17:30:58+00:00,,0.805787037037037
60965,Instrumentation_evaluate numexpr,"- Initially 0% coverage
- Added test cases and have seen improvement in coverage to 50%

",[],,2025-02-19 20:25:47+00:00,2025-02-19 20:26:04+00:00,,0.00019675925925925926
60963,remove unused dtype from MultiIndex constructor,"One possible fix for #60962

This could go through a deprecation warning, although anyone currently passing `dtype` to `MultiIndex` is already having their code (silently) not behave as intended. Keeping the parameter but raising an error wouldn't be any less breaking that removing the argument. Happy to take a different strategy if people prefer though

- [ ] closes #60962 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['MultiIndex'],,2025-02-19 10:54:23+00:00,2025-02-20 17:34:39+00:00,,1.277962962962963
60962,BUG: `dtype` silently ignored in `MultiIndex` constructor,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
pd.MultiIndex([[1,2,3], [4,5,6]], [[0,1,2], [0,1,2]], dtype='float64')
```

### Issue Description

This outputs
```
MultiIndex([(1, 4),
            (2, 5),
            (3, 6)],
           )
```
`dtype` is ignored

### Expected Behavior

I think one of the following:
- `dtype` is respected
- the `dtype` argument is removed
- the `dtype` argument is kept but raises if it's not `None`

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.5
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.3
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : None
gcsfs                 : 2025.2.0
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : 3.9.2
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : 8.3.3
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None


</details>
","['Bug', 'Needs Triage']",,2025-02-19 10:45:42+00:00,2025-02-20 17:34:40+00:00,,1.2840046296296297
60961,ENH: Integrate the pyspark in pandas,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I wish I could use Pandas to handle large datasets efficiently without running into memory issues. Pandas is great for data analysis but struggles with large datasets that don't fit in memory. This feature would allow seamless integration between Pandas and PySpark, enabling users to process large datasets using Spark‚Äôs distributed computing while still leveraging the familiar Pandas syntax.

### Feature Description

Seamlessly integrate Pandas with PySpark by automatically converting large Pandas DataFrames into Spark DataFrames while preserving Pandas-like syntax for efficient distributed computing. üöÄ

### Alternative Solutions

import pyspark.pandas as ps
psdf = ps.DataFrame({'id': range(1000000), 'value': range(1000000)})
import dask.dataframe as dd
ddf = dd.read_csv(""large_dataset.csv"")
import modin.pandas as mpd
df = mpd.read_csv(""large_file.csv"")
import vaex
df = vaex.open(""large_file.csv"")


### Additional Context

_No response_","['Enhancement', 'Needs Triage']",,2025-02-19 10:27:14+00:00,2025-02-19 10:43:29+00:00,,0.011284722222222222
60960,"DOC: Improve examples in Series.str.isnumeric shared docstring to include decimal, fraction, negatives and exponents (#60750)","- [x] closes #60750 
- [x] All [code checks passed](https://pandas.pydata.org/docs/dev/development/contributing_documentation.html#previewing-changes)
- [x] Validated changes for formatting issues using `scripts/validate_docstrings.py`

### Tasks performed

1.  Improved the existing example for `Series.str.isnumeric` to include Unicode fractions using shared docs.

2. Add a new example to clear confusion regarding decimals, exponents and negative values

### Before
![image](https://github.com/user-attachments/assets/e599b678-2736-4200-8e01-21445e5b59de)


### After 
![image](https://github.com/user-attachments/assets/c6180846-de53-4058-829d-5fb7da8c58a3)




",['Docs'],,2025-02-19 05:37:23+00:00,2025-02-21 01:12:41+00:00,,1.8161805555555555
60959,BUG: DataFrame construction fails with `pa.json_` Arrow extension type,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
$ import pandas as pd
$ import pyarrow as pa
$ arr = ['{""bar"": True, ""foo"": 10}']
$ pd.DataFrame({'json_col': arr}, pd.ArrowDtype(pa.json_(pa.string())))

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[7], line 5
      2 import pyarrow as pa
      4 arr = ['{""bar"": True, ""foo"": 10}']
----> 5 pd.DataFrame({'json_col': arr}, pd.ArrowDtype(pa.json_(pa.string())))

File ~/src/bigframes/venv/lib/python3.12/site-packages/pandas/core/frame.py:778, in DataFrame.__init__(self, data, index, columns, dtype, copy)
    772     mgr = self._init_mgr(
    773         data, axes={""index"": index, ""columns"": columns}, dtype=dtype, copy=copy
    774     )
    776 elif isinstance(data, dict):
    777     # GH#38939 de facto copy defaults to False only in non-dict cases
--> 778     mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)
    779 elif isinstance(data, ma.MaskedArray):
    780     from numpy.ma import mrecords

File ~/src/bigframes/venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:503, in dict_to_mgr(data, index, columns, dtype, typ, copy)
    499     else:
    500         # dtype check to exclude e.g. range objects, scalars
    501         arrays = [x.copy() if hasattr(x, ""dtype"") else x for x in arrays]
--> 503 return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)

File ~/src/bigframes/venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:116, in arrays_to_mgr(arrays, columns, index, dtype, verify_integrity, typ, consolidate)
    114     index = _extract_index(arrays)
    115 else:
--> 116     index = ensure_index(index)
    118 # don't force copy because getting jammed in an ndarray anyway
    119 arrays, refs = _homogenize(arrays, index, dtype)

File ~/src/bigframes/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7649, in ensure_index(index_like, copy)
   7647         return Index(index_like, copy=copy, tupleize_cols=False)
   7648 else:
-> 7649     return Index(index_like, copy=copy)

File ~/src/bigframes/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:532, in Index.__new__(cls, data, dtype, copy, name, tupleize_cols)
    528     return cls(np.asarray(data), dtype=dtype, copy=copy, name=name)
    529 elif not is_list_like(data) and not isinstance(data, memoryview):
    530     # 2022-11-16 the memoryview check is only necessary on some CI
    531     #  builds, not clear why
--> 532     raise cls._raise_scalar_data_error(data)
    534 else:
    535     if tupleize_cols:
    536         # GH21470: convert iterable to list before determining if empty

File ~/src/bigframes/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:5289, in Index._raise_scalar_data_error(cls, data)
   5284 @final
   5285 @classmethod
   5286 def _raise_scalar_data_error(cls, data):
   5287     # We return the TypeError so that we can raise it from the constructor
   5288     #  in order to keep mypy happy
-> 5289     raise TypeError(
   5290         f""{cls.__name__}(...) must be called with a collection of some ""
   5291         f""kind, {repr(data) if not isinstance(data, np.generic) else str(data)} ""
   5292         ""was passed""
   5293     )

TypeError: Index(...) must be called with a collection of some kind, extension<arrow.json>[pyarrow] was passed
```

### Issue Description

Apache Arrow v19.0 introduced the `pa.json_` extension type ([doc](https://arrow.apache.org/docs/format/CanonicalExtensions.html#json)). Currently, attempting to create a pandas DataFrame using this data type results in an error. The detailed error call stack can be observed in the reproducible example above. 

However, creating a pandas Series with pa.json_ works correctly. Here is an example that shows that Series construction works.

```Python
$ import pandas as pd
$ import pyarrow as pa
$ arr = ['{""bar"": True, ""foo"": 10}']
$ pd.Series(arr, dtype=pd.ArrowDtype(pa.json_(pa.string())))
0    {""bar"": True, ""foo"": 10}
dtype: extension<arrow.json>[pyarrow]
```

### Expected Behavior

Pandas should support DataFrame construction with the `pa.json_` Arrow extension type, consistent with its support for Series and Index objects.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.1
python-bits           : 64
OS                    : Linux
OS-release            : 6.10.11-1rodete2-amd64
Version               : #1 SMP PREEMPT_DYNAMIC Debian 6.10.11-1rodete2 (2024-10-16)
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 23.2.1
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : None
gcsfs                 : 2025.2.0
jinja2                : None
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : 0.27.0
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : 2.0.38
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-02-18 21:08:43+00:00,2025-02-18 21:50:40+00:00,,0.029131944444444443
60958,ENH: Support `pa.json_` in arrow extension type,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
$ import pandas as pd
$ import pyarrow as pa
$ pd.api.types.pandas_dtype(pd.ArrowDtype(pa.json_(pa.string()))).type

---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In[2], line 4
      1 import pandas as pd
      2 import pyarrow as pa
----> 4 pd.api.types.pandas_dtype(pd.ArrowDtype(pa.json_(pa.string()))).type

File ~/src/bigframes/venv/lib/python3.12/site-packages/pandas/core/dtypes/dtypes.py:2169, in ArrowDtype.type(self)
   2167 elif isinstance(pa_type, pa.ExtensionType):
   2168     return type(self)(pa_type.storage_type).type
-> 2169 raise NotImplementedError(pa_type)

NotImplementedError: extension<arrow.json>
```

### Issue Description

Apache Arrow v19.0 introduced the `pa.json_` extension type ([doc](https://arrow.apache.org/docs/format/CanonicalExtensions.html#json)). Currently, pandas.ArrowDtype.type does not correctly handle this new type.

The `ArrowDtype.type` method is crucial for various pandas dtype APIs, including `pd.api.types.pandas_dtype()` and `pd.api.types.is_timedelta64_dtype()`. When used with `pd.ArrowDtype(pa.json_(pa.string()))`, these APIs produce unexpected results.

The issue is that the pandas `ArrowDtype.type` method should return the underlying storage type of the arrow json type.



### Expected Behavior

`pa.json_` is a standard Arrow extension type. `ArrowDtype.type` should accurately return its storage type, mirroring the behavior of other Arrow extension types.
Specifically, `pd.ArrowDtype(pa.json_(pa.string())).type` should reflect the storage type, which is `pa.string()` as shown below.

Codes to show arrow storage type for `pa.json_`:
```python
$ import pyarrow as pa
$ pa.json_(pa.string()).storage_type
DataType(string)
```

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.1
python-bits           : 64
OS                    : Linux
OS-release            : 6.10.11-1rodete2-amd64
Version               : #1 SMP PREEMPT_DYNAMIC Debian 6.10.11-1rodete2 (2024-10-16)
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 23.2.1
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : None
gcsfs                 : 2025.2.0
jinja2                : None
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : 0.27.0
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : 2.0.38
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Enhancement', 'Arrow']","{'login': 'asharmalik19', 'id': 58248342, 'node_id': 'MDQ6VXNlcjU4MjQ4MzQy', 'avatar_url': 'https://avatars.githubusercontent.com/u/58248342?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/asharmalik19', 'html_url': 'https://github.com/asharmalik19', 'followers_url': 'https://api.github.com/users/asharmalik19/followers', 'following_url': 'https://api.github.com/users/asharmalik19/following{/other_user}', 'gists_url': 'https://api.github.com/users/asharmalik19/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/asharmalik19/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/asharmalik19/subscriptions', 'organizations_url': 'https://api.github.com/users/asharmalik19/orgs', 'repos_url': 'https://api.github.com/users/asharmalik19/repos', 'events_url': 'https://api.github.com/users/asharmalik19/events{/privacy}', 'received_events_url': 'https://api.github.com/users/asharmalik19/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-18 20:47:40+00:00,2025-03-12 23:51:31+00:00,asharmalik19,22.12767361111111
60957,check if datetime is compared with arrowExtensionArray and convert ri‚Ä¶,"‚Ä¶ght side to datetime

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-02-18 19:38:29+00:00,2025-02-19 01:31:02+00:00,,0.24482638888888889
60956,BUG: df.to_sql with append setting doesn't respect previous table deletions within the same transaction,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
from sqlalchemy import create_engine

engine = create_engine("""")

with engine.begin() as connection:
    # Delete the table if it exists
    connection.execute(text(f""DROP TABLE IF EXISTS schema.table""))
    df = pd.DataFrame([{""test1"": 5}])
    # Write the DataFrame to the database
    df.to_sql(name=""table"", con=connection, if_exists=""append"", schema=""schema"", index=False, chunksize=5000)
```

### Issue Description

using sqlalchemy 2.0.38
using pandas 2.2.3

In the above example, i get the following error:

(psycopg2.errors.UndefinedColumn) column ""test1"" of relation ""jobs_PDA"" does not exist
LINE 1: INSERT INTO workflow_stage.""jobs_PDA"" (test1) VALUES (5)

### Expected Behavior

Usually, df.to_sql with if_exists='append' will create a new table if one doesn't already exist.  Since I am deleting the table in my transaction before i run df.to_sql, i expect the transaction to be commited with scheam.table being deleted, then recreated with column 'test1' int, and then populated with a single row {test1:5}.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.5
python-bits           : 64
OS                    : Darwin
OS-release            : 24.2.0
Version               : Darwin Kernel Version 24.2.0: Fri Dec  6 18:56:34 PST 2024; root:xnu-11215.61.5~2/RELEASE_ARM64_T6020
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.12.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.38
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-02-18 19:09:05+00:00,2025-02-18 22:57:14+00:00,,0.1584375
60955,REF: Use more conditional nogil & const memoryviews,,['Internals'],,2025-02-18 17:45:39+00:00,2025-02-18 19:36:11+00:00,,0.07675925925925926
60954,BUG: Segmentation Fault when changing a column name in a DataFrame,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import re
import uuid
import numpy as np
import pandas as pd

## Generate example DataFrame
t = pd.date_range(start='2023-01-01 00:00', periods=10, freq='10min')
x = np.random.randn(t.size)
y = np.random.randn(t.size)
df = pd.DataFrame({
    'Timestamp': t,
    'X position (m)': x,
    'Y position (m)': y,
    'Temperature (degC)': temp,
})
df = pd.concat([
    pd.DataFrame(
        [dict(
            zip(list(df.columns),
            ['SignalId'] + [str(uuid.uuid4()) for i in range(df.columns.size - 1)]
        ))]
    ),
    df], ignore_index=True
)
df = df.set_index('Timestamp')

## Change column name inplace
for i, c in enumerate(list(df.columns)):
    newc = re.sub(r'\s+position\s+', ' ', c)
    df.columns.values[i] = newc

## Printing DataFrame to screen may generate a segmentation fault
df
```

### Issue Description

When a column name from a DataFrame is changed inplace (at the values), sometimes it leads to a *segmentation fault*. This seems more likely if the DataFrame contains mixed element types (as per example below).

Hypotheses are:
- The change in the name leads to corruption of the data in memory.
- NumPy version >2 leads to different data types that may conflict somehow with some operations.

Example:

```python
>>> import re
>>> import uuid
>>> import numpy as np
>>> import pandas as pd
>>> 
>>> t = pd.date_range(start='2023-01-01 00:00', periods=10, freq='10min')
>>> x = np.random.randn(t.size)
>>> y = np.random.randn(t.size)
>>> temp = np.random.randn(t.size)
>>> df = pd.DataFrame({
...     'Timestamp': t,
...     'X position (m)': x,
...     'Y position (m)': y,
...     'Temperature (degC)': temp,
... })
>>> df = pd.concat([
...     pd.DataFrame(
...         [dict(
...             zip(list(df.columns),
...             ['SignalId'] + [str(uuid.uuid4()) for i in range(df.columns.size - 1)]
...         ))]
...     ),
...     df], ignore_index=True
... )
>>> df = df.set_index('Timestamp')
>>> 
>>> df
                                           X position (m)                        Y position (m)                    Temperature (degC)
Timestamp                                                                                                                            
SignalId             da8a0a1b-a022-48cc-9e17-91b4b103cc5b  e92dad78-6128-45d5-8545-b45e80345da9  3106111b-0f53-4122-a89f-e1f78aac72b9
2023-01-01 00:00:00                               1.66612                              0.503874                             -0.202982
2023-01-01 00:10:00                             -1.266542                              0.141686                              0.488124
2023-01-01 00:20:00                              -0.46789                             -0.132084                             -1.011771
2023-01-01 00:30:00                              1.276952                             -0.811061                             -1.735414
2023-01-01 00:40:00                              1.178987                             -0.245169                              1.295712
2023-01-01 00:50:00                             -1.503673                               0.60517                             -0.946938
2023-01-01 01:00:00                             -1.095622                             -0.920928                             -0.233186
2023-01-01 01:10:00                             -1.276511                              0.710022                               1.94653
2023-01-01 01:20:00                             -0.470105                             -0.643144                              1.380882
2023-01-01 01:30:00                              1.426826                             -0.286228                              1.351435
>>> for i, c in enumerate(list(df.columns)):
...     newc = re.sub(r'\s+position\s+', ' ', c)
...     df.columns.values[i] = newc
... 
>>> df
Segmentation fault (core dumped)
```

### Expected Behavior

Though the operation may be debatable (the change inplace of the column name via `df.column.values[i] = new_name`), it is a valid operation without any other warning or error message. The ensuing segmentation fault is completely random (so very hard to diagnose).

Hence the expected behaviour is to either block these operations, or alternatively to fully allow those if these are to be permitted.

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.11
python-bits           : 64
OS                    : Linux
OS-release            : 4.19.0-27-amd64
Version               : #1 SMP Debian 4.19.316-1 (2024-06-25)
machine               : x86_64
processor             :
byteorder             : little
LC_ALL                : en_US.UTF-8
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.0.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 24.0
Cython                : None
sphinx                : None
IPython               : 8.18.1
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.13.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : 2024.7.0
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None
</details>
","['Docs', 'Index']","{'login': 'Manju080', 'id': 84699147, 'node_id': 'MDQ6VXNlcjg0Njk5MTQ3', 'avatar_url': 'https://avatars.githubusercontent.com/u/84699147?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Manju080', 'html_url': 'https://github.com/Manju080', 'followers_url': 'https://api.github.com/users/Manju080/followers', 'following_url': 'https://api.github.com/users/Manju080/following{/other_user}', 'gists_url': 'https://api.github.com/users/Manju080/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Manju080/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Manju080/subscriptions', 'organizations_url': 'https://api.github.com/users/Manju080/orgs', 'repos_url': 'https://api.github.com/users/Manju080/repos', 'events_url': 'https://api.github.com/users/Manju080/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Manju080/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-18 10:07:42+00:00,2025-03-11 16:49:36+00:00,Manju080,21.279097222222223
60953,"ENH: updated str_is_numeric(), allows floats","- [X] closes #60750 
- [X] Tests added and passed
- [X] All code checks passed
- [X] Added type annotations to new arguments/methods/functions.
- [X] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-02-18 01:08:33+00:00,2025-02-21 01:14:04+00:00,,3.0038310185185186
60952,Bug: Fix convert_dtypes not preserving timezone details for ArrowDtype,"- [x] closes #60237
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Dtype Conversions'],,2025-02-18 00:09:09+00:00,2025-02-18 20:35:58+00:00,,0.8519560185185185
60951,DOC: Correct a typo: Gitlens -> GitLens,"Correct a typo: Gitlens -> GitLens

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-17 21:40:58+00:00,2025-02-18 17:08:43+00:00,,0.8109375
60950,Bug fix contribution,"- [ ] closes #60766 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-02-17 19:11:44+00:00,2025-03-10 17:34:08+00:00,,20.932222222222222
60949,Fix error `value_counts` result with pyarrow categorical columns,"- [x] closes #60563 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
","['Categorical', 'Arrow']",,2025-02-17 17:05:00+00:00,2025-02-19 17:13:49+00:00,,2.006122685185185
60948,[backport 2.3.x] API: ignore empty range/object dtype in Index setop operations (string dtype compat) (#60797),"(cherry picked from commit ee06e714fcb35e0b6d321b3edd454eb0e363e5e4)

Backport of https://github.com/pandas-dev/pandas/pull/60797",[],,2025-02-17 09:37:37+00:00,2025-06-12 14:04:12+00:00,,115.18512731481482
60947,BUILD: Trouble installing pandas on Windows,"### Installation check

- [x] I have read the [installation guide](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#installing-pandas).


### Platform

Ger√§t PRN konnte nicht initialisiert werden.

### Installation Method

pip install

### pandas Version

2.2.3

### Python Version

3.11.9

### Installation Logs

Hello everyone,
I am currently trying to install asreview from Uni Utrecht, but there accurs a problem which seems to be related to pandas installation.
As I tried installing pandas the same error occurs. See below:
The installation is to be executed right from Windows command line.
<details>

pip install pandas
Defaulting to user installation because normal site-packages is not writeable
Collecting pandas
  Using cached pandas-2.2.3.tar.gz (4.4 MB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Installing backend dependencies ... done
  Preparing metadata (pyproject.toml) ... error
  error: subprocess-exited-with-error

  √ó Preparing metadata (pyproject.toml) did not run successfully.
  ‚îÇ exit code: 1
  ‚ï∞‚îÄ> [12 lines of output]
      + meson setup C:\*********\AppData\Local\Temp\pip-install-zbkfzy9s\pandas_2ad6fccfe0c843c78cc606c094498a41 C:\*******\AppData\Local\Temp\pip-install-zbkfzy9s\pandas_2ad6fccfe0c843c78cc606c094498a41\.mesonpy-yu7welhd\build -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=C:\********\AppData\Local\Temp\pip-install-zbkfzy9s\pandas_2ad6fccfe0c843c78cc606c094498a41\.mesonpy-yu7welhd\build\meson-python-native-file.ini
      The Meson build system
      Version: 1.2.1
      Source dir: C:\*********\AppData\Local\Temp\pip-install-zbkfzy9s\pandas_2ad6fccfe0c843c78cc606c094498a41
      Build dir: C:\*********\AppData\Local\Temp\pip-install-zbkfzy9s\pandas_2ad6fccfe0c843c78cc606c094498a41\.mesonpy-yu7welhd\build
      Build type: native build
      Project name: pandas
      Project version: 2.2.3

      ..\..\meson.build:2:0: ERROR: Could not parse vswhere.exe output

      A full log can be found at C:\********\AppData\Local\Temp\pip-install-zbkfzy9s\pandas_2ad6fccfe0c843c78cc606c094498a41\.mesonpy-yu7welhd\build\meson-logs\meson-log.txt
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

√ó Encountered error while generating package metadata.
‚ï∞‚îÄ> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.

</details>

I hope I gathered all infromation you need and to help me.
","['Build', 'Needs Info']",,2025-02-17 07:16:59+00:00,2025-08-05 17:06:18+00:00,,169.4092476851852
60946,ENH: Add HalfYear offsets,"- [ ] closes #60928
- [ ] closes #22362
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Frequency'],,2025-02-17 02:25:03+00:00,2025-03-03 18:21:16+00:00,,14.664039351851851
60945,My feature branch to issue #19129  (read_json and orient='table' With Numeric Column),"- [x] closes #[19129 ](https://github.com/pandas-dev/pandas/issues/19129)
- [x] [Tests added and passed
- [x] All [code checks passed
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

### New Behavior

The following code will now raise a `ValueError` with the message: 

#### Example:
```python
import pandas as pd

# Create DataFrame with numeric column names
df = pd.DataFrame([[1, 2, 3, 4]], columns=[5, 6, 7, 8])

# Attempt to serialize to JSON with 'table' orient
df.to_json('test.json', orient='table')


ValueError: Column names must be strings for JSON serialization with orient='table'.
```

Note : This is my first attempt at contributions. So, I would like to point out that there might be flaws and would appreciate any feedback.","['IO JSON', 'Stale']",,2025-02-16 22:44:42+00:00,2025-06-30 18:26:07+00:00,,133.82042824074074
60944,BUG: Fix MultiIndex from_tuples on tuples with NaNs,"- [x] closes #60695 
       closes #60988 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Bug', 'MultiIndex']",,2025-02-16 18:17:02+00:00,2025-03-07 23:51:45+00:00,,19.23244212962963
60943,BUG(string dtype): Resolve pytables xfail when reading with condition,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Continuation of #60663; the whatsnew added there covers this too.
","['IO HDF5', 'Strings']",,2025-02-16 17:42:38+00:00,2025-02-18 01:31:01+00:00,,1.3252662037037037
60942,"BUG: pd.Series.rename(..., inplace=True) returns a pd.Series and not nont","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
In [1]: import pandas as pd

In [2]: pd.Series([1, 2, 3])
Out[2]:
0    1
1    2
2    3
dtype: int64

In [3]: pd.Series([1, 2, 3]).rename('A')
Out[3]:
0    1
1    2
2    3
Name: A, dtype: int64

In [4]: pd.Series([1, 2, 3]).rename('A', inplace=True). # should return None
Out[4]:
0    1
1    2
2    3
Name: A, dtype: int64
```

### Issue Description

According to the [documation](https://pandas.pydata.org/docs/dev/reference/api/pandas.Series.rename.html), inplace operations should return None and only modify the object in place without doing a deepcopy.
However when running the rename operation on `pd.Series` with `inplace=True` the type of the returns is `pd.Series` and not None.
This seems to originate from quick look up in the `_set_name` operations that return and object no matter the value of `inplace` (cf https://github.com/pandas-dev/pandas/blob/6bcd30397d67c3887288c7a82c2c235ce8bc3c7f/pandas/core/series.py#L1835-L1850).
And then the `rename` operation only returns the result of `_set_name` without distinguishing the `inplace` value.

### Expected Behavior

The docs suggest that the return of the `rename(..., inplace=True)` should be None.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.1
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:06 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T8103
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.1.3
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : 8.29.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : 3.9.2
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.3
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Docs', 'good first issue', 'rename', 'inplace']",,2025-02-16 15:42:49+00:00,2025-02-22 01:12:31+00:00,,5.395625
60941,BUG: Fixed assign failure when with Copy-on-Write,"- [x] closes #60309 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v2.3.0.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-02-16 14:48:22+00:00,2025-04-02 16:18:26+00:00,,45.0625462962963
60940,ENH: Add dtype argument to str.decode,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Ref: https://github.com/pandas-dev/pandas/pull/60795#discussion_r1947937837

PyArrow-backed strings cannot handle surrogates. When users have `infer_string=True` and PyArrow installed, they can end up with a failure they can't workaround when calling `str.decode`. Adding the dtype argument allows for a workaround.","['Enhancement', 'Strings']",,2025-02-16 12:55:33+00:00,2025-02-18 17:39:50+00:00,,2.1974189814814813
60939,DOC: Add security note for Excel export with formula cells,"- [ ] closes #29095
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-02-16 09:59:15+00:00,2025-03-10 17:34:52+00:00,,22.316400462962964
60938,ENH(string dtype): Implement cumsum for Python-backed strings,Follow-up on https://github.com/pandas-dev/pandas/pull/60633,['Strings'],,2025-02-15 23:06:45+00:00,2025-02-19 02:35:42+00:00,,3.1451041666666666
60936,BUG(string dtype): Empty sum produces incorrect result,"- [x] closes #60229 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Groupby', 'Missing-data', 'Strings']",,2025-02-15 14:11:50+00:00,2025-03-10 16:06:53+00:00,,23.07989583333333
60935,Update base.py(fix for issue #60908),"The use of np.where allows for a more efficient and clear assignment of values. It checks the condition (old_codes == -1) and assigns -1 for those positions while filling in new_lev_codes for valid indices. This approach minimizes the chances of mismatched lengths and ensures that the new codes array is constructed correctly.


",[],,2025-02-15 12:43:19+00:00,2025-02-16 09:13:45+00:00,,0.8544675925925926
60934,fix for #60695 fix Series constructor dropping key levels when keys have varying entry counts,"Ensures that the Series constructor preserves all key (index) levels, even when keys have different numbers of entries.
Addresses issue #60695 by maintaining consistency in index handling.
",[],,2025-02-15 11:41:39+00:00,2025-03-10 17:35:12+00:00,,23.245520833333334
60932,DOC: Correct typos in developer guide for consistency,"Correct typos in developer guide for consistency

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-14 02:21:04+00:00,2025-02-14 18:19:50+00:00,,0.6658101851851852
60931,DOC: Update two more links in pandas Ecosystem,"Update two more links in pandas Ecosystem.

1. In the table schema specification of IO, the dataprotocols.org domain has moved to datapackage.org:
https://datapackage.org/standard/table-schema/ 

2. Removed the "">"" at the end of a Lux link to make it work:
https://lux-api.readthedocs.io/en/latest/source/guide/vis.html

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-14 01:41:01+00:00,2025-02-14 01:55:05+00:00,,0.009768518518518518
60930,Backport PR #60929 on branch 2.3.x (TST: Update numpy version check for test_pandas_dtype_numpy_warning),Backport PR #60929: TST: Update numpy version check for test_pandas_dtype_numpy_warning,"['Testing', 'Dependencies']",,2025-02-14 01:11:26+00:00,2025-02-14 01:54:27+00:00,,0.029872685185185186
60929,TST: Update numpy version check for test_pandas_dtype_numpy_warning,"xref https://github.com/pandas-dev/pandas/pull/60875

I guess I incorrectly assumed that this would be removed in 2.2.3.","['Testing', 'Dependencies']",,2025-02-13 22:57:47+00:00,2025-02-14 01:10:57+00:00,,0.09247685185185185
60928,ENH: Control resampling at halfyear with origin,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
s1 = pd.Series(1, pd.date_range('2025', freq='D', periods=700)).resample('2QS-JAN').sum()
s2 = pd.Series(1, pd.date_range('2025-04', freq='D', periods=700)).resample('2QS-JAN').sum()

# s1 expectedly has timestamps in january and july
# s1
# 2025-01-01    181
# 2025-07-01    184
# 2026-01-01    181
# 2026-07-01    154
# Freq: 2QS-JAN, dtype: int64    # NB frequency

# but s2 unexpectedly has timestamps in april and october
# s2
# 2025-04-01    183
# 2025-10-01    182
# 2026-04-01    183
# 2026-10-01    152
# Freq: 2QS-JAN, dtype: int64    # NB frequency

s1.index.freq == s2.index.freq   # True
```

### Issue Description

It seems there is no way to force where the period boundaries are when resampling at the 2-Quarter frequency. Resampling at `2QS-APR` gives the same results for `s1` and `s2` as those shown above.

### Expected Behavior

I'd expect the index of `s2` to also have timestamps on the first of January and July.

### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.10.12
python-bits           : 64
OS                    : Linux
OS-release            : 6.9.3-76060903-generic
Version               : #202405300957~1738770968~22.04~d5f7c84 SMP PREEMPT_DYNAMIC Wed F
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : 7.3.7
IPython               : 8.29.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.9.2
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.3
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None
</details>
","['Enhancement', 'Frequency', 'Resample']","{'login': 'snitish', 'id': 7503884, 'node_id': 'MDQ6VXNlcjc1MDM4ODQ=', 'avatar_url': 'https://avatars.githubusercontent.com/u/7503884?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/snitish', 'html_url': 'https://github.com/snitish', 'followers_url': 'https://api.github.com/users/snitish/followers', 'following_url': 'https://api.github.com/users/snitish/following{/other_user}', 'gists_url': 'https://api.github.com/users/snitish/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/snitish/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/snitish/subscriptions', 'organizations_url': 'https://api.github.com/users/snitish/orgs', 'repos_url': 'https://api.github.com/users/snitish/repos', 'events_url': 'https://api.github.com/users/snitish/events{/privacy}', 'received_events_url': 'https://api.github.com/users/snitish/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-13 22:52:27+00:00,2025-03-03 18:21:17+00:00,snitish,17.811689814814816
60927,BUG: Unable to round-trip nested arrow extension types with `pa.Table.to_pandas`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pyarrow as pa
import cudf
import pandas as pd

In [19]: data = [{""text"": ""hello"", ""list_col"": np.asarray([1, 2], dtype=""uint32"")}]

In [20]: df = cudf.DataFrame(data)

In [21]: arrow_types_pdf = df.to_pandas(arrow_type=True)

In [22]: arrow_types_pdf
Out[22]: 
    text list_col
0  hello    [1 2]

In [23]: arrow_types_pdf.dtypes
Out[23]: 
text                    string[pyarrow]
list_col    list<item: uint32>[pyarrow]
dtype: object

In [24]: pa_table = pa.Table.from_pandas(arrow_types_pdf)

In [25]: pa_table
Out[25]: 
pyarrow.Table
text: string
list_col: list<item: uint32>
  child 0, item: uint32
----
text: [[""hello""]]
list_col: [[[1,2]]]

In [26]: pa_table.to_pandas()
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[26], line 1
----> 1 pa_table.to_pandas()

File /datasets/pgali/envs/cudfdev/lib/python3.12/site-packages/pyarrow/array.pxi:887, in pyarrow.lib._PandasConvertible.to_pandas()

File /datasets/pgali/envs/cudfdev/lib/python3.12/site-packages/pyarrow/table.pxi:5132, in pyarrow.lib.Table._to_pandas()

File /datasets/pgali/envs/cudfdev/lib/python3.12/site-packages/pyarrow/pandas_compat.py:783, in table_to_dataframe(options, table, categories, ignore_metadata, types_mapper)
    780     table = _add_any_metadata(table, pandas_metadata)
    781     table, index = _reconstruct_index(table, index_descriptors,
    782                                       all_columns, types_mapper)
--> 783     ext_columns_dtypes = _get_extension_dtypes(
    784         table, all_columns, types_mapper)
    785 else:
    786     index = _pandas_api.pd.RangeIndex(table.num_rows)

File /datasets/pgali/envs/cudfdev/lib/python3.12/site-packages/pyarrow/pandas_compat.py:862, in _get_extension_dtypes(table, columns_metadata, types_mapper)
    857 dtype = col_meta['numpy_type']
    859 if dtype not in _pandas_supported_numpy_types:
    860     # pandas_dtype is expensive, so avoid doing this for types
    861     # that are certainly numpy dtypes
--> 862     pandas_dtype = _pandas_api.pandas_dtype(dtype)
    863     if isinstance(pandas_dtype, _pandas_api.extension_dtype):
    864         if hasattr(pandas_dtype, ""__from_arrow__""):

File /datasets/pgali/envs/cudfdev/lib/python3.12/site-packages/pyarrow/pandas-shim.pxi:148, in pyarrow.lib._PandasAPIShim.pandas_dtype()

File /datasets/pgali/envs/cudfdev/lib/python3.12/site-packages/pyarrow/pandas-shim.pxi:151, in pyarrow.lib._PandasAPIShim.pandas_dtype()

File /datasets/pgali/envs/cudfdev/lib/python3.12/site-packages/pandas/core/dtypes/common.py:1645, in pandas_dtype(dtype)
   1640     with warnings.catch_warnings():
   1641         # GH#51523 - Series.astype(np.integer) doesn't show
   1642         # numpy deprecation warning of np.integer
   1643         # Hence enabling DeprecationWarning
   1644         warnings.simplefilter(""always"", DeprecationWarning)
-> 1645         npdtype = np.dtype(dtype)
   1646 except SyntaxError as err:
   1647     # np.dtype uses `eval` which can raise SyntaxError
   1648     raise TypeError(f""data type '{dtype}' not understood"") from err

TypeError: data type 'list<item: uint32>[pyarrow]' not understood

In [27]: pa_table.to_pandas(ignore_metadata=True)
Out[27]: 
    text list_col
0  hello   [1, 2]
```

### Issue Description

It looks like `pa.Table.to_pandas` is not yet compatible with arrow extension types that pandas supports and the conversion back fails in `pandas_dtype` API.

### Expected Behavior

Round-trip the dataframe without errors.

### Installed Versions

<details>

In [28]: pd.show_versions()

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.8
python-bits           : 64
OS                    : Linux
OS-release            : 5.4.0-182-generic
Version               : #202-Ubuntu SMP Fri Apr 26 12:29:36 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.0.2
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : 3.0.12
sphinx                : 8.1.3
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : 6.125.1
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : None
numba                 : 0.60.0
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 18.1.0
pyreadstat            : None
pytest                : 7.4.4
python-calamine       : None
pyxlsb                : None
s3fs                  : 2025.2.0
scipy                 : 1.15.1
sqlalchemy            : 2.0.38
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Closing Candidate', 'Arrow']",,2025-02-13 21:24:29+00:00,2025-02-13 22:24:15+00:00,,0.04150462962962963
60926,DOC: add series.info to api reference,"This was added in https://github.com/pandas-dev/pandas/pull/37320#pullrequestreview-819720418 but probably forgotten from the api reference?

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-13 19:53:15+00:00,2025-02-13 22:28:32+00:00,,0.10783564814814815
60924,docs: clarify `None` case behavior for `sheet_name` in `pandas.read_excel`,"- [x] closes #60909  (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-13 09:22:58+00:00,2025-02-13 17:41:26+00:00,,0.3461574074074074
60922,BUG: `pd.concat` with a slightly nontrivial join on a `DatetimeIndex` with anything other than `ns` resolution gives arbitrarily wrong results,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

idx = pd.date_range(""2025-01-29 01:36"",periods=4,freq=""1 min"",unit=""us"")
ab = pd.DataFrame(index=idx,data=dict(a=[1,2,3,4],b=[2,2,2,2]))
cd = pd.DataFrame(index=idx[:3],data=dict(c=[9,8,7],d=[6,6,6]))

abcd = pd.concat([ab,cd],axis=""columns"")
print(abcd)
assert abcd.shape[0] == 4
```

### Issue Description

The above example attempts to concatenate a 4-row `DataFrame` with a 3-row `DataFrame` by joining on the index;
the first three index values match exactly. The expected result is a 4-row `DataFrame` as follows, that you can obtain with `unit=""ns""`:
```
                     a  b    c    d
2025-01-29 01:36:00  1  2  9.0  6.0
2025-01-29 01:37:00  2  2  8.0  6.0
2025-01-29 01:38:00  3  2  7.0  6.0
2025-01-29 01:39:00  4  2  NaN  NaN
```
Instead, with `unit=""us""` the result is a 2-row `DataFrame`, where the first row is correct, and the second row is completely made up from outer space:
```
                       a    b    c    d
2025-01-29 01:36:00  1.0  2.0  9.0  6.0
2025-01-29 18:16:00  NaN  NaN  NaN  NaN
```
With `unit=""s""`, the result is similarly wrong, but with a different made-up row index:
```
                       a    b    c    d
2025-01-29 01:36:00  1.0  2.0  9.0  6.0
3926-05-28 12:16:00  NaN  NaN  NaN  NaN
```

### Expected Behavior

The correct result is returned.

### Installed Versions

I noticed the issue with the following versions: (latest python 3.13.2, latest pandas 2.2.3):
<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.2
python-bits           : 64
OS                    : Darwin
OS-release            : 24.3.0
Version               : Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:16 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_GB.UTF-8
LOCALE                : None.UTF-8

pandas                : 2.2.3
numpy                 : 2.1.3
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : 0.61.0
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : 2025.1.2
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>

I also reproduced on python 3.11 with pandas 2.2.0","['Bug', 'Reshaping', 'Non-Nano']",,2025-02-12 20:58:24+00:00,2025-02-12 21:52:10+00:00,,0.03733796296296296
60921,DOC: Little contrast in documentation accordion cards,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/getting_started/index.html

### Documentation problem

Originally I reported upstream to the pydata-sphinx-theme issue tracker: https://github.com/pydata/pydata-sphinx-theme/issues/2110 

On the pandas Getting started page, https://pandas.pydata.org/docs/getting_started/index.html, I saw following when using dark theme in Firefox 134.0 (64-bit) on Ubuntu:

![Image](https://github.com/user-attachments/assets/945903f7-55f9-4fbb-8698-09a09ad73dab)

I could not really read the text of the spoiler names under Intro to pandas as they are virtually black on black, so¬†I am forced to switch to light mode instead. (Looking at the code what I am looking at seems to be called tutorial accordion cards, but I might be wrong).

The theme developers in the upstream issue noted that the component used seems to be a custom one built by the Pandas team, so reporting this here.

**BUT** as I was in the process of reporting it here the checkbox at the top of the form had asked me to check whether the issue still persists in the _dev_ version of the documentation. Funny thing is that it doesn't. But it became worse. Now instead of the spoiler title being unreadable the spoiler body isn't:


![Image](https://github.com/user-attachments/assets/7ba563bf-40ba-43d8-98a2-c006c618017d)

### Suggested fix for documentation

The component in question or its application should be fixed so that text is readable in both dark and light themes.",['Docs'],,2025-02-12 17:23:20+00:00,2025-02-12 21:44:20+00:00,,0.18125
60919,ENH: Make merge_asof preserve the index,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import datetime as dt

print(pd.__version__)  # 2.2.3

left = pd.DataFrame({
    'left_date': pd.date_range(dt.date(2025, 1, 1), dt.date(2025, 1, 5)),
})

left = left.drop([0, 1])

right = pd.DataFrame({
    'right_date': pd.date_range(dt.date(2025, 1, 1), dt.date(2025, 1, 5)),
    'value': range(5)
})

merged = pd.merge_asof(left, right, left_on='left_date', right_on='right_date')

index_before = left.index.tolist()
index_after = merged.index.tolist()
print(index_before)  # [2, 3, 4] since first two dropped
print(index_after)  # should be [2, 3, 4] but is [0, 1, 2]
```

### Issue Description

merge_asof is has the unexpected side effect of resetting a RangeIndex. If there are gaps in the RangeIndex in the left dataframe ahead of the call, there will be no gaps in the dataframe resulting from the call. 

### Expected Behavior

By default, I would expect the index to be untouched, or at least expect an ignore_index keyword argument to be able to control this behavior. 

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.9
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.19045
machine               : AMD64
processor             : AMD64 Family 25 Model 97 Stepping 2, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : None
LOCALE                : English_United States.1252

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Enhancement', 'Reshaping', 'Needs Discussion', 'Closing Candidate']",,2025-02-12 13:48:41+00:00,2025-08-05 16:53:53+00:00,,174.1286111111111
60918,Add space after inline code and lower-case pandas in ecosystem.md,"- pandas was used in lowercase p all along, so this change was for sake of consistency 
- add missing space; its absence doesn't seem to be breaking anything, but still looks better formatted this way",['Docs'],,2025-02-12 04:08:11+00:00,2025-02-12 17:59:47+00:00,,0.5775
60917,DOC: Update the Numba jit links in window.rst,"Update the Numba jit links in window.rst.

Correct links:
- https://numba.readthedocs.io/en/stable/user/overview.html
- https://numba.readthedocs.io/en/stable/user/jit.html

Related to PR #60877. I did a search on ``https://numba`` in the repo, and I have corrected most links on Numba documentation. 

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-12 04:01:38+00:00,2025-02-12 17:58:58+00:00,,0.5814814814814815
60916,Backport PR #60795: TST(string dtype): Resolve xfails in pytables,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Testing', 'IO HDF5', 'Strings']",,2025-02-11 22:26:44+00:00,2025-02-16 17:39:04+00:00,,4.8002314814814815
60915,DOC: Conbench PoC benchmark is down,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

In the current [benchmark documentation](https://pandas.pydata.org/community/benchmarks.html) we have the following links for viewing the benchmarks:

- Original server: [asv](https://asv-runner.github.io/asv-collection/pandas/)
- OVH server: [asv](https://pandas.pydata.org/benchmarks/asv/) (benchmarks results can also be visualized in this [Conbench PoC](http://57.128.112.95:5000/)

This Cornbench PoC points to http://57.128.112.95:5000/ and it is currently down.

I've found an old link for a project of the same name but the repo have been deleted: https://github.com/DeaMariaLeon/Conbench-PoC

### Documentation problem

A broken link in the documentation

### Suggested fix for documentation

Either find the maintainer (I think it is [Dea Maria](https://github.com/DeaMariaLeon/)) and check how to set it up again or if the address has changed or just remove this link","['Docs', 'Benchmark']","{'login': 'jackbtlr', 'id': 16514207, 'node_id': 'MDQ6VXNlcjE2NTE0MjA3', 'avatar_url': 'https://avatars.githubusercontent.com/u/16514207?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/jackbtlr', 'html_url': 'https://github.com/jackbtlr', 'followers_url': 'https://api.github.com/users/jackbtlr/followers', 'following_url': 'https://api.github.com/users/jackbtlr/following{/other_user}', 'gists_url': 'https://api.github.com/users/jackbtlr/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/jackbtlr/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/jackbtlr/subscriptions', 'organizations_url': 'https://api.github.com/users/jackbtlr/orgs', 'repos_url': 'https://api.github.com/users/jackbtlr/repos', 'events_url': 'https://api.github.com/users/jackbtlr/events{/privacy}', 'received_events_url': 'https://api.github.com/users/jackbtlr/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-11 22:17:08+00:00,2025-04-13 17:58:41+00:00,jackbtlr,60.82052083333333
60914,BUG: Unexpected rounding behaviour,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
print (pd.DataFrame([[-0.025]]).round(2).values)
print (pd.DataFrame([[-0.025001]]).round(2).values)
print (round(-0.025, 2))
print (round(-0.025001, 2))

#output:
#[[-0.02]]
#[[-0.03]]
#-0.03
#-0.03
```

### Issue Description

I would expect all values to be -0.03 but pandas rounds -0.025 to -0.02.  I suspect this is due to [bankers rounding](https://stackoverflow.com/questions/10825926/python-3-x-rounding-behavior), which would be fine, but it also looks like pandas doesn't mimic the native python rounding behaviour, which rounds both to -0.03 - this might trip people up.   

### Expected Behavior

Round -0.025 to -0.03, or if this explicitly avoided as part of your rounding strategy, at least make your strategy match the python round function.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : d9cdd2ee5a58015ef6f4d15c7226110c9aab8140
python                : 3.10.15.final.0
python-bits           : 64
OS                    : Windows
OS-release            : 10
Version               : 10.0.22631
machine               : AMD64
processor             : Intel64 Family 6 Model 186 Stepping 3, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en
LOCALE                : English_United Kingdom.1252

pandas                : 2.2.2
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
setuptools            : 75.1.0
pip                   : 22.3.1
Cython                : None
pytest                : 8.3.4
hypothesis            : None
sphinx                : 7.3.7
blosc                 : None
feather               : None
xlsxwriter            : None
lxml.etree            : None
html5lib              : None
pymysql               : None
psycopg2              : None
jinja2                : 3.1.4
IPython               : 8.27.0
pandas_datareader     : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
bottleneck            : 1.3.7
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
gcsfs                 : None
matplotlib            : 3.9.2
numba                 : None
numexpr               : 2.10.1
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
pyarrow               : None
pyreadstat            : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
zstandard             : None
tzdata                : 2023.3
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Docs', 'Numeric Operations']","{'login': 'palbha', 'id': 20269788, 'node_id': 'MDQ6VXNlcjIwMjY5Nzg4', 'avatar_url': 'https://avatars.githubusercontent.com/u/20269788?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/palbha', 'html_url': 'https://github.com/palbha', 'followers_url': 'https://api.github.com/users/palbha/followers', 'following_url': 'https://api.github.com/users/palbha/following{/other_user}', 'gists_url': 'https://api.github.com/users/palbha/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/palbha/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/palbha/subscriptions', 'organizations_url': 'https://api.github.com/users/palbha/orgs', 'repos_url': 'https://api.github.com/users/palbha/repos', 'events_url': 'https://api.github.com/users/palbha/events{/privacy}', 'received_events_url': 'https://api.github.com/users/palbha/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-11 20:35:37+00:00,2025-02-17 21:25:01+00:00,palbha,6.034305555555555
60913,Roadmap page has numbered-only list when should be a mix of numbered and unnumbered,"[about / roadmap page in the website](https://pandas.pydata.org/about/roadmap.html) shows a numbered list of 17 items and this doesn't seem to be the expected result by looking at the code:

https://github.com/pandas-dev/pandas/blob/05de25381f71657bd425d2c4045d81a46b2d3740/web/pandas/about/roadmap.md?plain=1#L108-L145",['Docs'],"{'login': 'michellesweering', 'id': 30811910, 'node_id': 'MDQ6VXNlcjMwODExOTEw', 'avatar_url': 'https://avatars.githubusercontent.com/u/30811910?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/michellesweering', 'html_url': 'https://github.com/michellesweering', 'followers_url': 'https://api.github.com/users/michellesweering/followers', 'following_url': 'https://api.github.com/users/michellesweering/following{/other_user}', 'gists_url': 'https://api.github.com/users/michellesweering/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/michellesweering/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/michellesweering/subscriptions', 'organizations_url': 'https://api.github.com/users/michellesweering/orgs', 'repos_url': 'https://api.github.com/users/michellesweering/repos', 'events_url': 'https://api.github.com/users/michellesweering/events{/privacy}', 'received_events_url': 'https://api.github.com/users/michellesweering/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-11 19:58:06+00:00,2025-07-22 16:27:35+00:00,michellesweering,160.85380787037036
60912,Uniformize date format in index.html,"- [X] closes #60911 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Web'],,2025-02-11 16:32:32+00:00,2025-02-11 17:08:50+00:00,,0.025208333333333333
60911,Date format different in the same page,"https://github.com/pandas-dev/pandas/blob/02de8140251096386cbefab0186d45af0c3d8ebd/web/pandas/index.html#L124

This date format line is different from other date lines in the same page. While this is %Y-%m-%d, others are ""%b %d, %Y"".",[],,2025-02-11 16:31:51+00:00,2025-02-11 17:08:51+00:00,,0.025694444444444443
60910,pandas.pydata.org is down,After loading for a while I get a cloudflare timeout error.,"['Docs', 'Admin', 'Web']",,2025-02-11 14:52:28+00:00,2025-02-11 17:50:56+00:00,,0.12393518518518519
60909,BUG: pandas.read_excel returns dict type if sheet_name=None,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
df = pd.read_excel(""test_data/test.xlsx"", sheet_name=None)
print(type(df))
```

### Issue Description

Function `pandas.read_excel` when parameter `sheet_name` is set to `None` return dict object apart from `pandas.core.frame.DataFrame`.

### Expected Behavior

It should return DF

### Installed Versions

pandas==2.2.3
","['Docs', 'IO Excel']",,2025-02-11 09:28:31+00:00,2025-02-13 17:41:27+00:00,,2.3423148148148147
60907,ENH: Improved error message and raise new error for small-string NaN ‚Ä¶,"‚Ä¶edge case in HDFStore.append (#60829)

* Add clearer error messages for datatype mismatch in HDFStore.append. Raise ValueError when nan_rep too large for pytable column. Add and modify applicable test code.

* Fix missed tests and correct mistake in error message.

* Remove excess comments. Reverse error type change to avoid api changes. Move nan_rep tests into separate function.

(cherry picked from commit 57340ecd08580f26ee4a976c1f68b2f563c41569)

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Error Reporting', 'IO HDF5']",,2025-02-10 21:53:39+00:00,2025-02-10 22:28:25+00:00,,0.02414351851851852
60906,BUG: Fix bug in DataFrame binary op not respecting fill_value in case‚Ä¶,"‚Ä¶ of MultiIndex columns

- [ ] closes #60903
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

When `fill_value` is not None, we should not reindex the dataframes, as the `_arith_method_with_reindex` method doesn't handle `fill_value`. Instead, we should go via the regular `_flex_arith_method` route as reindexing is no longer necessary when `fill_value` is provided.

Bug introduced in #60538 so not adding to whatsnew.","['Numeric Operations', 'MultiIndex']",,2025-02-10 17:13:22+00:00,2025-02-10 18:23:27+00:00,,0.04866898148148148
60905,DOC: Should `pandas.api.types.is_dtype_equal()` be documented?,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

None:  It's not there!

### Documentation problem

`pandas.api.types.is_dtype_equal()` is not documented, but it is used in `tests/extension/decimal/array.py` which is used as an example `ExtensionArray` implementation

### Suggested fix for documentation

Unsure if we want this in the public API or not, but if so, we ought to fix it.

See https://github.com/pandas-dev/pandas-stubs/pull/1112 for some discussion","['Docs', 'Dtype Conversions']","{'login': 'wheeleha', 'id': 114460106, 'node_id': 'U_kgDOBtKFyg', 'avatar_url': 'https://avatars.githubusercontent.com/u/114460106?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/wheeleha', 'html_url': 'https://github.com/wheeleha', 'followers_url': 'https://api.github.com/users/wheeleha/followers', 'following_url': 'https://api.github.com/users/wheeleha/following{/other_user}', 'gists_url': 'https://api.github.com/users/wheeleha/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/wheeleha/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/wheeleha/subscriptions', 'organizations_url': 'https://api.github.com/users/wheeleha/orgs', 'repos_url': 'https://api.github.com/users/wheeleha/repos', 'events_url': 'https://api.github.com/users/wheeleha/events{/privacy}', 'received_events_url': 'https://api.github.com/users/wheeleha/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-10 16:57:57+00:00,2025-05-03 20:00:54+00:00,wheeleha,82.1270486111111
60904,DOC: fix ES01 for pandas.api.types.infer_dtype,"fixes

```
pandas.api.types.infer_dtype ES01
```",['Docs'],,2025-02-10 09:30:34+00:00,2025-02-10 18:18:55+00:00,,0.36690972222222223
60903,BUG: Adding DataFrames with misaligned MultiIndex produces NaN despite fill_value=0,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# Create two DataFrames with MultiIndex
index1 = pd.MultiIndex.from_tuples([('A', 'one'), ('A', 'two')])
index2 = pd.MultiIndex.from_tuples([('B', 'one'), ('B', 'two')])

df1 = pd.DataFrame([[1, 2]], columns=index1)
df2 = pd.DataFrame([[3, 4]], columns=index2)

# Adding DataFrames with different MultiIndex
result = df1.add(df2, fill_value=0)
print(result)
```

### Issue Description

I have two data frames with unaligned multi-indices. When adding the two data frames, with fill_value=0, I'd expect the missing values to be replaced with zero before performing the addition operation, as described in the documentation of `DataFrame.add`. However, the above example produces this output:

```
    A       B    
  one two one two
0 NaN NaN NaN NaN
```

The problem affects the current main branch (tested with commit https://github.com/pandas-dev/pandas/commit/e557039fda7d4325184cf76520892b3a635ec2dd). No released version is affected (yet). The behavior was introduced by https://github.com/pandas-dev/pandas/pull/60538. Before this PR, the code was producing the expected output.

### Expected Behavior

I'd expect this output:

```
A B
one two one two
0 1.0 2.0 3.0 4.0
```


### Installed Versions

<details>
INSTALLED VERSIONS
------------------
commit                : 72fd708761f1598f1a8ce9b693529b81fd8ca252
python                : 3.10.8
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.0-130-generic
Version               : #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 3.0.0.dev0+1839.g72fd708761
numpy                 : 1.26.4
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : 3.0.11
sphinx                : 8.1.3
IPython               : 8.30.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : 1.4.2
fastparquet           : 2024.11.0
fsspec                : 2024.10.0
html5lib              : 1.1
hypothesis            : 6.122.4
gcsfs                 : 2024.10.0
jinja2                : 3.1.4
lxml.etree            : 5.3.0
matplotlib            : 3.10.0
numba                 : 0.60.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
psycopg2              : 2.9.10
pymysql               : 1.4.6
pyarrow               : 18.1.0
pyreadstat            : 1.2.8
pytest                : 8.3.4
python-calamine       : None
pytz                  : 2024.2
pyxlsb                : 1.0.10
s3fs                  : 2024.10.0
scipy                 : 1.14.1
sqlalchemy            : 2.0.36
tables                : 3.10.1
tabulate              : 0.9.0
xarray                : 2024.9.0
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : 0.23.0
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None
</details>
","['Bug', 'Indexing', 'Numeric Operations', 'MultiIndex']","{'login': 'snitish', 'id': 7503884, 'node_id': 'MDQ6VXNlcjc1MDM4ODQ=', 'avatar_url': 'https://avatars.githubusercontent.com/u/7503884?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/snitish', 'html_url': 'https://github.com/snitish', 'followers_url': 'https://api.github.com/users/snitish/followers', 'following_url': 'https://api.github.com/users/snitish/following{/other_user}', 'gists_url': 'https://api.github.com/users/snitish/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/snitish/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/snitish/subscriptions', 'organizations_url': 'https://api.github.com/users/snitish/orgs', 'repos_url': 'https://api.github.com/users/snitish/repos', 'events_url': 'https://api.github.com/users/snitish/events{/privacy}', 'received_events_url': 'https://api.github.com/users/snitish/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-10 09:23:10+00:00,2025-02-10 18:23:28+00:00,snitish,0.3752083333333333
60902,DOC: fix ES01 for pandas.CategoricalDtype,"fixes

```
pandas.CategoricalDtype ES01
```",['Docs'],,2025-02-10 08:28:36+00:00,2025-02-10 18:19:31+00:00,,0.4103587962962963
60901,ENH: Add an iterdicts() function,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

I wish I could iterate through dictionaries of each row's contents in a DataFrame, the same way I could do so with namedtuples through itertuples(). Performing the `namedtuple`-to-`dict` conversion process isn't difficult normally, but in some situation (e.g. doing so in a list/set/dict comprehension), it's more convenient to have a generator that does the process automatically for you.

### Feature Description

Add a new function to DataFrames, `iterdicts`, that takes an `index` argument (equivalent to the same argument in `itertuples`) and returns each row as a dictionary the same way itertuples does so as a namedtuple. (No need to take a ""name"" argument, since that's irrelevant for dictionaries.)
```python
def iterdicts(self, index=True):
    for x in self.itertuples(index):
        yield x._asdict()
```

### Alternative Solutions

Write a custom function that does the same thing externally.
```python
def iterdicts(df, index=True):
    for x in df.itertuples(index):
        yield x._asdict()
```

EDIT (4/4/25): Alternatively, use `map` and an anonymous function to create the generator.

```python
map(lambda x: x._asdict(), df.itertuples())
```

### Additional Context

_No response_","['Enhancement', 'Needs Triage', 'Closing Candidate']",,2025-02-09 18:09:41+00:00,2025-08-05 16:22:26+00:00,,176.92552083333334
60900,DOC: fix ES01 for pandas.read_json,"fixes

```
pandas.read_json ES01
```",['Docs'],,2025-02-09 17:06:07+00:00,2025-02-10 18:20:58+00:00,,1.0519791666666667
60899,DOC: fix ES01 for pandas.HDFStore.put,"fixes

```
pandas.HDFStore.put ES01
```",['Docs'],,2025-02-09 17:01:26+00:00,2025-02-10 18:21:39+00:00,,1.0557060185185185
60898,Bug cov nat,"- closes #53115 
","['Datetime', 'Missing-data']",,2025-02-09 15:33:27+00:00,2025-05-23 17:25:26+00:00,,103.0777662037037
60897,BUG: Memory leak when creating a df inside a loop,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
import tracemalloc
import numpy as np
import time
import gc

# Start memory tracking
tracemalloc.start()

iteration = 0

Row_Number = 20000

while iteration < 1000:
    
    test_lst = [*range(12)]
    
    for i in range(12):
        
        # Create a DataFrame with X amount of rows
        df = pd.DataFrame({
            ""A"": np.arange(Row_Number),  # Sequential Row_Numbers from 0 to 999999
            ""B"": np.random.rand(Row_Number),  # Random floats between 0 and 1
            ""C"": np.random.randint(0, 100, size=Row_Number),  # Random integers between 0 and 99
            ""D"": np.random.choice([""apple"", ""banana"", ""cherry""], size=Row_Number),  # Random categories
            ""E"": np.random.randn(Row_Number)  # Normally distributed random Row_Numbers
        })

        test_lst[i] = df # The bug also appears without appending to list

        del df # Deleting df at the end of loop doesnt affect memory leak
  
    del test_lst # Deleting list at the end of loop doesnt affect memory leak
        
    time.sleep(0.01)
    
    iteration += 1

    # Check memory usage for 3rd party packages
    if iteration % 1 == 0:
    
        snapshot = tracemalloc.take_snapshot()
        
        # Get memory statistics **without filtering** first
        top_stats = snapshot.statistics(""lineno"")
        
        print(f""\n[ Memory Snapshot at iteration {iteration} ]"")
        for stat in top_stats[:5]:  # Show top memory-consuming locations
            print(stat)
```

### Issue Description

By using tracemalloc (a tool to track memory usage in loops), I can see that pandas doesnt release memory when creating dfs inside a loop. The problem seems to come from pandas\core\internals\blocks around line 228. Would be nice if anyone could find a fix to this.

### Expected Behavior

That the memory doesnt leak

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.1
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.22631
machine               : AMD64
processor             : Intel64 Family 6 Model 186 Stepping 2, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en
LOCALE                : Norwegian Bokm√•l_Norway.1252

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : None
sphinx                : 8.1.3
IPython               : 8.31.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 19.0.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : 2.4.2
pyqt5                 : None

</details>
","['Bug', 'Performance', 'Windows', 'Constructors', 'Closing Candidate']",,2025-02-09 12:21:56+00:00,2025-08-05 16:52:48+00:00,,177.18810185185185
60896,fix: incorrect ISO week 53 conversion when only 52 weeks exist,"- [x] closes #60885 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Datetime'],,2025-02-09 08:59:34+00:00,2025-02-12 18:20:27+00:00,,3.389502314814815
60894,BUG: Prevent pd.Series.groupby from showing FutureWarning,"- [X] closes #60831
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [X] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

## Linked Issue
- Future warning observed when series.groupby is called where its name is an integer. The warning seems to stem from `is_in_obj()` defined in `get_grouper()` ; Below indexing results in the warning since `gpr.name` is integer type. For example :

```python
>>>import pandas as pd
>>>arr = [['a', 'a', 'b', 'b'], ['aa', 'bb', 'aa', 'bb']]
>>>idx = pd.MultiIndex.from_arrays(arr, names=['index1', 'index2'])
>>>ser = pd.Series([10, 20, 30, 40], index=idx, name=2)
>>>ser

index1  index2
a       aa        10
        bb        20
b       aa        30
        bb        40
Name: 2, dtype: int64

>>>ser.groupby(ser)
FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`

```

## Proposed Code Change
- Since `pd.Series` doesn't have columns, added type check so that `is_in_obj()` is called only when `obj` is a `DataFrame`.

```python
    for gpr, level in zip(keys, levels):
        if isinstance(obj, DataFrame) and is_in_obj(gpr):  # df.groupby(df['name'])
            in_axis = True
            exclusions.add(gpr.name)
```

Please let me know if there are any changes needed. Thanks!","['Bug', 'Groupby', 'Warnings']",,2025-02-09 06:25:37+00:00,2025-02-12 02:28:08+00:00,,2.8350810185185185
60893,DOC: fix ES01 for pandas.io.formats.style.Styler,"fixes

```
pandas.io.formats.style.Styler ES01
```",['Docs'],,2025-02-09 03:57:28+00:00,2025-02-10 18:22:12+00:00,,1.6005092592592594
60892,DOC: fix ES01 for pandas.DataFrame.sparse,"fixes

```
pandas.DataFrame.sparse ES01
```",['Docs'],,2025-02-09 03:49:38+00:00,2025-02-10 18:20:14+00:00,,1.6045833333333333
60891,DOC: fix ES01 for pandas.DataFrame.set_flags and pandas.Series.set_flags,"fixes

```
pandas.DataFrame.set_flags  ES01
pandas.Series.set_flags ES01
```",['Docs'],,2025-02-09 03:42:38+00:00,2025-02-10 18:17:36+00:00,,1.6076157407407408
60890,DOC: fix ES01 for pandas.Period,"fixes

```
pandas.Period ES01
```",['Docs'],,2025-02-08 17:03:35+00:00,2025-02-08 18:56:12+00:00,,0.07820601851851852
60889,DOC: fix ES01 for pandas.array,"fixes

```
pandas.array ES01
```",['Docs'],,2025-02-08 16:43:39+00:00,2025-02-08 18:55:30+00:00,,0.0915625
60888,DOC: fix ES01 for pandas.DataFrame.shape,"fixes
```
pandas.DataFrame.shape ES01
```",['Docs'],,2025-02-08 16:07:22+00:00,2025-02-08 18:54:53+00:00,,0.11633101851851851
60887,DOC: fix ES01 for pandas.option_context,"fixes

```
pandas.option_context ES01
```",['Docs'],,2025-02-08 15:57:21+00:00,2025-02-08 18:54:14+00:00,,0.12283564814814815
60886,DOC: should `DateOffset` always be used instead of `BaseOffset`?,"There's currently 4 pages in the docs which mention BaseOffset:
- https://pandas.pydata.org/docs/reference/api/pandas.Period.asfreq.html
- https://pandas.pydata.org/docs/reference/api/pandas.Period.now.html
- https://pandas.pydata.org/docs/reference/api/pandas.tseries.frequencies.to_offset.html

However, `BaseOffset` isn't user-facing

Should they just be replaced with `DateOffset`?

This is also relevant for `pandas-stubs` which uses `BaseOffset` in a few places

@jbrockmendel is this ok to do?

Based on 

https://github.com/pandas-dev/pandas/blob/0c4ca3a9e4baa9b4fa8cbc81c57f2e2996636c10/pandas/_libs/tslibs/offsets.pyx#L1620-L1632

they should be interchangeable?","['Docs', 'Typing']",,2025-02-08 14:27:28+00:00,2025-03-24 16:41:46+00:00,,44.09326388888889
60885,BUG: pandas to_datetime() returns incorrect isoweek conversion in week 53 when only 52 weeks exist,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
pd.to_datetime(""2024-53-1"", format=""%G-%V-%u"")
```

### Issue Description

When using python [format codes](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes) to resolve an isoweek notation (_""%G-%V-%u""_) back to an iso date, to_datetime() incorrectly works with non-existing weeks. In the example below the third call should not return a valid date, as no week 53 exists in the isoclander year 2024 (the first lines are non-isoclandar, the last line is the first week in isocalendar 2025, which are all correct).

![Image](https://github.com/user-attachments/assets/8a50f2d0-3b41-42ce-96f4-edcc50bda818)

This behavior can be seen in others years with 52 isoweeks as well, e.g. pd.to_datetime(""2023-53-1"", format=""%G-%V-%u"") also returns the date of the first isoweek of 2024.

The python standard library correctly raises an error when the same thing is tried:

![Image](https://github.com/user-attachments/assets/f26a9c3e-370d-420c-9db8-96d75cf5d573)


### Expected Behavior

Raise an error for misformatted date string.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.6
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.26100
machine               : AMD64
processor             : AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
byteorder             : little
LC_ALL                : None
LANG                  : en
LOCALE                : English_Germany.1252

pandas                : 2.2.3
numpy                 : 2.1.2
pytz                  : 2024.1
dateutil              : 2.9.0
pip                   : 24.2
Cython                : None
sphinx                : 8.0.2
IPython               : 8.28.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : 1.1
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : 3.9.2
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 18.1.0
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : None
tables                : None
tabulate              : 0.9.0
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2024.2
qtpy                  : 2.4.1
pyqt5                 : None

</details>
","['Bug', 'datetime.date']",,2025-02-08 14:09:01+00:00,2025-02-12 18:20:28+00:00,,4.174618055555555
60884,DOC: fix a few typos in the User Guide,Fixed a few typos in the User Guide.,['Docs'],,2025-02-08 09:00:24+00:00,2025-02-08 18:58:48+00:00,,0.41555555555555557
60883,Fix crosstab(aggfunc='skew') bug,"Fix `IndexError` in `crosstab` with `aggfunc=‚Äòskew‚Äô`.

* Check if table is empty before accessing last row in `_normalize` function in `pandas/core/reshape/pivot.py`.
* Skip normalization and return empty table if it is.
* Add test case in `pandas/tests/reshape/test_crosstab.py` for `aggfunc=‚Äòskew‚Äô`.
* Ensure test case doesn‚Äôt raise `IndexError`.

",[],,2025-02-08 06:18:33+00:00,2025-03-10 17:36:09+00:00,,30.470555555555556
60882,BUG: Don't ignore errors when casting dtype in Series constructor,"- [ ] closes #60728
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

In the constructor for `Series`, when the input data is another `Series` with a different `dtype` than the one specified in the constructor, the dtype conversion currently doesn't throw errors and silently sets the wrong dtype.
```
>>> example = pd.Series(
...     pd.Series([pd.NaT], dtype=""datetime64[ns]""), dtype=""timedelta64[ns]""
... )
>>> print(example.dtype)
datetime64[ns]
```
",['Dtype Conversions'],,2025-02-08 03:01:52+00:00,2025-02-08 19:00:13+00:00,,0.6655208333333333
60881,BUG: Unhandled Rust panic when processing sheets with missing formatting data,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
1. Make an excel document using Microsoft Excel. Rename the document's extension to .zip from .xlsx and extract the data as a zip file. The file contents will be extracted in a new directory. Make a modification to the xl/styles.xml file to remove the name attribute from any instance of the cellStyles tag, so it looks something like this:

<cellStyles count=""1""><cellStyle xfId=""0"" builtinId=""0"" /></cellStyles></styleSheet>

2. Select all the files within the directory and zip them back up, renaming the output zip file to .xlsx

3. Attempt to load the file as an ExcelFile object in pandas using the following code:

try:
	e = pd.ExcelFile($YOUR_FILE_NAME, engine=""openpyxl"")
except Exception as exc: 
	print(exc)
	try:
		e = pd.ExcelFile($YOUR_FILE_NAME, engine=""openpyxl"")
	except Exception as ex:
		print(ex)

You should get something like:

-traceback
Traceback (most recent call last):
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/platform_flow_common/tasks/flows/preliminary/excel.py"", line 367, in create_data_frame_sheet_file_object
    excel = pd.ExcelFile(path_or_buffer=excel_file, engine=pandas_engine)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_base.py"", line 1567, in __init__
    self._reader = self._engines[engine](
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py"", line 553, in __init__
    super().__init__(
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_base.py"", line 573, in __init__
    self.book = self.load_workbook(self.handles.handle, engine_kwargs)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py"", line 572, in load_workbook
    return load_workbook(
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/reader/excel.py"", line 346, in load_workbook
    reader.read()
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/reader/excel.py"", line 299, in read
    apply_stylesheet(self.archive, self.wb)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py"", line 198, in apply_stylesheet
    stylesheet = Stylesheet.from_tree(node)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py"", line 103, in from_tree
    return super(Stylesheet, cls).from_tree(node)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py"", line 87, in from_tree
    obj = desc.expected_type.from_tree(el)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py"", line 87, in from_tree
    obj = desc.expected_type.from_tree(el)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py"", line 103, in from_tree
    return cls(**attrib)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/styles/named_styles.py"", line 229, in __init__
    self.name = name
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/base.py"", line 46, in __set__
    raise TypeError(msg)
TypeError: <class 'openpyxl.styles.named_styles._NamedCellStyle'>.name should be <class 'str'> but value is <class 'NoneType'>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/platform_flow_common/tasks/flows/preliminary/excel.py"", line 371, in create_data_frame_sheet_file_object
    excel = pd.ExcelFile(path_or_buffer=excel_file)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_base.py"", line 1567, in __init__
    self._reader = self._engines[engine](
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py"", line 553, in __init__
    super().__init__(
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_base.py"", line 573, in __init__
    self.book = self.load_workbook(self.handles.handle, engine_kwargs)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py"", line 572, in load_workbook
    return load_workbook(
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/reader/excel.py"", line 346, in load_workbook
    reader.read()
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/reader/excel.py"", line 299, in read
    apply_stylesheet(self.archive, self.wb)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py"", line 198, in apply_stylesheet
    stylesheet = Stylesheet.from_tree(node)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py"", line 103, in from_tree
    return super(Stylesheet, cls).from_tree(node)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py"", line 87, in from_tree
    obj = desc.expected_type.from_tree(el)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py"", line 87, in from_tree
    obj = desc.expected_type.from_tree(el)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py"", line 103, in from_tree
    return cls(**attrib)
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/styles/named_styles.py"", line 229, in __init__
    self.name = name
  File ""/Users/username/.local/share/virtualenvs/platform-excel-flow-v1_0-xHjD71YU/lib/python3.9/site-packages/openpyxl/descriptors/base.py"", line 46, in __set__
    raise TypeError(msg)
TypeError: <class 'openpyxl.styles.named_styles._NamedCellStyle'>.name should be <class 'str'> but value is <class 'NoneType'>

And then you get:

PanicException: index out of bounds: the len is 0 but the index is 0
```

### Issue Description

My company processes excel files, and we often encounter errors in the way a file is constructed. We raise specific errors in cases when the file is encrypted, when the file cannot be opened, when there are formatting errors, etc. so we can notify other team members or clients that something is wrong with their data source. I observed a Rust panic which is not caught when using pandas-calamine engine to load an excel sheet that has structural formatting errors. This is a concern because it doesn't appear there's any way to handle the exception in Python, and thus we cannot surface the right kind of error.

Not sure if this belongs as an issue on pandas or on pyO3 since the rust bindings are managed through that library...

### Expected Behavior

I would expect a different kind of exception to be raised, one native to the Python environment. It doesn't matter what.

### Installed Versions

<details>

>>> pd.show_versions()

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.9.16
python-bits           : 64
OS                    : Darwin
OS-release            : 22.6.0
Version               : Darwin Kernel Version 22.6.0: Wed Jul  5 22:22:05 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6000
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.0.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 24.0
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.13.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2025.2.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : 5.3.0
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : 3.1.0
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : 1.0.10
s3fs                  : None
scipy                 : None
sqlalchemy            : 2.0.38
tables                : None
tabulate              : None
xarray                : None
xlrd                  : 2.0.1
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Needs Triage']",,2025-02-07 23:53:42+00:00,2025-02-08 01:11:19+00:00,,0.05390046296296296
60880,Backport PR #60847 on branch 2.3.x (TST/CI: skipif numba tests on Ubuntu ARM for numba 0.61),Backport of #60847,"['Testing', 'numba']",,2025-02-07 23:37:28+00:00,2025-02-08 01:08:13+00:00,,0.06302083333333333
60878,Backport PR #60875 on branch 2.3.x (TST/CI: Address enforced numpy DeprecationWarning in test_pandas_dtype_numpy_warning),Backport PR #60875: TST/CI: Address enforced numpy DeprecationWarning in test_pandas_dtype_numpy_warning,['Testing'],,2025-02-07 20:25:31+00:00,2025-02-07 23:25:26+00:00,,0.12494212962962963
60877,DOC: Update the Numba troubleshooting URL,"DOC: Update the Numba troubleshooting URL.

Correct link:
https://numba.readthedocs.io/en/stable/user/troubleshoot.html

The old link does not work:
https://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#the-compiled-code-is-too-slow

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-07 19:42:46+00:00,2025-02-07 19:50:03+00:00,,0.0050578703703703706
60876,Backport PR #60873: TST/CI: xfail test_frame_setitem_dask_array_into_new_col for numpy>2.1,Manual backport of https://github.com/pandas-dev/pandas/pull/60873#issuecomment-2643779671,['Testing'],,2025-02-07 19:18:48+00:00,2025-02-07 19:50:50+00:00,,0.02224537037037037
60875,TST/CI: Address enforced numpy DeprecationWarning in test_pandas_dtype_numpy_warning,"e.g.

```bash
=================================== FAILURES ===================================
_______________________ test_pandas_dtype_numpy_warning ________________________
[gw1] linux -- Python 3.11.11 /home/runner/micromamba/envs/test/bin/python3.11

    def test_pandas_dtype_numpy_warning():
        # GH#51523
        with tm.assert_produces_warning(
            DeprecationWarning,
            check_stacklevel=False,
            match=""Converting `np.integer` or `np.signedinteger` to a dtype is deprecated"",
        ):
>           pandas_dtype(np.integer)

pandas/tests/dtypes/test_common.py:796: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dtype = <class 'numpy.integer'>

    def pandas_dtype(dtype) -> DtypeObj:
        """"""
        Convert input into a pandas only dtype object or a numpy dtype object.
    
        Parameters
        ----------
        dtype : object
            The object to be converted into a dtype.
    
        Returns
        -------
        np.dtype or a pandas dtype
            The converted dtype, which can be either a numpy dtype or a pandas dtype.
    
        Raises
        ------
        TypeError if not a dtype
    
        See Also
        --------
        api.types.is_dtype : Return true if the condition is satisfied for the arr_or_dtype.
    
        Examples
        --------
        >>> pd.api.types.pandas_dtype(int)
        dtype('int64')
        """"""
        # short-circuit
        if isinstance(dtype, np.ndarray):
            return dtype.dtype
        elif isinstance(dtype, (np.dtype, ExtensionDtype)):
            return dtype
    
        # builtin aliases
        if dtype is str and using_string_dtype():
            from pandas.core.arrays.string_ import StringDtype
    
            return StringDtype(na_value=np.nan)
    
        # registered extension types
        result = registry.find(dtype)
        if result is not None:
            if isinstance(result, type):
                # GH 31356, GH 54592
                warnings.warn(
                    f""Instantiating {result.__name__} without any arguments.""
                    f""Pass a {result.__name__} instance to silence this warning."",
                    UserWarning,
                    stacklevel=find_stack_level(),
                )
                result = result()
            return result
    
        # try a numpy dtype
        # raise a consistent TypeError if failed
        try:
            with warnings.catch_warnings():
                # GH#51523 - Series.astype(np.integer) doesn't show
                # numpy deprecation warning of np.integer
                # Hence enabling DeprecationWarning
                warnings.simplefilter(""always"", DeprecationWarning)
>               npdtype = np.dtype(dtype)
E               TypeError: Converting 'np.integer' or 'np.signedinteger' to a dtype is not allowed

pandas/core/dtypes/common.py:1843: TypeError

During handling of the above exception, another exception occurred:

    def test_pandas_dtype_numpy_warning():
        # GH#51523
>       with tm.assert_produces_warning(
            DeprecationWarning,
            check_stacklevel=False,
            match=""Converting `np.integer` or `np.signedinteger` to a dtype is deprecated"",
        ):

pandas/tests/dtypes/test_common.py:791: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../micromamba/envs/test/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _assert_caught_expected_warnings(
        *,
        caught_warnings: Sequence[warnings.WarningMessage],
Warning:         expected_warning: type[Warning] | tuple[type[Warning], ...],
        match: str | None,
        check_stacklevel: bool,
    ) -> None:
        """"""Assert that there was the expected warning among the caught warnings.""""""
        saw_warning = False
        matched_message = False
        unmatched_messages = []
        warning_name = (
            tuple(x.__name__ for x in expected_warning)
            if isinstance(expected_warning, tuple)
            else expected_warning.__name__
        )
    
        for actual_warning in caught_warnings:
            if issubclass(actual_warning.category, expected_warning):
                saw_warning = True
    
                if check_stacklevel:
                    _assert_raised_with_correct_stacklevel(actual_warning)
    
                if match is not None:
                    if re.search(match, str(actual_warning.message)):
                        matched_message = True
                    else:
                        unmatched_messages.append(actual_warning.message)
    
        if not saw_warning:
>           raise AssertionError(f""Did not see expected warning of class {warning_name!r}"")
E           AssertionError: Did not see expected warning of class 'DeprecationWarning'

pandas/_testing/_warnings.py:188: AssertionError

```",['Testing'],,2025-02-07 19:05:25+00:00,2025-02-07 20:25:03+00:00,,0.05530092592592593
60874,DOC: Correct a typo in ecosystem.md,"Correct a typo in ecosystem.md.

This is **an** community-maintained list -> This is **a** community-maintained list

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-07 18:44:48+00:00,2025-02-07 18:54:27+00:00,,0.006701388888888889
60873,TST/CI: xfail test_frame_setitem_dask_array_into_new_col for numpy>2.1,"Split from https://github.com/pandas-dev/pandas/pull/60847

Will be fixed in the next Dask release https://github.com/pandas-dev/pandas/pull/60847#issuecomment-2636482009",['Testing'],,2025-02-07 18:37:33+00:00,2025-02-07 19:07:34+00:00,,0.020844907407407406
60871,PERF: Fix groupby skipna performance,"- [ ] closes #60870
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Groupby', 'Performance']",,2025-02-06 23:33:24+00:00,2025-02-10 18:24:53+00:00,,3.7857523148148147
60870,PERF: Regression in groupby ops from adding skipna,"https://github.com/rhshadrach/asv-runner/issues/42

Due to #60752 - cc @snitish","['Groupby', 'Missing-data', 'Performance', 'Regression']",,2025-02-06 21:30:07+00:00,2025-02-10 18:24:55+00:00,,3.8713888888888888
60868,DOC: fix ES01 for pandas.get_option,"fixes

```
pandas.get_option ES01
```",['Docs'],,2025-02-06 18:25:35+00:00,2025-02-07 18:27:02+00:00,,1.0010069444444445
60867,BUG: Fix frozenset display in pprint,"- [x] closes #60690
    - Fixed in #60828 but with a bug
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- ~~[ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
    - Already added by #60828",['Output-Formatting'],,2025-02-06 18:12:46+00:00,2025-02-10 18:25:52+00:00,,4.0090972222222225
60866,DOC: Update the read_csv in action in cookbook.rst,"In cookbook.rst, let's update the read_csv in action to a recently written Datacamp tutorial:
https://www.datacamp.com/tutorial/pandas-read-csv

The old link not only does not work, but also refers to pandas v0.10 (an outdated version).
https://wesmckinney.com/blog/update-on-upcoming-pandas-v0-10-new-file-parser-other-performance-wins/

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-06 18:04:12+00:00,2025-02-06 18:28:49+00:00,,0.017094907407407406
60865,DOC: Correct a typo in pyarrow.rst,"Correct a typo in pyarrow.rst.  
``""int64[pyarrow]""""`` -> Remove the extra double quotation mark at the end.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-06 17:52:28+00:00,2025-02-06 17:53:08+00:00,,0.000462962962962963
60864,Fix Error Message in .query() for DataFrame with Duplicate Column Names,"**Summary of Changes:**

- Enhanced the error messaging in the .query() method for pandas DataFrames when duplicate column names are present.
- Prior to this change, invoking .query() on a DataFrame with duplicate column names resulted in an unclear TypeError, making it difficult for users to understand the root cause.
- With this update, users will now receive a more descriptive and helpful ValueError, similar to when columns are accessed directly, with a message such as:
  `""ValueError: cannot reindex on an axis with duplicate labels""`

**Reasoning Behind the Change:**

- The current behavior of .query() did not offer clear feedback when users attempted to run queries on DataFrames with duplicate column names.
- By improving the error message, we enhance the overall user experience, making it easier for users to diagnose and resolve issues related to duplicate columns.

**Testing Approach:**

- I tested the change by creating a sample DataFrame with duplicate column names and attempted to execute a .query() operation.
- Below is the test case used:
```
import pandas as pd

# Create a DataFrame with duplicate column names
df = pd.DataFrame({
    ""A"": [1, 2, 3, 4, 5],
    ""B"": [10, 8, 6, 4, 2],
    ""A"": [5, 4, 3, 2, 1],  # Duplicate column name ""A""
})

# Test the query functionality
try:
    result = df.query(""A <= 4 and B <= 8"")
    print(result)
except Exception as e:
    print(f""Error: {e}"")
```

- After applying the fix, the code will raise a ValueError, indicating that queries cannot be executed due to duplicate column names, making it much easier to pinpoint the issue.

**Issue Addressed:**
- This PR resolves the issue documented in [#60863](https://github.com/pandas-dev/pandas/issues/60863), where .query() failed to provide a clear error message when used on DataFrames containing duplicate column names.",['Stale'],,2025-02-06 12:54:38+00:00,2025-03-10 17:35:26+00:00,,32.195
60862,Enable get-attr-with-constant (B009),"The original reasoning to disable this rule is because `getattr` is needed to side step `mypy`, but `mypy` doesn't complain about the fix anymore.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Code Style'],,2025-02-06 07:42:09+00:00,2025-02-06 17:15:35+00:00,,0.3982175925925926
60860,Remove unused code,"After https://github.com/pandas-dev/pandas/pull/59296 is merged, the note is no longer relevant and the function `tokenize_backtick_quoted_string` is unused

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Clean'],,2025-02-05 20:53:45+00:00,2025-02-05 21:46:22+00:00,,0.03653935185185185
60859,Use annotations from the standard library,"This is the preferred way to annotate starting from Python 3.9. All changes are auto-fixed by `ruff`

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-02-05 20:02:07+00:00,2025-02-05 20:33:36+00:00,,0.021863425925925925
60858,Disallow empty comment,"Look like the intent of the empty comments in some places is to create a visual block of code, but this is done fairly rarely, compared to just use a new line, so I think it's reasonable to enable this rule to avoid code clutter or empty comments as the result of some massy search and replace.

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Code Style'],,2025-02-05 18:59:04+00:00,2025-02-05 19:32:52+00:00,,0.02347222222222222
60857,[backport 2.3.x] TST(string_dtype): Refine scope of string xfail in test_http_headers (#60811),"(cherry picked from commit c430c613e6c712a39d07146b8adb083d55943840)

Backport of https://github.com/pandas-dev/pandas/pull/60811",[],,2025-02-05 08:29:03+00:00,2025-02-05 10:56:02+00:00,,0.10207175925925926
60856,"[backport 2.3.x] TST (string): from_dummies, dropna (#60818)","(cherry picked from commit ea7ff0ea4606f47a672f75793f4ea2b3eb0b87f5)

Backport of https://github.com/pandas-dev/pandas/pull/60818",['Strings'],,2025-02-05 08:24:33+00:00,2025-02-05 17:38:29+00:00,,0.3846759259259259
60855,DOC: fix ES01 for pandas.DataFrame.select_dtypes,"fixes

```
pandas.DataFrame.select_dtypes ES01
```",['Docs'],,2025-02-05 08:04:31+00:00,2025-02-05 17:40:43+00:00,,0.4001388888888889
60854,DOC: fix ES01 for pandas.Interval.is_empty,"fixes

```
pandas.Interval.is_empty ES01
pandas.IntervalIndex.is_empty ES01
pandas.arrays.IntervalArray.is_empty ES01
```",['Docs'],,2025-02-05 07:30:30+00:00,2025-02-05 17:42:35+00:00,,0.42505787037037035
60853,DOC: fix ES01 for pandas.Period.day,"fixes

```
pandas.Period.day ES01
```",['Docs'],,2025-02-05 07:20:41+00:00,2025-02-05 17:43:05+00:00,,0.43222222222222223
60852,DOC: fix ES01 for pandas.plotting.table,"fixes

```
pandas.plotting.table ES01
```",['Docs'],,2025-02-05 07:12:50+00:00,2025-02-05 17:42:00+00:00,,0.4369212962962963
60851,DOC: fix ES01 for pandas.read_orc,"fixes

```
pandas.read_orc ES01
```",['Docs'],,2025-02-05 07:04:37+00:00,2025-02-05 17:41:22+00:00,,0.4421875
60850,BUG: Avoid casting to float for datetimelike in min/max reductions,"- [ ] closes #60646
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.
",['Dtype Conversions'],,2025-02-05 06:14:00+00:00,2025-02-05 17:46:47+00:00,,0.48109953703703706
60849,DOC: Update a link in cookbook.rst,"In the pandas Cookbook, the Time Series - Aggregation and plotting time series has an invalid link:
https://nipunbatra.github.io/blog/visualisation/2013/05/01/aggregation-timeseries.html

This link should be:
https://nipunbatra.github.io/blog/posts/2013-05-01-aggregation-timeseries.html

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-05 02:01:38+00:00,2025-02-05 02:48:30+00:00,,0.032546296296296295
60848,TST: Remove test_pickle_generalurl_read in favor of test_request_headers,"`test_pickle_generalurl_read` appears redundant with `pandas/tests/io/test_http_headers.py::test_request_headers` where the latter uses the `httpserver` fixture and doesn't attempt to patch `urllib.request.urlopen`.

I was seeing `test_pickle_generalurl_read` being particularly slow in the cudf test suite, but best to remove this test as it's redundant.","['Testing', 'IO Network']",,2025-02-04 22:02:18+00:00,2025-02-05 17:43:53+00:00,,0.8205439814814814
60847,TST/CI: skipif numba tests on Ubuntu ARM for numba 0.61,"cc @phofl could use help looking into the failure in `test_frame_setitem_dask_array_into_new_col`

https://github.com/pandas-dev/pandas/actions/runs/13127760620/job/36627207210","['Testing', 'numba']",,2025-02-04 18:13:47+00:00,2025-02-07 23:32:39+00:00,,3.221435185185185
60846,DOC: Update Bodo project description in ecosystem page,"- [x] closes #60845 (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-04 15:47:32+00:00,2025-02-04 17:55:17+00:00,,0.08871527777777778
60845,DOC: Update Bodo project description in ecosystem page,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/community/ecosystem.html#out-of-core

### Documentation problem

Bodo is now open source so the description is out of date.

### Suggested fix for documentation

Bodo description needs to be updated. Submitting a PR.","['Docs', 'Needs Triage']",,2025-02-04 15:46:25+00:00,2025-02-04 17:55:18+00:00,,0.08950231481481481
60844,DOC: Closed parameter not intuitively documented in DataFrame.rolling,"- [x] closes #60485
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Window']",,2025-02-04 01:58:47+00:00,2025-02-08 12:52:14+00:00,,4.453784722222222
60843,TST: parametrize Decimal ujson test,,"['Testing', 'IO JSON']",,2025-02-03 21:40:48+00:00,2025-02-03 22:22:19+00:00,,0.02883101851851852
60842,DOC: Fix description of skipna parameter in groupby reductions,Fixing some issues in descriptions of the `skipna` parameter in groupby reductions (identified while working on #60752),['Docs'],,2025-02-03 20:06:09+00:00,2025-02-03 22:07:49+00:00,,0.08449074074074074
60841,CLN: Unnecessary while loops,Where `while` loops can be calculated without looping or better described by a for loop,['Clean'],,2025-02-03 18:21:36+00:00,2025-02-03 20:27:15+00:00,,0.08725694444444444
60840,[pre-commit.ci] pre-commit autoupdate,"<!--pre-commit.ci start-->
updates:
- [github.com/astral-sh/ruff-pre-commit: v0.8.6 ‚Üí v0.9.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.8.6...v0.9.4)
- [github.com/codespell-project/codespell: v2.3.0 ‚Üí v2.4.1](https://github.com/codespell-project/codespell/compare/v2.3.0...v2.4.1)
- [github.com/PyCQA/isort: 5.13.2 ‚Üí 6.0.0](https://github.com/PyCQA/isort/compare/5.13.2...6.0.0)
- [github.com/pre-commit/mirrors-clang-format: v19.1.6 ‚Üí v19.1.7](https://github.com/pre-commit/mirrors-clang-format/compare/v19.1.6...v19.1.7)
- [github.com/trim21/pre-commit-mirror-meson: v1.6.1 ‚Üí v1.7.0](https://github.com/trim21/pre-commit-mirror-meson/compare/v1.6.1...v1.7.0)
<!--pre-commit.ci end-->",['Code Style'],,2025-02-03 16:31:41+00:00,2025-02-03 19:20:08+00:00,,0.11697916666666666
60839,DOC: Update parameter descriptions in `cut` function for clarity,"- [ ] closes #51992 
",['Docs'],,2025-02-03 13:41:21+00:00,2025-02-03 17:51:31+00:00,,0.17372685185185185
60838,BUG: Unknown Error - Getting from Databricks SQL Python - From PyArrow module (pyarrow.lib.ArrowException),"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
arr = arr.to_numpy(zero_copy_only=False)
```

### Issue Description

**Description:**
Hi there,

I'm getting this behaviour from databricks sql connectors due to it's dependency of Pandas. Though of posting it here to get any idea to fix it. B'coz I'm getting the exception when I try to convert the data with utf-8 encoded string to numpy array in pandas and py-arrow. Also Just curious to know is there any specific version of pandas or py-arrow that I can use to fix this issue. Any help would be appreciated here!

**Versions:**
Python: 3.11.9
Databricks SQL Connector: 3.3.0


**Code:**
Below is the code I'm using to fetch data from databricks which has some utf-8 encoded char (ÔøΩ) in the data.

``` 
sql_query = f"""""" SELECT Column FROM table LIMIT 10 """"""

host = os.getenv(""DATABRICKS_HOST"")
http_path = os.getenv(""DATABRICKS_HTTP_PATH"")

connection = sql.connect(server_hostname=host, http_path=http_path)
with conn.cursor() as cursor:
        cursor.execute(sql_query)
        response = fetchmany(cursor)

```

**Error:**

  ```
response = fetchmany(cursor)
               ^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/my_agent/app_helper/db_helper.py"", line 35, in fetchmany
    query_results = cursor.fetchmany(fetch_size)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/my_agent_connectors/dq_databricks/dependencies/databricks/sql/client.py"", line 976, in fetchmany
    return self.active_result_set.fetchmany(size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/my_agent_connectors/dq_databricks/dependencies/databricks/sql/client.py"", line 1235, in fetchmany
    return self._convert_arrow_table(self.fetchmany_arrow(size))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/my_agent_connectors/dq_databricks/dependencies/databricks/sql/client.py"", line 1161, in _convert_arrow_table
    df = table_renamed.to_pandas(
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""pyarrow/array.pxi"", line 884, in pyarrow.lib._PandasConvertible.to_pandas
  File ""pyarrow/table.pxi"", line 4192, in pyarrow.lib.Table._to_pandas
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/pyarrow/pandas_compat.py"", line 776, in table_to_dataframe
    blocks = _table_to_blocks(options, table, categories, ext_columns_dtypes)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/pyarrow/pandas_compat.py"", line 1131, in _table_to_blocks
    return [_reconstruct_block(item, columns, extension_columns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/pyarrow/pandas_compat.py"", line 1131, in <listcomp>
    return [_reconstruct_block(item, columns, extension_columns)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/pyarrow/pandas_compat.py"", line 736, in _reconstruct_block
    pd_ext_arr = pandas_dtype.__from_arrow__(arr)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/pandas/core/arrays/string_.py"", line 230, in __from_arrow__
    arr = arr.to_numpy(zero_copy_only=False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""pyarrow/array.pxi"", line 1581, in pyarrow.lib.Array.to_numpy
  File ""pyarrow/error.pxi"", line 91, in pyarrow.lib.check_status
pyarrow.lib.ArrowException: Unknown error: Wrapping Ruta 204 ÔøΩ Zapote failed
 ```

### Expected Behavior

It should support and parse the utf-8 encoded characters as well.

### Installed Versions



INSTALLED VERSIONS
------------------
commit           : 8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7
python           : 3.11.9.final.0
python-bits      : 64
OS               : Darwin
OS-release       : 23.6.0
Version          : Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:04 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8122
machine          : x86_64
processor        : i386
byteorder        : little
LC_ALL           : None
LANG             : en_US.UTF-8
LOCALE           : en_US.UTF-8

pandas           : 1.5.2
numpy            : 1.23.4
pytz             : 2022.1
dateutil         : 2.9.0.post0
setuptools       : 65.5.0
pip              : 24.0
Cython           : 3.0.10
pytest           : 7.4.2
hypothesis       : None
sphinx           : None
blosc            : None
feather          : None
xlsxwriter       : None
lxml.etree       : None
html5lib         : None
pymysql          : None
psycopg2         : 2.9.9
jinja2           : 3.1.4
IPython          : None
pandas_datareader: None
bs4              : None
bottleneck       : None
brotli           : None
fastparquet      : None
fsspec           : None
gcsfs            : None
matplotlib       : None
numba            : None
numexpr          : None
odfpy            : None
openpyxl         : 3.1.3
pandas_gbq       : None
pyarrow          : 16.1.0
pyreadstat       : None
pyxlsb           : None
s3fs             : None
scipy            : None
snappy           : None
sqlalchemy       : 1.4.52
tables           : None
tabulate         : None
xarray           : None
xlrd             : None
xlwt             : None
zstandard        : None
","['Bug', 'IO SQL', 'Needs Info', 'Arrow']",,2025-02-03 12:22:09+00:00,2025-08-05 17:04:03+00:00,,183.19576388888888
60837,DOC: fix ES01 for pandas.Series.array,"fixes

```
pandas.Series.array ES01
```",['Docs'],,2025-02-03 07:04:42+00:00,2025-02-03 17:47:10+00:00,,0.4461574074074074
60836,DOC: fix ES01 for pandas.DataFrame.columns,"fixes

```
pandas.DataFrame.columns ES01
```",['Docs'],,2025-02-03 06:42:22+00:00,2025-02-03 17:46:36+00:00,,0.4612731481481481
60835,DOC: fix ES01 for pandas.core.resample.Resampler.indices,"fixes

```
pandas.core.resample.Resampler.indices ES01
```",['Docs'],,2025-02-03 05:36:36+00:00,2025-02-03 17:46:08+00:00,,0.5066203703703703
60834,DOC: fix ES01 for pandas.reset_option,"fixes

```
pandas.reset_option ES01
```",['Docs'],,2025-02-03 05:30:29+00:00,2025-02-03 17:45:34+00:00,,0.510474537037037
60832,DOC: Closed parameter not intuitively documented in DataFrame.rolling ,"- [x] closes #60485 
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Docs', 'Window']",,2025-02-02 20:03:00+00:00,2025-02-03 17:53:02+00:00,,0.9097453703703704
60831,BUG: `pd.Series.groupby` issues `FutureWarning`,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

# Some index that are not integers
index = pd.date_range(start='2000-01-01', periods=3, freq='YS')

# Integer as a name
data = pd.Series([1, 2, 3], index=index, name=2)

data.groupby(data) # FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
```

### Issue Description

The warning comes from this line:
https://github.com/pandas-dev/pandas/blob/0691c5cf90477d3503834d983f69350f250a6ff7/pandas/core/groupby/grouper.py#L1015

Here, `gpr.name` is `2`, which results in the warning. If the index consists of integers, this means `obj[gpr.name]` will actually return the line (which then fails the comparison).


I have not checked on the main branch, but the same line might be present here:
https://github.com/pandas-dev/pandas/blob/d72f165eb327898b1597efe75ff8b54032c3ae7b/pandas/core/groupby/grouper.py#L853

### Expected Behavior

Don't issue `FutureWarning`

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.13.0
python-bits           : 64
OS                    : Windows
OS-release            : 11
Version               : 10.0.22621
machine               : AMD64
processor             : Intel64 Family 6 Model 186 Stepping 3, GenuineIntel
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : English_United Kingdom.1252

pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : 8.32.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : 3.10.0
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : 0.23.0
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Groupby', 'Warnings']","{'login': 'sanggon6107', 'id': 68040183, 'node_id': 'MDQ6VXNlcjY4MDQwMTgz', 'avatar_url': 'https://avatars.githubusercontent.com/u/68040183?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/sanggon6107', 'html_url': 'https://github.com/sanggon6107', 'followers_url': 'https://api.github.com/users/sanggon6107/followers', 'following_url': 'https://api.github.com/users/sanggon6107/following{/other_user}', 'gists_url': 'https://api.github.com/users/sanggon6107/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/sanggon6107/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/sanggon6107/subscriptions', 'organizations_url': 'https://api.github.com/users/sanggon6107/orgs', 'repos_url': 'https://api.github.com/users/sanggon6107/repos', 'events_url': 'https://api.github.com/users/sanggon6107/events{/privacy}', 'received_events_url': 'https://api.github.com/users/sanggon6107/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-02 18:03:53+00:00,2025-02-22 15:38:38+00:00,sanggon6107,19.899131944444445
60830,DOC: `pandas.DataFrame.to_html` additional description for the border parameter ,"- [x] closes #60148  (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-02 15:54:05+00:00,2025-02-04 17:50:49+00:00,,2.0810648148148148
60829,ENH: Improved error message and raise new error for small-string NaN edge case in HDFStore.append,"Updated **pytables.py** to improve error messages caused by datatype mismatches in **HDFStore.append**. Also added **ValueError** for when the NaN representation cannot fit into the column. Modified tests concerning the improved error message and added new test for when column is type string with length <3 and as such **nan_rep** 'nan' is too big.

- [ ] closes #16300
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests)
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).","['Error Reporting', 'IO HDF5']",,2025-02-02 11:31:54+00:00,2025-02-05 17:48:57+00:00,,3.261840277777778
60828,EHN: handle frozenset in pprint,"- [ ] closes #60690 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Output-Formatting'],,2025-02-02 09:54:43+00:00,2025-02-05 17:49:31+00:00,,3.3297222222222222
60827,CHORE: Enable mistakenly ignored tests,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

While working on another issue, I came across this test that is ignored because of the wrong indentation. This PR is to enable it. Please confirm since you are the last author @jbrockmendel 
",['Testing'],,2025-02-02 09:24:52+00:00,2025-02-02 20:12:30+00:00,,0.4497453703703704
60826,BUG: stack with empty level list,"- [ ] closes #60740
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Please instruct of which `whatsnew` to add. As of the time of writing there are 2.3.0 and 3.0.0
",['Reshaping'],,2025-02-02 09:03:06+00:00,2025-02-04 03:27:33+00:00,,1.7669791666666668
60825,DOC: Split up the IO docs,"- [y] closes #10446
- [-] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [y] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [-] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [-] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",[],,2025-02-02 03:54:25+00:00,2025-03-24 16:47:09+00:00,,50.53662037037037
60824,fix for 47734 - df.eval can't concatenate string column and string via +,"- [x] closes #47734
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Stale'],,2025-02-01 16:24:22+00:00,2025-03-19 16:07:56+00:00,,45.98858796296296
60823,"BUG: pd.HDFStore(file, mode='a') increases file size unnecessarily when file exists and dataframe contains string-based columns","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import os
import warnings
import numpy as np
import pandas as pd

warnings.filterwarnings(""ignore"")  # PerformanceWarning

iterations = 10

print(""'w' mode'"")
file = ""w.h5""
for i in range(iterations):
    # Create a large random DataFrame
    df = pd.DataFrame(np.random.rand(1000, 100))
    df = df.assign(label=""hellothere"")

    # Save and reload the DataFrame with 'w' mode
    with pd.HDFStore(file, mode=""w"") as store:
        store.put(""data"", df)

    with pd.HDFStore(file, mode=""r"") as store:
        read_df = store.get(""data"")

    assert df.equals(read_df)

    print(f""'{file}' size: {os.path.getsize(file)}"")

print(""'a' mode'"")
file = ""a.h5""
for i in range(iterations):
    # Create a large random DataFrame
    df = pd.DataFrame(np.random.rand(1000, 100))
    df = df.assign(label=""hellothere"")

    # Save and reload the DataFrame with 'a' mode
    with pd.HDFStore(file, mode=""a"") as store:
        store.put(""data"", df)

    with pd.HDFStore(file, mode=""r"") as store:
        read_df = store.get(""data"")

    assert df.equals(read_df)

    print(f""'{file}' size: {os.path.getsize(file)}"")

print(""'a' mode, only numerical'"")
file = ""a_numerical.h5""
for i in range(iterations):
    # Create a large random DataFrame
    df = pd.DataFrame(np.random.rand(1000, 100))

    # Save and reload the DataFrame with 'a' mode
    with pd.HDFStore(file, mode=""a"") as store:
        store.put(""data"", df)

    with pd.HDFStore(file, mode=""r"") as store:
        read_df = store.get(""data"")

    assert df.equals(read_df)

    print(f""'{file}' size: {os.path.getsize(file)}"")

print(""'a' mode, only strings'"")
file = ""a_strings.h5""
for i in range(iterations):
    # Create a large random DataFrame
    df = pd.DataFrame({""label"": [""hellothere""] * 1000})

    # Save and reload the DataFrame with 'a' mode
    with pd.HDFStore(file, mode=""a"") as store:
        store.put(""data"", df)

    with pd.HDFStore(file, mode=""r"") as store:
        read_df = store.get(""data"")

    assert df.equals(read_df)

    print(f""'{file}' size: {os.path.getsize(file)}"")
```

### Issue Description

When saving dataframes to HDF5 using pd.HDFStore(file, 'a') and the dataframe to be stored contains string data columns, the size of the resulting file will increase if the file already existed even if it should not. This behavior impacts a situation where an existing .h5 file is being updated with more data. This is a **low-priority bug**, since the issue is avoidable in this situation by using the 'w' open mode instead. 

Example output:
```
'w' mode'
'w.h5' size: 3974104
'w.h5' size: 3974104
'w.h5' size: 3974104
'w.h5' size: 3974104
'w.h5' size: 3974104
'a' mode'
'a.h5' size: 3974104
'a.h5' size: 4776152
'a.h5' size: 5578200
'a.h5' size: 6380248
'a.h5' size: 7182296
'a' mode, only numerical'
'a_numerical.h5' size: 815240
'a_numerical.h5' size: 815312
'a_numerical.h5' size: 815312
'a_numerical.h5' size: 815312
'a_numerical.h5' size: 815312
'a' mode, only strings'
'a_strings.h5' size: 1070008
'a_strings.h5' size: 1076152
'a_strings.h5' size: 1080248
'a_strings.h5' size: 1084344
'a_strings.h5' size: 1088440
```

As we can see, as identically-sized data is being written into a.h5 and a_strings.h5, the size of the file increases.

Apologies in advance for not providing a fix, but since the workaround is very easy I didn't want to spend much time digging into it. Also sorry if it's written in documentation somewhere to avoid using the 'a' option. 

### Expected Behavior

Opening an HDFStore in 'a' mode and overwriting keys with dataframes containing string values does not lead to unnecessarily increasing file size.

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.3
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-52-generic
Version               : #53-Ubuntu SMP PREEMPT_DYNAMIC Sat Jan 11 00:06:25 UTC 2025
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8
pandas                : 2.2.3
numpy                 : 2.2.2
pytz                  : 2025.1
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.15.1
sqlalchemy            : None
tables                : 3.10.2
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2025.1
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'IO HDF5']","{'login': 'PedroM4rques', 'id': 155019955, 'node_id': 'U_kgDOCT1qsw', 'avatar_url': 'https://avatars.githubusercontent.com/u/155019955?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/PedroM4rques', 'html_url': 'https://github.com/PedroM4rques', 'followers_url': 'https://api.github.com/users/PedroM4rques/followers', 'following_url': 'https://api.github.com/users/PedroM4rques/following{/other_user}', 'gists_url': 'https://api.github.com/users/PedroM4rques/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/PedroM4rques/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/PedroM4rques/subscriptions', 'organizations_url': 'https://api.github.com/users/PedroM4rques/orgs', 'repos_url': 'https://api.github.com/users/PedroM4rques/repos', 'events_url': 'https://api.github.com/users/PedroM4rques/events{/privacy}', 'received_events_url': 'https://api.github.com/users/PedroM4rques/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-02-01 06:58:06+00:00,2025-03-31 21:17:07+00:00,PedroM4rques,58.59653935185185
60822,DOC: Move NumPy Byte Order page in gotchas.rst,"Move NumPy Byte Order page in `gotchas.rst`.

New link: https://numpy.org/doc/stable/user/byteswapping.html

Old link does not work.
https://numpy.org/doc/stable/user/basics.byteswapping.html

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-02-01 05:17:24+00:00,2025-02-01 19:18:25+00:00,,0.5840393518518519
60821,Backport PR #60709: ENH(string dtype): Make str.decode return str dtype,Backport of #60709,"['Enhancement', 'Strings']",,2025-01-30 21:06:15+00:00,2025-02-05 10:54:49+00:00,,5.575393518518519
60820,test_datetimes.py: fix literal string,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
","['Error Reporting', 'Clean']",,2025-01-30 12:04:06+00:00,2025-03-03 23:11:49+00:00,,32.46369212962963
60818,"TST (string): from_dummies, dropna","- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Lines 3, 5, and 6 in the document Will shared last week.  I think the line 5 one (dropna) would also be solved in a different way by #60797.",['Strings'],,2025-01-30 00:24:11+00:00,2025-01-30 17:31:46+00:00,,0.713599537037037
60817,STY: Enable shellcheck pre-commit hook,"Shellcheck ensures that our shell scripts follow some best practices https://www.shellcheck.net/
",['Code Style'],,2025-01-29 17:59:12+00:00,2025-02-10 18:26:28+00:00,,12.018935185185185
60816,BUG: Union of two DateTimeIndexes is incorrectly calculated,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
from pandas import DatetimeIndex

l = DatetimeIndex(['2023-05-24 00:00:00+00:00', '2023-05-24 00:15:00+00:00',
               '2023-05-24 00:30:00+00:00', '2023-05-24 00:45:00+00:00',
               '2023-05-24 01:00:00+00:00'],
              dtype='datetime64[ms, UTC]', name='ts', freq='15min') 

r = DatetimeIndex(['2023-05-24 00:00:00+00:00', '2023-05-24 00:30:00+00:00',
               '2023-05-24 01:00:00+00:00'],
              dtype='datetime64[ms, UTC]', name='ts', freq='30min') 

union = r.union(l)

print(union)

assert len(union) == len(l)
assert all(r.union(l) == l)
```

### Issue Description

The union of two datetime-indexes as given in the reproducible example is calculated incorrectly, the result on newer Pandas versions is

```python
DatetimeIndex(['2023-05-24 00:00:00+00:00', '2051-11-29 16:00:00+00:00',
               '2080-06-06 08:00:00+00:00'],
              dtype='datetime64[ms, UTC]', name='ts', freq='15T')
```

The first failing version is the one I put into ""Installed Versions"". The error happens exactly from Pandas 2.1.0 onwards, Pandas 1.* and up to 2.0.3 work fine. Neither the numpy nor the Python version matter.

### Expected Behavior

The expected result in the given case is that `l` is returned.

### Installed Versions

INSTALLED VERSIONS
------------------
commit              : ba1cccd19da778f0c3a7d6a885685da16a072870
python              : 3.10.16.final.0
python-bits         : 64
OS                  : Linux
OS-release          : 6.12.10-200.fc41.x86_64
Version             : #1 SMP PREEMPT_DYNAMIC Fri Jan 17 18:05:24 UTC 2025
machine             : x86_64
processor           : 
byteorder           : little
LC_ALL              : None
LANG                : en_US.UTF-8
LOCALE              : en_US.UTF-8

pandas              : 2.1.0
numpy               : 1.26.4
pytz                : 2024.2
dateutil            : 2.9.0.post0
tzdata              : 2025.1
","['Bug', 'Regression', 'Needs Discussion', 'Non-Nano']",,2025-01-29 15:45:23+00:00,2025-06-02 17:24:35+00:00,,124.06888888888889
60815,DOC: Missing documentation for `Styler.columns` and `Styler.index`,"### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/dev/reference/api/pandas.io.formats.style.Styler.html#pandas.io.formats.style.Styler

### Documentation problem

The attributes `columns` and `index` are not documented for the `Styler` class.

### Suggested fix for documentation

Document those attributes.


Initially reported here in `pandas-stubs` : https://github.com/pandas-dev/pandas-stubs/issues/1102","['Docs', 'Styler']","{'login': 'Rishab260', 'id': 90474550, 'node_id': 'MDQ6VXNlcjkwNDc0NTUw', 'avatar_url': 'https://avatars.githubusercontent.com/u/90474550?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/Rishab260', 'html_url': 'https://github.com/Rishab260', 'followers_url': 'https://api.github.com/users/Rishab260/followers', 'following_url': 'https://api.github.com/users/Rishab260/following{/other_user}', 'gists_url': 'https://api.github.com/users/Rishab260/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/Rishab260/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/Rishab260/subscriptions', 'organizations_url': 'https://api.github.com/users/Rishab260/orgs', 'repos_url': 'https://api.github.com/users/Rishab260/repos', 'events_url': 'https://api.github.com/users/Rishab260/events{/privacy}', 'received_events_url': 'https://api.github.com/users/Rishab260/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-01-29 15:25:29+00:00,2025-02-21 18:06:56+00:00,Rishab260,23.112118055555555
60814,FIX BUG: Series constructor from dictionary drops key (index) levels when not all keys have same number of entries #60695,"
This is a simple fix, the keys were dropped from uneven tuples sue to zip behavior so I changed to zip_longest.  I performance tested zip_longest and on equal length tuple pairs it actually outperforms zip - go figure.
Unit test is also added",[],,2025-01-29 14:14:47+00:00,2025-01-29 14:36:45+00:00,,0.01525462962962963
60812,Next Pandas Release Question,"Will there be another patch release any time soon?
I see the last regular release 2.2.3 was in September.

Specifically, I am interested in picking up this bugfix https://github.com/pandas-dev/pandas/issues/60102
Considering if I will have to backport it",[],,2025-01-28 22:58:36+00:00,2025-04-17 09:46:00+00:00,,78.44958333333334
60811,TST(string_dtype): Refine scope of string xfail in test_http_headers,"This xfail should really only affect fastparquet
","['Testing', 'Strings']",,2025-01-28 21:55:53+00:00,2025-01-29 00:17:22+00:00,,0.09825231481481482
60810,BUG: Inconsistent dtype with GroupBy for StrDtype and all missing values,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
>>> df = pd.DataFrame({""a"": [""a""] * 3, ""b"": pd.Series([None] * 3, dtype=pd.StringDtype(na_value=np.nan))})
>>> df
   a    b
0  a  NaN
1  a  NaN
2  a  NaN
>>> df.groupby(""a"").sum()
   b
a   
a  0
>>> df.groupby(""a"").sum().dtypes
b    str
dtype: object
>>> df.groupby(""a"").min()
    b
a    
a NaN
>>> df.groupby(""a"").min().dtypes
b    float64
dtype: object
```

### Issue Description

The sum reduction return type is partially discussed in https://github.com/pandas-dev/pandas/issues/60229 but I didn't see anything for `min` 

Note that this discrepancy is the root cause of the test failure shown at https://github.com/pandas-dev/pandas/blob/dec6eb29b35c884e78c82525e1bb30280208714c/pandas/tests/resample/test_resampler_grouper.py#L465

@rhshadrach 

### Expected Behavior

I think in all cases here we should still be returning a `str` type.

### Installed Versions

'3.0.0.dev0+1824.g8d6d29cac3.dirty'
","['Bug', 'Groupby', 'Strings']","{'login': 'rhshadrach', 'id': 45562402, 'node_id': 'MDQ6VXNlcjQ1NTYyNDAy', 'avatar_url': 'https://avatars.githubusercontent.com/u/45562402?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/rhshadrach', 'html_url': 'https://github.com/rhshadrach', 'followers_url': 'https://api.github.com/users/rhshadrach/followers', 'following_url': 'https://api.github.com/users/rhshadrach/following{/other_user}', 'gists_url': 'https://api.github.com/users/rhshadrach/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/rhshadrach/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/rhshadrach/subscriptions', 'organizations_url': 'https://api.github.com/users/rhshadrach/orgs', 'repos_url': 'https://api.github.com/users/rhshadrach/repos', 'events_url': 'https://api.github.com/users/rhshadrach/events{/privacy}', 'received_events_url': 'https://api.github.com/users/rhshadrach/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-01-28 21:39:07+00:00,2025-04-19 15:22:38+00:00,rhshadrach,80.73855324074074
60808,Backport PR #60796 on branch 2.3.x (BUG: is_*_array returns true on empty object dtype),Backport PR #60796: BUG: is_*_array returns true on empty object dtype,"['Bug', 'Internals']",,2025-01-28 06:59:31+00:00,2025-01-28 18:19:14+00:00,,0.47202546296296294
60807,"DOC: fix PR02,SA01,ES01 for pandas.tseries.offsets.BDay and pandas.tseries.offsets.BusinessDay","fixes

```
pandas.tseries.offsets.BDay PR02,SA01,ES01
pandas.tseries.offsets.BusinessDay PR02,SA01,ES01
```",['Stale'],,2025-01-28 06:55:39+00:00,2025-03-10 17:39:54+00:00,,41.44739583333333
60806,DOC: Expand on different Getitem uses,"This is confusing to my students, so figured it would be helpful to call it out explicitly.

- [ ] ~~closes #xxxx (Replace xxxx with the GitHub issue number)~~
- [ ] [Tests ~~added and~~ passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~~
- [ ] ~~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~~
",['Docs'],,2025-01-28 05:46:53+00:00,2025-05-21 15:57:55+00:00,,113.42432870370371
60805,"DOC: fix PR01,RT03,SA01 for pandas.core.resample.Resampler.transform","fixes

```
pandas.core.resample.Resampler.transform PR01,RT03,SA01
```",['Docs'],,2025-01-28 04:34:08+00:00,2025-01-28 18:11:55+00:00,,0.5679050925925926
60804,BUG: Fix extra decimal places in DataFrame.to_csv() with quoting=csv.QUOTE_NONNUMERIC and float16/float32 dtypes (#60699),"- [ ] closes #60699 
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) 
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file if fixing a bug or adding a new feature.

1. Resolved by converting floats to strings to preserve decimal representation.
2. Removed unnecessary `quoting=None` logic for `float` arrays.
3. Added tests for float16, float32, and float64 cases with mixed values.

## Issue
[`Dataframe.to_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) generates extra decimal places in output when `quoting=csv.QUOTE_NONNUMERIC` , dataframe's `dtype=float16 / float32` and `float_format=None`.

## Reason
- `Dataframe.to_csv()` internally uses ` get_values_for_csv()` and when `quoting` is specified (=`csv.QUOTE_NONNUMERIC`), it converts numpy `float` array to `object`. 

https://github.com/pandas-dev/pandas/blob/57d248978a4168aa73871a62ab79c47dc2977bb0/pandas/core/indexes/base.py#L7751-L7765

### `np.array(values, dtype=""object"")` affects `float16`, `float32` and `float64` differently

- For `float16`, `float32` 
  - Have limited precision, therefore numbers are stored as approximations rather than exact values (8.57 stored internally in memory as 8.5703125)
  - When converted to `object` array, internal binary representation of the float16 values is stored inside Python's float ([equivalent to `numpy.float64`](https://numpy.org/doc/stable/user/basics.types.html#extended-precision)), which can fully display that exact binary representation
  - Therefore, extra decimal places appear in the output for `dtype=float16` and `dtype=float32` when conversion to `dtype=object`

```python
arr = np.array([8.57, 0.156, -0.312, 123.3, -54.5, np.nan], dtype=np.float16)
print(arr)
# [  8.57    0.156  -0.312 123.3   -54.5       nan]

arr_obj = arr.astype(object)
print(arr_obj)
# [8.5703125 0.156005859375 -0.31201171875 123.3125 -54.5 nan]
```

- `float64`
  - Due to 52 bits of precision, `float64` represent most decimal numbers (like 8.57) exactly or with an extremely small error that is practically undetectable when converted to a higher precision or displayed as a Python `float`
  - When you convert `float64` numpy array to `object`,  internal binary representation is directly transferred to the object type and there is no ""extra decimals"" in the output.

```python
arr = np.array([8.57, 0.156, -0.312, 123.3, -54.5, np.nan], dtype=np.float64)
print(arr)
# [  8.57    0.156  -0.312 123.3   -54.5       nan]

arr_obj = arr.astype(object)
print(arr_obj)
# [8.57 0.156 -0.312 123.3 -54.5 nan]
```

## Fix Implemented
To preserve the decimal representation in case of `dtype=float16` and `float32`, we convert numpy float array to strings and then convert them back to [Python's `float` which is nearly equivalent to `numpy.float64`](https://numpy.org/doc/stable/user/basics.types.html#extended-precision)

- Conversion to `str` preserves  decimal representation and prevents exposing the internal binary representation.
- **Conversion to `float` is necessary** to avoid treating float values as string and storing them in 64-bit (double precision) preserves the string representation.

Additionally, in the original code
When `quoting` is `None`, converting first to `str` and then back to `object` is unnecessary work because the replacement of `na_rep` can be done directly on an object array ([na_rep : str](https://github.com/pandas-dev/pandas/blob/57d248978a4168aa73871a62ab79c47dc2977bb0/pandas/core/indexes/base.py#L7699)). 

Therefore, `quoting=None` branch was removed to streamline the logic.

```python
    elif values.dtype.kind == ""f"" and not isinstance(values.dtype, SparseDtype):
        # see GH#13418: no special formatting is desired at the
        # output (important for appropriate 'quoting' behaviour),
        # so do not pass it through the FloatArrayFormatter
        if float_format is None and decimal == ""."":
            mask = isna(values)

            if values.dtype in [np.float16, np.float32]:
                values = np.array(values, dtype=""str"") # preserve decimal representation
                values = values.astype(float, copy=False) # preserve string representation 

            values = values.astype(object, copy=False)
            values[mask] = na_rep
            return values
```

## Testing
Successfully pass all existing test cases in `test_to_csv.py` with tests added for dataframes with `dtype` as `float16`, `float32` and `float64` with mix of negative, positive and missing values and `quoting=csv.QUOTE_NONNUMERIC`

```python
1. {""col"": [8.57, 0.156, -0.312, 123.3, -54.5, np.nan]} and dtype=""float16""

2. {""col"": [8.57, 1.234567, -2.345678, 1e6, -1.5e6, np.nan]} and dtype=""float32""

3. {""col"": [8.57, 3.141592653589793, -2.718281828459045, 1.01e12, -5.67e11, np.nan]} and dtype=""float64""
```",['Stale'],,2025-01-28 01:32:35+00:00,2025-03-03 18:22:19+00:00,,34.701203703703705
60803,BUG: Most recent conda-forge package limited to python 3.9?,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
docker run --rm -it mambaorg/micromamba
micromamba install pandas -c conda-forge -c defaults
```

### Issue Description

Sorry if this issue is in the wrong place! It seems there were previously conda-forge packages for linux-64 up to python v3.13 but the latest package only has v3.9:

![Image](https://github.com/user-attachments/assets/ba6daf88-d266-40c5-b559-9df0170ca135)

https://anaconda.org/conda-forge/pandas/files

What this means is that installing pandas via the example above chooses to install python 3.9 unless the user selects a newer version of python, which is probably suboptimal?

![Image](https://github.com/user-attachments/assets/9ccc86ce-599c-462d-8513-12a2bc7f8012)

Thanks for your consideration!

### Expected Behavior

Conda-forge packages for all supported versions of python released at the same time?

### Installed Versions

```python
>>> pd.show_versions()                                                                                                                                        [11/1762]
                                         
INSTALLED VERSIONS          
------------------          
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.9.21
python-bits           : 64  
OS                    : Linux
OS-release            : 6.1.119-129.201.amzn2023.x86_64
Version               : #1 SMP PREEMPT_DYNAMIC Tue Dec  3 21:07:35 UTC 2024
machine               : x86_64
processor             :     
byteorder             : little
LC_ALL                : C.UTF-8
LANG                  : C.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 2.0.2
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 25.0
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : None
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : None
```","['Bug', 'Build']",,2025-01-27 23:33:33+00:00,2025-01-30 21:10:38+00:00,,2.900752314814815
60802,"DOC: Specify what ""non-null"" means in DataFrame.info()","### Pandas version checks

- [x] I have checked that the issue still exists on the latest versions of the docs on `main` [here](https://pandas.pydata.org/docs/dev/)


### Location of the documentation

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html

### Documentation problem

Non-null is not specific

### Suggested fix for documentation

Link to documentation or specify exactly what non-null means. In particular, for float64s NaN are considered ""null"". And does it also represent NULLs in the Nullable integer types? https://pandas.pydata.org/docs/user_guide/integer_na.html

Pandas is not consistent with its terminology of NA, NULL, and NaN. 
NaN is a floating point value that is not in the IEEE standard as a missing value.
R uses NA consistently and SQL uses NULL consistently in 3VL. ","['Docs', 'Missing-data']","{'login': 'KevsterAmp', 'id': 109636487, 'node_id': 'U_kgDOBojrhw', 'avatar_url': 'https://avatars.githubusercontent.com/u/109636487?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/KevsterAmp', 'html_url': 'https://github.com/KevsterAmp', 'followers_url': 'https://api.github.com/users/KevsterAmp/followers', 'following_url': 'https://api.github.com/users/KevsterAmp/following{/other_user}', 'gists_url': 'https://api.github.com/users/KevsterAmp/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/KevsterAmp/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/KevsterAmp/subscriptions', 'organizations_url': 'https://api.github.com/users/KevsterAmp/orgs', 'repos_url': 'https://api.github.com/users/KevsterAmp/repos', 'events_url': 'https://api.github.com/users/KevsterAmp/events{/privacy}', 'received_events_url': 'https://api.github.com/users/KevsterAmp/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}",2025-01-27 22:18:02+00:00,2025-04-10 16:04:04+00:00,KevsterAmp,72.74030092592592
60800,BUG: Cannot connect to odoo,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
pd.test()
```

### Issue Description

I found an error in pandas, after I installed it I couldn't connect it to one of the modules in odoo. I then checked it and I found some small modules in pandas that were Fatal Error, so I tested the pandas module and the results were like this
""725 failed, 171537 passed, 25922 skipped, 3935 deselected, 1003 xfailed, 77 xpassed, 3 warnings, 729 errors""

### Expected Behavior

I'm just a regular user but I understand enough about modules like this, sorry I can't give a clear answer

### Installed Versions

<details>

Replace this line with the output of pd.show_versions()

</details>
","['Bug', 'Needs Info', 'Closing Candidate']",,2025-01-27 14:26:06+00:00,2025-07-23 09:20:44+00:00,,176.78793981481482
60799,TST: Add test for exceptional behavior when calling `view()` on `BaseStringArray`,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [x] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This PR introduces additional tests for the view method of BaseStringArray, which was recently added in PR [#60713](https://github.com/pandas-dev/pandas/pull/60713). The existing test suite did not cover this method, as shown in the coverage reports below. (I also run the entire test suite locally and double checked that the line is not covered).

To verify the tests, you can run:
```bash
cd tooling/
pytest --cov=$PWD/../pandas/core/arrays/ --cov-report=xml ../pandas/tests/indexes/test_base.py::TestIndex
```
Note: Currently, running pytest from the root directory is resulting in an error in the coverage collection (regardless of which test). If you have any suggestions on how to resolve this issue, please let me know.

This PR aims to ensure that the `view` method is thoroughly tested and meets the pandas testing standards. Your feedback and suggestions are welcome.

## Coverage Before
![test_pr_60713_coverage_before_anonymized](https://github.com/user-attachments/assets/4cfa79e5-9451-432f-b177-8dc966ff6d4e)


## Coverage After
![test_pr_60713_coverage_after_anonymized](https://github.com/user-attachments/assets/98c8ca7a-dfe3-4680-b153-b5d8d57c4b52)


Thanks in advance, let me know if you need any more input from my side

",['Testing'],,2025-01-27 13:49:34+00:00,2025-01-27 23:29:37+00:00,,0.4028125
60798,"BUG: replace(to_replace=pd.NaT, value=None) different from replace({pd.NaT: None})","### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
df = pd.read_pickle(""example.pkl"")

df
                        ts               Start                 End
23 2025-01-27 09:49:44.045 2025-01-27 09:49:44                 NaT
28 2025-01-27 06:50:56.046 2025-01-27 06:50:54 2025-01-27 06:50:56


df.replace(to_replace=pd.NaT, value=None)
                        ts               Start                 End
23 2025-01-27 09:49:44.045 2025-01-27 09:49:44                 NaT
28 2025-01-27 06:50:56.046 2025-01-27 06:50:54 2025-01-27 06:50:56

df.replace({pd.NaT: None})
                            ts                Start                  End
23  2025-01-27 09:49:44.045000  2025-01-27 09:49:44                 None
28  2025-01-27 06:50:56.046000  2025-01-27 06:50:54  2025-01-27 06:50:56

df.replace(to_replace=pd.NaT, value=None).dtypes
ts       datetime64[ns]
Start    datetime64[ns]
End      datetime64[ns]
dtype: object

df.replace({pd.NaT: None}).dtypes
ts       object
Start    object
End      object
dtype: object
```

### Issue Description

In my application I read data from a database via asyncpg and then process it with pandas.
Recently I encountered an issue where the replace command changes the datatypes of unrelated columns if I use it with a dictionary argument. 
Using replace with the arguments ""to_replace"" and ""value"", however, works. 

Somehow my dataframe is weird, I was not able to create a pure code example to reproduce this and only saving and loading my dataframe as a pickle file made it reproducible. However, due to GitHub limitations I cannot share the pickle file here which is probably due to pickle files being unsafe to unpickle from untrusted sources.
I did try to recreate the issue in code and also using other file formats but that somhow seems to loose important metadata that causes the issue.


This is the metadata of the dataframe as it shows in the VS-code debugger:
![Image](https://github.com/user-attachments/assets/f85d4906-04ef-46d9-95c8-f4df75e2aa48)

### Expected Behavior

I would expect that these two results are the same:

`df.replace(to_replace=pd.NaT, value=None).dtypes`
`df.replace({pd.NaT: None}).dtypes`

### Installed Versions

<details>

INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.12.5
python-bits           : 64
OS                    : Linux
OS-release            : 5.15.167.4-microsoft-standard-WSL2
Version               : #1 SMP Tue Nov 5 00:21:55 UTC 2024
machine               : x86_64
processor             : 
byteorder             : little
LC_ALL                : None
LANG                  : C.UTF-8
LOCALE                : C.UTF-8

pandas                : 2.2.3
numpy                 : 2.2.0
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : None
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : None
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : None
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : None
pyreadstat            : None
pytest                : 8.3.4
python-calamine       : None
pyxlsb                : None
s3fs                  : None
scipy                 : 1.14.1
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None

</details>
","['Bug', 'Duplicate Report', 'replace']",,2025-01-27 12:58:16+00:00,2025-01-27 21:35:33+00:00,,0.35922453703703705
60797,API: ignore empty range/object dtype in Index setop operations (string dtype compat),"Exploring one option to address https://github.com/pandas-dev/pandas/issues/60338

This makes that inserting/union etc with an empty RangeIndex or empty Index with object dtype (the types of index that get created for empty objects by default), ignores the dtype of that empty index.  
This improves the workflow of creating an empty dataframe and adding columns or resetting the index (you can see the removed xfails). Also most of the test changes are changes that are essentially reverting previous edits (typically adding an explicit `dtype=object`) to get the tests passing for infer_string, and I think almost all those test changes show a better behaviour now.



I still want to add some explicit tests for the original use case (although everything is implicitly already covered in other tests, I think)","['Strings', 'Index', 'setops']",,2025-01-26 14:10:59+00:00,2025-02-17 09:15:42+00:00,,21.79494212962963
60796,BUG: is_*_array returns true on empty object dtype,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Want this in 2.3 for #60795.
","['Bug', 'Internals']",,2025-01-26 14:03:17+00:00,2025-01-28 06:59:07+00:00,,1.7054398148148149
60795,TST(string dtype): Resolve xfails in pytables,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

Looks like using `where` that results in empty will still give object dtype. xfailing those tests here and plan to tackle in a followup.","['Testing', 'IO HDF5', 'Strings']",,2025-01-26 13:23:32+00:00,2025-02-10 14:23:53+00:00,,15.041909722222222
60794,BUG: Bug in mask method when handling pd.NA with Int64Dtype,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd
from pandas import Series
from pandas.api.extensions import Int64Dtype
series = Series([None, 1, 2, None, 3, 4, None], dtype=Int64Dtype())
result = series.mask(series <= 2, -99)
print(result)
```

### Issue Description

I am encountering an issue with the mask method in pandas when it is used with a Series of type Int64Dtype. Specifically, when trying to mask pd.NA values, they are being replaced, which is not the expected behavior. I expected the pd.NA values to remain unchanged, but they are being incorrectly filled.

### Expected Behavior

Series([None, -99, -99, None, 3, 4, None], dtype=Int64Dtype())

### Installed Versions

python: 3.11.1
pandas: 2.1.3
","['Bug', 'Duplicate Report', 'NA - MaskedArrays']",,2025-01-26 11:53:00+00:00,2025-01-27 21:36:27+00:00,,1.405173611111111
60793,"[backport 2.3.x] BUG: fix construction of Series / Index from dict keys when ""str"" dtype is specified explicitly (#60436)","(cherry picked from commit 84bf1ef82912ebf497a304b0ffd90914bfc41ea9)

Backport of https://github.com/pandas-dev/pandas/pull/60436",[],,2025-01-26 11:32:04+00:00,2025-01-26 13:50:38+00:00,,0.09622685185185186
60792,[2.3.x] DEPS: Drop Python 3.9,Selective backport of https://github.com/pandas-dev/pandas/pull/58238 to drop Python 3.9 support for the 2.3.0 release,"['CI', 'Dependencies']",,2025-01-26 10:03:01+00:00,2025-01-26 18:08:31+00:00,,0.3371527777777778
60791,BUG: fix combine_first reorders columns,"I changed an old test for the correct order of columns.

~~Note that the fix can also be done in `combine`, if it is preferred to be fixed there, since `combine_first` calls `combine`.~~

With my previous fix, a test in ""Future infer strings"" failed, which is the corner case when `self` is an empty dataframe. I then made the fix in `combine`.

- [x] closes #60427 (Replace xxxx with the GitHub issue number)
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Reshaping'],,2025-01-26 09:20:02+00:00,2025-01-27 20:54:25+00:00,,1.482210648148148
60790,[backport 2.3.x] CI: Remove CircleCI in favor of GHA ARM builds (#60761),"(cherry picked from commit f3045db91dbb89306c15b1673987cc70912a76b5)

Backport of https://github.com/pandas-dev/pandas/pull/60761",[],,2025-01-26 08:47:30+00:00,2025-01-26 09:52:45+00:00,,0.0453125
60789,TST(string dtype): Resolve pytable xfails,"- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

",[],,2025-01-26 03:27:56+00:00,2025-01-26 13:18:57+00:00,,0.41042824074074075
60788,this is for github training,"this is for github training
",[],,2025-01-25 17:34:18+00:00,2025-01-25 18:03:42+00:00,,0.020416666666666666
60787,DOC: Update a link in tutorials.rst,"DOC: Update a link in tutorials.rst

Statistical Data Analysis in Python, tutorial by Christopher Fonnesbeck from SciPy 2013

New link: https://github.com/fonnesbeck/statistical-analysis-python-tutorial

The old link does not work.
https://conference.scipy.org/scipy2013/tutorial_detail.php?id=109

- [ ] closes #xxxx (Replace xxxx with the GitHub issue number)
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.
",['Docs'],,2025-01-25 05:28:00+00:00,2025-01-25 17:00:26+00:00,,0.48085648148148147
60786,ENH: generic `save` and `read` methods for DataFrame,"### Feature Type

- [x] Adding new functionality to pandas

- [ ] Changing existing functionality in pandas

- [ ] Removing existing functionality in pandas


### Problem Description

Currently, pandas has separate IO methods for each file format (to_csv, read_parquet, etc.). This requires users to:
- Remember multiple method names
- Change code when switching formats

### Feature Description

A unified `save`/`read` API would simplify common IO operations while maintaining explicit control when needed:
- File type is inferred from the filepath extension, but a `format` arg can be passed to be explicit, raising an error in some cases where the inferred file type disagrees with passed file type.
- Both methods accept `**kwargs` and pass them along to the underlying file-type-specific pandas IO methods. 
- Optionally, support some basic translation across discrepancies in arg names in existing IO methods (i.e. ""usecols"" in `read_csv` vs ""columns"" in `read_parquet`).

```
# Simplest happy path:
df.save('data.csv')  # Uses to_csv
df = pd.read('data.parquet')  # Uses read_parquet

# Optionally, be explicit about expected file type
df.save('data.csv', format=""csv"")  # Uses to_csv
df = pd.read('data.parquet', format=""parquet"")  # Uses read_parquet

# Raises ValueError for conflicting format info:
df.save('data.csv', format='parquet')  # Conflicting types
df.save('data.txt', format='csv')  # .txt implies text format

# Reading allows overrides for misnamed files (or should we require users to rename their files properly first?)
df = pd.read('mislabeled.txt', format='parquet')

# Not sure if we should allow save when inferred file type is not a standard type:
df.save('data', format='csv')  # No extension, needs type
df.save('mydata.unknown', format='csv')  # Unclear extension
```


### Alternative Solutions

Existing functionality is OK, just not the simplest to use.

### Additional Context

_No response_","['Enhancement', 'IO Data', 'Needs Discussion', 'Closing Candidate']",,2025-01-25 01:18:47+00:00,2025-08-05 16:20:37+00:00,,192.62627314814816
60785,Backport PR #60784 on branch 2.3.x (TST(string_dtype): Fix minor issue with CSV parser and column dtype),Backport PR #60784: TST(string_dtype): Fix minor issue with CSV parser and column dtype,"['Testing', 'Strings']",,2025-01-24 23:16:43+00:00,2025-01-25 03:15:21+00:00,,0.16571759259259258
60784,TST(string_dtype): Fix minor issue with CSV parser and column dtype,,"['Testing', 'Strings']",,2025-01-24 22:20:07+00:00,2025-01-24 23:16:18+00:00,,0.039016203703703706
60783,Update boxplot.py,"Refactored the code to improve type hinting compatibility  across several functions:
- replaced the | operator with Union for Python versions before 3.10
- added more detailed error messages
- improved logging for edge cases
- redundant logic is simplified, and handling for empty arrays and invalid color arguments",[],,2025-01-24 21:55:26+00:00,2025-02-18 17:42:30+00:00,,24.82435185185185
60782,Backport PR #60711: TST(string dtype): Resolve xfail in groupby.test_‚Ä¶,Backport of https://github.com/pandas-dev/pandas/pull/60711,[],,2025-01-24 20:43:42+00:00,2025-01-24 21:43:06+00:00,,0.04125
60781,[backport 2.3.x] TST(string dtype): Fix xfails in test_block_internals.py (#60765),"(cherry picked from commit d38706af66249ef74e42671a480261c68bedfbce)

Backport of https://github.com/pandas-dev/pandas/pull/60765",[],,2025-01-24 20:29:46+00:00,2025-01-24 21:42:33+00:00,,0.05054398148148148
60780,[backport 2.3.x] CI: Test Github Actions Arm64 Runners (#60722),"(cherry picked from commit b98336653128790661d4c66d398f3e44d481dd3b)

Backport of https://github.com/pandas-dev/pandas/pull/60722",[],,2025-01-24 20:26:57+00:00,2025-01-24 22:09:18+00:00,,0.07107638888888888
60779,BUG: pd.read_csv Incorrect Checksum validation for COMPOSITE Checksum,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import base64
import zlib

import awswrangler as wr
import boto3
import pandas as pd

# DL DEV
AWS_ACCESS_KEY_ID = <Redacted>
AWS_SECRET_ACCESS_KEY = <Redacted>
AWS_SESSION_TOKEN = <Redacted>
session_west = boto3.Session(
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
    aws_session_token=AWS_SESSION_TOKEN,
    region_name=""eu-west-1"",
)

client = session_west.client(""s3"")
localpath = <Redacted>
bigfile = ""bigfile.csv""
smallfile = ""smallfile.csv""
bucket = ""checksum-test-bucket""
s3path = ""checksum-test""

for filetype in [smallfile, bigfile]:
    with open(f""{localpath}{filetype}"", ""rb"") as file:

        # Calculate CRC32 ourselves for reference
        crcval = zlib.crc32(file.read())
        crc_bytes = crcval.to_bytes(4, ""big"")
        crc = base64.b64encode(crc_bytes).decode(""utf-8"")
        print(f""{filetype} - {crc}"")

    with open(f""{localpath}{filetype}"", ""rb"") as file:

        client.put_object(
            Bucket=bucket, Key=f""{s3path}/put_object/{filetype}"", Body=file
        )

    client.upload_file(
        Bucket=bucket,
        Key=f""{s3path}/upload_file/{filetype}"",
        Filename=f""{localpath}{filetype}"",
    )

for filetype in [smallfile, bigfile]:
    for upload_method in [""put_object"", ""upload_file""]:

        path = f""s3://{bucket}/{s3path}/{upload_method}/{filetype}""
        print(path)
        try:
            fw: pd.DataFrame = wr.s3.read_csv(
                path=path,
                dtype=""object"",
                boto3_session=session_west,
            )
            print(fw.shape)
        except Exception as e:
            print(f""wrangler failed - {e}"")

        try:
            fp = pd.read_csv(
                path,
                storage_options={
                    ""key"": AWS_ACCESS_KEY_ID,
                    ""secret"": AWS_SECRET_ACCESS_KEY,
                    ""token"": AWS_SESSION_TOKEN,
                },
            )
            print(fp.shape)
        except Exception as e:
            print(f""Pandas fail - {e}"")

        try:
            client = session_west.client(""s3"")
            fb = client.get_object(
                Bucket=bucket,
                Key=f""{s3path}/{upload_method}/{filetype}"",
                ChecksumMode=""ENABLED"",
            )
            print(f'{fb[""ChecksumCRC32""]} - {fb[""ChecksumType""]}')
        except Exception as e:
            print(f""boto error - {e}"")
```

### Issue Description

Boto3 >=1.36.0 has modified behaviour to add CRC32 checksum by default where supported.

When accessing s3 objects with pd.read_csv any s3 object that has created a COMPOSITE checksum fails reading as the checksum compared against is the FULL_OBJECT checksum. 
Composite checksum appears to be calculated when an object exceeds ~10Mb when using boto3 upload_file(), seemingly it switches to a multi-part upload behind the scenes at that threshold. Other explicit multi-part uploads will presumably have the same behaviour.

Included test using both Pandas and Awswrangler for completeness

Output for failing versions
```pip show boto3 botocore s3transfer pandas awswrangler| egrep 'Name:|Version:'
Name: boto3
Version: 1.36.5
Name: botocore
Version: 1.36.5
Name: s3transfer
Version: 0.11.2
Name: pandas
Version: 2.2.3
Name: awswrangler
Version: 3.11.0


smallfile.csv - CbsfmA==
bigfile.csv - vGPIeA==
s3://checksum-test-bucket/checksum-test/put_object/smallfile.csv
(1461, 91)
(1461, 91)
CbsfmA== - FULL_OBJECT
s3://checksum-test-bucket/checksum-test/upload_file/smallfile.csv
(1461, 91)
(1461, 91)
CbsfmA== - FULL_OBJECT
s3://checksum-test-bucket/checksum-test/put_object/bigfile.csv
(20467, 91)
(20467, 91)
vGPIeA== - FULL_OBJECT
s3://checksum-test-bucket/checksum-test/upload_file/bigfile.csv
wrangler failed - Expected checksum DIoExg== did not match calculated checksum: vGPIeA==
Pandas fail - Expected checksum DIoExg== did not match calculated checksum: vGPIeA==
DIoExg==-2 - COMPOSITE
```

Using boto3 <1.36 all scenarios from the example code work

Test with older version
```pip install ""boto3<1.36.0""	```

Output from working version
```show boto3 botocore s3transfer pandas awswrangler| egrep 'Name:|Version:'
Name: boto3
Version: 1.35.99
Name: botocore
Version: 1.35.99
Name: s3transfer
Version: 0.10.4
Name: pandas
Version: 2.2.3
Name: awswrangler
Version: 3.11.0


smallfile.csv - CbsfmA==
bigfile.csv - vGPIeA==
s3://checksum-test-bucket/checksum-test/put_object/smallfile.csv
(1461, 91)
(1461, 91)
None - None
s3://checksum-test-bucket/checksum-test/upload_file/smallfile.csv
(1461, 91)
(1461, 91)
None - None
s3://checksum-test-bucket/checksum-test/put_object/bigfile.csv
(20467, 91)
(20467, 91)
None - None
s3://checksum-test-bucket/checksum-test/upload_file/bigfile.csv
(20467, 91)
(20467, 91)
None - None```


### Expected Behavior

When reading using pd.read_csv the checksum calculated for comparison should be aware of whether the stored checksum is FULL_OBJECT or COMPOSITE and handle it correctly. 



### Installed Versions

<details>

Working versions
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.11
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-1021-aws
Version               : #23~22.04.1-Ubuntu SMP Tue Dec 10 16:50:46 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.utf8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.12.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 16.0.0
pyreadstat            : None
pytest                : 8.2.0
python-calamine       : None
pyxlsb                : None
s3fs                  : 2024.12.0
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.1
qtpy                  : None
pyqt5                 : None
None

Failing versions
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.11
python-bits           : 64
OS                    : Linux
OS-release            : 6.8.0-1021-aws
Version               : #23~22.04.1-Ubuntu SMP Tue Dec 10 16:50:46 UTC 2024
machine               : x86_64
processor             : x86_64
byteorder             : little
LC_ALL                : None
LANG                  : en_US.utf8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.26.4
pytz                  : 2024.1
dateutil              : 2.9.0.post0
pip                   : 24.3.1
Cython                : None
sphinx                : None
IPython               : None
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : None
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2024.12.0
html5lib              : None
hypothesis            : None
gcsfs                 : None
jinja2                : 3.1.4
lxml.etree            : None
matplotlib            : None
numba                 : None
numexpr               : None
odfpy                 : None
openpyxl              : None
pandas_gbq            : None
psycopg2              : None
pymysql               : None
pyarrow               : 16.0.0
pyreadstat            : None
pytest                : 8.2.0
python-calamine       : None
pyxlsb                : None
s3fs                  : 2024.12.0
scipy                 : None
sqlalchemy            : None
tables                : None
tabulate              : None
xarray                : None
xlrd                  : None
xlsxwriter            : None
zstandard             : None
tzdata                : 2024.1
qtpy                  : None
pyqt5                 : None
None
</details>
","['Bug', 'IO CSV', 'IO Network', 'Needs Triage']",,2025-01-24 11:48:54+00:00,2025-01-27 12:34:43+00:00,,3.0318171296296295
60778,PERF: Avoid a numpy array copy in ArrowExtensionArray._to_datetimearray,We shouldn't need to copy from the `astype` when converting a `ArrowExtensionArray` to a `DatetimeArray` or `TimedeltaArray`,"['Performance', 'Arrow']",,2025-01-23 20:50:16+00:00,2025-01-24 18:04:43+00:00,,0.8850347222222222
60777,Fix arrow groupby na,"- [x] closes #60567 
- [x] Tests added and passed
- [x] All code checks passed
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [x] Added an entry in the latest `doc/source/whatsnew/v3.0.0.rst` file for the bug fix.
",['Arrow'],,2025-01-23 19:49:29+00:00,2025-02-24 23:29:40+00:00,,32.15290509259259
60776,DOC: fix SA01 for pandas.tseries.offsets.LastWeekOfMonth,"fixes

```
pandas.tseries.offsets.LastWeekOfMonth SA01
```",['Docs'],,2025-01-23 17:51:27+00:00,2025-01-23 18:53:55+00:00,,0.04337962962962963
60775,"DOC: fix ES01,SA01 for pandas.tseries.offsets.CustomBusinessMonthEnd.‚Ä¶","fixes

```
pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset ES01,SA01
pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset ES01,SA01
```",['Docs'],,2025-01-23 17:29:57+00:00,2025-01-23 18:19:45+00:00,,0.034583333333333334
60773,BUG: datetime64 column has incorrect unit when created with pd.Timestamp ,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
ts_list = [""2021-01-01 00:00:00"", ""2021-01-01 00:00:01"", ""2021-01-01 00:00:02""]
df = pd.DataFrame(
    {
        ""ts1"": [pd.Timestamp(ts) for ts in ts_list],
        ""ts2"": pd.to_datetime(ts_list),
    }
).assign(
    ts3=pd.Timestamp(ts_list[0]),
    ts4=pd.Timestamp(ts_list[0], unit=""ns""),
    ts5=pd.to_datetime(ts_list[0]),
)
```

### Issue Description

Then

```
df.dtypes
```

gives 

```
ts1    datetime64[ns]
ts2    datetime64[ns]
ts3     datetime64[s]
ts4     datetime64[s]
ts5    datetime64[ns]
dtype: object
```

### Expected Behavior

I would expect the above to output 

```
ts1    datetime64[ns]
ts2    datetime64[ns]
ts3     datetime64[ns]
ts4     datetime64[ns]
ts5    datetime64[ns]
dtype: object
```

### Installed Versions

<details>

```
INSTALLED VERSIONS
------------------
commit                : 0691c5cf90477d3503834d983f69350f250a6ff7
python                : 3.11.10
python-bits           : 64
OS                    : Darwin
OS-release            : 24.2.0
Version               : Darwin Kernel Version 24.2.0: Fri Dec  6 19:02:41 PST 2024; root:xnu-11215.61.5~2/RELEASE_ARM64_T6030
machine               : arm64
processor             : arm
byteorder             : little
LC_ALL                : en_US.UTF-8
LANG                  : en_US.UTF-8
LOCALE                : en_US.UTF-8

pandas                : 2.2.3
numpy                 : 1.24.4
pytz                  : 2024.2
dateutil              : 2.9.0.post0
pip                   : 24.2
Cython                : 3.0.11
sphinx                : None
IPython               : 8.31.0
adbc-driver-postgresql: None
adbc-driver-sqlite    : None
bs4                   : 4.12.3
blosc                 : None
bottleneck            : 1.3.7
dataframe-api-compat  : None
fastparquet           : None
fsspec                : 2023.12.2
html5lib              : 1.1
hypothesis            : 6.123.17
gcsfs                 : None
jinja2                : 3.1.5
lxml.etree            : 5.3.0
matplotlib            : 3.8.4
numba                 : 0.60.0
numexpr               : 2.10.2
odfpy                 : None
openpyxl              : 3.1.5
pandas_gbq            : None
psycopg2              : 2.9.10
pymysql               : None
pyarrow               : 16.1.0
pyreadstat            : None
pytest                : 7.4.4
python-calamine       : None
pyxlsb                : None
s3fs                  : 2023.12.2
scipy                 : 1.13.0
sqlalchemy            : 2.0.36
tables                : 3.9.2
tabulate              : 0.9.0
xarray                : 2025.1.1
xlrd                  : 2.0.1
xlsxwriter            : 3.2.0
zstandard             : 0.23.0
tzdata                : 2024.2
qtpy                  : None
pyqt5                 : None
```

</details>
","['Bug', 'Needs Triage']",,2025-01-23 13:04:34+00:00,2025-01-23 21:00:55+00:00,,0.3307986111111111
60771,[backport 2.3.x] ENH: Enable pytables to round-trip with StringDtype (#60663),"(cherry picked from commit 60325b86e28edf40cb02444367efbc8deb2b5231)

Backport of https://github.com/pandas-dev/pandas/pull/60663",['Strings'],,2025-01-23 07:45:03+00:00,2025-01-23 16:11:32+00:00,,0.35172453703703704
60770,BUG: arrow backend get wrong result,"### Pandas version checks

- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [x] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
### Describe the bug, including details regarding any error messages, version, and platform.

when pandas has a null columnÔºåcompare will get a FalseÔºå

import duckdb as dd
df=dd.sql(""select null as id"").df()
df['id']>1

0    False
Name: id, dtype: bool

but change to arrow, will get NA, how to get False?

import pyarrow as pa
import pandas as pd
df2=pa.Table.from_pandas(df).to_pandas(types_mapper=pd.ArrowDtype,use_threads=True)
df2['id']>1

0    <NA>
Name: id, dtype: bool[pyarrow]

### Component(s)

Python
```

### Issue Description

pandas2.2.3Ôºåuse arrow backendÔºå
got NAÔºåneed FalseÔºå
how to got same resultÔºü

### Expected Behavior

df['id']>1Ôºåwant return False

### Installed Versions

pandas2.2.3
","['Bug', 'Missing-data', 'Arrow']",,2025-01-23 07:37:39+00:00,2025-01-25 02:11:56+00:00,,1.7738078703703704
60769,BUG: value_counts() method in panda Series,"### Pandas version checks

- [ ] I have checked that this issue has not already been reported.

- [ ] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.

- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.


### Reproducible Example

```python
import pandas as pd

s = pd.Series([3, 1, 2, 3, 4, np.nan])
s.value_counts(normalize=True)
```

### Issue Description

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[737], [line 1](vscode-notebook-cell:?execution_count=737&line=1)
----> [1](vscode-notebook-cell:?execution_count=737&line=1) s = pd.Series([3, 1, 2, 3, 4, np.nan])
      [2](vscode-notebook-cell:?execution_count=737&line=2) s.value_counts(normalize=True)

TypeError: 'Index' object is not callable

### Expected Behavior

Must create a series and count the unique values

### Installed Versions

","['Bug', 'Needs Triage']",,2025-01-23 03:44:51+00:00,2025-01-23 03:55:53+00:00,,0.007662037037037037
60765,TST(string dtype): Fix xfails in test_block_internals.py,,['Strings'],,2025-01-22 21:54:09+00:00,2025-01-24 20:21:29+00:00,,1.9356481481481482
60764,TST (string dtype): follow-up fix for pyarrow 19.0 update,"Small follow-up on https://github.com/pandas-dev/pandas/pull/60716. This change is already included in the backport PR https://github.com/pandas-dev/pandas/pull/60755, so targeting 3.0 here (on 2.3.x this was needed because there for some reason more jobs were already using pyarrow 19.0)","['Testing', 'Strings', 'IO Parquet']",,2025-01-22 21:14:26+00:00,2025-01-23 16:03:46+00:00,,0.7842592592592592
60763,[backport 2.3.x] API(str dtype): Raise on StringDtype for unary op + (#60710),"(cherry picked from commit 1bb264c443f6be64ac28ff9afc0341eed0bcc455)

Backport of https://github.com/pandas-dev/pandas/pull/60710",['Strings'],,2025-01-22 20:26:46+00:00,2025-01-22 21:23:21+00:00,,0.03929398148148148
60762,CI: Update some CI configurations,"* Bumps mysql/postgres/moto container services
* Makes musl and 32 bit jobs run on Python 3.13
* Bumps musl container image (previous one was EOL last year)
* Consolidates some `pip install`s",['CI'],,2025-01-22 19:25:54+00:00,2025-02-03 18:08:43+00:00,,11.946400462962963
60761,CI: Remove CircleCI in favor of GHA ARM builds,"After https://github.com/pandas-dev/pandas/pull/60722, our unit test and wheel builds work successfully on GHA ARM runners. Additionally, now we're successfully uploading nightly ARM wheels to https://anaconda.org/scientific-python-nightly-wheels/pandas/files. Therefore, we can remove CircleCI from our CI",['CI'],,2025-01-22 18:56:39+00:00,2025-01-26 08:44:11+00:00,,3.5746759259259258
60760,Backport PR #60718 on branch 2.3.x (DOC: Whatsnew for sorting mode result),Backport PR #60718: DOC: Whatsnew for sorting mode result,['Docs'],,2025-01-22 17:54:14+00:00,2025-01-22 18:34:59+00:00,,0.02829861111111111
60759,"DOC: fix RT03,SA01 for pandas.plotting.andrews_curves","fixes

```
pandas.plotting.andrews_curves RT03,SA01
```",['Docs'],,2025-01-22 16:56:56+00:00,2025-01-22 17:39:36+00:00,,0.02962962962962963
60758,ENH: Add JupyterLite-powered shell for the website (reprise of #47428),"- [x] closes #60747
- [ ] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [ ] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.
- [ ] Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.

This pull request aims to reinstate the machinery for adding a JupyterLite shell for the `pandas` website, based on discussions in #60747 and on Slack, please see them for a rationale on this change (short answer: it's been a while in 2025 and things might be smoother now).

An interactive shell was first discussed in #46682 and later removed in #49807. There was a request to reinstate this in https://github.com/pandas-dev/pandas/pull/49807#issuecomment-1361430698 which might not have been noticed, so I hope #60747 and this PR bring more visibility to the proposal.

In particular, this PR adds back the previous changes from #47428, with only minor differences in the configuration. I've used (and pinned) the `jupyterlite-pyodide-kernel` for the REPL, which in-turn provides Pyodide version 0.5.2, which comes with `pandas` version 2.2.3.

The differences in the changes from the previous PR are as follows:
- newer versions of JupyterLite and `jupyterlite-pyodide-kernel` have been incorporated, i.e., 0.5.0 and 0.5.2 respectively
- source maps have been disabled when building JuptyerLite, which should reduce the size of static assets significantly and allow for faster load times
- the word ""Experimental"" has been added to the REPL's Markdown heading to indicate it as such

As mentioned in #60747, it is also possible to use the https://jupyterlite.github.io/demo/ REPL in the iframe to remove dependencies, however, it would come at the cost of disabled optimisations and a general lack of control for how the REPL is built.

cc: @jtpio, please feel free to add any suggestions!","['Enhancement', 'Web']",,2025-01-22 14:57:51+00:00,2025-03-04 01:25:35+00:00,,40.43592592592593
60757,"DOC: fix PR07,SA01 for pandas.arrays.TimedeltaArray","fixes

```
pandas.arrays.TimedeltaArray PR07,SA01
```",['Docs'],,2025-01-22 14:48:59+00:00,2025-01-22 17:38:57+00:00,,0.1180324074074074
60756,Miscellaneous updates for Pyodide 0.27: bump WASM CI and revise Arrow compatibility note,"- [ ] ~closes #xxxx (Replace xxxx with the GitHub issue number)~
- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature
- [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).
- [ ] ~Added [type annotations](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#type-hints) to new arguments/methods/functions.~
- [ ] ~Added an entry in the latest `doc/source/whatsnew/vX.X.X.rst` file if fixing a bug or adding a new feature.~

I noticed via #60747 that the Pyodide CI job for `pandas` in `unit-tests.yml` is still using a version of Pyodide[^1] that is quite old by this point; we no longer support it, as we have recently released Pyodide 0.27 this January (https://github.com/pyodide/pyodide/releases/tag/0.27.1). On the other hand, `cibuildwheel` in `wheels.yml` builds against Pyodide 0.26 at the moment.

Other notes around the changes here:
- we unvendored `pyodide-build` from the Pyodide runtime/repository, so its version does not stay in sync with the Pyodide runtime version.
- the Node.js version has been bumped to 20, though 22 should work, too.
- the Pyodide cross-build environment folder has been added to the `.gitignore` file
- PyArrow is now [supported](https://github.com/joemarshall/pyarrow-pyodide/) in Pyodide/WASM ([docs on compilation](https://arrow.apache.org/docs/developers/cpp/emscripten.html)), and I've updated the PDEP-10 document here to remove the point surrounding its previous unavailability in Pyodide/PyScript/other WASM environments.
- I removed an expected failure case in `TestCoercionFloat32.test_setitem` that now xpasses with Emscripten 3.1.58.

Please let me know if you want me to split any of the changes to a different PR. Thank you!

[^1]: I have plans in mind to make these upgrades more seamless via https://github.com/pyodide/pyodide-actions/issues/12 by letting Dependabot do such a job, but I haven't got around to sitting down and spending a bit of time doing so.","['Testing', 'CI']",,2025-01-22 10:54:47+00:00,2025-01-22 17:58:56+00:00,,0.29454861111111114
60755,[backport 2.3.x] Update PyArrow conversion and arrow/parquet tests for pyarrow 19.0 (#60716),"(cherry picked from commit 5efac8250787414ec580f0472e2b563032ec7d53)

Backport of https://github.com/pandas-dev/pandas/pull/60716",[],,2025-01-22 10:23:40+00:00,2025-01-22 14:30:16+00:00,,0.17125
